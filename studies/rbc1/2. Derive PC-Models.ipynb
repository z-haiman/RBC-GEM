{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3208d0-39f0-4d23-8d86-6de6fa19fd8b",
   "metadata": {},
   "source": [
    "# Create Proteome-Constrained RBC model via OVERLAY workflow \n",
    "This notebook facilitates the construction of a proteome constrained model (\"pcModel\") via the OVERLAY methodology.\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968a45f-c732-43c5-bfc4-1114f8d8cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    GEM_NAME,\n",
    "    build_string,\n",
    "    get_annotation_df,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    split_string,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    ATTR_SUBCLASS_DICT,\n",
    "    DEFAULT_COMPARTMENT_CONSTRAINT_PREFIX,\n",
    "    DEFAULT_CONCENTRATION_BOUND,\n",
    "    DEFAULT_CONSTRAINT_PREFIX,\n",
    "    DEFAULT_ENZYME_FORWARD_SUFFIX,\n",
    "    DEFAULT_ENZYME_REVERSE_SUFFIX,\n",
    "    DEFAULT_ENZYME_TOTAL_SUFFIX,\n",
    "    DEFAULT_ISOFORM_CONSTRAINT_PREFIX,\n",
    "    DEFAULT_KEFF,\n",
    "    Enzyme,\n",
    "    EnzymeDilution,\n",
    "    Protein,\n",
    "    ProteinDilution,\n",
    "    ProteomeBudget,\n",
    "    ProteomeBudgetDilution,\n",
    "    add_relaxation_budget,\n",
    "    construct_pcmodel_from_tables,\n",
    "    create_complex_table,\n",
    "    create_enzyme_table,\n",
    "    create_protein_table,\n",
    "    create_sequence_table,\n",
    ")\n",
    "from rbc_gem_utils.util import strip_plural\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c19f01-8e9f-448e-bcbb-64fb84358e1b",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d822cd-8d55-40c1-81d3-34165bf0f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "COBRA_CONFIGURATION.bounds = (-1e3, 1e3)\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae972b5d-74b6-4530-a55f-14b45fefd4c6",
   "metadata": {},
   "source": [
    "## Load RBC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac203d-e751-4070-9920-52277287b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"RBComics\"\n",
    "data_path = Path(\"data\").resolve()\n",
    "models_path = Path(\"models\").resolve()\n",
    "figures_path = Path(\"figures\").resolve()\n",
    "dataset_path = Path(dataset_name).resolve()\n",
    "\n",
    "imagetype = \"svg\"\n",
    "transparent = True\n",
    "save_figures = True\n",
    "\n",
    "ftype = \"xml\"\n",
    "model = read_cobra_model(models_path / f\"{GEM_NAME.replace('-', '_')}.{ftype}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a3d73-7dee-4165-ac00-a21f45d98ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "mapping_key = \"uniprot\"\n",
    "annotation_cols = [mapping_key]\n",
    "\n",
    "df_model_mappings = (\n",
    "    get_annotation_df(model.genes, annotation_cols)\n",
    "    .rename({\"id\": annotation_type}, axis=1)\n",
    "    .dropna(subset=[mapping_key])\n",
    ")\n",
    "for col in df_model_mappings.columns:\n",
    "    df_model_mappings[col] = df_model_mappings[col].apply(lambda x: split_string(x))\n",
    "    df_model_mappings = df_model_mappings.explode(col).drop_duplicates().dropna()\n",
    "df_model_mappings = df_model_mappings.sort_values(annotation_type)\n",
    "\n",
    "print(df_model_mappings.nunique(dropna=True))\n",
    "df_model_mappings = df_model_mappings.reset_index(drop=True)\n",
    "df_model_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae5bf0-27c9-43c3-9e99-b0278f4e5491",
   "metadata": {},
   "source": [
    "## Assemble data for PC-model\n",
    "### Load protein data\n",
    "#### Protein amino acid sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b24e89-a6d8-40d1-b830-032681929c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isoforms_sequences = pd.read_csv(\n",
    "    data_path / \"uniprot_isoforms_sequences.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=None,\n",
    ").fillna(pd.NA)\n",
    "print(df_isoforms_sequences[df_isoforms_sequences[\"erythroid\"]][\"uniprot\"].unique())\n",
    "df_isoforms_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d1592-c3e0-41a2-b52f-cfb4699da14b",
   "metadata": {},
   "source": [
    "#### Determine protein isoforms and associated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ed5b2-a8a5-4f8d-ab82-590d0f52e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erythroid first, then canonical to enable drop_duplicates to keep erythroid over canonical\n",
    "df_model_isoforms_sequences = (\n",
    "    pd.concat(\n",
    "        (\n",
    "            df_isoforms_sequences[df_isoforms_sequences[\"erythroid\"]],\n",
    "            df_isoforms_sequences[df_isoforms_sequences[\"canonical\"]],\n",
    "            df_isoforms_sequences[df_isoforms_sequences[\"backup\"]],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    .fillna(pd.NA)\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\n",
    "        [\"uniprot\", \"erythroid\", \"uniprot.isoform\"], ascending=[True, False, True]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    df_model_isoforms_sequences[[\"canonical\", \"erythroid\", \"backup\", \"avoid\"]].sum(\n",
    "        axis=0\n",
    "    )\n",
    ")\n",
    "print(f\"Total: {len(df_model_isoforms_sequences)}\")\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"uniprot\",\n",
    "        \"uniprot.isoform\",\n",
    "        \"sequence.id\",\n",
    "        \"sequence\",\n",
    "        \"sequence.length\",\n",
    "        \"canonical\",\n",
    "        \"erythroid\",\n",
    "        \"backup\",\n",
    "        \"avoid\",\n",
    "    ],\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences.copy()\n",
    "df_model_isoforms_sequences[\"keep\"] = df_model_isoforms_sequences[\"canonical\"].values\n",
    "to_avoid = df_model_isoforms_sequences[df_model_isoforms_sequences[\"avoid\"]][\n",
    "    \"uniprot\"\n",
    "].to_dict()\n",
    "df_model_isoforms_sequences.loc[\n",
    "    list(to_avoid),\n",
    "    \"keep\",\n",
    "] = False\n",
    "\n",
    "df_possible_backups = df_model_isoforms_sequences[\n",
    "    df_model_isoforms_sequences[\"uniprot\"].isin(list(to_avoid.values()))\n",
    "]\n",
    "df_possible_backups = df_possible_backups[~df_possible_backups[\"avoid\"]]\n",
    "df_model_isoforms_sequences.loc[\n",
    "    list(df_possible_backups.index),\n",
    "    \"keep\",\n",
    "] = True\n",
    "df_model_isoforms_sequences.loc[\n",
    "    df_model_isoforms_sequences[df_model_isoforms_sequences[\"erythroid\"]].index,\n",
    "    \"keep\",\n",
    "] = True\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences[\n",
    "    df_model_isoforms_sequences[\"keep\"]\n",
    "]\n",
    "\n",
    "lost_ids = set(df_isoforms_sequences[\"uniprot\"].unique()).difference(\n",
    "    set(df_model_isoforms_sequences[\"uniprot\"].unique())\n",
    ")\n",
    "if lost_ids:\n",
    "    lost_ids = df_isoforms_sequences[df_isoforms_sequences[\"uniprot\"].isin(lost_ids)]\n",
    "    df_model_isoforms_sequences = pd.concat(\n",
    "        (df_model_isoforms_sequences, lost_ids[lost_ids[\"canonical\"]]), axis=0\n",
    "    )\n",
    "print()\n",
    "print(\n",
    "    df_model_isoforms_sequences[[\"canonical\", \"erythroid\", \"backup\", \"avoid\"]].sum(\n",
    "        axis=0\n",
    "    )\n",
    ")\n",
    "print(f\"Total: {len(df_model_isoforms_sequences)}\")\n",
    "\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences.loc[\n",
    "    :, [\"uniprot\", \"sequence.id\", \"sequence\"]\n",
    "].copy()\n",
    "df_sequence_data = (\n",
    "    df_model_mappings.merge(\n",
    "        df_model_isoforms_sequences, left_on=\"uniprot\", right_on=\"uniprot\"\n",
    "    )\n",
    "    .loc[:, [\"genes\", \"uniprot\", \"sequence.id\", \"sequence\"]]\n",
    "    .copy()\n",
    ")\n",
    "df_sequence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2ea22-65c2-40b1-866e-956a86de3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_key = \"uniprot\"\n",
    "protein_id_key = (\n",
    "    \"sequence.id.genes\"  # genes, uniprot, sequence.id, or sequence.id.genes are best,\n",
    ")\n",
    "unique_gene_to_protein_map = True\n",
    "isoform_transform = False\n",
    "df_copy_numbers_data = None\n",
    "df_protein_data = create_sequence_table(\n",
    "    df_sequences=df_sequence_data,\n",
    "    mapping_key=mapping_key,\n",
    "    isoform_transform=isoform_transform,\n",
    ")\n",
    "ordered_isoform_ids = df_sequence_data[df_sequence_data[\"uniprot\"].duplicated(False)][\n",
    "    \"sequence.id\"\n",
    "]\n",
    "df_isoforms = df_protein_data[\n",
    "    df_protein_data[\"sequence.id\"].isin(ordered_isoform_ids)\n",
    "].copy()\n",
    "print(f\"Number of proteins: {len(df_isoforms[mapping_key].unique())}\")\n",
    "print(f\"Number of isoforms: {len(df_isoforms['sequence.id'].unique())}\")\n",
    "df_protein_data = df_protein_data.set_index(\"sequence.id\")\n",
    "df_protein_data = pd.concat(\n",
    "    (\n",
    "        df_protein_data.loc[ordered_isoform_ids],\n",
    "        df_protein_data.loc[df_protein_data.index.difference(ordered_isoform_ids)],\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "df_protein_data = df_protein_data.reset_index(drop=False)\n",
    "df_protein_data = df_protein_data.loc[\n",
    "    :, [\"genes\", \"uniprot\", \"sequence.id\", \"sequence\"]\n",
    "].copy()\n",
    "# print(df_isoforms[mapping_key])\n",
    "if protein_id_key == \"sequence.id.genes\":\n",
    "    protein_id_key = \"protein.id\"\n",
    "    sequence_id_updates = df_model_mappings.set_index(\"uniprot\")[\"genes\"].to_dict()\n",
    "    df_protein_data[\"protein.id\"] = df_protein_data[\"sequence.id\"].apply(\n",
    "        lambda seq_id: \"_\".join(\n",
    "            [sequence_id_updates.get(x, x) for x in seq_id.split(\"-\")]\n",
    "        )\n",
    "    )\n",
    "    df_isoforms[\"protein.id\"] = df_isoforms[\"sequence.id\"].apply(\n",
    "        lambda seq_id: \"_\".join(\n",
    "            [sequence_id_updates.get(x, x) for x in seq_id.split(\"-\")]\n",
    "        )\n",
    "    )\n",
    "    ids_to_fix = df_protein_data[\n",
    "        ~df_protein_data[\"sequence.id\"].isin(df_isoforms[\"sequence.id\"])\n",
    "    ].index\n",
    "    df_protein_data.loc[ids_to_fix, \"protein.id\"] = df_protein_data.loc[\n",
    "        ids_to_fix, \"protein.id\"\n",
    "    ].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "# Use to remove duplicates\n",
    "if unique_gene_to_protein_map:\n",
    "    df_protein_data = df_protein_data.drop_duplicates(\n",
    "        subset=[\"uniprot\"],\n",
    "        keep=\"first\",\n",
    "    )\n",
    "    protein_id_key = \"genes\"\n",
    "\n",
    "df_protein_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9eff5e-0f50-463e-a82c-40c4565e16b6",
   "metadata": {},
   "source": [
    "###  List all unique proteins, complexes, and enzymes\n",
    "#### Option 1: Initialize draft tables\n",
    "1. The draft tables are created and used to initialize the draft PC-model.\n",
    "    * The protein table can be used to initialize proteins and their molar weight ($\\textbf{d}$ vector).\n",
    "    * The complex table can be used to initialize complexes with their subunit stoichiometry ($\\textbf{C}$ matrix).\n",
    "        * All stoichiometric coefficients are initialized at a value of one.\n",
    "    * The enzyme table can be used to initialize enzymes with their effective rate constants ($\\textbf{K}_\\mathrm{eff}$ matrix).\n",
    "        * All $k_\\mathrm{eff}$ values are initialized at average rate constant of 65 $s^{-1}$  (or equivalently, 234000 $hr^{-1})$.\n",
    "\n",
    "2. The draft tables are made to be facilitate curation and data replacement. Therefore, the draft PC-model is exported with the draft tables. \n",
    "3. A refined PC-model can be created using the curated tables. \n",
    "\n",
    "#### Option 2: Load tables from files\n",
    "4. The formation of a draft model can be skipped if the curated tables already exist. They can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18560139-b484-4255-bffa-deed41fa153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel_tables = {}\n",
    "replace_compartments = {\n",
    "    # Cytosol:extracellular --> plasma membrane\n",
    "    \"c\": \"c\",\n",
    "    \"ce\": \"pm\",\n",
    "    \"e\": \"e\",  # Most extracellular reactions that occur are due to proteins bound to the external side of them membrane.\n",
    "}\n",
    "\n",
    "# Convert all protein compartments to one compartment\n",
    "simplify_compartments = True\n",
    "prefix = True\n",
    "optional_columns = True\n",
    "\n",
    "# Enzyme values for new tables\n",
    "max_weight_fraction = 100\n",
    "enzyme_keff_base = DEFAULT_KEFF\n",
    "enzyme_forward_suffix = DEFAULT_ENZYME_FORWARD_SUFFIX\n",
    "enzyme_reverse_suffix = DEFAULT_ENZYME_REVERSE_SUFFIX\n",
    "enzyme_total_suffix = DEFAULT_ENZYME_TOTAL_SUFFIX\n",
    "\n",
    "dict_of_id_keys = {\n",
    "    \"proteins\": protein_id_key,\n",
    "    \"complexes\": None,\n",
    "    \"enzymes\": \"reactions\",\n",
    "}\n",
    "\n",
    "# Provide filepaths to speed up creation process files, comment out to generate from scratch\n",
    "filepaths = {\n",
    "    \"proteins\": data_path / \"pcmodel_proteins.tsv\",\n",
    "    \"complexes\": data_path / \"pcmodel_complexes.tsv\",\n",
    "    \"enzymes\": data_path / \"pcmodel_enzymes.tsv\",\n",
    "    # \"complex_keffs\": data_path / \"pcmodel_complex_keffs.tsv\",\n",
    "    # \"enzyme_keffs\": data_path / \"pcmodel_enzyme_keffs.tsv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a4744-149f-4fe3-a274-bfb7c2cb97b1",
   "metadata": {},
   "source": [
    "##### Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb342b9-c941-47ab-b80f-5b11fec4fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"proteins\"\n",
    "# Otherwise try using main RBC-GEM files to make model proteins\n",
    "try:\n",
    "    df_proteins = pd.read_csv(filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    print(\"Loaded from main RBC-GEM file\")\n",
    "except (FileNotFoundError, KeyError):\n",
    "    # Otherwise, make from scratch\n",
    "    df_proteins = create_protein_table(\n",
    "        model,\n",
    "        df_protein_data=df_protein_data,\n",
    "        id_key=dict_of_id_keys.get(table_type),\n",
    "        prefix=prefix,\n",
    "        optional_columns=optional_columns,\n",
    "        annotation_columns=[\n",
    "            \"uniprot\",\n",
    "        ],\n",
    "        replace_compartments=replace_compartments,\n",
    "    )\n",
    "    print(\"Created new table\")\n",
    "    # Create column for identifiers if None exists, or if compartments were replaced\n",
    "    if not isoform_transform:\n",
    "        df_proteins[df_proteins[table_type].duplicated(False)]\n",
    "else:\n",
    "    df_proteins = df_protein_data.merge(\n",
    "        df_proteins[[\"uniprot\", \"compartment\"]],\n",
    "        left_on=\"uniprot\",\n",
    "        right_on=\"uniprot\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_proteins[\"protein\"] = df_proteins[protein_id_key].apply(lambda x: f\"protein_{x}\")\n",
    "    df_proteins = df_proteins.drop(\"protein.id\", axis=1)\n",
    "    df_proteins = df_proteins[\n",
    "        df_proteins[\"genes\"].isin(model.genes.list_attr(\"id\"))\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "if simplify_compartments:\n",
    "    df_proteins = df_proteins.groupby([\"genes\", \"protein\"]).agg(\n",
    "        lambda values: \";\".join(\n",
    "            [str(value) for value in list(values.dropna().unique())]\n",
    "        )\n",
    "    )\n",
    "    df_proteins[\"compartment\"] = \"pc\"\n",
    "    df_proteins = df_proteins.reset_index(drop=False)\n",
    "\n",
    "df_proteins[\"proteins\"] = df_proteins[[strip_plural(table_type), \"compartment\"]].apply(\n",
    "    lambda x: \"_\".join(x.values), axis=1\n",
    ")\n",
    "df_proteins = df_proteins.set_index(strip_plural(table_type))\n",
    "pcmodel_tables[table_type] = df_proteins.copy()\n",
    "df_proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610036dd-56de-4d9b-8a5b-147d569624ed",
   "metadata": {},
   "source": [
    "##### Complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190d981-1b98-486b-9e06-8c9344d6fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"complexes\"\n",
    "try:\n",
    "    df_complexes = pd.read_csv(filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    print(\"Loaded from main RBC-GEM file\")\n",
    "except (FileNotFoundError, KeyError):\n",
    "    genes_to_proteins = (\n",
    "        pcmodel_tables[\"proteins\"]\n",
    "        .groupby([\"genes\"], as_index=True)[\"proteins\"]\n",
    "        .agg(lambda x: build_string(list(x)))\n",
    "        .to_dict()\n",
    "    )\n",
    "    cofactor_genes = {}\n",
    "    # Create table\n",
    "    df_complexes = create_complex_table(\n",
    "        model,\n",
    "        genes_to_proteins=genes_to_proteins,\n",
    "        cofactor_genes=cofactor_genes,\n",
    "        id_key=dict_of_id_keys.get(table_type),\n",
    "        prefix=prefix,\n",
    "        optional_columns=optional_columns,\n",
    "        annotation_columns=[\n",
    "            # \"uniprot\"\n",
    "        ],\n",
    "        replace_compartments=replace_compartments,\n",
    "    )\n",
    "    print(\"Created new table\")\n",
    "\n",
    "else:\n",
    "    df_complexes = df_complexes.drop(\"molar_mass\", axis=1)\n",
    "    df_complexes = df_complexes[\n",
    "        df_complexes[\"genes\"].apply(\n",
    "            lambda genes: all([model.genes.has_id(gene) for gene in genes.split(\";\")])\n",
    "        )\n",
    "    ]\n",
    "    df_complexes[\"reactions\"] = df_complexes[\"reactions\"].apply(\n",
    "        lambda reactions: \";\".join(\n",
    "            [r for r in reactions.split(\";\") if model.reactions.has_id(r)]\n",
    "        )\n",
    "    )\n",
    "    df_complexes = df_complexes[df_complexes[\"reactions\"] != \"\"]\n",
    "    df_complexes = df_complexes.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"complex\",\n",
    "            \"subunits\",\n",
    "            \"compartment\",\n",
    "            \"reactions\",\n",
    "            \"genes\",\n",
    "            \"coefficients\",\n",
    "            \"cofactors\",\n",
    "            \"notes\",\n",
    "        ],\n",
    "    ]\n",
    "# Address isoform mapping to complexes\n",
    "isoforms_map = defaultdict(list)\n",
    "complex_name_update = defaultdict(list)\n",
    "for x in df_proteins[df_proteins[\"genes\"].duplicated(False)].index:\n",
    "    isoforms_map[x.rsplit(\"_\", maxsplit=1)[0]].append(x)\n",
    "    complex_name_update[x.rsplit(\"_\", maxsplit=1)[0].replace(\"protein_\", \"\")].append(\n",
    "        x.replace(\"protein_\", \"\")\n",
    "    )\n",
    "df_isoforms_complexes = df_complexes[\n",
    "    df_complexes[\"subunits\"].apply(\n",
    "        lambda proteins: bool(set(isoforms_map).intersection(proteins.split(\";\")))\n",
    "    )\n",
    "]\n",
    "df_updated_rows = []\n",
    "for _, row in df_isoforms_complexes.iterrows():\n",
    "    complex_names = [\n",
    "        complex_name\n",
    "        for complex_name in itertools.product(\n",
    "            *[complex_name_update.get(c, [c]) for c in row[\"complex\"].split(\"_\")]\n",
    "        )\n",
    "    ]\n",
    "    combos = [\n",
    "        list(combo)\n",
    "        for combo in itertools.product(\n",
    "            *[\n",
    "                isoforms_map.get(protein, [protein])\n",
    "                for protein in row[\"subunits\"].split(\";\")\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for complex_name, combo in zip(complex_names, combos):\n",
    "        new_row = row.to_dict()\n",
    "        new_row[\"complex\"] = \"_\".join(complex_name)\n",
    "        new_row[\"subunits\"] = \";\".join(combo)\n",
    "        df_updated_rows.append(new_row)\n",
    "\n",
    "df_complexes = pd.concat(\n",
    "    (\n",
    "        df_complexes[~df_complexes.index.isin(df_isoforms_complexes.index)],\n",
    "        pd.DataFrame(df_updated_rows),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "\n",
    "if simplify_compartments:\n",
    "    df_complexes = df_complexes.groupby([\"subunits\", \"complex\"]).agg(\n",
    "        lambda values: \";\".join(\n",
    "            [str(value) for value in list(values.dropna().unique())]\n",
    "        )\n",
    "    )\n",
    "    df_complexes[\"compartment\"] = \"pc\"\n",
    "    df_complexes = df_complexes.reset_index(drop=False)\n",
    "\n",
    "df_complexes[\"complexes\"] = df_complexes[\n",
    "    [strip_plural(table_type), \"compartment\"]\n",
    "].apply(lambda x: \"_\".join(x.values), axis=1)\n",
    "df_complexes[\"subunits\"] = df_complexes[[\"subunits\", \"compartment\"]].apply(\n",
    "    lambda values: \";\".join(\n",
    "        [\n",
    "            \"_\".join((x, values[\"compartment\"])) if not x.endswith(\"_pc\") else x\n",
    "            for x in values[\"subunits\"].split(\";\")\n",
    "        ]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df_complexes = df_complexes.set_index(strip_plural(table_type))\n",
    "pcmodel_tables[table_type] = df_complexes.copy()\n",
    "df_complexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5388d72-79df-4444-886c-82ca4ff0d7ba",
   "metadata": {},
   "source": [
    "##### Enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3f525-31d4-41a4-bd1e-7b0c6242f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"enzymes\"\n",
    "try:\n",
    "    df_enzymes = pd.read_csv(filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    print(\"Loaded from main RBC-GEM file\")\n",
    "except (FileNotFoundError, KeyError):\n",
    "    complexes_to_reactions = (\n",
    "        pcmodel_tables[\"complexes\"].set_index(\"complexes\")[\"reactions\"].to_dict()\n",
    "    )\n",
    "    df_enzymes = create_enzyme_table(\n",
    "        model,\n",
    "        complexes_to_reactions=complexes_to_reactions,\n",
    "        enzyme_keff_base=enzyme_keff_base,\n",
    "        enzyme_forward_suffix=enzyme_forward_suffix,\n",
    "        enzyme_reverse_suffix=enzyme_reverse_suffix,\n",
    "        id_key=dict_of_id_keys.get(table_type),\n",
    "        prefix=prefix,\n",
    "        optional_columns=optional_columns,\n",
    "        annotation_columns=[\n",
    "            # \"uniprot\"\n",
    "        ],\n",
    "        replace_compartments=replace_compartments,\n",
    "    )\n",
    "    print(\"Created new table\")\n",
    "    if replace_compartments:\n",
    "        df_enzymes[\"compartment\"] = df_enzymes[\"compartment\"].replace(\n",
    "            replace_compartments\n",
    "        )\n",
    "else:\n",
    "    df_enzymes = df_enzymes.loc[\n",
    "        :, [\"complexes\", \"compartment\", \"reactions\", \"enzyme\", \"direction\"]\n",
    "    ]\n",
    "\n",
    "if simplify_compartments:\n",
    "    df_enzymes = df_enzymes.groupby([\"complexes\", \"enzyme\"]).agg(\n",
    "        lambda values: \";\".join(\n",
    "            [str(value) for value in list(values.dropna().unique())]\n",
    "        )\n",
    "    )\n",
    "    df_enzymes[\"compartment\"] = \"pc\"\n",
    "    df_enzymes = df_enzymes.reset_index(drop=False)\n",
    "\n",
    "df_enzymes[table_type] = df_enzymes[[strip_plural(table_type), \"compartment\"]].apply(\n",
    "    lambda x: \"_\".join(x.values), axis=1\n",
    ")\n",
    "df_enzymes = df_enzymes.set_index(strip_plural(table_type))\n",
    "pcmodel_tables[table_type] = df_enzymes.copy()\n",
    "df_enzymes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee3dbe-cb7b-40a7-b3e6-56c9a238df06",
   "metadata": {},
   "source": [
    "## Create PC-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b1787-95e1-4848-a4cc-d4c79245c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_table = pcmodel_tables[\"proteins\"].reset_index(drop=False)\n",
    "complex_table = pcmodel_tables[\"complexes\"].reset_index(drop=False)\n",
    "enzyme_table = pcmodel_tables[\"enzymes\"].reset_index(drop=False)\n",
    "max_weight_fraction = 100\n",
    "\n",
    "pcmodel, final_pcmodel_tables = construct_pcmodel_from_tables(\n",
    "    model,\n",
    "    protein_table=protein_table,\n",
    "    complex_table=complex_table,\n",
    "    enzyme_table=enzyme_table,\n",
    "    max_weight_fraction=max_weight_fraction,\n",
    "    enzyme_keff_base=enzyme_keff_base,\n",
    "    enzyme_forward_suffix=enzyme_forward_suffix,\n",
    "    enzyme_reverse_suffix=enzyme_reverse_suffix,\n",
    "    enzyme_total_suffix=enzyme_total_suffix,\n",
    "    include_complex_dilutions=True,  # Relaxes constraints areound complexes. Recommend to start, can be set to zero later or removed entirely\n",
    "    irrev_rxn_complex_keff=0,  # Set as None to ignore, small number to keep in model, 0 to remove from complex-enzyme mapping\n",
    ")\n",
    "if simplify_compartments:\n",
    "    pcmodel.compartments = {\"pc\": \"protein compartment\"}\n",
    "# Print summary\n",
    "for attr, subclass_dict in ATTR_SUBCLASS_DICT.items():\n",
    "    n = len(\n",
    "        getattr(pcmodel, attr).query(\n",
    "            lambda x: not isinstance(x, tuple(subclass_dict.values()))\n",
    "        )\n",
    "    )\n",
    "    print(f\"Number of {attr}: {n}\")\n",
    "    for key, subcls in subclass_dict.items():\n",
    "        obj_list = getattr(pcmodel, attr).query(lambda x: isinstance(x, subcls))\n",
    "        n = len(obj_list)\n",
    "        print(f\"Number of {key}: {n}\")\n",
    "        if subcls in (Enzyme, EnzymeDilution):\n",
    "            print(\n",
    "                f\"Forward variable: {len(obj_list.query(lambda x: enzyme_forward_suffix in x.id))}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Reverse variable: {len(obj_list.query(lambda x: enzyme_reverse_suffix in x.id))}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Summation variable : {len(obj_list.query(lambda x: enzyme_total_suffix in x.id))}\"\n",
    "            )\n",
    "    print()\n",
    "\n",
    "keff_table = final_pcmodel_tables[\"enzymes\"].copy()\n",
    "keff_table[\"direction\"] = keff_table[\"reactions\"].apply(\n",
    "    lambda rid: model.reactions.get_by_id(rid).reaction\n",
    ")\n",
    "keff_table[\"direction\"] = keff_table[\"direction\"].apply(\n",
    "    lambda x: x.replace(\"<=>\", \"-->\")\n",
    ")\n",
    "keff_table[\"direction\"] = keff_table[[\"enzyme\", \"direction\"]].apply(\n",
    "    lambda x: (\n",
    "        x[\"direction\"].replace(\"-->\", \"<--\")\n",
    "        if x[\"enzyme\"].endswith(DEFAULT_ENZYME_REVERSE_SUFFIX)\n",
    "        else x[\"direction\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "keff_table[\"complexes\"] = keff_table[\"complexes\"].apply(lambda x: x.split(\";\"))\n",
    "keff_table[\"complex_keff\"] = keff_table[\"complex_keff\"].apply(lambda x: x.split(\";\"))\n",
    "keff_table = keff_table.explode([\"complexes\", \"complex_keff\"])\n",
    "keff_table[\"complex\"] = keff_table[[\"complexes\", \"compartment\"]].apply(\n",
    "    lambda x: x[\"complexes\"].replace(f\"_{x['compartment']}\", \"\"), axis=1\n",
    ")\n",
    "keff_table = keff_table.groupby([\"enzyme\", \"complex\"], as_index=False).agg(\n",
    "    lambda x: list(x.unique())[0]\n",
    ")\n",
    "keff_table = keff_table.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"enzyme\",\n",
    "        \"enzyme_keff\",\n",
    "        \"complex\",\n",
    "        \"complex_keff\",\n",
    "        \"compartment\",\n",
    "        \"reactions\",\n",
    "        \"direction\",\n",
    "    ],\n",
    "]\n",
    "complex_keff_table = keff_table.drop(\"enzyme_keff\", axis=1).drop_duplicates()\n",
    "enzyme_keff_table = (\n",
    "    keff_table.groupby([\"enzyme\", \"enzyme_keff\"], as_index=False)[\n",
    "        [\"reactions\", \"direction\"]\n",
    "    ]\n",
    "    .agg(lambda x: list(x.unique())[0])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "final_pcmodel_tables[\"complex_keffs\"] = complex_keff_table\n",
    "final_pcmodel_tables[\"enzyme_keffs\"] = enzyme_keff_table\n",
    "\n",
    "n_cplx_keff = len(\n",
    "    complex_keff_table[complex_keff_table[\"complex_keff\"].astype(float) != 0]\n",
    ")\n",
    "print(f\"Number of non-zero complex rate constants: {n_cplx_keff}\")\n",
    "\n",
    "n_enzyme_keff = len(\n",
    "    enzyme_keff_table[enzyme_keff_table[\"enzyme_keff\"].astype(float) != 0]\n",
    ")\n",
    "print(f\"Number of non-zero enzyme rate constants: {n_enzyme_keff}\")\n",
    "\n",
    "\n",
    "for table_type, df_table in final_pcmodel_tables.items():\n",
    "    df_table.to_csv(data_path / f\"pcmodel_{table_type}.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7554cd-dbf7-4286-a29e-81281e44f767",
   "metadata": {},
   "source": [
    "### Formulate additional protein constraints\n",
    "#### Address isoforms and compartments with additional constraints\n",
    "For isoforms and/or compartments, place an additional constraint such that the total sum of all isoforms does not exceed the measured concentraiton value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04a412-75e3-4ca8-b629-46f8fafcb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_table = pcmodel_tables[\"proteins\"]\n",
    "mapping_key = \"uniprot\"\n",
    "df_additional_constraints = protein_table[protein_table[mapping_key].duplicated(False)]\n",
    "df_additional_constraints = df_additional_constraints.groupby(\n",
    "    [\n",
    "        \"genes\",\n",
    "        mapping_key,\n",
    "    ],\n",
    "    as_index=False,\n",
    ").agg(lambda x: list(x))\n",
    "if not df_additional_constraints.empty:\n",
    "    if \"lower_bound\" in df_additional_constraints.columns:\n",
    "        df_additional_constraints[\"lower_bound\"] = df_additional_constraints[\n",
    "            \"lower_bound\"\n",
    "        ].apply(min)\n",
    "    if \"upper_bound\" in df_additional_constraints.columns:\n",
    "        df_additional_constraints[\"upper_bound\"] = df_additional_constraints[\n",
    "            \"upper_bound\"\n",
    "        ].apply(max)\n",
    "\n",
    "data = {}\n",
    "for idx, row in df_additional_constraints.iterrows():\n",
    "    # Technically, always one gene but refers to genes attribute\n",
    "    genes = row[\"genes\"]\n",
    "    uniprot = model.genes.get_by_id(genes).annotation.get(mapping_key, \"\")\n",
    "    proteins = split_string(row.get(\"proteins\"))\n",
    "    proteins = pcmodel.metabolites.get_by_any(proteins)\n",
    "    is_compartment = len({p.compartment for p in proteins}) > 1\n",
    "    is_isoform = (\n",
    "        len(\n",
    "            {\n",
    "                p.id.replace(f\"_{p.compartment}\", \"\").split(\n",
    "                    \"_\",\n",
    "                )[-1]\n",
    "                for p in proteins\n",
    "                if p.id.replace(f\"_{p.compartment}\", \"\")\n",
    "                .split(\n",
    "                    \"_\",\n",
    "                )[-1]\n",
    "                .isnumeric()\n",
    "            }\n",
    "        )\n",
    "        > 1\n",
    "    )\n",
    "    if is_compartment and not is_isoform:\n",
    "        default_prefix = DEFAULT_COMPARTMENT_CONSTRAINT_PREFIX\n",
    "    elif is_isoform and not is_compartment:\n",
    "        default_prefix = DEFAULT_ISOFORM_CONSTRAINT_PREFIX\n",
    "    else:\n",
    "        default_prefix = DEFAULT_CONSTRAINT_PREFIX\n",
    "    constraint_id = row.get(\"constraints\", f\"{default_prefix}{genes}\")\n",
    "    lower_bound = float(row.get(\"lower_bound\")) if row.get(\"lower_bound\") else 0\n",
    "    upper_bound = (\n",
    "        float(row.get(\"upper_bound\"))\n",
    "        if row.get(\"upper_bound\")\n",
    "        else DEFAULT_CONCENTRATION_BOUND\n",
    "    )\n",
    "    protein_dilutions = [\n",
    "        reaction\n",
    "        for protein in proteins\n",
    "        for reaction in list(protein.reactions)\n",
    "        if reaction.id.endswith(protein.id)\n",
    "    ]\n",
    "    # \"ISOCONS\" is short for \"ISOFORM CONSTRAINT\"\n",
    "    # \"COMPCONS\" is short for \"COMPARTMENT CONSTRAINT\"\n",
    "    # \"CONS\" for general constraint\n",
    "    data[idx] = {\n",
    "        \"constraints\": constraint_id,\n",
    "        \"genes\": genes,\n",
    "        \"proteins\": build_string([p.id for p in proteins]),\n",
    "        \"reactions\": build_string([p.id for p in protein_dilutions]),\n",
    "        # Assume sum of isoforms is a constant, works well with proteomic measurements that do not distinguish\n",
    "        \"coefficients\": \";\".join([str(1) for p in protein_dilutions]),\n",
    "        \"lower_bound\": lower_bound,\n",
    "        \"upper_bound\": upper_bound,\n",
    "        \"unit\": \"nmol / gDW\",\n",
    "        mapping_key: uniprot,\n",
    "    }\n",
    "df_additional_constraints = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "df_additional_constraints.to_csv(\n",
    "    data_path / f\"constraints_proteins_{pcmodel.id}.tsv\", sep=\"\\t\", index=False\n",
    ")\n",
    "df_additional_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7be1c-67b8-4ebb-92ee-bb53b312d30f",
   "metadata": {},
   "source": [
    "## Add additional protein constraints to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bb685-f825-4f2a-bc0d-66d50606d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_additional_constraints = pd.read_csv(\n",
    "        data_path / f\"constraints_proteins_{pcmodel.id}.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index_col=None,\n",
    "    )\n",
    "except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "    df_additional_constraints = pd.DataFrame()\n",
    "else:\n",
    "    if not df_additional_constraints.empty:\n",
    "        for constraint_id, row in df_additional_constraints.set_index(\n",
    "            \"constraints\"\n",
    "        ).iterrows():\n",
    "            reactions = pcmodel.reactions.get_by_any(row[\"reactions\"].split(\";\"))\n",
    "            coefficients = row[\"coefficients\"].split(\";\")\n",
    "            abundance = sum(\n",
    "                [\n",
    "                    int(coeff) * reaction.flux_expression\n",
    "                    for reaction, coeff in zip(reactions, coefficients)\n",
    "                ]\n",
    "            )\n",
    "            lower_bound = float(row.get(\"lower_bound\")) if row.get(\"lower_bound\") else 0\n",
    "            upper_bound = (\n",
    "                float(row.get(\"upper_bound\"))\n",
    "                if row.get(\"upper_bound\")\n",
    "                else DEFAULT_CONCENTRATION_BOUND\n",
    "            )\n",
    "            if constraint_id in pcmodel.constraints:\n",
    "                # TODO warn\n",
    "                pcmodel.remove_cons_vars(pcmodel.constraints[constraint_id])\n",
    "            additional_constraint = pcmodel.problem.Constraint(\n",
    "                abundance,\n",
    "                name=constraint_id,\n",
    "                lb=lower_bound,\n",
    "                ub=upper_bound,\n",
    "            )\n",
    "            pcmodel.add_cons_vars(additional_constraint)\n",
    "\n",
    "df_additional_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398f43f-208a-413a-850b-e78e37a0025f",
   "metadata": {},
   "source": [
    "### Annotate proteins with UniProt IDs and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fa420-ace9-4354-a71e-6e2e49833bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_to_uniprot = protein_table.set_index(\"proteins\")[\"uniprot\"].to_dict()\n",
    "protein_to_sequence = protein_table.set_index(\"proteins\")[\"sequence\"].to_dict()\n",
    "\n",
    "for protein_dilution in pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, ProteinDilution)\n",
    "):\n",
    "    if protein_to_uniprot.get(f\"{protein_dilution.id}\".replace(\"PROTDL_\", \"\")):\n",
    "        protein_dilution.annotation[\"uniprot\"] = protein_to_uniprot[\n",
    "            f\"{protein_dilution.id}\".replace(\"PROTDL_\", \"\")\n",
    "        ]\n",
    "        protein_dilution.annotation[\"uniprot.aa_sequence\"] = protein_to_sequence[\n",
    "            f\"{protein_dilution.id}\".replace(\"PROTDL_\", \"\")\n",
    "        ]\n",
    "\n",
    "for protein in pcmodel.metabolites.query(lambda x: isinstance(x, Protein)):\n",
    "    if protein_to_uniprot.get(protein.id):\n",
    "        protein.annotation[\"uniprot\"] = protein_to_uniprot[protein.id]\n",
    "        protein.annotation[\"uniprot.aa_sequence\"] = protein_to_sequence[protein.id]\n",
    "\n",
    "\n",
    "enzyme_to_reaction = enzyme_table.set_index(\"enzymes\")[\"reactions\"].to_dict()\n",
    "for enzyme_dilution in pcmodel.reactions.query(lambda x: isinstance(x, EnzymeDilution)):\n",
    "    if enzyme_to_reaction.get(f\"{enzyme_dilution.id}\".replace(\"ENZDL_\", \"\")):\n",
    "        # Make it easier to use later\n",
    "        enzyme_dilution.annotation[\"reaction\"] = enzyme_to_reaction[\n",
    "            f\"{enzyme_dilution.id}\".replace(\"ENZDL_\", \"\")\n",
    "        ]\n",
    "\n",
    "for enzyme in pcmodel.metabolites.query(lambda x: isinstance(x, Enzyme)):\n",
    "    if enzyme_to_reaction.get(enzyme.id):\n",
    "        enzyme.annotation[\"reaction\"] = enzyme_to_reaction[enzyme.id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5ed10-611d-44a1-b924-cf3badb5a39f",
   "metadata": {},
   "source": [
    "### Set proteome budget constraints for low abundance and high-abundance proteomes\n",
    "* RBCs are enucleated, terminally differentiated cells that are composed of 95% to 98% Hb by dry mass (mass of all the constituents of a cell in the absence of water)\n",
    "    * PMID: 13429433, PMID: 13999462, PMID: 21796773, **PMID: 34378368**\n",
    "* Therefore, remove hemoglobin from the low abundance proteome budget constraint and create a new constraint specific to hemoglobin abundance.\n",
    "* Assume 90% minimum of dry mass is hemoglobin, and up to 10% of dry mass are other proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954117e4-76e8-4035-a16d-94289415015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proteome budget for low abundance proteins\n",
    "PBDL_proteome_budget = pcmodel.reactions.get_by_id(\"PBDL_proteome_budget\")\n",
    "PBDL_proteome_budget.id = \"PBDL_proteome_budget\"\n",
    "PBDL_proteome_budget.name = \"Proteome budget demand (Low abundance)\"\n",
    "\n",
    "proteome_budget = pcmodel.metabolites.get_by_id(\"proteome_budget\")\n",
    "proteome_budget.id = \"proteome_budget\"\n",
    "proteome_budget.name = \"Proteome Budget Constraint (Low abundance)\"\n",
    "\n",
    "# Proteome budget for hemoglobin\n",
    "PBDL_hemoglobin_budget = PBDL_proteome_budget.copy()\n",
    "hemoglobin_budget = list(PBDL_hemoglobin_budget.metabolites).pop()\n",
    "PBDL_hemoglobin_budget.id = \"PBDL_hemoglobin_budget\"\n",
    "PBDL_hemoglobin_budget.name = \"Proteome budget demand (Hemoglobin)\"\n",
    "\n",
    "hemoglobin_budget.id = \"hemoglobin_budget\"\n",
    "hemoglobin_budget.name = \"Hemoglobin Budget Constraint\"\n",
    "\n",
    "PBDL_hemoglobin_budget.bounds = (900, 1000)\n",
    "PBDL_proteome_budget.bounds = (0.0, 100)\n",
    "\n",
    "pcmodel.add_reactions([PBDL_hemoglobin_budget])\n",
    "\n",
    "remove_from_low_abundance_budget = [\n",
    "    \"HBA\",\n",
    "    \"HBB\",\n",
    "    \"HBD\",\n",
    "    \"HBE1\",\n",
    "    \"HBG1\",\n",
    "    \"HBG2\",\n",
    "    \"HBM\",\n",
    "    \"HBQ1\",\n",
    "    \"HBZ\",\n",
    "]\n",
    "for reaction in proteome_budget.reactions:\n",
    "    if any(\n",
    "        [f\"protein_{gid}\" in reaction.id for gid in remove_from_low_abundance_budget]\n",
    "    ):\n",
    "        reaction.add_metabolites(\n",
    "            {hemoglobin_budget: reaction.get_coefficient(proteome_budget)}\n",
    "        )\n",
    "        reaction.subtract_metabolites(\n",
    "            {proteome_budget: reaction.get_coefficient(proteome_budget)}\n",
    "        )\n",
    "\n",
    "for reaction in sorted(\n",
    "    pcmodel.metabolites.get_by_id(\"hemoglobin_budget\").reactions, key=lambda x: x.id\n",
    "):\n",
    "    print(reaction)\n",
    "\n",
    "# Add total budget constraint for hemoglobin and protein\n",
    "pcmodel.add_metabolites(\n",
    "    [\n",
    "        ProteomeBudget(\n",
    "            id=\"total_budget\",\n",
    "            name=\"Total Budget Constraint\",\n",
    "            compartment=proteome_budget.compartment,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "total_budget = pcmodel.metabolites.get_by_id(\"total_budget\")\n",
    "PBDL_total_budget = f\"PBDL_{total_budget.id}\"\n",
    "pcmodel.add_reactions(\n",
    "    [\n",
    "        ProteomeBudgetDilution(\n",
    "            id=PBDL_total_budget,\n",
    "            name=\"Total budget demand\",\n",
    "            lower_bound=0,\n",
    "            upper_bound=1000,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "PBDL_total_budget = pcmodel.reactions.get_by_id(PBDL_total_budget)\n",
    "print()\n",
    "for reaction in pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, ProteomeBudgetDilution)\n",
    "):\n",
    "    if PBDL_total_budget.id == reaction.id:\n",
    "        reaction.add_metabolites({total_budget: -1}, combine=False)\n",
    "    else:\n",
    "        reaction.add_metabolites({total_budget: 1}, combine=False)\n",
    "    print(reaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b852f8-6444-40e7-bed3-27741a75842e",
   "metadata": {},
   "source": [
    "### Ensure model can be optimized for glucose uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b619-2bf2-4923-96ca-b6136398e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_rxns = [\"NaKt\"]\n",
    "pcmodel.objective = sum(\n",
    "    [pcmodel.reactions.get_by_id(rid).flux_expression for rid in objective_rxns]\n",
    ")\n",
    "pcsol = pcmodel.optimize()\n",
    "pcsol.fluxes.loc[\n",
    "    [r.id for r in model.reactions if r.id in pcsol.fluxes[pcsol.fluxes != 0].index]\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fde0a-9090-4c06-9849-937303d72538",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsol.fluxes.loc[\n",
    "    [\n",
    "        r.id\n",
    "        for r in pcmodel.reactions.query(lambda x: isinstance(x, ProteinDilution))\n",
    "        if r.id in pcsol.fluxes[pcsol.fluxes != 0].index\n",
    "    ]\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91db47-c712-4090-998c-d9e528c40975",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsol.fluxes.loc[\n",
    "    [\n",
    "        r.id\n",
    "        for r in pcmodel.reactions.query(lambda x: isinstance(x, EnzymeDilution))\n",
    "        if r.id in pcsol.fluxes[pcsol.fluxes != 0].index\n",
    "    ]\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a01f53-12d7-464b-b633-762fb818f823",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995d1dc-1355-4ace-b469-3067a9932791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular model\n",
    "write_cobra_model(model, filename=models_path / f\"{model}.xml\")\n",
    "write_cobra_model(model, filename=models_path / f\"{model}.json\")\n",
    "\n",
    "# Protein constrained  without curated keffs\n",
    "write_cobra_model(pcmodel, filename=models_path / f\"{pcmodel}.xml\")\n",
    "write_cobra_model(pcmodel, filename=models_path / f\"{pcmodel}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c7c65-f808-4970-af4d-fc43f20ab8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed6456-9e04-414a-9dec-e1aa13c0fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0839ecb1-89cd-47e7-acd1-a9839c82b0f6",
   "metadata": {},
   "source": [
    "### Create PC-model representative of RBC-Omics\n",
    "Can only be done after pcFVA results are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e37c2-f7eb-4981-9624-616a5814af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reaction_bounds = pd.read_csv(\n",
    "    dataset_path / f\"{pcmodel.id}_{dataset_name}_reaction_bounds.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=\"reactions\",\n",
    ")\n",
    "df_reaction_bounds = df_reaction_bounds.rename(\n",
    "    {\"minimum\": \"lower_bound\", \"maximum\": \"upper_bound\"}, axis=1\n",
    ")\n",
    "\n",
    "pcmodel_dataset_parameterized = pcmodel.copy()\n",
    "pcmodel_dataset_parameterized.id += f\"_{dataset_name}\"\n",
    "add_relaxation_budget(pcmodel_dataset_parameterized, 0, verbose=False)\n",
    "for rid, bounds in df_reaction_bounds.iterrows():\n",
    "    reaction = pcmodel_dataset_parameterized.reactions.get_by_id(rid)\n",
    "    reaction.bounds = bounds\n",
    "\n",
    "\n",
    "# Protein constrained  without curated keffs\n",
    "write_cobra_model(\n",
    "    pcmodel_dataset_parameterized,\n",
    "    filename=models_path / f\"{pcmodel_dataset_parameterized}.xml\",\n",
    ")\n",
    "write_cobra_model(\n",
    "    pcmodel_dataset_parameterized,\n",
    "    filename=models_path / f\"{pcmodel_dataset_parameterized}.json\",\n",
    ")\n",
    "pcmodel_dataset_parameterized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
