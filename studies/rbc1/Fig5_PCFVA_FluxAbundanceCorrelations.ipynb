{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2537d45b-6871-43b9-81f8-e3639df15ac5",
   "metadata": {},
   "source": [
    "# Analyze models using pcFVA\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import gurobipy as gp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as mpl_venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from cobra.flux_analysis.variability import flux_variability_analysis\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    GEM_NAME,\n",
    "    build_string,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    split_string,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_ENZYME_TOTAL_SUFFIX,\n",
    "    ComplexDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    ")\n",
    "from rbc_gem_utils.visualization import cmap_map\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f0e62-ca1f-4201-a29d-dc3221be59c1",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d9475-8441-4f92-b46e-6257c5a7d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e8, 1e8)\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6fa4-161e-4511-bf31-0b75d3b93dcb",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e2876-f438-4461-a0ed-785316e97e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\").resolve()\n",
    "models_path = Path(\"models\").resolve()\n",
    "figures_path = Path(\"figures\").resolve()\n",
    "\n",
    "dataset_name = \"RBComics\"\n",
    "dataset_path = Path(dataset_name).resolve()\n",
    "dataset_models_dirpath = Path(f\"{dataset_path}/pcmodels\")\n",
    "pcfva_results_dirpath = Path(f\"{dataset_path}/pcFVA\")\n",
    "version = \"1.2.0\"\n",
    "\n",
    "# Make sure to unzip the models first if you are going to simulate!\n",
    "sample_prefix, time_prefix = (\"S\", \"D\")\n",
    "# Integers are easier to work with for time points\n",
    "timepoints = [10, 23, 42]\n",
    "\n",
    "imagetype = \"png\"\n",
    "transparent = True\n",
    "save_figures = True\n",
    "overwrite = True\n",
    "\n",
    "ftype = \"xml\"\n",
    "model = read_cobra_model(f\"{models_path}/{GEM_NAME.replace('-', '_')}.{ftype}\")\n",
    "pcmodel = load_overlay_model(filename=f\"{models_path}/{model.id}_PC.{ftype}\")\n",
    "\n",
    "# For this workflow, shut off complex dilution reactions at the start\n",
    "for cplx_dilution in pcmodel.reactions.query(lambda x: isinstance(x, ComplexDilution)):\n",
    "    cplx_dilution.bounds = (0, 0)\n",
    "\n",
    "add_relaxation_budget(pcmodel, 0, verbose=False)\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d97f4-6742-4a9c-a919-b1592a8ec944",
   "metadata": {},
   "source": [
    "### Generate list of PC-models to load and simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2bc87e-0c1d-4fdc-bbc8-ef696ed58c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_from_id(model_id, sample_prefix=\"\"):\n",
    "    sample = model_id.rsplit(\"_\", 2)[-2]\n",
    "    try:\n",
    "        return int(sample.replace(sample_prefix, \"\"))\n",
    "    except ValueError:\n",
    "        return sample\n",
    "\n",
    "\n",
    "def get_time_from_id(model_id, time_prefix=\"\"):\n",
    "    time = model_id.rsplit(\"_\", 2)[-1]\n",
    "    try:\n",
    "        return int(time.replace(time_prefix, \"\"))\n",
    "    except ValueError:\n",
    "        return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817cff64-3ae8-4c34-861d-b62255e92fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(\n",
    "    [\n",
    "        fp.parts[-1].replace(fp.suffix, \"\")\n",
    "        for fp in list(dataset_models_dirpath.iterdir())\n",
    "        if fp.parts[-1].startswith(pcmodel.id)\n",
    "    ]\n",
    ")\n",
    "sample_model_ids = sorted(\n",
    "    [\n",
    "        x\n",
    "        for x in model_names\n",
    "        if isinstance(get_sample_from_id(x, sample_prefix), (int, float))\n",
    "    ],\n",
    "    key=lambda x: (\n",
    "        get_sample_from_id(x, sample_prefix),\n",
    "        get_time_from_id(x, time_prefix),\n",
    "    ),\n",
    ")\n",
    "operation_model_ids = sorted(\n",
    "    [\n",
    "        x\n",
    "        for x in model_names\n",
    "        if not isinstance(get_sample_from_id(x, sample_prefix), (int, float))\n",
    "    ],\n",
    "    key=lambda x: (\n",
    "        get_sample_from_id(x, sample_prefix),\n",
    "        get_time_from_id(x, time_prefix),\n",
    "    ),\n",
    ")\n",
    "operations = set([get_sample_from_id(x, sample_prefix) for x in operation_model_ids])\n",
    "model_names = operation_model_ids + sample_model_ids\n",
    "list_of_pcmodels = model_names.copy()\n",
    "list_of_pcmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4e5e8-eac9-4cbe-871a-56a754751001",
   "metadata": {},
   "source": [
    "### Generate results using pcFVA for context specific models\n",
    "Note that this can take a signficiant amount of time depending on the number of models and their sizes. Best to use a targeted approach in generating results. \n",
    "Alternatively, skip result generation and load the previously generated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1abd2-7782-4769-ba5a-d988093c83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "ftype = \"xml\"  # In our experience, SBML/XML loads faster, but will take up to 4x more space uncompressed as compared to JSON\n",
    "use_only_necessary_reactions = True\n",
    "optimum_percents = [0.00, 0.50, 0.90, 0.99]\n",
    "enzyme_total_suffix = DEFAULT_ENZYME_TOTAL_SUFFIX\n",
    "# Reactions in addition to the minimum for flux-abundance correlations\n",
    "list_of_reactions = []\n",
    "# # Use to get ALL reactions in the original model\n",
    "# list_of_reactions += model.reactions.list_attr(\"id\")\n",
    "# # Use to get ALL reactions in the PC model\n",
    "# list_of_reactions += pcmodel.reactions.list_attr(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5300dc7f-6735-462f-8e38-d19c8f9b3185",
   "metadata": {},
   "source": [
    "#### Generate results for subset of PC model reactions\n",
    "##### Reactions necessary for all flux-abundance correlation computations.\n",
    "To reduce computation time, a subset of reactions can be defined. \n",
    "For flux-abundance correlations, the minimum reaction set are reactions associated with genes associated and the corresponding enzyme dilution reaction for total enzyme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa8be4-8866-4116-8cb8-95328eb69832",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_reaction_list = model.reactions.query(lambda x: x.gene_reaction_rule).list_attr(\n",
    "    \"id\"\n",
    ")\n",
    "enzymes_list = pcmodel.reactions.query(\n",
    "    lambda x: x.id.startswith(f\"ENZDL_enzyme_\") and enzyme_total_suffix in x.id\n",
    ").list_attr(\"id\")\n",
    "relaxation_list = pcmodel.reactions.query(\n",
    "    lambda x: x.id.startswith(f\"RELAX_\")\n",
    ").list_attr(\"id\")\n",
    "budget_list = pcmodel.reactions.query(lambda x: x.id.startswith(f\"PBDL_\")).list_attr(\n",
    "    \"id\"\n",
    ")\n",
    "\n",
    "reaction_enzymes_map = {\n",
    "    rid: tuple(\n",
    "        pcmodel.reactions.query(\n",
    "            lambda x: x.id.startswith(f\"ENZDL_enzyme_{rid}_\")\n",
    "        ).list_attr(\"id\")\n",
    "    )\n",
    "    for rid in min_reaction_list\n",
    "}\n",
    "enzyme_reaction_map = {\n",
    "    enzyme: rid for rid, enzymes in reaction_enzymes_map.items() for enzyme in enzymes\n",
    "}\n",
    "if not enzymes_list:\n",
    "    enzymes_list = [\n",
    "        enzyme\n",
    "        for enzyme, rid in enzyme_reaction_map.items()\n",
    "        if rid in min_reaction_list\n",
    "    ]\n",
    "min_reaction_list += enzymes_list + relaxation_list\n",
    "print(\n",
    "    f\"Number of reactions minimize/maximize (minimum): {len(min_reaction_list)} / {len(pcmodel.reactions)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54897e9c-f167-4d4d-84ad-e1d1d340a621",
   "metadata": {},
   "source": [
    "##### Refined set of PC model reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f77e8-fada-451c-876d-fb3af50ee78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_only_necessary_reactions:\n",
    "    reaction_list = min_reaction_list.copy()\n",
    "else:\n",
    "    list_of_reactions = [getattr(rid, \"_id\", rid) for rid in list_of_reactions]\n",
    "    # No summation variables, only enzyme pairs\n",
    "    reaction_list = sorted(\n",
    "        [\n",
    "            x if isinstance(x, str) else x.id\n",
    "            for x in set(min_reaction_list).union(list_of_reactions)\n",
    "        ]\n",
    "    )\n",
    "print(\n",
    "    f\"Number of reactions minimize/maximize (chosen):: {len(reaction_list)} / {len(pcmodel.reactions)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32b712-9c1d-4c52-991c-e40e79659f2e",
   "metadata": {},
   "source": [
    "## Run pcFVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9b058-479d-47a2-bae3-105d18c02de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = False  # Keep off to use previously computed results\n",
    "\n",
    "pcfva_solutions = {}\n",
    "index_cols = [\"reactions\", \"optimum\", \"model\"]\n",
    "if run_computations:\n",
    "    for idx, pcmodel_sample in enumerate(list_of_pcmodels, start=1):\n",
    "        filepath = Path(f\"{pcfva_results_dirpath}/{pcmodel_sample}_FVAresults.tsv\")\n",
    "        if filepath.exists():\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"{idx}) Already finished {pcmodel_sample}, will load results after finishing remaining models.\"\n",
    "                )\n",
    "            continue\n",
    "\n",
    "        print(\"================================================\")\n",
    "        print(f\"Computing pcFVA results for {pcmodel_sample}\")\n",
    "        print(\"================================================\")\n",
    "        if isinstance(pcmodel_sample, str):\n",
    "            if verbose:\n",
    "                print(f\"Loading {pcmodel_sample}.\")\n",
    "            pcmodel_sample = load_overlay_model(\n",
    "                f\"{dataset_models_dirpath}/{pcmodel_sample}.{ftype}\"\n",
    "            )\n",
    "        try:\n",
    "            optimum_solutions = []\n",
    "            if verbose:\n",
    "                print(f\"Starting simulations for {pcmodel_sample}\")\n",
    "            for optimum_percent in optimum_percents:\n",
    "                pcfva_sol = flux_variability_analysis(\n",
    "                    pcmodel_sample,\n",
    "                    reaction_list=reaction_list,\n",
    "                    loopless=False,\n",
    "                    fraction_of_optimum=optimum_percent,\n",
    "                    processes=COBRA_CONFIGURATION.processes,\n",
    "                )\n",
    "                pcfva_sol.index = pd.MultiIndex.from_tuples(\n",
    "                    [\n",
    "                        (rid, optimum_percent, pcmodel_sample.id)\n",
    "                        for rid in pcfva_sol.index\n",
    "                    ],\n",
    "                    names=index_cols,\n",
    "                )\n",
    "                optimum_solutions.append(pcfva_sol)\n",
    "                if verbose:\n",
    "                    print(f\"Finished pcFVA for percent optimum: {optimum_percent}.\")\n",
    "            pcfva_sol = pd.concat(optimum_solutions, axis=0)\n",
    "            pcfva_sol.to_csv(filepath, sep=\"\\t\", index=True)\n",
    "            pcfva_solutions[str(pcmodel_sample)] = pcfva_sol\n",
    "            if verbose:\n",
    "                print(f\"Finished all simulations for {pcmodel_sample}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"{pcmodel_sample} failed due to an exception.\")\n",
    "            with open(f\"{pcfva_results_dirpath}/pcFVA-errors.log\", \"a\") as file:\n",
    "                file.write(f\"{pcmodel_sample} failed due to an exception. {str(e)}\\n\")\n",
    "\n",
    "    # Load missing solutions if interuptions required\n",
    "    for pcmodel_sample in list_of_pcmodels:\n",
    "        if pcmodel_sample in pcfva_solutions:\n",
    "            continue\n",
    "        filepath = Path(f\"{pcfva_results_dirpath}/{pcmodel_sample}_FVAresults.tsv\")\n",
    "        if filepath.exists():\n",
    "            pcfva_solutions[str(pcmodel_sample)] = pd.read_csv(\n",
    "                filepath, sep=\"\\t\", index_col=index_cols\n",
    "            )\n",
    "    pcfva_solutions = {\n",
    "        k: pcfva_solutions[k] for k in list_of_pcmodels if k in pcfva_solutions\n",
    "    }\n",
    "\n",
    "if pcfva_solutions:\n",
    "    df_pcfva_all = pd.concat(list(pcfva_solutions.values()), axis=0)\n",
    "    # Regroup solutions\n",
    "    df_pcfva_all = df_pcfva_all.sort_index(level=index_cols).reset_index(drop=False)\n",
    "    df_pcfva_all.to_csv(\n",
    "        f\"{dataset_path}/{pcmodel.id}_FVAresults_ALL.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "else:\n",
    "    df_pcfva_all = pd.DataFrame()\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7cefd-e3bb-4240-8b90-d69db8635f42",
   "metadata": {},
   "source": [
    "## Load pcFVA generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a12d9-85cb-4ea7-b2a5-5882debb1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if results were recently generated in this run, otherwise load DataFrame of generated results\n",
    "try:\n",
    "    assert not df_pcfva_all.empty\n",
    "except (NameError, AssertionError):\n",
    "    df_pcfva_all = pd.read_csv(\n",
    "        f\"{dataset_path}/{pcmodel.id}_{dataset_name}_FVAresults_ALL.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index_col=None,\n",
    "    )\n",
    "    # Filter out results for models not in the desired model list\n",
    "\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f7f40-8067-4277-ab18-7e600c82af53",
   "metadata": {},
   "source": [
    "#### Export minimum and maximum ranges for dataset specific PC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1a7a0-4f5d-4870-a1c1-1eebdc1d7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reaction_ranges = df_pcfva_all.groupby([\"reactions\"]).agg(\n",
    "    {\n",
    "        \"minimum\": \"min\",\n",
    "        \"maximum\": \"max\",\n",
    "    }\n",
    ")\n",
    "df_reaction_ranges.to_csv(\n",
    "    f\"{dataset_path}/{pcmodel.id}_{dataset_name}_reaction_bounds.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=True,\n",
    ")\n",
    "df_reaction_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6eb414-f71a-4f2e-8bcb-640c7e3488de",
   "metadata": {},
   "source": [
    "### Parse main results into smaller DataFrames\n",
    "#### Seperate by reaction variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae1cb0-bae7-47d1-b41f-98992c03a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize entries with prefixes used for seperating DataFrames\n",
    "dict_of_dataframes_types = {\n",
    "    \"reactions\": None,\n",
    "    \"proteins\": \"PROTDL\",\n",
    "    # \"complexes\": \"CPLXFM\",\n",
    "    # \"complex_dilutions\": \"CPLXDL\",\n",
    "    \"enzymes\": \"ENZDL\",\n",
    "    # \"enzyme_formation\": \"ENZFM\",\n",
    "    \"budgets\": \"PBDL\",\n",
    "    \"relaxation\": \"RELAX\",\n",
    "}\n",
    "for key, prefix in dict_of_dataframes_types.copy().items():\n",
    "    if prefix:\n",
    "        df = df_pcfva_all[\n",
    "            df_pcfva_all[\"reactions\"].apply(lambda x: x.startswith(prefix))\n",
    "        ]\n",
    "    else:\n",
    "        df = df_pcfva_all[\n",
    "            df_pcfva_all[\"reactions\"].apply(lambda x: x in model.reactions)\n",
    "        ]\n",
    "    dict_of_dataframes_types[key] = df.copy()\n",
    "\n",
    "dict_of_dataframes_types;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8742473-5a5b-4471-822f-eaa612a2c658",
   "metadata": {},
   "source": [
    "#### Seperate by optimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2bac0-c7e7-491e-ab8e-a4e0f9ad785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_of_dataframes_opt = {\n",
    "#     optimum: df_pcfva_all[df_pcfva_all[\"optimum\"] == optimum].copy()\n",
    "#     for optimum in df_pcfva_all[\"optimum\"].unique()\n",
    "# }\n",
    "# print(list(dict_of_dataframes_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23e55b-5a2d-4580-983c-7f8227c39b95",
   "metadata": {},
   "source": [
    "#### Seperate by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea597bab-442b-4abd-ac75-825fdcea2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_of_dataframes_model = {\n",
    "#     model_id: df_pcfva_all[df_pcfva_all[\"model\"] == model_id].copy()\n",
    "#     for model_id in df_pcfva_all[\"model\"].unique()\n",
    "# }\n",
    "# print(list(dict_of_dataframes_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6476fbf-f086-4152-ab98-135440043c40",
   "metadata": {},
   "source": [
    "### Create DataFrame for correlation calculations\n",
    "#### Get maximum reaction fluxes and associated abundance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dfceb-c9dc-48df-8b31-f0d158a68d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_list = [\"model\", \"reactions\"]\n",
    "always_abundance_independent = [\n",
    "    r.id for r in model.reactions.query(lambda x: not x.boundary and not x.genes)\n",
    "]\n",
    "print(\n",
    "    f\"Number of reactions w/o genes, always abundance independent: {len(always_abundance_independent)}\"\n",
    ")\n",
    "always_abundance_independent;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19cb9f9-871f-41f4-a572-e92dcff48cf4",
   "metadata": {},
   "source": [
    "##### Get maximum reaction flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e67907-f746-460b-ab45-60efcd10eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum value of the reaction flux in each direction, regardless of percent optimum\n",
    "df = dict_of_dataframes_types[\"reactions\"].copy()\n",
    "df = df.groupby(groupby_list)[[\"minimum\", \"maximum\"]].agg(\n",
    "    {\n",
    "        \"minimum\": \"min\",\n",
    "        \"maximum\": \"max\",\n",
    "    }\n",
    ")\n",
    "df_max_flux_per_model = df.abs().max(axis=1)\n",
    "df_max_flux_per_model.name = \"Flux\"\n",
    "df_max_flux_per_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb9fb8-7e7d-4ba2-8de4-7051c13af472",
   "metadata": {},
   "source": [
    "##### Get maximum flux range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a99639-204d-4286-b3d4-2191e1d38b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine flux range\n",
    "df = dict_of_dataframes_types[\"reactions\"].copy()\n",
    "df[\"Range\"] = df[\"maximum\"] - df[\"minimum\"]\n",
    "df_flux_range_per_model = df.groupby(groupby_list)[\"Range\"].max()\n",
    "df_flux_range_per_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ea1ef-8ee4-41c6-83da-67b659756066",
   "metadata": {},
   "source": [
    "##### Get maximum abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d80d2e-1a14-41f2-b34d-e8929b5dc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine span association with reaction\n",
    "df = dict_of_dataframes_types[\"enzymes\"].copy()\n",
    "df[\"reactions\"] = df[\"reactions\"].apply(lambda x: enzyme_reaction_map[x])\n",
    "df_max_enzyme_per_model = df.groupby(groupby_list)[\"maximum\"].max()\n",
    "df_max_enzyme_per_model.name = \"Abundance\"\n",
    "df_max_enzyme_per_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17d54c-92ff-4cf7-ad1a-00f25ab25b1f",
   "metadata": {},
   "source": [
    "##### Merge into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edc286-d63c-44cb-ae79-7e90abeaa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reaction_flux_abundance = (\n",
    "    pd.merge(\n",
    "        df_max_flux_per_model,\n",
    "        df_flux_range_per_model,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    .merge(df_max_enzyme_per_model, left_index=True, right_index=True)\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df_reaction_flux_abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba9cef-0b08-4410-bb7f-5fe1269d617e",
   "metadata": {},
   "source": [
    "### Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044e8f9-4a4c-4e70-8702-ee52a00657c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_correlation_df(df, pvalue_tol):\n",
    "    df[\"pvalue\"] = df[\"pvalue\"].apply(\n",
    "        lambda x: -np.log10(x if x >= pvalue_tol else pvalue_tol)\n",
    "    )\n",
    "    df = df.sort_values([\"pvalue\", \"rho\"], ascending=[False, False])\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_correlations(\n",
    "    df, ax=None, histx=True, histy=True, colorbar=True, vertical_lines=None, **kwargs\n",
    "):\n",
    "    # Define figure if no axes provided.\n",
    "    scatter_inch = kwargs.get(\"scatter_inch\", 5.0)\n",
    "    hist_inch = kwargs.get(\"hist_inch\", 1.0)\n",
    "    hist_pad = kwargs.get(\"hist_pad\", 0.25)\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(\n",
    "            nrows=1,\n",
    "            ncols=1,\n",
    "            figsize=(\n",
    "                scatter_inch + (hist_inch + hist_pad if histy else 0),\n",
    "                scatter_inch + (hist_inch + hist_pad if histx else 0),\n",
    "            ),\n",
    "        )\n",
    "    # X-axis is rho, Y-axis is expected as -log10(pvalue) from correlation prep\n",
    "    xy = {\"x\": \"rho\", \"y\": \"pvalue\"}\n",
    "    limits = {\n",
    "        \"x\": (kwargs.get(\"xmin\", -1.0), kwargs.get(\"xmax\", 1.0)),\n",
    "        \"y\": (kwargs.get(\"ymin\", 0.0), kwargs.get(\"ymax\", df[xy[\"y\"]].max())),\n",
    "    }\n",
    "    pads = {\n",
    "        axis: kwargs.get(f\"{axis}pad\", (limits[axis][1] - limits[axis][0]) / 2 / 20)\n",
    "        for axis in list(xy)\n",
    "    }\n",
    "    cmap = kwargs.get(\"cmap\", \"viridis\")\n",
    "    zorder = kwargs.get(\"zorder\", 2)\n",
    "    edgecolor = kwargs.get(\"edgecolor\", \"black\")\n",
    "    edgewidth = kwargs.get(\"edgewidth\", 0.5)\n",
    "    scatter = ax.scatter(\n",
    "        xy[\"x\"],\n",
    "        xy[\"y\"],\n",
    "        data=df,\n",
    "        c=kwargs.get(\"c\", xy[\"y\"]),\n",
    "        s=kwargs.get(\"s\", 40),\n",
    "        zorder=zorder,\n",
    "        edgecolor=edgecolor,\n",
    "        linewidth=edgewidth,\n",
    "        cmap=mpl.colormaps.get_cmap(cmap) if isinstance(cmap, str) else cmap,\n",
    "        norm=mpl.colors.Normalize(\n",
    "            vmin=limits[\"y\"][0] - pads[\"y\"], vmax=limits[\"y\"][1] + pads[\"y\"]\n",
    "        ),\n",
    "    )\n",
    "    ax.set_xlabel(r\"Spearman Correlation $(\\rho)$\", fontdict={\"size\": \"xx-large\"})\n",
    "    ax.set_ylabel(\"-log$_{10}$(p-value)\", fontdict={\"size\": \"xx-large\"})\n",
    "    ax.set_xlim((limits[\"x\"][0] - pads[\"x\"], limits[\"x\"][1] + pads[\"x\"]))\n",
    "    ax.set_ylim((limits[\"y\"][0] - pads[\"y\"], limits[\"y\"][1] + pads[\"y\"]))\n",
    "\n",
    "    major_ticks = {axis: kwargs.get(f\"{axis}tick_major\") for axis in list(xy)}\n",
    "    minor_ticks = {\n",
    "        axis: kwargs.get(\n",
    "            f\"{axis}tick_minor\",\n",
    "            major_ticks[axis] / 2 if major_ticks[axis] is not None else None,\n",
    "        )\n",
    "        for axis in list(xy)\n",
    "    }\n",
    "    for axis in list(xy):\n",
    "        if major_ticks[axis] is not None:\n",
    "            getattr(ax, f\"{axis}axis\").set_major_locator(\n",
    "                mpl.ticker.MultipleLocator(major_ticks[axis])\n",
    "            )\n",
    "        if minor_ticks[axis] is not None:\n",
    "            getattr(ax, f\"{axis}axis\").set_minor_locator(\n",
    "                mpl.ticker.MultipleLocator(minor_ticks[axis])\n",
    "            )\n",
    "        ax.tick_params(axis=axis, labelsize=\"large\")\n",
    "\n",
    "    if vertical_lines:\n",
    "        for lineval, (lineprops, textprops) in vertical_lines.items():\n",
    "            if lineprops:\n",
    "                ax.vlines(\n",
    "                    x=lineval,\n",
    "                    ymin=limits[\"y\"][0] - pads[\"y\"],\n",
    "                    ymax=limits[\"y\"][1] + pads[\"y\"],\n",
    "                    **lineprops,\n",
    "                )\n",
    "            if textprops:\n",
    "                ax.text(x=lineval + pads[\"x\"] / 2, transform=ax.transData, **textprops)\n",
    "\n",
    "    if kwargs.get(\"grid\", False):\n",
    "        ax.grid(True, **dict(which=\"both\", alpha=0.75))\n",
    "\n",
    "    if colorbar:\n",
    "        cax = ax.inset_axes(\n",
    "            [\n",
    "                limits[\"x\"][0] - pads[\"x\"],  # lower left corner xpos\n",
    "                limits[\"y\"][0] - pads[\"y\"],  # lower left corner ypos\n",
    "                pads[\"x\"],  # width of colorbar\n",
    "                limits[\"y\"][1]\n",
    "                + pads[\"y\"]\n",
    "                + pads[\n",
    "                    \"y\"\n",
    "                ],  # height of colorbar, need extra ypad to make up for lowering ypos\n",
    "            ],\n",
    "            transform=ax.transData,\n",
    "        )\n",
    "        cbar = ax.get_figure().colorbar(scatter, cax=cax)\n",
    "        cax.set_ylim((limits[\"y\"][0] - pads[\"y\"], limits[\"y\"][1] + pads[\"y\"]))\n",
    "        cax.set_xticks([])\n",
    "        cax.set_yticks([])\n",
    "\n",
    "    ax_histx = None\n",
    "    ax_histy = None\n",
    "    if histx or histy:\n",
    "        divider = make_axes_locatable(ax)\n",
    "        # Histogram axes\n",
    "        ax_histx = (\n",
    "            divider.append_axes(\"top\", hist_inch, pad=hist_pad, sharex=ax)\n",
    "            if histx\n",
    "            else None\n",
    "        )\n",
    "        ax_histy = (\n",
    "            divider.append_axes(\"right\", hist_inch, pad=hist_pad, sharey=ax)\n",
    "            if histy\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        for axis, ax_hist in zip(list(xy), [ax_histx, ax_histy]):\n",
    "            if ax_hist is None:\n",
    "                continue\n",
    "            binwidth = kwargs.get(\n",
    "                f\"{axis}binwidth\",\n",
    "                (\n",
    "                    minor_ticks[axis]\n",
    "                    if minor_ticks[axis] is not None\n",
    "                    else major_ticks[axis]\n",
    "                ),\n",
    "            )\n",
    "            counts, bins, patches = ax_hist.hist(\n",
    "                df[xy[axis]],\n",
    "                bins=np.arange(limits[axis][0], limits[axis][1] + binwidth, binwidth),\n",
    "                orientation=\"vertical\" if axis == \"x\" else \"horizontal\",\n",
    "                zorder=zorder,\n",
    "                edgecolor=edgecolor,\n",
    "                linewidth=edgewidth,\n",
    "            )\n",
    "            other = \"y\" if axis == \"x\" else \"x\"\n",
    "            ax_hist.tick_params(\n",
    "                axis=axis, **{f\"label{'bottom' if axis == 'x' else 'left'}\": False}\n",
    "            )\n",
    "            ax_hist.tick_params(axis=other, labelsize=\"large\")\n",
    "            getattr(ax_hist, f\"set_{other}label\")(\"Frequency\", fontsize=\"large\")\n",
    "\n",
    "            tick_major_int = kwargs.get(f\"hist{axis}_{other}tick_major\")\n",
    "            if tick_major_int is not None:\n",
    "                getattr(ax_hist, f\"{other}axis\").set_major_locator(\n",
    "                    mpl.ticker.MultipleLocator(tick_major_int)\n",
    "                )\n",
    "                getattr(ax_hist, f\"{other}axis\").set_minor_locator(\n",
    "                    mpl.ticker.MultipleLocator(tick_major_int / 2)\n",
    "                )\n",
    "            getattr(ax_hist, f\"set_{other}lim\")((0, max(counts) * 1.1))\n",
    "            if kwargs.get(\"grid\", False):\n",
    "                ax_hist.grid(True, **dict(which=\"both\", alpha=0.75))\n",
    "\n",
    "            if vertical_lines and (axis == \"x\" and ax_hist is not None):\n",
    "                for lineval, (lineprops, _) in vertical_lines.items():\n",
    "                    if lineprops:\n",
    "                        ax_hist.vlines(\n",
    "                            x=lineval, ymin=0.0, ymax=max(counts) * 1.1, **lineprops\n",
    "                        )\n",
    "\n",
    "    return ax, ax_histx, ax_histy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8894ec-dd74-4f3e-9ead-9348dcc47b4a",
   "metadata": {},
   "source": [
    "### Create subgroups of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af894f3-5652-464b-a197-059240cdbd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't include mean/median in correlation calculations\n",
    "model_groups = {\n",
    "    \"ALL\": [\n",
    "        x\n",
    "        for x in list_of_pcmodels\n",
    "        if not any([op.capitalize() in x for op in operations])\n",
    "    ],\n",
    "    \"OPERATIONS\": operation_model_ids,\n",
    "}\n",
    "# model_groups.update({\n",
    "#     f\"{time_prefix}{time}\": [x for x in model_groups[\"ALL\"] if x.endswith(f\"{time_prefix}{time}\")]\n",
    "#     for time in timepoints\n",
    "# })\n",
    "list(model_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae761ba-04c4-425f-bc0a-c403d116081d",
   "metadata": {},
   "source": [
    "### Compute correlations between maximum flux and abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d44225-0f81-4d75-a42a-dca67d633909",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_rankings_group_dict = defaultdict(dict)\n",
    "verbose = False\n",
    "reaction_list = list(df_reaction_flux_abundance[\"reactions\"].unique())\n",
    "corr_results_dirpath = Path(f\"{dataset_path}/correlations\")\n",
    "corr_results_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1cde1-a8dc-4bf2-a83a-74d6a77f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = False  # Keep off to use previously computed results\n",
    "\n",
    "group_name = \"ALL\"\n",
    "column_pair = (\"Flux\", \"Abundance\")\n",
    "\n",
    "if group_name in operations or group_name == \"OPERATIONS\":\n",
    "    raise Exception(\"Cannot use models created using data from statistical operations.\")\n",
    "\n",
    "group_model_list = model_groups[group_name]\n",
    "\n",
    "\n",
    "filepath = Path(f\"{corr_results_dirpath}/{column_pair[0]}_{column_pair[1]}.tsv\")\n",
    "if filepath.exists() and not run_computations:\n",
    "    print(\n",
    "        \"Already computed correlations between '{}' and '{}' for '{}' models\".format(\n",
    "            *column_pair, group_name\n",
    "        )\n",
    "    )\n",
    "    df_correlations = pd.read_csv(f\"{filepath}\", sep=\"\\t\", index_col=0)\n",
    "    df_correlations = df_correlations.loc[reaction_list]\n",
    "elif run_computations:\n",
    "    print(\"=========================================================================\")\n",
    "    print(\n",
    "        \"Computing correlations between '{}' and '{}' for '{}' models\".format(\n",
    "            *column_pair, group_name\n",
    "        )\n",
    "    )\n",
    "    print(\"=========================================================================\")\n",
    "    correlations_dict = defaultdict(dict)\n",
    "    model_list = group_model_list.copy()\n",
    "    for rid in reaction_list:\n",
    "        df = df_reaction_flux_abundance[df_reaction_flux_abundance[\"reactions\"] == rid]\n",
    "        df = df.drop(\"reactions\", axis=1)\n",
    "        df = df.set_index(\"model\")\n",
    "        # Expected warnings emitted are due to constant input array, in which the correlation coefficient is not defined. Corresponds to the nan values.\n",
    "        with warnings.catch_warnings(action=\"ignore\"):\n",
    "            rho, pvalue = spearmanr(df.loc[model_list, list(column_pair)])\n",
    "        correlations_dict[rid][\"rho\"] = rho\n",
    "        correlations_dict[rid][\"pvalue\"] = pvalue\n",
    "        if verbose:\n",
    "            print(f\"For reaction {rid}: rho={rho}, p={pvalue}\")\n",
    "    df_correlations = pd.DataFrame.from_dict(correlations_dict, orient=\"index\")\n",
    "    df_correlations.to_csv(f\"{filepath}\", sep=\"\\t\", index=True)\n",
    "else:\n",
    "    df_correlations = pd.DataFrame()\n",
    "\n",
    "spearman_rankings_group_dict[group_name][column_pair] = df_correlations\n",
    "spearman_rankings_group_dict[group_name][column_pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22138e-4dfc-4bce-b3ac-f3b843bfb069",
   "metadata": {},
   "source": [
    "#### Visualize correlation results\n",
    "##### Set common visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad33f3f-ecc7-4726-9e70-bc9f440e6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistent plot dimensions and values\n",
    "pvalue_tol = 1e-320\n",
    "scatter_inch = 5  # Length x width of scatter plot\n",
    "hist_inch = 1  # Length or width of histogram addition\n",
    "hist_pad = 0.4  # Space between scatter and histogram\n",
    "cmap = \"viridis\"\n",
    "edgecolor = \"black\"\n",
    "edgewidth = 0.5\n",
    "grid = False\n",
    "zorder = 2\n",
    "histx = True\n",
    "histy = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0ef4e-d2ad-4e66-b054-3bb0edc3c4c2",
   "metadata": {},
   "source": [
    "##### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8447b-5954-449d-9434-e11e351b8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"ALL\"  # Use models in visualizations\n",
    "column_pair = (\"Flux\", \"Abundance\")\n",
    "xmin, xmax = (-0.60, 1.00)\n",
    "xpad = 0.05\n",
    "\n",
    "plot_kwargs = dict(\n",
    "    xmin=xmin,\n",
    "    xmax=xmax,\n",
    "    xpad=xpad,\n",
    "    edgecolor=edgecolor,\n",
    "    edgewidth=edgewidth,\n",
    "    cmap=cmap,\n",
    "    zorder=zorder,\n",
    "    scatter_inch=scatter_inch,\n",
    "    hist_inch=hist_inch,\n",
    "    hist_pad=hist_pad,\n",
    "    grid=grid,\n",
    "    xtick_major=0.2,\n",
    "    xtick_minor=0.1,  # Determines minor tick and thus bin size if not otherwise set\n",
    "    # xbinwidth=0.1, # Determined by minor ticks if not otherwise set\n",
    "    histx_ytick_major=100,  # Major y-tick interval for histogram aligned with x-axis\n",
    "    ytick_major=40,\n",
    "    ytick_minor=10,  # Determines minor tick and thus bin size if not otherwise set\n",
    "    # ybinwidth=10,  # Determined by minor ticks if not otherwise set\n",
    "    histy_xtick_major=500,  # Major x-tick interval for histogram aligned with y-axis\n",
    ")\n",
    "\n",
    "\n",
    "df_corr = spearman_rankings_group_dict[group_name][column_pair].copy()\n",
    "# Remove correlations that could not be calculated due to fixed/blocked flux\n",
    "df_corr = df_corr[~df_corr.isna().any(axis=1)]\n",
    "df_corr = prepare_correlation_df(df_corr, pvalue_tol=pvalue_tol)\n",
    "\n",
    "# For abundance lines\n",
    "abundance_dep_rho_lb = 0.8\n",
    "abundance_cor_rho_lb = 0.5\n",
    "ypos = 4\n",
    "ww = 11\n",
    "rotation = 90\n",
    "fontsize = \"large\"\n",
    "linewidth = 2\n",
    "vertical_lines = {\n",
    "    abundance_dep_rho_lb: (\n",
    "        dict(color=\"black\", linestyle=\"-\", linewidth=linewidth),\n",
    "        dict(\n",
    "            y=ypos,\n",
    "            s=\"\\n\".join(textwrap.wrap(\"Abundance dependent\", width=ww)),\n",
    "            rotation=rotation,\n",
    "            fontsize=fontsize,\n",
    "        ),\n",
    "    ),\n",
    "    abundance_cor_rho_lb: (\n",
    "        dict(color=\"xkcd:dark grey\", linestyle=\"--\", linewidth=linewidth),\n",
    "        dict(\n",
    "            y=ypos,\n",
    "            s=\"\\n\".join(textwrap.wrap(\"Abundance correlated\", width=ww)),\n",
    "            rotation=rotation,\n",
    "            fontsize=fontsize,\n",
    "        ),\n",
    "    ),\n",
    "    xmin: (\n",
    "        dict(),\n",
    "        dict(\n",
    "            y=ypos,\n",
    "            s=\"\\n\".join(textwrap.wrap(\"Abundance independent\", width=ww)),\n",
    "            rotation=rotation,\n",
    "            fontsize=fontsize,\n",
    "        ),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "nrows, ncols = (1, 1)\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(\n",
    "        (scatter_inch + (hist_inch + hist_pad if histx else 0)) * ncols,\n",
    "        (scatter_inch + (hist_inch + hist_pad if histy else 0)) * nrows,\n",
    "    ),\n",
    ")\n",
    "ax_scatter, ax_histx, ax_histy = plot_correlations(\n",
    "    df_corr,\n",
    "    ax=ax,\n",
    "    histx=histx,\n",
    "    histy=histy,\n",
    "    colorbar=True,\n",
    "    vertical_lines=vertical_lines,\n",
    "    **plot_kwargs,\n",
    ")\n",
    "ax_scatter.set_title(\n",
    "    f\"Correlates between Flux and Abundance\",\n",
    "    fontsize=\"x-large\",\n",
    ")\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        f\"{figures_path}/Fig5_PanelG_FluxAbunCorrelates.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec723f45-4001-4836-9cb9-92bc29149f10",
   "metadata": {},
   "source": [
    "### Enrich results with subsystems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542a424-af15-4b29-b0ee-ca20eb8bc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pathways = pd.read_csv(\n",
    "    f\"{data_path}/subsystems.tsv\", sep=\"\\t\", index_col=0, dtype=str\n",
    ")\n",
    "cat_cols = [\"subsystem\", \"category\"]\n",
    "df_pathways = df_pathways.fillna(\"\").reset_index()\n",
    "\n",
    "# Categories that should be excluded from the figure\n",
    "categories_to_exclude = {\"Pseudoreactions\", \"Model total\"}\n",
    "# Main categories in figure and abbreviations, all unmapped categories are mapped to \"Other\"\n",
    "categories_to_keep = {\n",
    "    \"Amino acid metabolism\": mpl.cm.spring,\n",
    "    \"Carbohydrate metabolism\": mpl.cm.Greens,\n",
    "    \"Lipid metabolism\": mpl.cm.Blues,\n",
    "    \"Metabolism of cofactors and vitamins\": mpl.cm.summer,\n",
    "    \"Nucleotide metabolism\": mpl.cm.winter,\n",
    "    \"Reactive species\": mpl.cm.Reds,\n",
    "    \"Transport reactions\": mpl.cm.Purples,\n",
    "    \"Other\": mpl.cm.gray_r,\n",
    "}\n",
    "use_abbrevs = True\n",
    "abbrevs = {\n",
    "    \"Amino acid metabolism\": \"A\",\n",
    "    \"Carbohydrate metabolism\": \"C\",\n",
    "    \"Lipid metabolism\": \"L\",\n",
    "    \"Metabolism of cofactors and vitamins\": \"V\",\n",
    "    \"Nucleotide metabolism\": \"N\",\n",
    "    \"Reactive species\": \"R\",\n",
    "    \"Transport reactions\": \"T\",\n",
    "    \"Other\": \"O\",\n",
    "}\n",
    "barsize = 0.8\n",
    "cmax = 0.8\n",
    "cmin = 0.15\n",
    "\n",
    "\n",
    "colormaps_normal = dict(\n",
    "    zip(\n",
    "        categories_to_keep,\n",
    "        [\n",
    "            cmap_map(lambda x: x * 1, categories_to_keep[k])(cmax)\n",
    "            for k in categories_to_keep\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "category_colors = {key: tuple(value(cmax)) for key, value in categories_to_keep.items()}\n",
    "\n",
    "# Group \"Metabolism of other amino acids\" with amino acids rather than treat as \"other\"\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].replace(\n",
    "    \"Metabolism of other amino acids\", \"Amino acid metabolism\"\n",
    ")\n",
    "df_pathways = df_pathways.rename({\"name\": \"subsystem\"}, axis=1)\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].apply(\n",
    "    lambda category: (\n",
    "        \"Other\"\n",
    "        if (\n",
    "            category not in categories_to_keep and category not in categories_to_exclude\n",
    "        )\n",
    "        else category\n",
    "    )\n",
    ")\n",
    "mapping_dict = df_pathways[cat_cols].set_index(\"subsystem\").squeeze().to_dict()\n",
    "\n",
    "df_pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9c42b-a3bf-449f-85df-925e29144934",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"ALL\"\n",
    "column_pair = (\"Flux\", \"Abundance\")\n",
    "df_correlations_flux_abundance = spearman_rankings_group_dict[group_name][\n",
    "    column_pair\n",
    "].copy()\n",
    "gene_map = {\n",
    "    r: build_string(sorted([g.id for g in pcmodel.reactions.get_by_id(r).genes]))\n",
    "    for r in df_correlations_flux_abundance.index\n",
    "}\n",
    "df_correlations_flux_abundance.index = pd.MultiIndex.from_tuples(\n",
    "    [(r, gene_map[r]) for r in df_correlations_flux_abundance.index],\n",
    "    names=(\"reaction\", \"genes\"),\n",
    ")\n",
    "df_correlations_flux_abundance = df_correlations_flux_abundance.reset_index(drop=False)\n",
    "df_correlations_flux_abundance = df_correlations_flux_abundance.sort_values(\n",
    "    [\"pvalue\", \"rho\", \"genes\", \"reaction\"], ascending=[True, False, True, True]\n",
    ")\n",
    "df_correlations_flux_abundance = df_correlations_flux_abundance.reset_index(drop=True)\n",
    "df_correlations_flux_abundance[\"subsystem\"] = df_correlations_flux_abundance[\n",
    "    \"reaction\"\n",
    "].apply(lambda x: model.reactions.get_by_id(x).subsystem)\n",
    "df_correlations_flux_abundance = df_correlations_flux_abundance.merge(\n",
    "    df_pathways[[\"subsystem\", \"category\"]],\n",
    "    left_on=\"subsystem\",\n",
    "    right_on=\"subsystem\",\n",
    ")\n",
    "df_correlations_flux_abundance.to_csv(\n",
    "    f\"{dataset_path}/{pcmodel.id}_{dataset_name}_FLUXABUN_CORRELATIONS.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "df_blocked_w_abun = df_correlations_flux_abundance[\n",
    "    df_correlations_flux_abundance[[\"rho\", \"pvalue\"]].isna().all(axis=1)\n",
    "]\n",
    "df_abun_dep = df_correlations_flux_abundance.loc[\n",
    "    df_correlations_flux_abundance[\n",
    "        df_correlations_flux_abundance[\"rho\"] >= abundance_dep_rho_lb\n",
    "    ].index\n",
    "]\n",
    "df_abun_cor = df_correlations_flux_abundance.loc[\n",
    "    df_correlations_flux_abundance[\n",
    "        df_correlations_flux_abundance[\"rho\"] < abundance_dep_rho_lb\n",
    "    ].index\n",
    "]\n",
    "df_abun_cor = df_abun_cor.loc[\n",
    "    df_abun_cor[df_abun_cor[\"rho\"] >= abundance_cor_rho_lb].index\n",
    "]\n",
    "df_abun_ind = df_correlations_flux_abundance.loc[\n",
    "    df_correlations_flux_abundance[\n",
    "        df_correlations_flux_abundance[\"rho\"] < abundance_cor_rho_lb\n",
    "    ].index\n",
    "]\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Number of abundance dependent reactions\\t({abundance_dep_rho_lb} <= rho      ): {len(df_abun_dep)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of abundance correlated reactions\\t({abundance_cor_rho_lb} <= rho < {abundance_dep_rho_lb}): {len(df_abun_cor)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of abundance independent reactions\\t(       rho < {abundance_cor_rho_lb}): {len(df_abun_ind)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of blocked reactions with associated abundance:\\t{len(df_blocked_w_abun)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of spontaneous reactions (no gene association):\\t{len(always_abundance_independent)}\"\n",
    ")\n",
    "df_correlations_flux_abundance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d7034-ff08-42a9-9453-b52ef8760721",
   "metadata": {},
   "source": [
    "#### Abundance dependent\n",
    "##### Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e4286-c82b-4ca0-8842-169a9ac86ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df_abun_dep.copy()\n",
    "abun_cutoff = \"$\\\\rho \\\\geq$\" + f\"{abundance_dep_rho_lb}\"\n",
    "\n",
    "df_counts = df_counts[\"subsystem\"].value_counts()\n",
    "df_counts = (\n",
    "    df_pathways[df_pathways[\"subsystem\"] != \"Pseudoreactions\"][\n",
    "        [\"subsystem\", \"category\"]\n",
    "    ]\n",
    "    .merge(\n",
    "        df_counts,\n",
    "        left_on=\"subsystem\",\n",
    "        right_on=\"subsystem\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "df_counts[\"category\"] = df_counts[\"category\"].apply(\n",
    "    lambda x: (\n",
    "        \"Other\" if x not in categories_to_keep and x not in categories_to_exclude else x\n",
    "    )\n",
    ")\n",
    "df_counts = df_counts.groupby([\"category\", \"subsystem\"])[[\"count\"]].sum().astype(int)\n",
    "df_counts = df_counts.reset_index(drop=False).sort_values(\n",
    "    by=[\"category\", \"count\"], ascending=[True, False]\n",
    ")\n",
    "df_counts_subsystem = df_counts.set_index(\"subsystem\")\n",
    "df_counts = df_counts.groupby([\"category\"]).agg(\n",
    "    {\"subsystem\": lambda x: list(x), \"count\": \"size\"}\n",
    ")\n",
    "\n",
    "colors = {}\n",
    "# Set colors\n",
    "for category, (subsystems, size) in df_counts.iterrows():\n",
    "    colors.update(\n",
    "        dict(\n",
    "            zip(\n",
    "                subsystems,\n",
    "                categories_to_keep[category](np.linspace(cmax - 0.1, cmin, size)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "df_counts_subsystem[\"color\"] = colors\n",
    "df_counts_subsystem = df_counts_subsystem.reset_index(drop=False)\n",
    "df_counts_category = df_counts_subsystem.groupby(\"category\")[[\"count\"]].sum()\n",
    "df_counts_category[\"color\"] = category_colors\n",
    "df_counts_category[\"abbrev\"] = {k: abbrevs[k] for k in df_counts_category.index}\n",
    "df_counts_category = df_counts_category.reset_index(drop=False)\n",
    "\n",
    "\n",
    "df_ring0, df_ring1 = df_counts_category, df_counts_subsystem\n",
    "fig_ring, ax_ring = plt.subplots(1, 1, figsize=(3.3, 3.3))\n",
    "\n",
    "wedgesize = 0.43\n",
    "radius = 1\n",
    "startangle = -30\n",
    "linewidth = 0.75\n",
    "edgecolor = \"k\"\n",
    "labeldistance = 1.2\n",
    "\n",
    "# ring_idx = 1\n",
    "# labeldistance += wedgesize\n",
    "# ax_ring.pie(\n",
    "#     df_ring1[\"count\"].values,\n",
    "#     radius=radius + (ring_idx * wedgesize),\n",
    "#     colors=df_ring1[\"color\"].values,\n",
    "#     # labels=df_ring1[\"name\"].values,\n",
    "#     wedgeprops=dict(\n",
    "#         width=wedgesize, linewidth=linewidth, edgecolor=edgecolor, clip_on=False\n",
    "#     ),\n",
    "#     textprops={\"fontsize\": \"large\", \"va\": \"center\", \"ha\": \"center\"},\n",
    "#     startangle=startangle,\n",
    "# )\n",
    "# Use for nice legend\n",
    "labels = [\n",
    "    \"{}({})\".format(k, v)\n",
    "    for k, v in zip(\n",
    "        df_ring0[\"abbrev\"].values if use_abbrevs else df_ring0[\"category\"].values,\n",
    "        df_ring0[\"count\"].values,\n",
    "    )\n",
    "]\n",
    "ring_idx = 0\n",
    "total = df_ring0[\"count\"].sum()\n",
    "\n",
    "ax_ring.pie(\n",
    "    df_ring0[\"count\"].values,\n",
    "    radius=radius + (ring_idx * wedgesize),\n",
    "    colors=df_ring0[\"color\"].values,\n",
    "    wedgeprops=dict(\n",
    "        width=wedgesize, linewidth=linewidth, edgecolor=edgecolor, clip_on=False\n",
    "    ),\n",
    "    textprops={\"fontsize\": \"x-large\", \"va\": \"center\", \"ha\": \"center\"},\n",
    "    startangle=startangle,\n",
    "    labeldistance=labeldistance,\n",
    "    labels=df_ring0[\"count\"].values,\n",
    ")\n",
    "ax_ring.annotate(\n",
    "    text=f\"{abun_cutoff}\\n{total} reactions\",\n",
    "    xy=(0, 0),\n",
    "    transform=ax.transAxes,\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=\"x-large\",\n",
    ")\n",
    "fig_ring.tight_layout()\n",
    "if save_figures:\n",
    "    fig_ring.savefig(\n",
    "        f\"{figures_path}/Fig5_PanelH_AbunDepReactions.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig_ring;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904373c-7d37-437a-9db6-df7abaf357d2",
   "metadata": {},
   "source": [
    "##### Genes/Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d658b-17b7-4ddc-ad85-bf45ef1ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticklabels_on_bars = True\n",
    "hits_seperator = 50\n",
    "cutoff = 10\n",
    "df = df_abun_dep.copy()\n",
    "df[\"genes\"] = df[\"genes\"].apply(split_string)\n",
    "df = df.explode(\"genes\")\n",
    "list_of_genes = list(df[\"genes\"].unique())\n",
    "list_of_categories = list(df[\"category\"].unique())\n",
    "\n",
    "df_main = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            gene: df[df[\"genes\"] == gene][\"category\"].value_counts().to_dict()\n",
    "            for gene in list_of_genes\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "df_main.index.name = \"genes\"\n",
    "df_main = pd.concat(\n",
    "    (\n",
    "        df_main,\n",
    "        df.groupby(\"genes\")[\"reaction\"].agg(lambda x: tuple(list(x.unique()))),\n",
    "    ),\n",
    "    axis=1,\n",
    ").reset_index(drop=False)\n",
    "df_main = df_main.set_index(\"genes\")\n",
    "df_to_group = df_main[df_main.duplicated(keep=False)].reset_index(drop=False)\n",
    "df_to_group = (\n",
    "    df_to_group.groupby(list(df_to_group.columns[1:]))\n",
    "    .agg(\n",
    "        {\n",
    "            \"genes\": lambda x: build_string(x),\n",
    "        }\n",
    "    )\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df_main = pd.concat(\n",
    "    (\n",
    "        df_main[~df_main.duplicated(keep=False)],\n",
    "        df_to_group.set_index(\"genes\"),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "df_main[\"total\"] = df_main.loc[:, list_of_categories].sum(axis=1)\n",
    "df_main = df_main.sort_values(by=\"total\", ascending=False)\n",
    "df_top_hits = df_main[df_main[\"total\"] >= cutoff]\n",
    "df_bot_hits = df_main[df_main[\"total\"] < cutoff]\n",
    "\n",
    "df_main = df_main[df_main[\"total\"] >= cutoff]\n",
    "df_upper = df_top_hits[df_top_hits[\"total\"] > hits_seperator].sort_values(\n",
    "    by=\"total\", ascending=True\n",
    ")\n",
    "df_main = df_top_hits[df_top_hits[\"total\"] <= hits_seperator]\n",
    "\n",
    "print(df_main.shape)\n",
    "df_main = df_main.sort_values(by=\"total\", ascending=True)\n",
    "\n",
    "if not df_upper.empty:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2,\n",
    "        ncols=1,\n",
    "        figsize=(5, 10),\n",
    "        height_ratios=[len(df_upper) / len(df_main), 1 - len(df_upper) / len(df_main)],\n",
    "        gridspec_kw=dict(hspace=0.1),\n",
    "    )\n",
    "    ax_upper, ax_main = axes.flatten()\n",
    "else:\n",
    "    fig, ax_main = plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n",
    "    ax_upper = None\n",
    "\n",
    "df = df_main\n",
    "ax = ax_main\n",
    "scalar = 1\n",
    "offset = np.zeros(len(df.index))\n",
    "height = 0.8\n",
    "for i, category in enumerate(list_of_categories):\n",
    "    series = df[category]\n",
    "    color = category_colors[category]\n",
    "    rects = ax.barh(\n",
    "        np.arange(0, len(series.index)) * 1,\n",
    "        series.values,\n",
    "        tick_label=series.index,\n",
    "        height=height,\n",
    "        left=offset,\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    offset += series.values\n",
    "    if i == len(list_of_categories) - 1 and ticklabels_on_bars:\n",
    "        ax.bar_label(rects, series.index, padding=10)\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "ax.set_ymargin(0.01)\n",
    "ax.set_xlim((0, scalar * 60 - 5))\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(scalar * 10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(scalar * 10 / 2))\n",
    "ax.xaxis.set_tick_params(labelsize=\"large\")\n",
    "ax.yaxis.set_tick_params(labelsize=\"medium\")\n",
    "ax.set_xlabel(\"Number of associated reactions\", fontsize=\"large\")\n",
    "\n",
    "if not df_upper.empty:\n",
    "    df = df_upper\n",
    "    ax = ax_upper\n",
    "    scalar = 5\n",
    "    offset = np.zeros(len(df.index))\n",
    "    for i, category in enumerate(list_of_categories):\n",
    "        series = df[category]\n",
    "        color = category_colors[category]\n",
    "        rects = ax.barh(\n",
    "            np.arange(0, len(series.index)) * 1.0,\n",
    "            series.values,\n",
    "            tick_label=series.index,\n",
    "            height=height,\n",
    "            left=offset,\n",
    "            color=color,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "        offset += series.values\n",
    "        if i == len(list_of_categories) - 1 and ticklabels_on_bars:\n",
    "            ax.bar_label(rects, series.index, padding=10)\n",
    "            ax.set_yticklabels([])\n",
    "    ax.set_ymargin(0.01)\n",
    "    ax.set_xlim((0, (scalar + 1) * 50 - 25))\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(scalar * 10))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(scalar * 10 / 2))\n",
    "    ax.yaxis.set_tick_params\n",
    "    ax.xaxis.set_tick_params(labelsize=\"large\")\n",
    "    ax.yaxis.set_tick_params(labelsize=\"large\")\n",
    "\n",
    "sns.despine(fig)\n",
    "\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        f\"{figures_path}/Fig5_PanelI_AbunDepProteins.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41086f35-7350-41ef-89bc-084cc14b4e65",
   "metadata": {},
   "source": [
    "#### Abundance correlated\n",
    "##### Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0d910-de0e-4908-9407-f3d51b7d8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df_abun_cor.copy()\n",
    "abun_cutoff = f\"{abundance_cor_rho_lb}\" + \"$\\\\leq \\\\rho <$\" + f\"{abundance_dep_rho_lb}\"\n",
    "\n",
    "df_counts = df_counts[\"subsystem\"].value_counts()\n",
    "df_counts = (\n",
    "    df_pathways[df_pathways[\"subsystem\"] != \"Pseudoreactions\"][\n",
    "        [\"subsystem\", \"category\"]\n",
    "    ]\n",
    "    .merge(\n",
    "        df_counts,\n",
    "        left_on=\"subsystem\",\n",
    "        right_on=\"subsystem\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "df_counts[\"category\"] = df_counts[\"category\"].apply(\n",
    "    lambda x: (\n",
    "        \"Other\" if x not in categories_to_keep and x not in categories_to_exclude else x\n",
    "    )\n",
    ")\n",
    "df_counts = df_counts.groupby([\"category\", \"subsystem\"])[[\"count\"]].sum().astype(int)\n",
    "df_counts = df_counts.reset_index(drop=False).sort_values(\n",
    "    by=[\"category\", \"count\"], ascending=[True, False]\n",
    ")\n",
    "df_counts_subsystem = df_counts.set_index(\"subsystem\")\n",
    "df_counts = df_counts.groupby([\"category\"]).agg(\n",
    "    {\"subsystem\": lambda x: list(x), \"count\": \"size\"}\n",
    ")\n",
    "\n",
    "colors = {}\n",
    "# Set colors\n",
    "for category, (subsystems, size) in df_counts.iterrows():\n",
    "    colors.update(\n",
    "        dict(\n",
    "            zip(\n",
    "                subsystems,\n",
    "                categories_to_keep[category](np.linspace(cmax - 0.1, cmin, size)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "df_counts_subsystem[\"color\"] = colors\n",
    "df_counts_subsystem = df_counts_subsystem.reset_index(drop=False)\n",
    "df_counts_category = df_counts_subsystem.groupby(\"category\")[[\"count\"]].sum()\n",
    "df_counts_category[\"color\"] = category_colors\n",
    "df_counts_category[\"abbrev\"] = {k: abbrevs[k] for k in df_counts_category.index}\n",
    "df_counts_category = df_counts_category.reset_index(drop=False)\n",
    "\n",
    "\n",
    "df_ring0, df_ring1 = df_counts_category, df_counts_subsystem\n",
    "fig_ring, ax_ring = plt.subplots(1, 1, figsize=(3.3, 3.3))\n",
    "\n",
    "wedgesize = 0.43\n",
    "radius = 1\n",
    "startangle = -30\n",
    "linewidth = 0.75\n",
    "edgecolor = \"k\"\n",
    "labeldistance = 1.2\n",
    "\n",
    "# ring_idx = 1\n",
    "# labeldistance += wedgesize\n",
    "# ax_ring.pie(\n",
    "#     df_ring1[\"count\"].values,\n",
    "#     radius=radius + (ring_idx * wedgesize),\n",
    "#     colors=df_ring1[\"color\"].values,\n",
    "#     # labels=df_ring1[\"name\"].values,\n",
    "#     wedgeprops=dict(\n",
    "#         width=wedgesize, linewidth=linewidth, edgecolor=edgecolor, clip_on=False\n",
    "#     ),\n",
    "#     textprops={\"fontsize\": \"large\", \"va\": \"center\", \"ha\": \"center\"},\n",
    "#     startangle=startangle,\n",
    "# )\n",
    "# Use for nice legend\n",
    "labels = [\n",
    "    \"{}({})\".format(k, v)\n",
    "    for k, v in zip(\n",
    "        df_ring0[\"abbrev\"].values if use_abbrevs else df_ring0[\"category\"].values,\n",
    "        df_ring0[\"count\"].values,\n",
    "    )\n",
    "]\n",
    "ring_idx = 0\n",
    "total = df_ring0[\"count\"].sum()\n",
    "\n",
    "ax_ring.pie(\n",
    "    df_ring0[\"count\"].values,\n",
    "    radius=radius + (ring_idx * wedgesize),\n",
    "    colors=df_ring0[\"color\"].values,\n",
    "    wedgeprops=dict(\n",
    "        width=wedgesize, linewidth=linewidth, edgecolor=edgecolor, clip_on=False\n",
    "    ),\n",
    "    textprops={\"fontsize\": \"x-large\", \"va\": \"center\", \"ha\": \"center\"},\n",
    "    startangle=startangle,\n",
    "    labeldistance=labeldistance,\n",
    "    labels=df_ring0[\"count\"].values,\n",
    ")\n",
    "ax_ring.annotate(\n",
    "    text=f\"{abun_cutoff}\\n{total} reactions\",\n",
    "    xy=(0, 0),\n",
    "    transform=ax.transAxes,\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=\"x-large\",\n",
    ")\n",
    "fig_ring.tight_layout()\n",
    "if save_figures:\n",
    "    fig_ring.savefig(\n",
    "        f\"{figures_path}/Fig5_PanelH_ExprCorReactions.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig_ring;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6ca11-8c29-49fb-a4fd-88c6b6cd4478",
   "metadata": {},
   "source": [
    "##### Genes/Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c635a51-d753-47d8-bfc5-01b66143e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticklabels_on_bars = True\n",
    "hits_seperator = 60\n",
    "cutoff = 3\n",
    "df = df_abun_cor.copy()\n",
    "df[\"genes\"] = df[\"genes\"].apply(split_string)\n",
    "df = df.explode(\"genes\")\n",
    "list_of_genes = list(df[\"genes\"].unique())\n",
    "list_of_categories = list(df[\"category\"].unique())\n",
    "\n",
    "df_main = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            gene: df[df[\"genes\"] == gene][\"category\"].value_counts().to_dict()\n",
    "            for gene in list_of_genes\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "df_main.index.name = \"genes\"\n",
    "df_main = pd.concat(\n",
    "    (\n",
    "        df_main,\n",
    "        df.groupby(\"genes\")[\"reaction\"].agg(lambda x: tuple(list(x.unique()))),\n",
    "    ),\n",
    "    axis=1,\n",
    ").reset_index(drop=False)\n",
    "df_main = df_main.set_index(\"genes\")\n",
    "df_to_group = df_main[df_main.duplicated(keep=False)].reset_index(drop=False)\n",
    "df_to_group = (\n",
    "    df_to_group.groupby(list(df_to_group.columns[1:]))\n",
    "    .agg(\n",
    "        {\n",
    "            \"genes\": lambda x: build_string(x),\n",
    "        }\n",
    "    )\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df_main = pd.concat(\n",
    "    (\n",
    "        df_main[~df_main.duplicated(keep=False)],\n",
    "        df_to_group.set_index(\"genes\"),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "df_main[\"total\"] = df_main.loc[:, list_of_categories].sum(axis=1)\n",
    "df_main = df_main.sort_values(by=\"total\", ascending=False)\n",
    "df_top_hits = df_main[df_main[\"total\"] >= cutoff]\n",
    "df_bot_hits = df_main[df_main[\"total\"] < cutoff]\n",
    "\n",
    "df_main = df_main[df_main[\"total\"] >= cutoff]\n",
    "df_upper = df_top_hits[df_top_hits[\"total\"] > hits_seperator].sort_values(\n",
    "    by=\"total\", ascending=True\n",
    ")\n",
    "df_main = df_top_hits[df_top_hits[\"total\"] <= hits_seperator]\n",
    "\n",
    "print(df_main.shape)\n",
    "df_main = df_main.sort_values(by=\"total\", ascending=True)\n",
    "\n",
    "if not df_upper.empty:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2,\n",
    "        ncols=1,\n",
    "        figsize=(5, 10),\n",
    "        height_ratios=[len(df_upper) / len(df_main), 1 - len(df_upper) / len(df_main)],\n",
    "        gridspec_kw=dict(hspace=0.1),\n",
    "    )\n",
    "    ax_upper, ax_main = axes.flatten()\n",
    "else:\n",
    "    fig, ax_main = plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n",
    "    ax_upper = None\n",
    "\n",
    "df = df_main\n",
    "ax = ax_main\n",
    "scalar = 1\n",
    "offset = np.zeros(len(df.index))\n",
    "height = 0.8\n",
    "for i, category in enumerate(list_of_categories):\n",
    "    series = df[category]\n",
    "    color = category_colors[category]\n",
    "    rects = ax.barh(\n",
    "        np.arange(0, len(series.index)) * 1,\n",
    "        series.values,\n",
    "        tick_label=series.index,\n",
    "        height=height,\n",
    "        left=offset,\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    offset += series.values\n",
    "    if i == len(list_of_categories) - 1 and ticklabels_on_bars:\n",
    "        ax.bar_label(rects, series.index, padding=10)\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "ax.set_ymargin(0.01)\n",
    "ax.set_xlim((0, scalar * hits_seperator))\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(scalar * 10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(scalar * 10 / 2))\n",
    "ax.xaxis.set_tick_params(labelsize=\"large\")\n",
    "ax.yaxis.set_tick_params(labelsize=\"medium\")\n",
    "ax.set_xlabel(\"Number of associated reactions\", fontsize=\"large\")\n",
    "\n",
    "if not df_upper.empty:\n",
    "    df = df_upper\n",
    "    ax = ax_upper\n",
    "    scalar = 5\n",
    "    offset = np.zeros(len(df.index))\n",
    "    for i, category in enumerate(list_of_categories):\n",
    "        series = df[category]\n",
    "        color = category_colors[category]\n",
    "        rects = ax.barh(\n",
    "            np.arange(0, len(series.index)) * 1.0,\n",
    "            series.values,\n",
    "            tick_label=series.index,\n",
    "            height=height,\n",
    "            left=offset,\n",
    "            color=color,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "        offset += series.values\n",
    "        if i == len(list_of_categories) - 1 and ticklabels_on_bars:\n",
    "            ax.bar_label(rects, series.index, padding=10)\n",
    "            ax.set_yticklabels([])\n",
    "    ax.set_ymargin(0.01)\n",
    "    ax.set_xlim((0, (scalar + 1) * 50 - 25))\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(scalar * 10))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(scalar * 10 / 2))\n",
    "    ax.yaxis.set_tick_params\n",
    "    ax.xaxis.set_tick_params(labelsize=\"large\")\n",
    "    ax.yaxis.set_tick_params(labelsize=\"large\")\n",
    "\n",
    "sns.despine(fig)\n",
    "\n",
    "# if save_figures:\n",
    "# fig.savefig(\n",
    "#     f\"{figures_path}/Fig5_Panel_ExprDepProteins.{imagetype}\",\n",
    "#     transparent=transparent,\n",
    "#     format=imagetype,\n",
    "# )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab167b0-b811-49b6-9db5-309e26edd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_hits.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee5d84-2610-44e8-80ac-5a205ad34a08",
   "metadata": {},
   "source": [
    "#### Abundance independent\n",
    "##### Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76636c-04ea-44a7-8e7b-61113065c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = pd.concat((df_abun_ind, df_blocked_w_abun), axis=0)\n",
    "abun_cutoff = abundance_cor_rho_lb\n",
    "abun_cutoff = \"$\\\\rho <$\" + f\"{abundance_cor_rho_lb}\"\n",
    "\n",
    "df_counts = df_counts[\"subsystem\"].value_counts()\n",
    "df_counts = (\n",
    "    df_pathways[df_pathways[\"subsystem\"] != \"Pseudoreactions\"][\n",
    "        [\"subsystem\", \"category\"]\n",
    "    ]\n",
    "    .merge(\n",
    "        df_counts,\n",
    "        left_on=\"subsystem\",\n",
    "        right_on=\"subsystem\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "df_counts[\"category\"] = df_counts[\"category\"].apply(\n",
    "    lambda x: (\n",
    "        \"Other\" if x not in categories_to_keep and x not in categories_to_exclude else x\n",
    "    )\n",
    ")\n",
    "df_counts = df_counts.groupby([\"category\", \"subsystem\"])[[\"count\"]].sum().astype(int)\n",
    "df_counts = df_counts.reset_index(drop=False).sort_values(\n",
    "    by=[\"category\", \"count\"], ascending=[True, False]\n",
    ")\n",
    "df_counts_subsystem = df_counts.set_index(\"subsystem\")\n",
    "df_counts = df_counts.groupby([\"category\"]).agg(\n",
    "    {\"subsystem\": lambda x: list(x), \"count\": \"size\"}\n",
    ")\n",
    "\n",
    "colors = {}\n",
    "# Set colors\n",
    "for category, (subsystems, size) in df_counts.iterrows():\n",
    "    colors.update(\n",
    "        dict(\n",
    "            zip(\n",
    "                subsystems,\n",
    "                categories_to_keep[category](np.linspace(cmax - 0.1, cmin, size)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "df_counts_subsystem[\"color\"] = colors\n",
    "df_counts_subsystem = df_counts_subsystem.reset_index(drop=False)\n",
    "df_counts_category = df_counts_subsystem.groupby(\"category\")[[\"count\"]].sum()\n",
    "df_counts_category[\"color\"] = category_colors\n",
    "df_counts_category[\"abbrev\"] = {k: abbrevs[k] for k in df_counts_category.index}\n",
    "df_counts_category = df_counts_category.reset_index(drop=False)\n",
    "\n",
    "\n",
    "df_ring0, df_ring1 = df_counts_category, df_counts_subsystem\n",
    "fig_ring, ax_ring = plt.subplots(1, 1, figsize=(3.3, 3.3))\n",
    "\n",
    "wedgesize = 0.43\n",
    "radius = 1\n",
    "startangle = -30\n",
    "linewidth = 0.75\n",
    "edgecolor = \"k\"\n",
    "labeldistance = 1.2\n",
    "\n",
    "# ring_idx = 1\n",
    "# labeldistance += wedgesize\n",
    "# ax_ring.pie(\n",
    "#     df_ring1[\"count\"].values,\n",
    "#     radius=radius + (ring_idx * wedgesize),\n",
    "#     colors=df_ring1[\"color\"].values,\n",
    "#     # labels=df_ring1[\"name\"].values,\n",
    "#     wedgeprops=dict(\n",
    "#         width=wedgesize, linewidth=linewidth, edgecolor=edgecolor, clip_on=False\n",
    "#     ),\n",
    "#     textprops={\"fontsize\": \"large\", \"va\": \"center\", \"ha\": \"center\"},\n",
    "#     startangle=startangle,\n",
    "# )\n",
    "# Use for nice legend\n",
    "labels = [\n",
    "    \"{}({})\".format(k, v)\n",
    "    for k, v in zip(\n",
    "        df_ring0[\"abbrev\"].values if use_abbrevs else df_ring0[\"category\"].values,\n",
    "        df_ring0[\"count\"].values,\n",
    "    )\n",
    "]\n",
    "ring_idx = 0\n",
    "total = df_ring0[\"count\"].sum()\n",
    "\n",
    "ax_ring.pie(\n",
    "    df_ring0[\"count\"].values,\n",
    "    radius=radius + (ring_idx * wedgesize),\n",
    "    colors=df_ring0[\"color\"].values,\n",
    "    wedgeprops=dict(\n",
    "        width=wedgesize, linewidth=linewidth, edgecolor=edgecolor, clip_on=False\n",
    "    ),\n",
    "    textprops={\"fontsize\": \"x-large\", \"va\": \"center\", \"ha\": \"center\"},\n",
    "    startangle=startangle,\n",
    "    labeldistance=labeldistance,\n",
    "    labels=df_ring0[\"count\"].values,\n",
    ")\n",
    "ax_ring.annotate(\n",
    "    text=f\"{abun_cutoff}\\n{total} reactions\",\n",
    "    xy=(0, 0),\n",
    "    transform=ax.transAxes,\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=\"x-large\",\n",
    ")\n",
    "fig_ring.tight_layout()\n",
    "if save_figures:\n",
    "    fig_ring.savefig(\n",
    "        f\"{figures_path}/Fig5_Panel_AbunIndepProteins.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig_ring;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e70b1-48be-47b0-964b-bc6d0b90a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticklabels_on_bars = True\n",
    "hits_seperator = 70\n",
    "cutoff = 3\n",
    "df = df_abun_ind.copy()\n",
    "df[\"genes\"] = df[\"genes\"].apply(split_string)\n",
    "df = df.explode(\"genes\")\n",
    "list_of_genes = list(df[\"genes\"].unique())\n",
    "list_of_categories = list(df[\"category\"].unique())\n",
    "\n",
    "df_main = (\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            gene: df[df[\"genes\"] == gene][\"category\"].value_counts().to_dict()\n",
    "            for gene in list_of_genes\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "df_main.index.name = \"genes\"\n",
    "df_main = pd.concat(\n",
    "    (\n",
    "        df_main,\n",
    "        df.groupby(\"genes\")[\"reaction\"].agg(lambda x: tuple(list(x.unique()))),\n",
    "    ),\n",
    "    axis=1,\n",
    ").reset_index(drop=False)\n",
    "df_main = df_main.set_index(\"genes\")\n",
    "df_to_group = df_main[df_main.duplicated(keep=False)].reset_index(drop=False)\n",
    "df_to_group = (\n",
    "    df_to_group.groupby(list(df_to_group.columns[1:]))\n",
    "    .agg(\n",
    "        {\n",
    "            \"genes\": lambda x: build_string(x),\n",
    "        }\n",
    "    )\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df_main = pd.concat(\n",
    "    (\n",
    "        df_main[~df_main.duplicated(keep=False)],\n",
    "        df_to_group.set_index(\"genes\"),\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "df_main[\"total\"] = df_main.loc[:, list_of_categories].sum(axis=1)\n",
    "df_main = df_main.sort_values(by=\"total\", ascending=False)\n",
    "df_top_hits = df_main[df_main[\"total\"] >= cutoff]\n",
    "df_bot_hits = df_main[df_main[\"total\"] < cutoff]\n",
    "\n",
    "df_main = df_main[df_main[\"total\"] >= cutoff]\n",
    "df_upper = df_top_hits[df_top_hits[\"total\"] > hits_seperator].sort_values(\n",
    "    by=\"total\", ascending=True\n",
    ")\n",
    "df_main = df_top_hits[df_top_hits[\"total\"] <= hits_seperator]\n",
    "\n",
    "print(df_main.shape)\n",
    "df_main = df_main.sort_values(by=\"total\", ascending=True)\n",
    "\n",
    "if not df_upper.empty:\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2,\n",
    "        ncols=1,\n",
    "        figsize=(5, 10),\n",
    "        height_ratios=[len(df_upper) / len(df_main), 1 - len(df_upper) / len(df_main)],\n",
    "        gridspec_kw=dict(hspace=0.1),\n",
    "    )\n",
    "    ax_upper, ax_main = axes.flatten()\n",
    "else:\n",
    "    fig, ax_main = plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n",
    "    ax_upper = None\n",
    "\n",
    "df = df_main\n",
    "ax = ax_main\n",
    "scalar = 1\n",
    "offset = np.zeros(len(df.index))\n",
    "height = 0.8\n",
    "for i, category in enumerate(list_of_categories):\n",
    "    series = df[category]\n",
    "    color = category_colors[category]\n",
    "    rects = ax.barh(\n",
    "        np.arange(0, len(series.index)) * 1,\n",
    "        series.values,\n",
    "        tick_label=series.index,\n",
    "        height=height,\n",
    "        left=offset,\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    offset += series.values\n",
    "    if i == len(list_of_categories) - 1 and ticklabels_on_bars:\n",
    "        ax.bar_label(rects, series.index, padding=10)\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "ax.set_ymargin(0.01)\n",
    "ax.set_xlim((0, scalar * hits_seperator))\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(scalar * 10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(scalar * 10 / 2))\n",
    "ax.xaxis.set_tick_params(labelsize=\"large\")\n",
    "ax.yaxis.set_tick_params(labelsize=\"medium\")\n",
    "ax.set_xlabel(\"Number of associated reactions\", fontsize=\"large\")\n",
    "\n",
    "if not df_upper.empty:\n",
    "    df = df_upper\n",
    "    ax = ax_upper\n",
    "    scalar = 5\n",
    "    offset = np.zeros(len(df.index))\n",
    "    for i, category in enumerate(list_of_categories):\n",
    "        series = df[category]\n",
    "        color = category_colors[category]\n",
    "        rects = ax.barh(\n",
    "            np.arange(0, len(series.index)) * 1.0,\n",
    "            series.values,\n",
    "            tick_label=series.index,\n",
    "            height=height,\n",
    "            left=offset,\n",
    "            color=color,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "        offset += series.values\n",
    "        if i == len(list_of_categories) - 1 and ticklabels_on_bars:\n",
    "            ax.bar_label(rects, series.index, padding=10)\n",
    "            ax.set_yticklabels([])\n",
    "    ax.set_ymargin(0.01)\n",
    "    ax.set_xlim((0, (scalar + 1) * 50 - 25))\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(scalar * 10))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(scalar * 10 / 2))\n",
    "    ax.yaxis.set_tick_params\n",
    "    ax.xaxis.set_tick_params(labelsize=\"large\")\n",
    "    ax.yaxis.set_tick_params(labelsize=\"large\")\n",
    "\n",
    "sns.despine(fig)\n",
    "\n",
    "# if save_figures:\n",
    "#     fig.savefig(\n",
    "#         f\"{figures_path}/Fig5_Panel_AbunIndepProteins.{imagetype}\",\n",
    "#         transparent=transparent,\n",
    "#         format=imagetype,\n",
    "#     )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514dc8a-9632-4fa6-8f04-dfbfaea7a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_abun_dep.copy()\n",
    "df[\"genes\"] = df[\"genes\"].apply(split_string)\n",
    "df = df.explode(\"genes\")\n",
    "dep_genes = set(df[\"genes\"].unique())\n",
    "dep_genes\n",
    "\n",
    "df = df_abun_cor.copy()\n",
    "df[\"genes\"] = df[\"genes\"].apply(split_string)\n",
    "df = df.explode(\"genes\")\n",
    "cor_genes = set(df[\"genes\"].unique())\n",
    "\n",
    "df = df_abun_ind.copy()\n",
    "df[\"genes\"] = df[\"genes\"].apply(split_string)\n",
    "df = df.explode(\"genes\")\n",
    "ind_genes = set(df[\"genes\"].unique())\n",
    "\n",
    "venn = mpl_venn.venn3(\n",
    "    subsets=[dep_genes, cor_genes, ind_genes],\n",
    "    set_labels=[\n",
    "        \"Abundance\\ndependent\",\n",
    "        \"Abundance\\ncorrelated\",\n",
    "        \"Abundance\\nindependent\",\n",
    "    ],\n",
    "    set_colors=(\"xkcd:red\", \"xkcd:blue\", \"xkcd:green\"),\n",
    "    alpha=0.5,\n",
    "    # ax=ax1,\n",
    ")\n",
    "circles = mpl_venn.venn3_circles(\n",
    "    subsets=[dep_genes, cor_genes, ind_genes], linestyle=\"-\", color=\"black\", linewidth=1\n",
    ")\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(\"x-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98255d2c-792f-4a9a-93e8-88f44688d931",
   "metadata": {},
   "source": [
    "#### Compute correlation matrices for correlations between fluxes and correlation between abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f1960-4b95-4836-a244-f8101f55820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flux = df_reaction_flux_abundance.pivot(\n",
    "    columns=\"model\", index=\"reactions\", values=\"Flux\"\n",
    ")\n",
    "df_flux_corr_all = df_flux.T.corr(method=\"spearman\")\n",
    "df_flux_corr_all.to_csv(\n",
    "    f\"{dataset_path}/{pcmodel.id}_{dataset_name}_FLUX_CORR_MAT.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=True,\n",
    ")\n",
    "nan_list = list(df_flux_corr_all.index[~df_flux_corr_all.isna().all(axis=0)])\n",
    "df_flux_corr = df_flux_corr_all.loc[nan_list, nan_list]\n",
    "\n",
    "\n",
    "df_abun = df_reaction_flux_abundance.pivot(\n",
    "    columns=\"model\", index=\"reactions\", values=\"Abundance\"\n",
    ")\n",
    "df_abun_corr_all = df_abun.T.corr(method=\"spearman\")\n",
    "df_abun_corr = df_abun_corr_all.loc[nan_list, nan_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c41ce-a8c8-4f85-9cf5-6edf858524d9",
   "metadata": {},
   "source": [
    "##### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a67e7-2e25-4576-9304-ca26bf338be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted(\n",
    "    df_flux_corr.index,\n",
    "    key=lambda x: (mapping_dict[model.reactions.get_by_id(x).subsystem], x),\n",
    ")\n",
    "df = df_flux_corr.loc[df]\n",
    "fig = sns.clustermap(\n",
    "    df,\n",
    "    figsize=(20, 12),\n",
    "    cmap=\"coolwarm\",\n",
    "    row_cluster=True,\n",
    "    col_cluster=True,\n",
    "    row_colors=[\n",
    "        category_colors[mapping_dict[model.reactions.get_by_id(x).subsystem]]\n",
    "        for x in df.index\n",
    "    ],\n",
    "    col_colors=[\n",
    "        category_colors[mapping_dict[model.reactions.get_by_id(x).subsystem]]\n",
    "        for x in df.index\n",
    "    ],\n",
    ")\n",
    "fig.data.to_csv(\n",
    "    f\"{dataset_path}/{pcmodel.id}_{dataset_name}_FLUX_CORR_MAT.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=True,\n",
    ")\n",
    "ax_heatmap = fig.ax_heatmap\n",
    "ax_heatmap.set_xlabel(\"Reactions\", fontsize=\"x-large\")\n",
    "ax_heatmap.xaxis.set_ticklabels([])\n",
    "\n",
    "ax_heatmap.set_ylabel(\"Reactions\", fontsize=\"x-large\")\n",
    "ax_heatmap.yaxis.set_ticklabels([])\n",
    "fig.ax_row_dendrogram.set_visible(False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc1ccb-6c0a-41fa-90ec-6d5ed0d9d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted(\n",
    "    df_abun_corr.index,\n",
    "    key=lambda x: (mapping_dict[model.reactions.get_by_id(x).subsystem], x),\n",
    ")\n",
    "df = df_abun_corr.loc[df]\n",
    "fig = sns.clustermap(\n",
    "    df,\n",
    "    figsize=(20, 12),\n",
    "    cmap=\"coolwarm\",\n",
    "    row_cluster=True,\n",
    "    col_cluster=True,\n",
    "    row_colors=[\n",
    "        category_colors[mapping_dict[model.reactions.get_by_id(x).subsystem]]\n",
    "        for x in df.index\n",
    "    ],\n",
    "    col_colors=[\n",
    "        category_colors[mapping_dict[model.reactions.get_by_id(x).subsystem]]\n",
    "        for x in df.index\n",
    "    ],\n",
    ")\n",
    "fig.data.to_csv(\n",
    "    f\"{dataset_path}/{pcmodel.id}_{dataset_name}_ABUN_CORR_MAT.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=True,\n",
    ")\n",
    "ax_heatmap = fig.ax_heatmap\n",
    "ax_heatmap.set_xlabel(\"Reactions\", fontsize=\"x-large\")\n",
    "ax_heatmap.xaxis.set_ticklabels([])\n",
    "\n",
    "ax_heatmap.set_ylabel(\"Reactions\", fontsize=\"x-large\")\n",
    "ax_heatmap.yaxis.set_ticklabels([])\n",
    "fig.ax_row_dendrogram.set_visible(False)\n",
    "fig.ax_col_dendrogram.set_visible(False)\n",
    "fig.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dea031-0ef4-45ee-bebc-93b084556242",
   "metadata": {},
   "source": [
    "### Visualize selected flux results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66466a3-88b3-453b-a6f4-24ef73086aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame for flux values\n",
    "group_name = \"OPERATIONS\"\n",
    "sort_by = [\"time\", \"sample\"]\n",
    "df_flux_all = dict_of_dataframes_types[\"reactions\"].copy()\n",
    "# df_flux_all = df_flux_all[df_flux_all[\"model\"].isin(model_groups[group_name])]\n",
    "df_flux_all[\"time\"] = df_flux_all[\"model\"].apply(\n",
    "    lambda x: get_time_from_id(x, time_prefix=time_prefix)\n",
    ")\n",
    "df_flux_all[\"sample\"] = df_flux_all[\"model\"].apply(\n",
    "    lambda x: get_sample_from_id(x, sample_prefix=sample_prefix)\n",
    ")\n",
    "df_flux_all = df_flux_all.sort_values(by=sort_by)\n",
    "\n",
    "# DataFrame for abundance values\n",
    "df_abun_all = dict_of_dataframes_types[\"enzymes\"].copy()\n",
    "# df_abun = df_abun[df_abun[\"model\"].isin(model_groups[group_name])]\n",
    "df_abun_all[\"time\"] = df_abun_all[\"model\"].apply(\n",
    "    lambda x: get_time_from_id(x, time_prefix=time_prefix)\n",
    ")\n",
    "df_abun_all[\"sample\"] = df_abun_all[\"model\"].apply(\n",
    "    lambda x: get_sample_from_id(x, sample_prefix=sample_prefix)\n",
    ")\n",
    "df_abun_all = df_abun_all.sort_values(by=sort_by)\n",
    "\n",
    "df_abun_all[\"reactions\"] = df_abun_all[\"reactions\"].apply(\n",
    "    lambda x: enzyme_reaction_map[x]\n",
    ")\n",
    "df_abun_all = df_abun_all.groupby(\n",
    "    [\"reactions\", \"model\", \"time\", \"sample\"], as_index=False\n",
    ")[\"maximum\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c52fd5-575e-4b94-8cad-a79a98847d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_group_name = \"Glycolysis\"  # If using same cell for multiple different file exports, change flux_group_name to prevent file overlap\n",
    "\n",
    "\n",
    "optimum_colors = {\n",
    "    0.00: \"xkcd:green\",\n",
    "    0.50: \"xkcd:dark yellow\",\n",
    "    0.90: \"xkcd:orange\",\n",
    "    0.99: \"xkcd:red\",\n",
    "}\n",
    "timepoint_colors = {\n",
    "    \"Day 10\": \"xkcd:white\",\n",
    "    \"Day 23\": \"xkcd:light blue\",\n",
    "    \"Day 42\": \"xkcd:light purple\",\n",
    "}\n",
    "\n",
    "# Leave empty to remove\n",
    "vline_samples = {\n",
    "    # \"Mean\": {\"color\": \"black\", \"linestyle\": \"--\"},\n",
    "    # \"Median\": {\"color\": \"black\", \"linestyle\": \":\"},\n",
    "}\n",
    "equilibrium_line = {\"color\": \"black\", \"linestyle\": \":\"}\n",
    "\n",
    "\n",
    "legend_at_bottom = False\n",
    "time_order_results = True\n",
    "rank_order_results = True\n",
    "sample_order_results = True  # Ignored if rank ordering\n",
    "sharex, sharey = (True, True)\n",
    "obj_rxn = model.reactions.query(lambda x: x.objective_coefficient)[0]\n",
    "\n",
    "fluxes_to_plot = np.array(\n",
    "    [\n",
    "        [\"HEX1\", \"PGI\", \"PFK\", \"TPI\", \"FBA\"],  # Glycolysis\n",
    "        [\"GAPD\", \"PGK\", \"PGM\", \"ENO\", \"PYK\"],  # Glycolysis\n",
    "        [\"LDH_L\", \"DPGM\", \"DPGase\", \"HB23DPGB\", \"NaKt\"],  # Hemoglobin and objective\n",
    "        [\"HEX1a\", \"GLCM\", \"G6PM\", \"\", \"\"],  # Hemoglobin and objective\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "column_pair = (\"Flux\", \"Abundance\")\n",
    "df_rho = spearman_rankings_group_dict[\"ALL\"][column_pair][\"rho\"]\n",
    "df_fluxes_to_plot = df_flux_all[\n",
    "    df_flux_all[\"reactions\"].isin(fluxes_to_plot.flatten())\n",
    "].copy()\n",
    "df_abun_to_plot = df_abun_all[\n",
    "    df_abun_all[\"reactions\"].isin(fluxes_to_plot.flatten())\n",
    "].copy()\n",
    "df_fluxes_to_plot[\"span\"] = df_fluxes_to_plot[\"maximum\"] - df_fluxes_to_plot[\"minimum\"]\n",
    "\n",
    "# Remove mean and medians if not desired\n",
    "df_fluxes_to_plot = df_fluxes_to_plot[\n",
    "    ~df_fluxes_to_plot[\"sample\"].isin(\n",
    "        [\n",
    "            \"Mean\" if \"Mean\" not in vline_samples else \"\",\n",
    "            \"Median\" if \"Median\" not in vline_samples else \"\",\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "timepoints = df_fluxes_to_plot[\"time\"].unique()\n",
    "samples = df_fluxes_to_plot[\"sample\"].unique()\n",
    "optimums = df_fluxes_to_plot[\"optimum\"].unique()\n",
    "index_points = np.arange(1, (len(samples) * len(timepoints)) + 1)\n",
    "\n",
    "sort_by = {}\n",
    "if time_order_results:\n",
    "    sort_by[\"time\"] = True\n",
    "if rank_order_results:\n",
    "    sort_by[\"span\"] = True\n",
    "    sort_by[\"maximum\"] = True\n",
    "    sort_by[\"minimum\"] = True\n",
    "if sample_order_results:\n",
    "    sort_by[\"sample\"] = True\n",
    "\n",
    "\n",
    "nrows, ncols = fluxes_to_plot.shape\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(4 * ncols, 2 * nrows),\n",
    "    sharex=sharex,\n",
    "    sharey=sharey,\n",
    ")\n",
    "axes = np.atleast_2d(axes)\n",
    "\n",
    "mid_col_ind = int(np.ceil(axes.shape[1] / 2)) - 1\n",
    "mid_row_ind = int(np.ceil(axes.shape[0] / 2)) - 1\n",
    "for rid, ax in zip(fluxes_to_plot.flatten(), axes.flatten()):\n",
    "    if not rid:\n",
    "        fig.delaxes(ax)\n",
    "        continue\n",
    "    df_flux_rxn = df_fluxes_to_plot[df_fluxes_to_plot[\"reactions\"] == rid].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    ymin_v, ymax_v = (\n",
    "        df_fluxes_to_plot[\"minimum\"].min() if sharey else df_flux_rxn[\"minimum\"].min(),\n",
    "        df_fluxes_to_plot[\"maximum\"].max() if sharey else df_flux_rxn[\"maximum\"].max(),\n",
    "    )\n",
    "    ypad_v = (\n",
    "        df_fluxes_to_plot[[\"maximum\", \"minimum\"]].abs().max(axis=1).max()\n",
    "        if sharey\n",
    "        else df_flux_rxn[[\"maximum\", \"minimum\"]].abs().max(axis=1).max()\n",
    "    ) * 0.05\n",
    "\n",
    "    if time_order_results:\n",
    "        for multiplier, (timepoint, color) in enumerate(timepoint_colors.items()):\n",
    "            offset = 0\n",
    "            xmin = multiplier * len(samples) - offset\n",
    "            xmax = (multiplier + 1) * len(samples) - offset\n",
    "\n",
    "            if multiplier != 0:\n",
    "                ax.vlines(\n",
    "                    x=xmin,\n",
    "                    ymin=ymin_v - ypad_v,\n",
    "                    ymax=ymax_v + ypad_v,\n",
    "                    linestyle=\"-\",\n",
    "                    color=\"black\",\n",
    "                    linewidth=1.5,\n",
    "                    zorder=5,\n",
    "                )\n",
    "            if (sharex and ax in axes[-1, :]) or not sharex:\n",
    "                ax.text(\n",
    "                    1 / 3 * multiplier + 1 / 3 / 2,\n",
    "                    -0.15,  # Adjust to alter position  of Day 10, 23, 42\n",
    "                    timepoint,\n",
    "                    transform=ax.transAxes,\n",
    "                    ha=\"center\",\n",
    "                    fontsize=\"large\",\n",
    "                )\n",
    "                if sharex and ax == axes[-1, mid_col_ind]:\n",
    "                    ax.set_xlabel(\"Samples\", labelpad=20, fontsize=\"xx-large\")\n",
    "\n",
    "    rho = f\"{df_rho.loc[rid]:.3f}\" if rid in df_rho else \"\\\\text{NaN}\"\n",
    "\n",
    "    ax.set_title(f\"{rid} $(\\\\rho = {rho})$\", fontsize=\"large\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlim((0 - offset, len(index_points) - offset))\n",
    "    ax.set_ylim((ymin_v - ypad_v, ymax_v + ypad_v))\n",
    "\n",
    "    for optimum, color in optimum_colors.items():\n",
    "        df_flux_rxn_opt = df_flux_rxn[df_flux_rxn[\"optimum\"] == optimum]\n",
    "        df_flux_rxn_opt = df_flux_rxn_opt.sort_values(\n",
    "            by=list(sort_by.keys()), ascending=list(sort_by.values())\n",
    "        )\n",
    "        df_flux_rxn_opt = df_flux_rxn_opt.set_index([\"time\", \"sample\"])\n",
    "        lower_line = ax.plot(\n",
    "            index_points,\n",
    "            df_flux_rxn_opt[\"minimum\"].values,\n",
    "            color=color,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        upper_line = ax.plot(\n",
    "            index_points,\n",
    "            df_flux_rxn_opt[\"maximum\"].values,\n",
    "            color=color,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            index_points,\n",
    "            df_flux_rxn_opt[\"minimum\"].values,\n",
    "            df_flux_rxn_opt[\"maximum\"].values,\n",
    "            color=color,\n",
    "            alpha=1,\n",
    "        )\n",
    "\n",
    "    for sample_id, options in vline_samples.items():\n",
    "        color = options[\"color\"]\n",
    "        linestyle = options[\"linestyle\"]\n",
    "        indicies = [\n",
    "            i\n",
    "            for i, (time, sample) in enumerate(df_flux_rxn_opt.index)\n",
    "            if sample == sample_id\n",
    "        ]\n",
    "        for sample_index in index_points[indicies]:\n",
    "            ax.vlines(\n",
    "                x=sample_index,\n",
    "                ymin=ymin - ypad,\n",
    "                ymax=ymax + ypad,\n",
    "                linestyle=linestyle,\n",
    "                color=color,\n",
    "                linewidth=1,\n",
    "                zorder=4,\n",
    "            )\n",
    "    if equilibrium_line:\n",
    "        ax.hlines(\n",
    "            0,\n",
    "            index_points[0],\n",
    "            index_points[-1],\n",
    "            zorder=4,\n",
    "            color=equilibrium_line[\"color\"],\n",
    "            linestyle=equilibrium_line[\"linestyle\"],\n",
    "            linewidth=1,\n",
    "        )\n",
    "\n",
    "    if ax == axes[mid_row_ind, 0]:\n",
    "        ax.set_ylabel(\"Flux (mmol/gDW/hr)\", fontsize=\"xx-large\")\n",
    "    ax.tick_params(axis=\"y\", labelsize=\"x-large\")\n",
    "\n",
    "    if (ax == axes[mid_row_ind, -1] and not legend_at_bottom) or (\n",
    "        ax == axes[-1, mid_col_ind] and legend_at_bottom\n",
    "    ):\n",
    "        legend_handles = [\n",
    "            mpl.patches.Patch(\n",
    "                facecolor=color,\n",
    "                edgecolor=\"black\",\n",
    "                label=(\"  \" if optimum < 0.1 else \"\")\n",
    "                + (f\"{optimum:.0%} Max. {obj_rxn.id}\"),\n",
    "            )\n",
    "            for optimum, color in optimum_colors.items()\n",
    "        ]\n",
    "        legend_handles += [\n",
    "            mpl.lines.Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                linestyle=options[\"linestyle\"],\n",
    "                color=options[\"color\"],\n",
    "                label=sample_id,\n",
    "            )\n",
    "            for sample_id, options in vline_samples.items()\n",
    "        ]\n",
    "        # if equilibrium_line:\n",
    "        #     legend_handles += [mpl.lines.Line2D([0], [0], linestyle=equilibrium_line[\"linestyle\"], color=equilibrium_line[\"color\"], label=\"Equilibrium\")]\n",
    "\n",
    "        if legend_at_bottom:\n",
    "            ax.legend(\n",
    "                handles=legend_handles,\n",
    "                loc=\"upper center\",\n",
    "                bbox_to_anchor=(0.5, -0.3),\n",
    "                fontsize=\"xx-large\",\n",
    "                ncols=len(legend_handles),\n",
    "                frameon=False,\n",
    "            )\n",
    "        else:\n",
    "            ax.legend(\n",
    "                handles=legend_handles,\n",
    "                loc=\"center left\",\n",
    "                bbox_to_anchor=(1, 0.5),\n",
    "                fontsize=\"xx-large\",\n",
    "                ncols=1,\n",
    "                frameon=False,\n",
    "                alignment=\"right\",\n",
    "            )\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    hspace=0.25 if sharex else 0.5,\n",
    "    wspace=0.05 if sharey else 0.2,\n",
    ")\n",
    "\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        f\"{figures_path}/SelectFluxRanges{flux_group_name}_{model.id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa2720-d91a-4629-a88d-51dc00c23ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flux_group_name = \"PPP\" # If using same cell for multiple different file exports, change flux_group_name to prevent file overlap\n",
    "\n",
    "\n",
    "# optimum_colors = {\n",
    "#     0.00: \"xkcd:green\",\n",
    "#     0.50: \"xkcd:dark yellow\",\n",
    "#     0.90: \"xkcd:orange\",\n",
    "#     0.99: \"xkcd:red\",\n",
    "# }\n",
    "# timepoint_colors = {\n",
    "#     \"Day 10\": \"xkcd:white\",\n",
    "#     \"Day 23\": \"xkcd:light blue\",\n",
    "#     \"Day 42\": \"xkcd:light purple\",\n",
    "# }\n",
    "\n",
    "# # Leave empty to remove\n",
    "# vline_samples = {\n",
    "#     # \"Mean\": {\"color\": \"black\", \"linestyle\": \"--\"},\n",
    "#     # \"Median\": {\"color\": \"black\", \"linestyle\": \":\"},\n",
    "# }\n",
    "# equilibrium_line = {\n",
    "#     \"color\": \"black\", \"linestyle\": \":\"\n",
    "# }\n",
    "\n",
    "\n",
    "# legend_at_bottom = False\n",
    "# time_order_results = True\n",
    "# rank_order_results = True\n",
    "# sample_order_results = True # Ignored if rank ordering\n",
    "# sharex, sharey = (True, True)\n",
    "# obj_rxn = model.reactions.query(lambda x: x.objective_coefficient)[0]\n",
    "\n",
    "# fluxes_to_plot = np.array([\n",
    "#     [\"G6PDH2\", \"PGL\", \"GND\", \"\",  \"\"], # Pentose phosphate pathway\n",
    "#     [\"RPE\", \"RPI\", \"TALA\", \"TKT2\", \"TKT1\"], # Pentose phosphate pathway\n",
    "# ])\n",
    "\n",
    "\n",
    "# column_pair = (\"Flux\", \"Abundance\")\n",
    "# df_rho = spearman_rankings_group_dict[\"ALL\"][column_pair][\"rho\"]\n",
    "# df_fluxes_to_plot = df_flux_all[df_flux_all[\"reactions\"].isin(fluxes_to_plot.flatten())].copy()\n",
    "# df_abun_to_plot = df_abun_all[df_abun_all[\"reactions\"].isin(fluxes_to_plot.flatten())].copy()\n",
    "# df_fluxes_to_plot[\"span\"] = df_fluxes_to_plot[\"maximum\"] - df_fluxes_to_plot[\"minimum\"]\n",
    "\n",
    "# # Remove mean and medians if not desired\n",
    "# df_fluxes_to_plot = df_fluxes_to_plot[~df_fluxes_to_plot[\"sample\"].isin([\n",
    "#    \"Mean\" if \"Mean\" not in vline_samples else \"\",\n",
    "#    \"Median\" if \"Median\" not in vline_samples else \"\",\n",
    "# ])]\n",
    "\n",
    "# timepoints = df_fluxes_to_plot[\"time\"].unique()\n",
    "# samples = df_fluxes_to_plot[\"sample\"].unique()\n",
    "# optimums = df_fluxes_to_plot[\"optimum\"].unique()\n",
    "# index_points = np.arange(1, (len(samples) * len(timepoints)) + 1)\n",
    "\n",
    "# sort_by = {}\n",
    "# if time_order_results:\n",
    "#     sort_by[\"time\"] = True\n",
    "# if rank_order_results:\n",
    "#     sort_by[\"span\"] = True\n",
    "#     sort_by[\"maximum\"] = True\n",
    "#     sort_by[\"minimum\"] = True\n",
    "# if sample_order_results:\n",
    "#     sort_by[\"sample\"] = True\n",
    "\n",
    "\n",
    "# nrows, ncols = fluxes_to_plot.shape\n",
    "# fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4*ncols, 2*nrows), sharex=sharex, sharey=sharey)\n",
    "# axes = np.atleast_2d(axes)\n",
    "\n",
    "# mid_col_ind = int(np.ceil(axes.shape[1]/2))-1\n",
    "# mid_row_ind = int(np.ceil(axes.shape[0]/2))-1\n",
    "# for rid, ax in zip(fluxes_to_plot.flatten(), axes.flatten()):\n",
    "#     if not rid:\n",
    "#         fig.delaxes(ax)\n",
    "#         continue\n",
    "#     df_flux_rxn = df_fluxes_to_plot[df_fluxes_to_plot[\"reactions\"] == rid].reset_index(drop=True)\n",
    "#     ymin_v, ymax_v = (\n",
    "#         df_fluxes_to_plot[\"minimum\"].min() if sharey else df_flux_rxn[\"minimum\"].min(),\n",
    "#         df_fluxes_to_plot[\"maximum\"].max() if sharey else df_flux_rxn[\"maximum\"].max()\n",
    "#     )\n",
    "#     ypad_v = (\n",
    "#         df_fluxes_to_plot[[\"maximum\", \"minimum\"]].abs().max(axis=1).max() if sharey\n",
    "#         else df_flux_rxn[[\"maximum\", \"minimum\"]].abs().max(axis=1).max()\n",
    "#     ) * 0.05\n",
    "\n",
    "#     if time_order_results:\n",
    "#         for multiplier, (timepoint, color) in enumerate(timepoint_colors.items()):\n",
    "#             offset = 0\n",
    "#             xmin = multiplier * len(samples) - offset\n",
    "#             xmax = (multiplier + 1) * len(samples) - offset\n",
    "\n",
    "#             if multiplier != 0:\n",
    "#                 ax.vlines(\n",
    "#                     x=xmin,\n",
    "#                     ymin=ymin_v - ypad_v,\n",
    "#                     ymax=ymax_v + ypad_v,\n",
    "#                     linestyle=\"-\",\n",
    "#                     color=\"black\",\n",
    "#                     linewidth=1.5,\n",
    "#                     zorder=5\n",
    "#                 )\n",
    "#             if (sharex and ax in axes[-1, :]) or not sharex:\n",
    "#                 ax.text(\n",
    "#                     1/3 * multiplier + 1/3/2,\n",
    "#                     -0.15,  # Adjust to alter position  of Day 10, 23, 42\n",
    "#                     timepoint,\n",
    "#                     transform=ax.transAxes,\n",
    "#                     ha=\"center\",\n",
    "#                     fontsize=\"large\"\n",
    "#                 )\n",
    "#                 if (sharex and ax == axes[-1, mid_col_ind]):\n",
    "#                     ax.set_xlabel(\"Samples\", labelpad=20, fontsize=\"xx-large\")\n",
    "\n",
    "#     rho = f\"{df_rho.loc[rid]:.3f}\" if rid in df_rho else \"\\\\text{NaN}\"\n",
    "\n",
    "#     ax.set_title(f\"{rid} $(\\\\rho = {rho})$\", fontsize=\"large\")\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_xlim((0 - offset, len(index_points) - offset))\n",
    "#     ax.set_ylim((ymin_v - ypad_v, ymax_v + ypad_v))\n",
    "\n",
    "#     for optimum, color in optimum_colors.items():\n",
    "#         df_flux_rxn_opt = df_flux_rxn[df_flux_rxn[\"optimum\"] == optimum]\n",
    "#         df_flux_rxn_opt = df_flux_rxn_opt.sort_values(by=list(sort_by.keys()), ascending=list(sort_by.values()))\n",
    "#         df_flux_rxn_opt = df_flux_rxn_opt.set_index([\"time\", \"sample\"])\n",
    "#         lower_line = ax.plot(index_points, df_flux_rxn_opt[\"minimum\"].values, color=color, linestyle=\"-\", linewidth=2)\n",
    "#         upper_line = ax.plot(index_points, df_flux_rxn_opt[\"maximum\"].values, color=color, linestyle=\"-\", linewidth=2)\n",
    "#         ax.fill_between(index_points, df_flux_rxn_opt[\"minimum\"].values, df_flux_rxn_opt[\"maximum\"].values, color=color, alpha=1)\n",
    "\n",
    "#     for sample_id, options in vline_samples.items():\n",
    "#         color = options[\"color\"]\n",
    "#         linestyle = options[\"linestyle\"]\n",
    "#         indicies = [i for i, (time, sample) in enumerate(df_flux_rxn_opt.index) if sample == sample_id]\n",
    "#         for sample_index in index_points[indicies]:\n",
    "#             ax.vlines(\n",
    "#                 x=sample_index,\n",
    "#                 ymin=ymin - ypad,\n",
    "#                 ymax=ymax + ypad,\n",
    "#                 linestyle=linestyle,\n",
    "#                 color=color,\n",
    "#                 linewidth=1,\n",
    "#                 zorder=4,\n",
    "#             )\n",
    "#     if equilibrium_line:\n",
    "#         ax.hlines(0, index_points[0], index_points[-1], zorder=4, color=equilibrium_line[\"color\"], linestyle=equilibrium_line[\"linestyle\"], linewidth=1)\n",
    "\n",
    "#     if ax == axes[mid_row_ind,0]:\n",
    "#         ax.set_ylabel(\"Flux (mmol/gDW/hr)\", fontsize=\"xx-large\")\n",
    "#     ax.tick_params(axis=\"y\", labelsize=\"x-large\")\n",
    "\n",
    "#     if (ax == axes[mid_row_ind,-1] and not legend_at_bottom) or (ax == axes[-1, mid_col_ind] and legend_at_bottom):\n",
    "#         legend_handles = [\n",
    "#             mpl.patches.Patch(facecolor=color, edgecolor=\"black\", label=(\"  \" if optimum < 0.1 else \"\") + (f\"{optimum:.0%} Max. {obj_rxn.id}\"))\n",
    "#             for optimum, color in optimum_colors.items()\n",
    "#         ]\n",
    "#         legend_handles += [mpl.lines.Line2D([0], [0], linestyle=options[\"linestyle\"], color=options[\"color\"], label=sample_id) for sample_id, options in vline_samples.items()]\n",
    "#         # if equilibrium_line:\n",
    "#         #     legend_handles += [mpl.lines.Line2D([0], [0], linestyle=equilibrium_line[\"linestyle\"], color=equilibrium_line[\"color\"], label=\"Equilibrium\")]\n",
    "\n",
    "#         if legend_at_bottom:\n",
    "#             ax.legend(handles=legend_handles, loc=\"upper center\",  bbox_to_anchor=(0.5, -0.3), fontsize=\"xx-large\", ncols=len(legend_handles), frameon=False)\n",
    "#         else:\n",
    "#             ax.legend(handles=legend_handles, loc=\"center left\",  bbox_to_anchor=(1, 0.5), fontsize=\"xx-large\", ncols=1, frameon=False, alignment=\"right\")\n",
    "\n",
    "# plt.subplots_adjust(\n",
    "#     hspace=0.25 if sharex else 0.5,\n",
    "#     wspace=0.05 if sharey else 0.2,\n",
    "# )\n",
    "\n",
    "# if save_figures:\n",
    "#     fig.savefig(\n",
    "#         f\"{figures_path}/SelectFluxRanges{flux_group_name}_{model.id}.{imagetype}\",\n",
    "#         transparent=transparent,\n",
    "#         format=imagetype,\n",
    "#     )\n",
    "# fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3a4aa-de01-4142-8894-0c10850e1fcb",
   "metadata": {},
   "source": [
    "#### Bar chart (better for small sample sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cb715-7a5d-4782-8350-c479aade6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimum_colors = {\n",
    "#     0.0: \"xkcd:green\",\n",
    "#     0.5: \"xkcd:dark yellow\",\n",
    "#     0.9: \"xkcd:orange\",\n",
    "#     0.99: \"xkcd:red\",\n",
    "# }\n",
    "# timepoint_colors = {\n",
    "#     \"Day 10\": \"xkcd:white\",\n",
    "#     \"Day 23\": \"xkcd:light blue\",\n",
    "#     \"Day 42\": \"xkcd:light pink\",\n",
    "# }\n",
    "\n",
    "# fluxes_to_plot = np.array([\n",
    "#     [\"ARGN\", \"ASNTA\", \"PFK\", \"FBA\", \"TPI\"], # Glycolysis\n",
    "#     [\"GAPD\", \"PGK\", \"PGM\", \"ENO\", \"PYK\"], # Glycolysis\n",
    "#     [\"G6PDH2\", \"GTHP\", \"GTHOy\", \"\", \"\"], # Pentose Phosphate Pathway\n",
    "#     [\"DPGM\", \"DPGase\", \"METHBCYTBR\", \"METHBFMNR\", \"SK_hb4_23dpg_c\"], # Glycolysis\n",
    "\n",
    "# ])\n",
    "# nrows, ncols = fluxes_to_plot.shape\n",
    "# sharex, sharey = (True, False)\n",
    "# fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10*ncols, 3*nrows), sharex=sharex, sharey=sharey)\n",
    "\n",
    "# column_pair = (\"Flux\", \"Abundance\")\n",
    "# timepoints = df_flux_all[\"time\"].unique()\n",
    "# samples = df_flux_all[\"sample\"].unique()\n",
    "# df_rho = spearman_rankings_group_dict[\"ALL\"][column_pair][\"rho\"]\n",
    "# df_flux = df_flux_all[df_flux_all[\"reactions\"].isin(list(fluxes_to_plot.flatten()))].copy()\n",
    "# for rid, ax in zip(fluxes_to_plot.flatten(), axes.flatten()):\n",
    "#     if not rid:\n",
    "#         fig.delaxes(ax)\n",
    "#         continue\n",
    "#     df_flux_rxn = df_flux[df_flux[\"reactions\"] == rid]\n",
    "#     ymin = df_flux[\"minimum\"].min() if sharey else df_flux_rxn[\"minimum\"].min()\n",
    "#     ymax = df_flux[\"maximum\"].max() if sharey else df_flux_rxn[\"maximum\"].max()\n",
    "#     ypad = (\n",
    "#         df_flux[[\"maximum\", \"minimum\"]].abs().max(axis=1).max() if sharey\n",
    "#         else df_flux_rxn[[\"maximum\", \"minimum\"]].abs().max(axis=1).max()\n",
    "#     ) * 0.05\n",
    "#     for multiplier, (timepoint, color) in enumerate(timepoint_colors.items()):\n",
    "#         xmin = multiplier * len(samples) - 0.5\n",
    "#         xmax = (multiplier + 1) * len(samples) - 0.5\n",
    "#         ax.axvspan(\n",
    "#             xmin=xmin,\n",
    "#             xmax=xmax,\n",
    "#             ymin=0,\n",
    "#             ymax=1,\n",
    "#             alpha=0.5,\n",
    "#             color=color,\n",
    "#         )\n",
    "#         if multiplier != 0:\n",
    "#             ax.vlines(\n",
    "#                 x=xmin,\n",
    "#                 ymin=ymin - ypad,\n",
    "#                 ymax=ymax + ypad,\n",
    "#                 linestyle=\":\",\n",
    "#                 color=\"black\",\n",
    "#                 linewidth=1.5,\n",
    "#             )\n",
    "#         if sharex and ax in axes[-1] or not sharex:\n",
    "#             ax.text(1/3 * multiplier + 1/3/2, -0.25, timepoint, transform=ax.transAxes, ha=\"center\", fontsize=\"x-large\")\n",
    "#     if rid in df_rho:\n",
    "#         rho = f\"{df_rho.loc[rid]:.3f}\"\n",
    "#     else:\n",
    "#         rho = \"NaN\"\n",
    "#     ax.set_title(f\"{rid} $(\\\\rho = {rho})$\", fontsize=\"xx-large\")\n",
    "#     for optimum, color in optimum_colors.items():\n",
    "#         df_flux_rxn_opt = df_flux_rxn[df_flux_rxn[\"optimum\"] == optimum]\n",
    "#         ax.bar(\n",
    "#             x=df_flux_rxn_opt[\"model\"],\n",
    "#             height=df_flux_rxn_opt[\"maximum\"] - df_flux_rxn_opt[\"minimum\"],\n",
    "#             bottom=df_flux_rxn_opt[\"minimum\"],\n",
    "#             width=0.5,\n",
    "#             color=color,\n",
    "#             linewidth=0.5,\n",
    "#             edgecolor=\"black\",\n",
    "#             tick_label=df_flux_rxn_opt[\"sample\"]\n",
    "#         )\n",
    "#     ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "#     ax.set_xlim((0 - 0.5, len(samples) * len(timepoints) - 0.5))\n",
    "#     ax.set_ylim((ymin - ypad, ymax + ypad))\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(\n",
    "#     hspace=0.2 if sharex else 0.5,\n",
    "#     wspace=0.05 if sharey else 0.1,\n",
    "# )\n",
    "# fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e478de-056d-427d-98fc-3bb9956c299f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
