{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2537d45b-6871-43b9-81f8-e3639df15ac5",
   "metadata": {},
   "source": [
    "# Create context-specific models using DeepRed Omics data\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import gurobipy as gp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as mpl_venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    write_cobra_model,\n",
    "    split_string,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    ProteinDilution,\n",
    "    ComplexDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    "    update_slack_value,\n",
    ")\n",
    "from rbc_gem_utils.util import AVOGADRO_NUMBER, DEFAULT_DRY_MASS_PER_CELL\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f0e62-ca1f-4201-a29d-dc3221be59c1",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d9475-8441-4f92-b46e-6257c5a7d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "COBRA_CONFIGURATION.bounds = (-1e8, 1e8)\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b7221-4c49-479b-a5ef-5d007fcba6c1",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4033573-4a89-48af-9043-9fb0a3afe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"DeepRedOmics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb2075-6d15-4b65-bde0-e7033b113b92",
   "metadata": {},
   "source": [
    "### Set variables for columns keys and sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009e699-4ffa-4327-bb8b-494e093e0be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = \"SAMPLE ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e016a2-d256-4997-9b06-7328ad1699a7",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ee113-88e1-42d1-b265-1082995c93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = True\n",
    "verbose = True\n",
    "objective_reactions = [\"NaKt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb342f9a-b338-47fc-bb2d-0646e2461184",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc605aef-98c2-4fa9-84c1-bbd2d022bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6fa4-161e-4511-bf31-0b75d3b93dcb",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2e09a-b2bd-4a4a-9475-def95a55c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_organisms = {\"Human\", \"Mouse\"}\n",
    "if organism not in valid_organisms:\n",
    "    raise ValueError(f\"Organism must be one of the following: {valid_organisms}\")\n",
    "\n",
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "\n",
    "results_dirpath = get_dirpath(use_temp=\"processed\") / model_id / \"OVERLAY\" / organism / dataset_name\n",
    "\n",
    "fitting_dirpath = results_dirpath / \"fitting\"\n",
    "sample_pcmodels_dirpath = results_dirpath / \"sample_pcmodels\"\n",
    "# Ensure directories exist\n",
    "results_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "fitting_dirpath.mkdir(exist_ok=True)\n",
    "sample_pcmodels_dirpath.mkdir(exist_ok=True)\n",
    "\n",
    "# Identify hemoglobin proteins\n",
    "if organism == \"Mouse\":\n",
    "    hemoglobin_proteins = {\n",
    "        k.replace(\"-\", \"_\"): v\n",
    "        for k, v in {\n",
    "            \"Hba\": \"P01942\",  # Hemoglobin subunit alpha\n",
    "            \"Hba-a1\": \"P01942\",\n",
    "            \"Hbb-b1\": \"P02088\",  # Hemoglobin subunit beta-1\n",
    "            \"Hbb-b2\": \"P02089\",  # Hemoglobin subunit beta-2\n",
    "            \"Hbb-bh0\": \"P04443\",  # Hemoglobin subunit beta-H0\n",
    "            \"Hbb-bh1\": \"P04444\",  # Hemoglobin subunit beta-H1\n",
    "            \"Hbz\": \"P06467\",  # Hemoglobin subunit zeta\n",
    "            \"Hba-x\": \"P06467\",\n",
    "            \"Hbz1\": \"P06467\",\n",
    "            \"Hbb-y\": \"P02104\",  # Hemoglobin subunit epsilon-Y2\n",
    "        }.items()\n",
    "    }\n",
    "else:\n",
    "    hemoglobin_proteins = {\n",
    "        \"HBA\": \"P69905\",  # Hemoglobin subunit alpha\n",
    "        \"HBB\": \"P68871\",  # Hemoglobin subunit beta\n",
    "        \"HBD\": \"P02042\",  # Hemoglobin subunit delta\n",
    "        \"HBE1\": \"P02100\",  # Hemoglobin subunit beta\n",
    "        \"HBG1\": \"P69891\",  # Hemoglobin subunit gamma-1\n",
    "        \"HBG2\": \"P69892\",  # Hemoglobin subunit gamma-2\n",
    "        \"HBM\": \"Q6B0K9\",  # Hemoglobin subunit mu\n",
    "        \"HBQ1\": \"P09105\",  # Hemoglobin subunit theta-1\n",
    "        \"HBZ\": \"P02008\",  # Hemoglobin subunit zeta\n",
    "    }\n",
    "\n",
    "# Load models\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caae67d-2d95-4598-b27f-0336b8ed3e34",
   "metadata": {},
   "source": [
    "## Load copy numbers and protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257b726-efd9-45cb-a309-11c10ea34ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load protein copy numbers\n",
    "df_copy_numbers = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_ProteinCopyNumbers.tsv\", sep=\"\\t\", index_col=sample_key\n",
    ")\n",
    "\n",
    "# Load protein data\n",
    "df_protein_data = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_ProteinData.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=\"Entry\",\n",
    ")\n",
    "\n",
    "\n",
    "sample_ids = list(df_copy_numbers.index.unique())\n",
    "print(f\"Number of samples: {len(sample_ids)}\")\n",
    "\n",
    "df_copy_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0f2b8-c950-44af-a911-124cd4b153db",
   "metadata": {},
   "source": [
    "## Integrate proteomics with model\n",
    "### Convert copy numbers to mg / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722b2f4-d349-4053-a6c7-95965361315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_to_mw = df_protein_data[\"Mass\"] / 1000  # g/mol --> # kg / mol\n",
    "df_mg_prot_per_gDW = (\n",
    "    df_copy_numbers  # protein copies / cell\n",
    "    * (1 / DEFAULT_DRY_MASS_PER_CELL)  # cell / pgDW\n",
    "    * (1e12 / 1)  # pgDW / gDW\n",
    "    * (1 / AVOGADRO_NUMBER)  # mol / protein copies\n",
    "    * (df_uniprot_to_mw)  # kg / mol\n",
    "    * (1e6 / 1)  # mg / kg\n",
    ").copy()\n",
    "df_mg_prot_per_gDW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f99db-0ce3-4342-848f-03ddae9e4710",
   "metadata": {},
   "source": [
    "### Scale measurements for proteome budget\n",
    "Note that this step will help ensure its theoretically possible for a perfect fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d6fe5-54dc-4288-8127-4f066b47ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "la_proteome_budget_value = 50\n",
    "hemoglobin_budget_value = 950\n",
    "total_budget_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b51a37-eb71-43ed-9355-bebae6c6cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into hemoglobin and low abundance proteomes\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW.loc[\n",
    "    :, df_mg_prot_per_gDW.columns.isin(hemoglobin_proteins.values())\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW.loc[\n",
    "    :, ~df_mg_prot_per_gDW.columns.isin(hemoglobin_proteins.values())\n",
    "]\n",
    "\n",
    "df_summary = {\n",
    "    \"Perfect total\": 1000,\n",
    "    \"Current total\": df_mg_prot_per_gDW.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Hemoglobin total\": df_mg_prot_per_gDW_hb.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Low abundance total\": df_mg_prot_per_gDW_la.loc[sample_ids]\n",
    "    .sum(axis=1)\n",
    "    .mean()\n",
    "    .item(),\n",
    "}\n",
    "df_summary[\"Remaining/Excess\"] = df_summary[\"Perfect total\"] - (\n",
    "    df_summary[\"Hemoglobin total\"] + df_summary[\"Low abundance total\"]\n",
    ")\n",
    "\n",
    "PBDL_proteome_budget = pcmodel.reactions.get_by_id(\"PBDL_proteome_budget\")\n",
    "PBDL_hemoglobin_budget = pcmodel.reactions.get_by_id(\"PBDL_hemoglobin_budget\")\n",
    "PBDL_total_budget = pcmodel.reactions.get_by_id(\"PBDL_total_budget\")\n",
    "\n",
    "if la_proteome_budget_value is None:\n",
    "    la_proteome_budget_value = PBDL_proteome_budget.upper_bound\n",
    "if hemoglobin_budget_value is None:\n",
    "    hemoglobin_budget_value = PBDL_hemoglobin_budget.upper_bound\n",
    "if total_budget_value is None:\n",
    "    total_budget_value = PBDL_total_budget.upper_bound\n",
    "\n",
    "assert total_budget_value >= (la_proteome_budget_value + hemoglobin_budget_value)\n",
    "\n",
    "PBDL_proteome_budget.upper_bound = la_proteome_budget_value\n",
    "PBDL_hemoglobin_budget.upper_bound = hemoglobin_budget_value\n",
    "PBDL_total_budget.upper_bound = total_budget_value\n",
    "\n",
    "# Scale values for low abundance proteome\n",
    "budget_value = la_proteome_budget_value\n",
    "df_mg_prot_per_gDW_la = (\n",
    "    budget_value * (df_mg_prot_per_gDW_la.T / df_mg_prot_per_gDW_la.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Low abundance scaled\"] = budget_value\n",
    "\n",
    "# Scale values for hemoglobin proteome\n",
    "budget_value = hemoglobin_budget_value\n",
    "df_mg_prot_per_gDW_hb = (\n",
    "    budget_value * (df_mg_prot_per_gDW_hb.T / df_mg_prot_per_gDW_hb.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Hemoglobin scaled\"] = budget_value\n",
    "\n",
    "budget_value = total_budget_value - sum(\n",
    "    [la_proteome_budget_value, hemoglobin_budget_value]\n",
    ")\n",
    "df_summary[\"Remaining scaled\"] = budget_value\n",
    "\n",
    "# Combine dataframes back into one\n",
    "df_mg_prot_per_gDW_normalized = pd.concat(\n",
    "    (df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la), axis=1\n",
    ")\n",
    "df_summary = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \" \" * max(30 - len(k), 0) + k: [f\"{v:.4f}\", f\"{v / 1000 * 100:.1f}%\"]\n",
    "        for k, v in df_summary.items()\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"mg protein / gDW / cell\", \"Percentage\"],\n",
    ")\n",
    "print(df_summary)\n",
    "df_mg_prot_per_gDW_normalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2c529-58f3-4fce-9c7b-d41f11e2f09b",
   "metadata": {},
   "source": [
    "### Convert mg / gDW to nmol / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5ef09-c5a2-4985-b9c7-9d26d593d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmol_prot_per_gDW = (\n",
    "    df_mg_prot_per_gDW_normalized  # mg / gDW\n",
    "    * (1 / df_uniprot_to_mw)  # mol / kg --> mmol / g --> umol / mg\n",
    "    * (1e3 / 1)  # nmol / umol\n",
    ").loc[:, df_mg_prot_per_gDW_normalized.columns]\n",
    "df_nmol_prot_per_gDW = df_nmol_prot_per_gDW.T\n",
    "df_nmol_prot_per_gDW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce81e95-0e7f-46a4-b1c8-b16e958155cd",
   "metadata": {},
   "source": [
    "## Create DataFrame for protein dilution reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7d9d3-4a84-4840-98f9-d080c6cf7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_protein_dilutions = pd.concat(\n",
    "    (\n",
    "        pd.Series(\n",
    "            {g.annotation.get(\"uniprot\"): g.id for g in model.genes}, name=\"genes\"\n",
    "        ),\n",
    "        pd.Series(\n",
    "            {\n",
    "                protdl.annotation.get(\"uniprot\"): protdl.id\n",
    "                for protdl in pcmodel.reactions.query(\n",
    "                    lambda x: isinstance(x, ProteinDilution)\n",
    "                )\n",
    "            },\n",
    "            name=\"PROTDL\",\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df_model_protein_dilutions.index.name = \"uniprot\"\n",
    "df_model_protein_dilutions = df_model_protein_dilutions[\n",
    "    df_model_protein_dilutions[\"genes\"].isin(model.genes.list_attr(\"id\"))\n",
    "].sort_values(\"PROTDL\")\n",
    "df_model_protein_dilutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42b24d-3128-4a82-a021-2447f61442f4",
   "metadata": {},
   "source": [
    "## Organize samples (optional)\n",
    "Use this for organizing samples if time-outs are an issue or multiple runs are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe9186-a9c8-496b-9e6c-2bc15ae6758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_nmol_prot_per_gDW.copy()\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fe128-1107-4bbb-a102-0477a5042fd4",
   "metadata": {},
   "source": [
    "### Map samples to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fac1a-e134-438d-942e-d04e61bf5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_key = \"uniprot\"\n",
    "df_samples.index.name = merge_key\n",
    "\n",
    "df_model = (\n",
    "    df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "    .merge(df_samples, left_index=True, right_index=True, how=\"left\")\n",
    "    .set_index(\"PROTDL\")\n",
    "    .sort_index()\n",
    ")\n",
    "no_experimental_measurements = [\n",
    "    protein_dilution\n",
    "    for protein_dilution, has_measurement in df_model.isna().all(axis=1).items()\n",
    "    if has_measurement\n",
    "]\n",
    "print(\n",
    "    f\"Model proteins mapped to measurements: {len(df_model) - len(no_experimental_measurements)}\"\n",
    ")\n",
    "print(f\"Model proteins without measurements: {len(no_experimental_measurements)}\")\n",
    "df_model[~df_model.isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967481e8-7f2f-41e8-ba1d-d5b3b3abe76e",
   "metadata": {},
   "source": [
    "#### Summarize mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1fde5-cb0b-47a2-9826-4b90a7e127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_proteins = set(df_samples.index)\n",
    "model_proteins = set(df_model_protein_dilutions.index)\n",
    "\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [\n",
    "        x\n",
    "        for x in df_mg_prot_per_gDW_normalized.columns\n",
    "        if x in list(hemoglobin_proteins.values())\n",
    "    ],\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [\n",
    "        x\n",
    "        for x in df_mg_prot_per_gDW.columns\n",
    "        if not x in list(hemoglobin_proteins.values())\n",
    "    ],\n",
    "]\n",
    "\n",
    "df_mapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, ~df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_mapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, ~df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "\n",
    "proteomes = {}\n",
    "round_int = 6\n",
    "for label, df in zip(\n",
    "    [\"hemoglobin\", \"low abundance\"], [df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la]\n",
    "):\n",
    "    df_modeled = df.loc[:, df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    df_remaining = df.loc[:, ~df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    means = (df_modeled.mean(), df_remaining.mean())\n",
    "    stdevs = (df_modeled.std(), df_remaining.std())\n",
    "    proteomes[(label, \"modeled\")] = round(means[0], round_int)\n",
    "    proteomes[(label, \"remaining\")] = round(means[1], round_int)\n",
    "proteomes = pd.Series(proteomes, name=\"Mean value across samples\")\n",
    "proteomes.index = [f\"Mean {k[0]} mass {k[1]}\" for k in proteomes.index]\n",
    "print(proteomes.head())\n",
    "proteomes = proteomes[proteomes != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c58e1d-4690-4dad-9d5c-23f3354e9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(3, 6))\n",
    "subsets = (\n",
    "    len(dataset_proteins),\n",
    "    len(model_proteins),\n",
    "    len(dataset_proteins.intersection(model_proteins)),\n",
    ")\n",
    "\n",
    "\n",
    "venn = mpl_venn.venn2(\n",
    "    subsets=subsets,\n",
    "    set_labels=(dataset_name, model.id),\n",
    "    set_colors=(\"red\", \"blue\"),\n",
    "    alpha=0.5,\n",
    "    ax=ax1,\n",
    ")\n",
    "circles = mpl_venn.venn2_circles(\n",
    "    subsets=subsets, linestyle=\"-\", color=\"black\", ax=ax1, linewidth=1\n",
    ")\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "ax1.set_title(\"Modeled proteome\", fontsize=\"xx-large\")\n",
    "\n",
    "\n",
    "label_color_map = {\n",
    "    \"Mean hemoglobin mass modeled\": (\"Hemoglobin\", \"xkcd:dark red\"),\n",
    "    \"Mean low abundance mass modeled\": (\"Low abundance\", \"xkcd:light blue\"),\n",
    "    \"Mean low abundance mass remaining\": (\"Not modeled\", \"xkcd:green\"),\n",
    "}\n",
    "edgecolor = \"black\"\n",
    "linewidth = 1\n",
    "ax2.pie(\n",
    "    x=proteomes.values,\n",
    "    colors=[label_color_map[k][1] for k in proteomes.index],\n",
    "    pctdistance=1.35,\n",
    "    counterclock=False,\n",
    "    autopct=lambda pct: f\"{pct * 1000/100:.2f}\\n\",\n",
    "    textprops=dict(fontsize=\"large\", ha=\"center\", va=\"top\"),\n",
    "    wedgeprops=dict(edgecolor=edgecolor, linewidth=linewidth),\n",
    ")\n",
    "handles = [\n",
    "    mpl.patches.Patch(\n",
    "        edgecolor=edgecolor,\n",
    "        linewidth=linewidth,\n",
    "        label=label_color_map[k][0],\n",
    "        facecolor=label_color_map[k][1],\n",
    "    )\n",
    "    for k in proteomes.index\n",
    "]\n",
    "ax2.legend(\n",
    "    handles=handles,\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    frameon=False,\n",
    ")\n",
    "ax2.set_xlabel(\"Mass (mg/gDW)\", fontsize=\"large\", labelpad=-10)\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        results_dirpath / f\"ModeledProteome.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b212aa-2689-4cd1-b5b8-08c57ad6aaba",
   "metadata": {},
   "source": [
    "## Create QP model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904c726-a9d6-4890-a74f-09a6fd3b9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qp(pcmodel, df):\n",
    "    x = []  # Variables\n",
    "    c = []  # Data * Weights\n",
    "    F = []  # Weights\n",
    "\n",
    "    for protdl, (data_value, weight) in df.iterrows():\n",
    "        protdl = pcmodel.reactions.get_by_id(protdl)\n",
    "        x.append(protdl.flux_expression)\n",
    "        c.append(weight * data_value)\n",
    "        F.append(weight)\n",
    "\n",
    "    x = sympy.Matrix(x)\n",
    "    c = sympy.Matrix(c)\n",
    "    F = sympy.DiagMatrix(sympy.Matrix(F))\n",
    "    # # QP Objective must be in form of 0.5 * x.T * F * x - c.T * x\n",
    "    objective = 0.5 * x.T * F * x - c.T * x\n",
    "    pcmodel.objective = objective[0]\n",
    "    pcmodel.objective_direction = \"min\"\n",
    "    pcmodel.tolerance = 1e-9\n",
    "\n",
    "    qp_sol = pcmodel.optimize()\n",
    "    return qp_sol\n",
    "\n",
    "\n",
    "def solve_qp_for_samples(\n",
    "    pcmodel, df_samples, df_weights=None, log_zero_replacement=1e-6, verbose=False\n",
    "):\n",
    "    qp_solutions_dict = {}\n",
    "    for sample_id, data_series in df_samples.items():\n",
    "        # Get protein values\n",
    "        data_series.name = \"Data\"\n",
    "        if df_weights is None:\n",
    "            data_weights = 1 / data_series.replace(0, 1)\n",
    "            data_weights = data_weights / data_weights.mean()\n",
    "        else:\n",
    "            data_weights = df_weights.loc[:, sample_id]\n",
    "        # Get protein weights\n",
    "        data_weights.name = \"Weights\"\n",
    "\n",
    "        # Map to model, currently model mapping DataFrame generated outside scope of function\n",
    "        df_model_data_weights = (\n",
    "            df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "            .merge(data_series, left_index=True, right_index=True, how=\"left\")\n",
    "            .merge(data_weights, left_index=True, right_index=True, how=\"left\")\n",
    "            .set_index(\"PROTDL\")\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "        df = (\n",
    "            df_model_data_weights.loc[:, [data_series.name, data_weights.name]]\n",
    "            .dropna(axis=0, how=\"all\")\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "        with pcmodel:\n",
    "            qp_sol = solve_qp(pcmodel, df)\n",
    "        \n",
    "        df_qp_sol = qp_sol.fluxes.loc[\n",
    "            pcmodel.reactions.query(lambda x: isinstance(x, ProteinDilution)).list_attr(\n",
    "                \"id\"\n",
    "            )\n",
    "        ]\n",
    "        df_qp_sol = (\n",
    "            pd.concat((df_model_data_weights, df_qp_sol), axis=1).dropna().sort_index()\n",
    "        )\n",
    "        # data_weights = df_qp_sol.loc[:, \"Weights\"]\n",
    "\n",
    "        df_qp_sol = df_qp_sol.rename(\n",
    "            {\"Data\": \"Measured Proteome\", \"fluxes\": \"Best-Fitted Proteome\"}, axis=1\n",
    "        )\n",
    "        df_qp_sol = df_qp_sol.loc[:, [\"Measured Proteome\", \"Best-Fitted Proteome\"]]\n",
    "\n",
    "        df = df_qp_sol.copy()\n",
    "        r2 = r2_score(df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\")\n",
    "        \n",
    "        df = df_qp_sol.apply(lambda x: [log_zero_replacement if np.isclose(y, 0, atol=1e-12) else y for y in x]).apply(np.log10)\n",
    "        r2_log10_w_outliers = r2_score(df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\")\n",
    "\n",
    "        df = df_qp_sol[~df_qp_sol.apply(lambda x: np.isclose(x, 0).any(), axis=1)].apply(np.log10)\n",
    "        r2_log10_wo_outliers = r2_score(df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\")\n",
    "        r2_values = (r2, r2_log10_w_outliers, r2_log10_wo_outliers)\n",
    "        qp_solutions_dict[sample_id] = (df_qp_sol, qp_sol.objective_value, r2_values)\n",
    "        if verbose:\n",
    "            # Recall that the objective is designed to try to minimize fitting error via maximizing R2, so 1 is a possibility\n",
    "            print(\"Sample '{}'\\tR^2: {:.4f}\\tR^2 log10 w/outliers: {:.4f}\\tR^2 log10 wo/outliers: {:.4f}\\tObjective: {:.5f}\".format(sample_id, *r2_values, qp_sol.objective_value))\n",
    "        # TODO catch bad fits\n",
    "\n",
    "    return qp_solutions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c865bd-1409-400d-9e1f-d8ad5c9c9093",
   "metadata": {},
   "source": [
    "### Set weightings for QP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a9e24-5841-476b-84fd-cfe3d48237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is provided as (Protein IDs x Sample IDs)\n",
    "# Use original copy number values for weights\n",
    "df_weights = df_copy_numbers.T.loc[df_protein_data.index, df_samples.columns]\n",
    "df_weights = 1 / df_weights.infer_objects(copy=False).replace(0, 1)\n",
    "df_weights /= df_weights.mean()\n",
    "df_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb5f5d-624d-4e1f-bb80-c96717ad21ee",
   "metadata": {},
   "source": [
    "### Fit data by solving QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7609232-c234-4f93-b438-d3cfbe8d36dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_zero_replacement = 1e-9\n",
    "fitting_data = {\"measured\": {}, \"best_fit\": {}, \"r2_objective\": {}}\n",
    "if run_computations:\n",
    "    qp_solutions_dict = solve_qp_for_samples(\n",
    "        pcmodel,\n",
    "        df_samples,\n",
    "        df_weights=df_weights,\n",
    "        log_zero_replacement=log_zero_replacement,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    for sample_id, (\n",
    "        df_qp_sol,\n",
    "        objective_value,\n",
    "        r2_values,\n",
    "    ) in qp_solutions_dict.items():\n",
    "        fitting_data[\"measured\"][sample_id] = df_qp_sol[\"Measured Proteome\"].to_dict()\n",
    "        fitting_data[\"best_fit\"][sample_id] = df_qp_sol[\n",
    "            \"Best-Fitted Proteome\"\n",
    "        ].to_dict()\n",
    "        fitting_data[\"r2_objective\"][sample_id] = {\n",
    "            \"Objective\": objective_value,\n",
    "            \"R^2\" : r2_values[0],\n",
    "            \"R^2 log10 w/ outliers\": r2_values[1],\n",
    "            \"R^2 log10 w/o outliers\": r2_values[2],\n",
    "        }\n",
    "    for key, data in fitting_data.items():\n",
    "        data = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        data.to_csv(fitting_dirpath / f\"proteome_{key}.tsv\", sep=\"\\t\", index=True)\n",
    "        fitting_data[key] = data\n",
    "else:\n",
    "    for key in fitting_data.keys():\n",
    "        fitting_data[key] = pd.read_csv(\n",
    "            fitting_dirpath / f\"proteome_{key}.tsv\", sep=\"\\t\", index_col=0\n",
    "        )\n",
    "    qp_solutions_dict = {}\n",
    "    for sample_id in df_samples.columns:\n",
    "        df_qp_sol = pd.concat(\n",
    "            (\n",
    "                fitting_data[\"measured\"].loc[:, sample_id],\n",
    "                fitting_data[\"best_fit\"].loc[:, sample_id],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        df_qp_sol.columns = [\"Measured Proteome\", \"Best-Fitted Proteome\"]\n",
    "        r2_values = (\n",
    "            fitting_data[\"r2_objective\"].loc[:, sample_id].values\n",
    "        )\n",
    "        objective_value, r2_values = r2_values[0], r2_values[1:]\n",
    "        qp_solutions_dict[sample_id] = (df_qp_sol, objective_value, r2_values)\n",
    "print(f\"Number of QP solutions: {len(qp_solutions_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8846cf-1031-4335-b50c-bc97a67b0573",
   "metadata": {},
   "source": [
    "### Plot fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34781490-7d30-49ab-8680-4088f4070a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = (1, 1)\n",
    "length = 5\n",
    "r2_text_loc = \"upper left\"\n",
    "transform = False\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(length * ncols, length * nrows),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "sns.despine(fig)\n",
    "\n",
    "(df_qp_sol, objective_value, r2_values) = qp_solutions_dict[sample_id]\n",
    "# Copy to prevent alterations to the original\n",
    "df_qp_sol = df_qp_sol.copy()\n",
    "xlabel, ylabel = df_qp_sol.columns\n",
    "\n",
    "ticks = 10 ** np.arange(*np.log10([log_zero_replacement, 1e8]), 3)\n",
    "if transform:\n",
    "    ticks = np.log10(ticks)\n",
    "    df_qp_sol.iloc[:, 0] = (\n",
    "        df_qp_sol.iloc[:, 0]\n",
    "        .apply(lambda x: log_zero_replacement if np.isclose(x, 0) else x)\n",
    "        .apply(np.log10)\n",
    "    )\n",
    "    df_qp_sol.iloc[:, 1] = (\n",
    "        df_qp_sol.iloc[:, 1]\n",
    "        .apply(lambda x: log_zero_replacement if np.isclose(x, 0) else x)\n",
    "        .apply(np.log10)\n",
    "    )\n",
    "perfect_fit_line = ax.plot(\n",
    "    [ticks[0], ticks[-1]],\n",
    "    [ticks[0], ticks[-1]],\n",
    "    linestyle=\":\",\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "zero_val = 0 if not transform else np.log10(log_zero_replacement)\n",
    "\n",
    "df_zeros = df_qp_sol[(df_qp_sol.apply(lambda x: np.isclose(x, zero_val))).any(axis=1)]\n",
    "df_perfect = df_qp_sol[\n",
    "    np.isclose(\n",
    "        abs(df_qp_sol[\"Measured Proteome\"] - df_qp_sol[\"Best-Fitted Proteome\"]), 0\n",
    "    )\n",
    "]\n",
    "df_perfect = df_perfect[~df_perfect.index.isin(df_zeros.index)]\n",
    "\n",
    "df_altered = df_qp_sol[\n",
    "    ~np.isclose(\n",
    "        abs(df_qp_sol[\"Measured Proteome\"] - df_qp_sol[\"Best-Fitted Proteome\"]), 0\n",
    "    )\n",
    "]\n",
    "df_altered = df_altered[~df_altered.index.isin(df_zeros.index)]\n",
    "df_always_zero = df_zeros[(df_zeros == zero_val).all(axis=1)]\n",
    "df_zeros = df_zeros[~df_zeros.index.isin(df_always_zero.index)]\n",
    "df_from_zeros = df_zeros[np.isclose(df_zeros[\"Measured Proteome\"], zero_val)]\n",
    "df_to_zeros = df_zeros[np.isclose(df_zeros[\"Best-Fitted Proteome\"], zero_val)]\n",
    "\n",
    "handles = [\n",
    "    ax.scatter(\n",
    "        data=df_perfect.replace(0, ticks[0]),\n",
    "        x=xlabel,\n",
    "        y=ylabel,\n",
    "        color=\"xkcd:blue\",\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1,\n",
    "    ),\n",
    "    ax.scatter(\n",
    "        data=df_altered.replace(0, ticks[0]),\n",
    "        x=xlabel,\n",
    "        y=ylabel,\n",
    "        color=\"xkcd:yellow\",\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1,\n",
    "    ),\n",
    "    ax.scatter(\n",
    "        data=df_from_zeros.replace(0, ticks[0]),\n",
    "        x=xlabel,\n",
    "        y=ylabel,\n",
    "        color=\"xkcd:green\",\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1,\n",
    "    ),\n",
    "    ax.scatter(\n",
    "        data=df_to_zeros.replace(0, ticks[0]),\n",
    "        x=xlabel,\n",
    "        y=ylabel,\n",
    "        color=\"xkcd:red\",\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1,\n",
    "    ),\n",
    "    ax.scatter(\n",
    "        data=df_always_zero.replace(0, ticks[0]),\n",
    "        x=xlabel,\n",
    "        y=ylabel,\n",
    "        color=\"xkcd:black\",\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"black\",\n",
    "        linewidths=1,\n",
    "    ),\n",
    "]\n",
    "labels = [\n",
    "    f\"Perfect fit\",\n",
    "    f\"Adjusted abundance\",\n",
    "    f\"Unexpressed to expressed\",\n",
    "    f\"Expressed to unexpressed\",\n",
    "    f\"Never expressed\",\n",
    "]\n",
    "\n",
    "sample_label = dataset_name\n",
    "if not transform:\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "fontdict = {\"size\": \"xx-large\"}\n",
    "ax.set_xlabel(xlabel, fontdict=fontdict)\n",
    "ax.set_ylabel(ylabel, fontdict=fontdict)\n",
    "\n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    loc=\"center left\",\n",
    "    ncols=1,\n",
    "    frameon=False,\n",
    "    fontsize=\"large\",\n",
    "    markerscale=2,\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=\"x-large\")\n",
    "ax.yaxis.set_tick_params(labelsize=\"x-large\")\n",
    "\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=\"x-large\")\n",
    "ax.yaxis.set_tick_params(labelsize=\"x-large\")\n",
    "\n",
    "r2_format = \" = {:.4f}\"\n",
    "if r2_text_loc == \"lower right\":\n",
    "    ax.text(\n",
    "        0.95,\n",
    "        0.1,\n",
    "        \"\\n\".join(\n",
    "            (\n",
    "                sample_label,\n",
    "                r\"$R^{2}$\" + r2_format.format(r2_values[0]),\n",
    "                r\"$R^{2}\\text{log}_{10}\\text{ w/  outliers}$\" + r2_format.format(r2_values[1]),\n",
    "                r\"$R^{2}\\text{log}_{10}\\text{ w/o outliers}$\" + r2_format.format(r2_values[2]),\n",
    "                \n",
    "            )\n",
    "        ),\n",
    "        transform=ax.transAxes,\n",
    "        color=\"black\",\n",
    "        fontsize=\"medium\",\n",
    "        ha=\"right\",\n",
    "    )\n",
    "elif r2_text_loc == \"upper left\":\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.8,\n",
    "        \"\\n\".join(\n",
    "            (\n",
    "                sample_label,\n",
    "                r\"$R^{2}$\" + r2_format.format(r2_values[0]),\n",
    "                r\"$R^{2}\\text{log}_{10}\\text{ w/  outliers}$\" + r2_format.format(r2_values[1]),\n",
    "                r\"$R^{2}\\text{log}_{10}\\text{ w/o outliers}$\" + r2_format.format(r2_values[2]),\n",
    "                \n",
    "            )\n",
    "        ),\n",
    "        transform=ax.transAxes,\n",
    "        color=\"black\",\n",
    "        fontsize=\"medium\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "else:\n",
    "    pass\n",
    "fig.tight_layout()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath\n",
    "        / f\"QPfitting_{'' if not transform else 'log10_'}{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3095c-dd82-45c1-b076-c51d9f87b200",
   "metadata": {},
   "source": [
    "### Determine best value for slack variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d0cf9-6669-4514-9b24-77f0be484c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_determination_models = [dataset_name]\n",
    "list_of_pcmodels = []\n",
    "for sample_id in slack_determination_models:\n",
    "    df_qp_sol, objective_value, r2_values = qp_solutions_dict[sample_id]\n",
    "    # Create a copy of the model\n",
    "    pcmodel_sample = pcmodel.copy()\n",
    "    pcmodel_sample.id = f\"{pcmodel.id}_{sample_id}\"\n",
    "    for protdl in pcmodel_sample.reactions.query(\n",
    "        lambda x: isinstance(x, ProteinDilution)\n",
    "    ):\n",
    "        if protdl.id in df_qp_sol.index:\n",
    "            prot_bound = df_qp_sol.loc[protdl.id][\"Best-Fitted Proteome\"]\n",
    "        else:\n",
    "            prot_bound = 0\n",
    "        protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "    # Add the relaxation budget with slack = 0 first\n",
    "    add_relaxation_budget(pcmodel_sample, 0, int(verbose))\n",
    "    list_of_pcmodels += [pcmodel_sample]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9031c0-89d3-474a-800d-0138c7ce341c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slack_min = 1e-5  # Slack %\n",
    "slack_max = 1.5\n",
    "if run_computations:\n",
    "    solutions = {\n",
    "        pcmodel_sample.id: defaultdict(list)\n",
    "        for pcmodel_sample in list_of_pcmodels\n",
    "    }\n",
    "    for slack_value in np.geomspace(slack_min, slack_max, 101):\n",
    "        if int(verbose):\n",
    "            print(f\"Updating slack variable to {slack_value:.6f}.\")\n",
    "        for pcmodel_sample in list_of_pcmodels:\n",
    "            update_slack_value(pcmodel_sample, slack_value, verbose=False)\n",
    "            relax_demand = pcmodel_sample.reactions.get_by_id(f\"PBDL_relaxation_budget\")\n",
    "            pcmodel_sample.objective = (\n",
    "                sum(\n",
    "                    [\n",
    "                        r.flux_expression\n",
    "                        for r in pcmodel_sample.reactions.get_by_any(objective_reactions)\n",
    "                    ]\n",
    "                )\n",
    "                - relax_demand.flux_expression\n",
    "            )\n",
    "            pcmodel_sample.objective_direction = \"max\"\n",
    "            sol = pcmodel_sample.optimize()\n",
    "            obj_value = sol.objective_value\n",
    "            if not obj_value or np.isnan(obj_value):\n",
    "                if int(verbose) > 1:\n",
    "                    print(f\"No solution for {100 * slack_value:.6f}%\\n.\")\n",
    "                continue\n",
    "            else:\n",
    "                demand = relax_demand.flux\n",
    "                budget = relax_demand.upper_bound\n",
    "            solutions[pcmodel_sample.id][\"model\"].append(pcmodel_sample.id)\n",
    "            solutions[pcmodel_sample.id][\"slack\"].append(slack_value)\n",
    "            solutions[pcmodel_sample.id][\"objective\"].append(obj_value)\n",
    "            solutions[pcmodel_sample.id][\"_\".join(objective_reactions)].append(\n",
    "                obj_value + demand\n",
    "            )\n",
    "            solutions[pcmodel_sample.id][\"relaxation\"].append(demand / budget)\n",
    "    solutions = {\n",
    "        pcmodel_sample_id: pd.DataFrame.from_dict(sol)\n",
    "        for pcmodel_sample_id, sol in solutions.items()\n",
    "    }\n",
    "    df_relaxation = pd.concat(list(solutions.values()), axis=0)\n",
    "    df_relaxation.to_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )\n",
    "else:\n",
    "    df_relaxation = pd.read_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.tsv\", sep=\"\\t\"\n",
    "    )\n",
    "    solutions = {\n",
    "        mid: df_relaxation[df_relaxation[\"model\"] == mid].drop(\"model\", axis=1)\n",
    "        for mid in df_relaxation[\"model\"].unique()\n",
    "    }\n",
    "df_relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d5690-9261-4e16-b079-26324cd3eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    3, 1, figsize=(4, 10), sharex=True, gridspec_kw=dict(hspace=0.05)\n",
    ")\n",
    "axes = axes.flatten()\n",
    "\n",
    "# ax3d = fig.add_subplot(2, 2, 4, projection=\"3d\")\n",
    "sns.despine(fig)\n",
    "\n",
    "handles = []\n",
    "labels = []\n",
    "chosen_slack_var = 0.0052\n",
    "linestyle = \"--\"\n",
    "color = \"xkcd:red\"\n",
    "for pcmodel_sample_id in list(solutions):\n",
    "\n",
    "    labels.append(pcmodel_sample_id)\n",
    "    s_values = solutions[str(pcmodel_sample_id)][\"slack\"].values\n",
    "    r_values = solutions[str(pcmodel_sample_id)][\"relaxation\"].values\n",
    "    o_values = solutions[str(pcmodel_sample_id)][\"objective\"].values\n",
    "    rxn_values = solutions[str(pcmodel_sample_id)][\"_\".join(objective_reactions)].values\n",
    "\n",
    "    zorder = 1\n",
    "    lw = 2\n",
    "    axes[0].plot(\n",
    "        s_values,\n",
    "        r_values,\n",
    "        label=str(pcmodel_sample_id),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        s_values,\n",
    "        o_values,\n",
    "        label=str(pcmodel_sample_id),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    axes[2].plot(\n",
    "        s_values,\n",
    "        rxn_values,\n",
    "        label=str(pcmodel_sample_id),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "\n",
    "fontdict = {\"size\": \"x-large\"}\n",
    "axes[-1].set_xlabel(r\"Slack variable $s$\", fontdict=fontdict)\n",
    "\n",
    "zorder = 2\n",
    "alpha = 0.7\n",
    "limit_pad_sclar = 1.2\n",
    "smin = s_values[0]\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i == 0:\n",
    "        ymin, ymax = (\n",
    "            -0.001, max(r_values) * limit_pad_sclar,\n",
    "        )\n",
    "    elif i == 1:\n",
    "        ymin, ymax = (\n",
    "            min(0, min(o_values)) * limit_pad_sclar,\n",
    "            max(o_values) * limit_pad_sclar,\n",
    "        )\n",
    "    elif i == 2:\n",
    "        ymin, ymax = (0, max(rxn_values) * limit_pad_sclar)\n",
    "    else:\n",
    "        pass\n",
    "    ax.vlines(chosen_slack_var, ymin=ymin, ymax=ymax, color=\"black\", linestyle=\":\")\n",
    "    ax.vlines(\n",
    "        smin,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.vlines(\n",
    "        1,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.set_xlim(smin / 2, slack_max)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.annotate(\n",
    "        rf\"$s = {chosen_slack_var}$\",\n",
    "        xy=(chosen_slack_var, ymax * 0.9),\n",
    "        xycoords=\"data\",\n",
    "        xytext=(5, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"left\",\n",
    "        fontsize=fontdict[\"size\"],\n",
    "    )\n",
    "    if i == 0:\n",
    "        ax.annotate(\n",
    "            rf\"$s > 0$\",\n",
    "            xy=(smin, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s \\leq 1$\",\n",
    "            xy=(1, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "    ax.fill_between((smin / 2, smin), ymin, ymax, color=\"xkcd:light grey\")\n",
    "    ax.annotate(\n",
    "        \"Infeasible\",\n",
    "        xy=(smin, (ymax + ymin) / 2),\n",
    "        xycoords=\"data\",\n",
    "        rotation=90,\n",
    "        xytext=(-2, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "        fontsize=fontdict[\"size\"],\n",
    "    )\n",
    "\n",
    "\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "axes[2].legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    ncols=1,\n",
    "    frameon=False,\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    ")\n",
    "\n",
    "\n",
    "axes[0].set_ylabel(\"Relaxation budget used\\n(mg/gDW)\", fontdict=fontdict)\n",
    "axes[1].set_ylabel(\"Objective\\nvalue\", fontdict=fontdict)\n",
    "axes[2].set_ylabel(f\"{'_'.join(objective_reactions)}\\n(mmol/gDW/hr)\", fontdict=fontdict)\n",
    "\n",
    "fig.align_labels()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath / f\"SlackPercentDetermination_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44927e48-3ffc-4429-b7b5-737e6e597a5b",
   "metadata": {},
   "source": [
    "### Formulate models from QP solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e22910-d710-4539-b300-193821b896ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "# SBML/XML loads faster, but will take up to 4x more space uncompressed as compared to JSON\n",
    "ftypes = {\n",
    "    \"xml\"\n",
    "    # \"json\",\n",
    "}\n",
    "\n",
    "slack_value = chosen_slack_var  # Slack %\n",
    "ftypes = set([ftypes]) if isinstance(ftypes, str) else set(ftypes)\n",
    "for sample_id, (df_qp_sol, objective_value, r2_values) in qp_solutions_dict.items():\n",
    "    # Create a copy of the model\n",
    "    sample_id = f\"{pcmodel.id}_{sample_id}\"\n",
    "    filenames = [sample_pcmodels_dirpath / f\"{sample_id}.{ftype}\" for ftype in ftypes]\n",
    "    if all([filename.exists() for filename in filenames]) and not overwrite:\n",
    "        print(f\"Model already created for {sample_id}\")\n",
    "        continue\n",
    "    pcmodel_sample = pcmodel.copy()\n",
    "    pcmodel_sample.id = sample_id\n",
    "    for protdl in pcmodel_sample.reactions.query(\n",
    "        lambda x: isinstance(x, ProteinDilution)\n",
    "    ):\n",
    "        if protdl.id in df_qp_sol.index:\n",
    "            prot_bound = df_qp_sol.loc[protdl.id][\"Best-Fitted Proteome\"]\n",
    "        else:\n",
    "            prot_bound = 0\n",
    "        protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "    # Add the relaxation budget\n",
    "    add_relaxation_budget(pcmodel_sample, slack_value, verbose)\n",
    "    relax_demand = pcmodel_sample.reactions.get_by_id(f\"PBDL_relaxation_budget\")\n",
    "    with pcmodel_sample:\n",
    "        pcmodel_sample.objective = relax_demand.flux_expression\n",
    "        pcmodel_sample.objective_direction = \"min\"\n",
    "        budget_min = pcmodel_sample.slim_optimize()\n",
    "        pcmodel_sample.objective_direction = \"max\"\n",
    "        budget_max = pcmodel_sample.slim_optimize()\n",
    "    relax_demand.bounds = (budget_min, budget_max)\n",
    "    # # Store model for later use\n",
    "    # list_of_relaxed_models += [pcmodel_sample]\n",
    "    for filename in filenames:\n",
    "        # Might as well overwrite all files, especially if model needed to be regenerated anyways\n",
    "        write_cobra_model(\n",
    "            pcmodel_sample,\n",
    "            filename=filename,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c7bda-f7bc-4c8d-8c2d-d4792ef0d318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
