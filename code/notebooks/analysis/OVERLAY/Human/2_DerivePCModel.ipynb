{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3208d0-39f0-4d23-8d86-6de6fa19fd8b",
   "metadata": {},
   "source": [
    "# Create Protein-Constrained RBC model via OVERLAY workflow \n",
    "This notebook facilitates the construction of a proteome constrained model (\"pcModel\") via the OVERLAY methodology.\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968a45f-c732-43c5-bfc4-1114f8d8cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    build_string,\n",
    "    get_annotation_df,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    split_string,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    ATTR_SUBCLASS_DICT,\n",
    "    DEFAULT_KEFF,\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    DEFAULT_PROTEOME_COMPARTMENT,\n",
    "    Budget,\n",
    "    BudgetDilution,\n",
    "    Complex,\n",
    "    ComplexDilution,\n",
    "    Enzyme,\n",
    "    EnzymeDilution,\n",
    "    Protein,\n",
    "    ProteinDilution,\n",
    "    construct_pcmodel_from_tables,\n",
    "    create_complex_table,\n",
    "    create_enzyme_table,\n",
    "    create_protein_table,\n",
    "    create_sequence_table,\n",
    ")\n",
    "from rbc_gem_utils.database import MGI_DB_TAG, UNIPROT_DB_TAG\n",
    "from rbc_gem_utils.util import strip_plural\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c19f01-8e9f-448e-bcbb-64fb84358e1b",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d822cd-8d55-40c1-81d3-34165bf0f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "COBRA_CONFIGURATION.bounds = (-1e3, 1e3)\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1895d-964d-4590-8308-d1bf64a21cc7",
   "metadata": {},
   "source": [
    "### Define organism and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfcfc4-804b-4a04-a38d-5366faa6a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b333100-6a8a-49a3-8e25-d95c840c5e65",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa426d8-681c-44ea-9246-9f6b53f292e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dirpath = get_dirpath(\"database\", UNIPROT_DB_TAG)\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b89b1-f3bb-418f-81de-1438c31cf7a0",
   "metadata": {},
   "source": [
    "### Define hemoglobin proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d07d8-c823-459e-95f7-fd357cb4c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_proteins = {\n",
    "    \"HBA\": \"P69905\",  # Hemoglobin subunit alpha\n",
    "    \"HBB\": \"P68871\",  # Hemoglobin subunit beta\n",
    "    \"HBD\": \"P02042\",  # Hemoglobin subunit delta\n",
    "    \"HBE1\": \"P02100\",  # Hemoglobin subunit beta\n",
    "    \"HBG1\": \"P69891\",  # Hemoglobin subunit gamma-1\n",
    "    \"HBG2\": \"P69892\",  # Hemoglobin subunit gamma-2\n",
    "    \"HBM\": \"Q6B0K9\",  # Hemoglobin subunit mu\n",
    "    \"HBQ1\": \"P09105\",  # Hemoglobin subunit theta-1\n",
    "    \"HBZ\": \"P02008\",  # Hemoglobin subunit zeta\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae972b5d-74b6-4530-a55f-14b45fefd4c6",
   "metadata": {},
   "source": [
    "## Load RBC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac203d-e751-4070-9920-52277287b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a3d73-7dee-4165-ac00-a21f45d98ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "mapping_key = \"uniprot\"\n",
    "annotation_cols = [mapping_key]\n",
    "\n",
    "df_model_mappings = (\n",
    "    get_annotation_df(model.genes, annotation_cols)\n",
    "    .rename({\"id\": annotation_type}, axis=1)\n",
    "    .dropna(subset=[mapping_key])\n",
    ")\n",
    "for col in df_model_mappings.columns:\n",
    "    df_model_mappings[col] = df_model_mappings[col].apply(lambda x: split_string(x))\n",
    "    df_model_mappings = df_model_mappings.explode(col).drop_duplicates().dropna()\n",
    "df_model_mappings = df_model_mappings.sort_values(annotation_type)\n",
    "\n",
    "print(df_model_mappings.nunique(dropna=True))\n",
    "df_model_mappings = df_model_mappings.reset_index(drop=True)\n",
    "df_model_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9eff5e-0f50-463e-a82c-40c4565e16b6",
   "metadata": {},
   "source": [
    "## Assemble data for PC-model\n",
    "### Load protein data\n",
    "#### Protein amino acid sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168b414-e397-4144-9283-ade328ab6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isoforms_sequences = pd.read_csv(\n",
    "    database_dirpath / f\"{UNIPROT_DB_TAG}_isoforms_sequences.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=None,\n",
    ").fillna(pd.NA)\n",
    "print(df_isoforms_sequences[df_isoforms_sequences[\"erythroid\"]][\"uniprot\"].unique())\n",
    "df_isoforms_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed08ce-df40-4451-afc0-a6cf6c720d5f",
   "metadata": {},
   "source": [
    "#### Determine protein isoforms and associated sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd6736-a2da-48ea-be6a-a946219eeee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erythroid first, then canonical to enable drop_duplicates to keep erythroid over canonical\n",
    "df_model_isoforms_sequences = (\n",
    "    pd.concat(\n",
    "        (\n",
    "            df_isoforms_sequences[df_isoforms_sequences[\"erythroid\"]],\n",
    "            df_isoforms_sequences[df_isoforms_sequences[\"canonical\"]],\n",
    "            df_isoforms_sequences[df_isoforms_sequences[\"backup\"]],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    .fillna(pd.NA)\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\n",
    "        [\"uniprot\", \"erythroid\", \"uniprot.isoform\"], ascending=[True, False, True]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    df_model_isoforms_sequences[[\"canonical\", \"erythroid\", \"backup\", \"avoid\"]].sum(\n",
    "        axis=0\n",
    "    )\n",
    ")\n",
    "print(f\"Total: {len(df_model_isoforms_sequences)}\")\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"uniprot\",\n",
    "        \"uniprot.isoform\",\n",
    "        \"sequence.id\",\n",
    "        \"sequence\",\n",
    "        \"sequence.length\",\n",
    "        \"canonical\",\n",
    "        \"erythroid\",\n",
    "        \"backup\",\n",
    "        \"avoid\",\n",
    "    ],\n",
    "].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences.copy()\n",
    "df_model_isoforms_sequences[\"keep\"] = df_model_isoforms_sequences[\"canonical\"].values\n",
    "to_avoid = df_model_isoforms_sequences[df_model_isoforms_sequences[\"avoid\"]][\n",
    "    \"uniprot\"\n",
    "].to_dict()\n",
    "df_model_isoforms_sequences.loc[\n",
    "    list(to_avoid),\n",
    "    \"keep\",\n",
    "] = False\n",
    "\n",
    "df_possible_backups = df_model_isoforms_sequences[\n",
    "    df_model_isoforms_sequences[\"uniprot\"].isin(list(to_avoid.values()))\n",
    "]\n",
    "df_possible_backups = df_possible_backups[~df_possible_backups[\"avoid\"]]\n",
    "df_model_isoforms_sequences.loc[\n",
    "    list(df_possible_backups.index),\n",
    "    \"keep\",\n",
    "] = True\n",
    "df_model_isoforms_sequences.loc[\n",
    "    df_model_isoforms_sequences[df_model_isoforms_sequences[\"erythroid\"]].index,\n",
    "    \"keep\",\n",
    "] = True\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences[\n",
    "    df_model_isoforms_sequences[\"keep\"]\n",
    "]\n",
    "\n",
    "lost_ids = set(df_isoforms_sequences[\"uniprot\"].unique()).difference(\n",
    "    set(df_model_isoforms_sequences[\"uniprot\"].unique())\n",
    ")\n",
    "if lost_ids:\n",
    "    lost_ids = df_isoforms_sequences[df_isoforms_sequences[\"uniprot\"].isin(lost_ids)]\n",
    "    df_model_isoforms_sequences = pd.concat(\n",
    "        (df_model_isoforms_sequences, lost_ids[lost_ids[\"canonical\"]]), axis=0\n",
    "    )\n",
    "print()\n",
    "print(\n",
    "    df_model_isoforms_sequences[[\"canonical\", \"erythroid\", \"backup\", \"avoid\"]].sum(\n",
    "        axis=0\n",
    "    )\n",
    ")\n",
    "print(f\"Total: {len(df_model_isoforms_sequences)}\")\n",
    "\n",
    "df_model_isoforms_sequences = df_model_isoforms_sequences.loc[\n",
    "    :, [\"uniprot\", \"sequence.id\", \"sequence\"]\n",
    "].copy()\n",
    "df_sequence_data = (\n",
    "    df_model_mappings.merge(\n",
    "        df_model_isoforms_sequences, left_on=\"uniprot\", right_on=\"uniprot\"\n",
    "    )\n",
    "    .loc[:, [\"genes\", \"uniprot\", \"sequence.id\", \"sequence\"]]\n",
    "    .copy()\n",
    ")\n",
    "df_sequence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e577b4-0524-458d-b169-84a4c38ab585",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_key = \"uniprot\"\n",
    "protein_id_key = (\n",
    "    \"sequence.id.genes\"  # genes, uniprot, sequence.id, or sequence.id.genes are best,\n",
    ")\n",
    "unique_gene_to_protein_map = True\n",
    "isoform_transform = False\n",
    "df_sequence_data = create_sequence_table(\n",
    "    df_sequence_data=df_sequence_data,\n",
    "    mapping_key=mapping_key,\n",
    "    isoform_transform=isoform_transform,\n",
    ")\n",
    "ordered_isoform_ids = df_sequence_data[df_sequence_data[\"uniprot\"].duplicated(False)][\n",
    "    \"sequence.id\"\n",
    "]\n",
    "df_isoforms = df_sequence_data[\n",
    "    df_sequence_data[\"sequence.id\"].isin(ordered_isoform_ids)\n",
    "].copy()\n",
    "print(f\"Number of proteins: {len(df_isoforms[mapping_key].unique())}\")\n",
    "print(f\"Number of isoforms: {len(df_isoforms['sequence.id'].unique())}\")\n",
    "df_sequence_data = df_sequence_data.set_index(\"sequence.id\")\n",
    "df_sequence_data = pd.concat(\n",
    "    (\n",
    "        df_sequence_data.loc[ordered_isoform_ids],\n",
    "        df_sequence_data.loc[df_sequence_data.index.difference(ordered_isoform_ids)],\n",
    "    ),\n",
    "    axis=0,\n",
    ")\n",
    "df_sequence_data = df_sequence_data.reset_index(drop=False)\n",
    "df_sequence_data = df_sequence_data.loc[\n",
    "    :, [\"genes\", \"uniprot\", \"sequence.id\", \"sequence\"]\n",
    "].copy()\n",
    "# print(df_isoforms[mapping_key])\n",
    "if protein_id_key == \"sequence.id.genes\":\n",
    "    protein_id_key = \"protein.id\"\n",
    "    sequence_id_updates = df_model_mappings.set_index(\"uniprot\")[\"genes\"].to_dict()\n",
    "    df_sequence_data[\"protein.id\"] = df_sequence_data[\"sequence.id\"].apply(\n",
    "        lambda seq_id: \"_\".join(\n",
    "            [sequence_id_updates.get(x, x) for x in seq_id.split(\"-\")]\n",
    "        )\n",
    "    )\n",
    "    df_isoforms[\"protein.id\"] = df_isoforms[\"sequence.id\"].apply(\n",
    "        lambda seq_id: \"_\".join(\n",
    "            [sequence_id_updates.get(x, x) for x in seq_id.split(\"-\")]\n",
    "        )\n",
    "    )\n",
    "    ids_to_fix = df_sequence_data[\n",
    "        ~df_sequence_data[\"sequence.id\"].isin(df_isoforms[\"sequence.id\"])\n",
    "    ].index\n",
    "    df_sequence_data.loc[ids_to_fix, \"protein.id\"] = df_sequence_data.loc[\n",
    "        ids_to_fix, \"protein.id\"\n",
    "    ].apply(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "# Use to remove duplicates\n",
    "if unique_gene_to_protein_map:\n",
    "    df_sequence_data = df_sequence_data.drop_duplicates(\n",
    "        subset=[\"uniprot\"],\n",
    "        keep=\"first\",\n",
    "    )\n",
    "    protein_id_key = \"genes\"\n",
    "\n",
    "df_sequence_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800b409-4eef-4530-b09f-72499523595d",
   "metadata": {},
   "source": [
    "###  List all unique proteins, complexes, and enzymes\n",
    "#### Option 1: Initialize draft tables\n",
    "1. The draft tables are created and used to initialize the draft PC-model.\n",
    "    * The protein table can be used to initialize proteins and their molar weight ($\\textbf{d}$ vector).\n",
    "    * The complex table can be used to initialize complexes with their subunit stoichiometry ($\\textbf{C}$ matrix).\n",
    "        * All stoichiometric coefficients are initialized at a value of one.\n",
    "    * The enzyme table can be used to initialize enzymes with their effective rate constants ($\\textbf{K}_\\mathrm{eff}$ matrix).\n",
    "        * All $k_\\mathrm{eff}$ values are initialized at average rate constant of 65 $s^{-1}$  (or equivalently, 234000 $hr^{-1})$.\n",
    "\n",
    "2. The draft tables are made to be facilitate curation and data replacement. Therefore, the draft PC-model is exported with the draft tables. \n",
    "3. A refined PC-model can be created using the curated tables. \n",
    "\n",
    "#### Option 2: Load tables from files\n",
    "4. The formation of a draft model can be skipped if the curated tables already exist. They can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18560139-b484-4255-bffa-deed41fa153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel_tables = {}\n",
    "replace_compartments = {\n",
    "    # Cytosol:extracellular --> plasma membrane\n",
    "    \"c\": \"c\",\n",
    "    \"ce\": \"pm\",\n",
    "    \"e\": \"e\",  # Most extracellular reactions that occur are due to proteins bound to the external side of them membrane.\n",
    "}\n",
    "\n",
    "# Convert all protein compartments to one compartment\n",
    "simplify_compartments = True\n",
    "prefix = True\n",
    "optional_columns = True\n",
    "map_human_to_organism = True\n",
    "\n",
    "# Enzyme values for new tables\n",
    "max_weight_fraction = 100\n",
    "enzyme_keff_base = DEFAULT_KEFF\n",
    "\n",
    "dict_of_id_keys = {\n",
    "    \"proteins\": protein_id_key,\n",
    "    \"complexes\": None,\n",
    "    \"enzymes\": \"reactions\",\n",
    "}\n",
    "\n",
    "# Provide filepaths to load a specific model\n",
    "model_filepaths = {\n",
    "    # \"proteins\": model_dirpath / f\"pcmodel_{model}_proteins.tsv\",\n",
    "    # \"complexes\": model_dirpath / f\"pcmodel_{model}_complexes.tsv\",\n",
    "    # \"enzymes\": model_dirpath / f\"pcmodel_{model}_enzymes.tsv\",\n",
    "    # \"complex_keffs\": model_dirpath / f\"pcmodel_{model}_complex_keffs.tsv\",\n",
    "    # \"enzyme_keffs\": model_dirpath / f\"pcmodel_{model}_enzyme_keffs.tsv\",\n",
    "    # \"constraints_proteins\": model_dirpath / f\"pcmodel_{model}_constraints_proteins.tsv\",\n",
    "    # \"constraints_reactions\": model_dirpath / f\"pcmodel_{model}_constraints_reactions.tsv\",\n",
    "    # \"constraints_additional\": model_dirpath / f\"pcmodel_{model}_constraints_additional.tsv\",\n",
    "}\n",
    "\n",
    "# Provide filepaths to general files\n",
    "filepaths = {\n",
    "    \"proteins\": overlay_dirpath / \"pcmodel_proteins.tsv\",\n",
    "    \"complexes\": overlay_dirpath / \"pcmodel_complexes.tsv\",\n",
    "    # \"enzymes\": overlay_dirpath / \"pcmodel_enzymes.tsv\",\n",
    "    # \"complex_keffs\": overlay_dirpath / \"pcmodel_complex_keffs.tsv\",\n",
    "    # \"enzyme_keffs\": overlay_dirpath / \"pcmodel_enzyme_keffs.tsv\",\n",
    "    # \"constraints_proteins\": overlay_dirpath / f\"pcmodel_constraints_proteins.tsv\",\n",
    "    # \"constraints_reactions\": overlay_dirpath / f\"pcmodel_constraints_reactions.tsv\",\n",
    "    # \"constraints_additional\": overlay_dirpath / f\"pcmodel_constraints_additional.tsv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9766ff-41be-42fe-944a-2b14d4dbf6b1",
   "metadata": {},
   "source": [
    "###### Create protein table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb342b9-c941-47ab-b80f-5b11fec4fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"proteins\"\n",
    "try:\n",
    "    # Try loading previously build model proteins\n",
    "    df_proteins = pd.read_csv(model_filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    print(\"Loaded from previously generated file\")\n",
    "except (FileNotFoundError, KeyError):\n",
    "    # Otherwise try using main RBC-GEM files to make model proteins\n",
    "    try:\n",
    "        df_proteins = pd.read_csv(filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    except (FileNotFoundError, KeyError):\n",
    "        # Otherwise, make from scratch\n",
    "        df_proteins = create_protein_table(\n",
    "            model,\n",
    "            df_sequence_data,\n",
    "            id_key=dict_of_id_keys.get(table_type),\n",
    "            prefix=prefix,\n",
    "            optional_columns=optional_columns,\n",
    "            annotation_columns=[\n",
    "                \"uniprot\",\n",
    "            ],\n",
    "            replace_compartments=replace_compartments,\n",
    "        )\n",
    "        print(\"Created new table\")\n",
    "        # Create column for identifiers if None exists, or if compartments were replaced\n",
    "        if not isoform_transform:\n",
    "            df_proteins[df_proteins[table_type].duplicated(False)]\n",
    "    else:\n",
    "        df_proteins = df_sequence_data.merge(\n",
    "            df_proteins[[\"uniprot\", \"compartment\"]],\n",
    "            left_on=\"uniprot\",\n",
    "            right_on=\"uniprot\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        df_proteins[\"protein\"] = df_proteins[protein_id_key].apply(\n",
    "            lambda x: f\"protein_{x}\"\n",
    "        )\n",
    "        df_proteins = df_proteins.drop(\"protein.id\", axis=1)\n",
    "        df_proteins = df_proteins[\n",
    "            df_proteins[\"genes\"].isin(model.genes.list_attr(\"id\"))\n",
    "        ].reset_index(drop=True)\n",
    "        print(\"Loaded from main RBC-GEM file\")\n",
    "\n",
    "if simplify_compartments:\n",
    "    df_proteins = df_proteins.groupby([\"genes\", \"protein\"]).agg(\n",
    "        lambda values: \";\".join(\n",
    "            [str(value) for value in list(values.dropna().unique())]\n",
    "        )\n",
    "    )\n",
    "    df_proteins[\"compartment\"] = DEFAULT_PROTEOME_COMPARTMENT\n",
    "    df_proteins = df_proteins.reset_index(drop=False)\n",
    "\n",
    "df_proteins[\"proteins\"] = df_proteins[[strip_plural(table_type), \"compartment\"]].apply(\n",
    "    lambda x: \"_\".join(x.values), axis=1\n",
    ")\n",
    "df_proteins = df_proteins.set_index(strip_plural(table_type))\n",
    "pcmodel_tables[table_type] = df_proteins.copy()\n",
    "\n",
    "if organism != \"Human\" and map_human_to_organism:\n",
    "    discrepancies = df_organism[~df_organism[\"genes\"].isin(df_proteins[\"genes\"])]\n",
    "    if not discrepancies.empty:\n",
    "        # A discrepancy may arise if a protein was deleted from UniProt but has not yet been recorded in the organism database.\n",
    "        # This variable can be used for manually checking\n",
    "        print(f\"Discrepancies from organism mapping: {len(discrepancies)}\")\n",
    "\n",
    "df_proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb74d96-8899-46c0-a1ee-a5039cb1a479",
   "metadata": {},
   "source": [
    "###### Create complex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190d981-1b98-486b-9e06-8c9344d6fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"complexes\"\n",
    "try:\n",
    "    df_complexes = pd.read_csv(model_filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    print(\"Loaded from previously generated file\")\n",
    "except (FileNotFoundError, KeyError):\n",
    "    try:\n",
    "        df_complexes = pd.read_csv(filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    except (FileNotFoundError, KeyError):\n",
    "        genes_to_proteins = (\n",
    "            pcmodel_tables[\"proteins\"]\n",
    "            .groupby([\"genes\"], as_index=True)[\"proteins\"]\n",
    "            .agg(lambda x: build_string(list(x)))\n",
    "            .to_dict()\n",
    "        )\n",
    "        cofactor_genes = {}\n",
    "        # Create table\n",
    "        df_complexes = create_complex_table(\n",
    "            model,\n",
    "            genes_to_proteins=genes_to_proteins,\n",
    "            cofactor_genes=cofactor_genes,\n",
    "            id_key=dict_of_id_keys.get(table_type),\n",
    "            optional_columns=optional_columns,\n",
    "            annotation_columns=[\n",
    "                # \"uniprot\"\n",
    "            ],\n",
    "            replace_compartments=replace_compartments,\n",
    "        )\n",
    "        print(\"Created new table\")\n",
    "    else:\n",
    "        df_complexes = df_complexes[\n",
    "            df_complexes[\"genes\"].apply(\n",
    "                lambda genes: all(\n",
    "                    [model.genes.has_id(gene) for gene in genes.split(\";\")]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        df_complexes[\"reactions\"] = df_complexes[\"reactions\"].apply(\n",
    "            lambda reactions: \";\".join(\n",
    "                [r for r in reactions.split(\";\") if model.reactions.has_id(r)]\n",
    "            )\n",
    "        )\n",
    "        df_complexes = df_complexes[df_complexes[\"reactions\"] != \"\"]\n",
    "        df_complexes = df_complexes.loc[\n",
    "            :,\n",
    "            [\n",
    "                \"complex\",\n",
    "                \"subunits\",\n",
    "                \"compartment\",\n",
    "                \"reactions\",\n",
    "                \"genes\",\n",
    "                \"coefficients\",\n",
    "                \"cofactors\",\n",
    "                \"notes\",\n",
    "            ],\n",
    "        ]\n",
    "        print(\"Loaded from main RBC-GEM file\")\n",
    "\n",
    "    # Address isoform mapping to complexes\n",
    "    isoforms_map = defaultdict(list)\n",
    "    complex_name_update = defaultdict(list)\n",
    "    for x in df_proteins[df_proteins[\"genes\"].duplicated(False)].index:\n",
    "        isoforms_map[x.rsplit(\"_\", maxsplit=1)[0]].append(x)\n",
    "        complex_name_update[\n",
    "            x.rsplit(\"_\", maxsplit=1)[0].replace(\"protein_\", \"\")\n",
    "        ].append(x.replace(\"protein_\", \"\"))\n",
    "    df_isoforms_complexes = df_complexes[\n",
    "        df_complexes[\"subunits\"].apply(\n",
    "            lambda proteins: bool(set(isoforms_map).intersection(proteins.split(\";\")))\n",
    "        )\n",
    "    ]\n",
    "    df_updated_rows = []\n",
    "    for _, row in df_isoforms_complexes.iterrows():\n",
    "        complex_names = [\n",
    "            complex_name\n",
    "            for complex_name in itertools.product(\n",
    "                *[complex_name_update.get(c, [c]) for c in row[\"complex\"].split(\"_\")]\n",
    "            )\n",
    "        ]\n",
    "        combos = [\n",
    "            list(combo)\n",
    "            for combo in itertools.product(\n",
    "                *[\n",
    "                    isoforms_map.get(protein, [protein])\n",
    "                    for protein in row[\"subunits\"].split(\";\")\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        for complex_name, combo in zip(complex_names, combos):\n",
    "            new_row = row.to_dict()\n",
    "            new_row[\"complex\"] = \"_\".join(complex_name)\n",
    "            new_row[\"subunits\"] = \";\".join(combo)\n",
    "            df_updated_rows.append(new_row)\n",
    "\n",
    "    df_complexes = pd.concat(\n",
    "        (\n",
    "            df_complexes[~df_complexes.index.isin(df_isoforms_complexes.index)],\n",
    "            pd.DataFrame(df_updated_rows),\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "if simplify_compartments:\n",
    "    df_complexes = df_complexes.groupby([\"subunits\", \"complex\"]).agg(\n",
    "        lambda values: \";\".join(\n",
    "            [str(value) for value in list(values.dropna().unique())]\n",
    "        )\n",
    "    )\n",
    "    df_complexes[\"compartment\"] = DEFAULT_PROTEOME_COMPARTMENT\n",
    "    df_complexes = df_complexes.reset_index(drop=False)\n",
    "\n",
    "df_complexes[\"complexes\"] = df_complexes[\n",
    "    [strip_plural(table_type), \"compartment\"]\n",
    "].apply(lambda x: \"_\".join(x.values), axis=1)\n",
    "df_complexes[\"subunits\"] = df_complexes[[\"subunits\", \"compartment\"]].apply(\n",
    "    lambda values: \";\".join(\n",
    "        [\n",
    "            \"_\".join((x, values[\"compartment\"])) if not x.endswith(\"_pc\") else x\n",
    "            for x in values[\"subunits\"].split(\";\")\n",
    "        ]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df_complexes = df_complexes.set_index(strip_plural(table_type))\n",
    "pcmodel_tables[table_type] = df_complexes.copy()\n",
    "if organism != \"Human\" and map_human_to_organism:\n",
    "    discrepancies = df_organism[~df_organism[\"genes\"].isin(df_complexes[\"genes\"])]\n",
    "    if not discrepancies.empty:\n",
    "        # A discrepancy may arise if a protein was deleted from UniProt but has not yet been recorded in the organism database.\n",
    "        # This variable can be used for manually checking\n",
    "        print(f\"Discrepancies from organism mapping: {len(discrepancies)}\")\n",
    "df_complexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5388d72-79df-4444-886c-82ca4ff0d7ba",
   "metadata": {},
   "source": [
    "##### Enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3f525-31d4-41a4-bd1e-7b0c6242f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"enzymes\"\n",
    "try:\n",
    "    df_enzymes = pd.read_csv(model_filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    print(\"Loaded from previously generated file\")\n",
    "except (FileNotFoundError, KeyError):\n",
    "    try:\n",
    "        df_enzymes = pd.read_csv(filepaths[table_type], sep=\"\\t\", index_col=None)\n",
    "    except (FileNotFoundError, KeyError):\n",
    "        complexes_to_reactions = (\n",
    "            pcmodel_tables[\"complexes\"].set_index(\"complexes\")[\"reactions\"].to_dict()\n",
    "        )\n",
    "        df_enzymes = create_enzyme_table(\n",
    "            model,\n",
    "            complexes_to_reactions=complexes_to_reactions,\n",
    "            id_key=dict_of_id_keys.get(table_type),\n",
    "            optional_columns=optional_columns,\n",
    "            annotation_columns=[\n",
    "                # \"uniprot\"\n",
    "            ],\n",
    "            replace_compartments=replace_compartments,\n",
    "        )\n",
    "        if replace_compartments:\n",
    "            df_enzymes[\"compartment\"] = df_enzymes[\"compartment\"].replace(\n",
    "                replace_compartments\n",
    "            )\n",
    "        print(\"Created new table\")\n",
    "    else:\n",
    "        print(\"Loaded from main RBC-GEM file\")\n",
    "\n",
    "\n",
    "if simplify_compartments:\n",
    "    df_enzymes = df_enzymes.groupby([\"complexes\", \"enzyme\"]).agg(\n",
    "        lambda values: \";\".join(\n",
    "            [str(value) for value in list(values.dropna().unique())]\n",
    "        )\n",
    "    )\n",
    "    df_enzymes[\"compartment\"] = DEFAULT_PROTEOME_COMPARTMENT\n",
    "    df_enzymes = df_enzymes.reset_index(drop=False)\n",
    "\n",
    "df_enzymes[table_type] = df_enzymes[[strip_plural(table_type), \"compartment\"]].apply(\n",
    "    lambda x: \"_\".join(x.values), axis=1\n",
    ")\n",
    "df_enzymes = df_enzymes.set_index(strip_plural(table_type))\n",
    "pcmodel_tables[table_type] = df_enzymes.copy()\n",
    "df_enzymes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee3dbe-cb7b-40a7-b3e6-56c9a238df06",
   "metadata": {},
   "source": [
    "## Create PC-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b1787-95e1-4848-a4cc-d4c79245c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_table = pcmodel_tables[\"proteins\"].reset_index(drop=False)\n",
    "complex_table = pcmodel_tables[\"complexes\"].reset_index(drop=False)\n",
    "enzyme_table = pcmodel_tables[\"enzymes\"].reset_index(drop=False)\n",
    "max_weight_fraction = 100\n",
    "\n",
    "pcmodel, final_pcmodel_tables = construct_pcmodel_from_tables(\n",
    "    model,\n",
    "    protein_table=protein_table,\n",
    "    complex_table=complex_table,\n",
    "    enzyme_table=enzyme_table,\n",
    "    max_weight_fraction=max_weight_fraction,\n",
    "    include_complex_dilutions=True,  # Relaxes constraints areound complexes. Recommend to start, can be set to zero later or removed entirely\n",
    "    irrev_rxn_complex_keff=0,  # Set as None to ignore, small number to keep in model, 0 to remove from complex-enzyme mapping\n",
    ")\n",
    "if simplify_compartments:\n",
    "    pcmodel.compartments = {DEFAULT_PROTEOME_COMPARTMENT: \"protein compartment\"}\n",
    "# Print summary\n",
    "for attr, subclass_dict in ATTR_SUBCLASS_DICT.items():\n",
    "    n = len(\n",
    "        getattr(pcmodel, attr).query(\n",
    "            lambda x: not isinstance(x, tuple(subclass_dict.values()))\n",
    "        )\n",
    "    )\n",
    "    print(f\"Number of {attr}: {n}\")\n",
    "    for key, subcls in subclass_dict.items():\n",
    "        obj_list = getattr(pcmodel, attr).query(lambda x: isinstance(x, subcls))\n",
    "        n = len(obj_list)\n",
    "        print(f\"Number of {key}: {n}\")\n",
    "        if subcls in (Enzyme, EnzymeDilution):\n",
    "            print(\n",
    "                f'Forward variable: {len(obj_list.query(lambda x: DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.forward\"] in x.id))}/{n}'\n",
    "            )\n",
    "            print(\n",
    "                f'Reverse variable: {len(obj_list.query(lambda x: DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.reverse\"] in x.id))}/{n}'\n",
    "            )\n",
    "            print(\n",
    "                f'Summation variable : {len(obj_list.query(lambda x: DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"] in x.id))}/{n}'\n",
    "            )\n",
    "    print()\n",
    "\n",
    "keff_table = final_pcmodel_tables[\"enzymes\"].copy()\n",
    "keff_table[\"direction\"] = keff_table[\"reactions\"].apply(\n",
    "    lambda rid: model.reactions.get_by_id(rid).reaction\n",
    ")\n",
    "keff_table[\"direction\"] = keff_table[\"direction\"].apply(\n",
    "    lambda x: x.replace(\"<=>\", \"-->\")\n",
    ")\n",
    "keff_table[\"direction\"] = keff_table[[\"enzyme\", \"direction\"]].apply(\n",
    "    lambda x: (\n",
    "        x[\"direction\"].replace(\"-->\", \"<--\")\n",
    "        if x[\"enzyme\"].endswith(\n",
    "            DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.reverse\"]\n",
    "        )\n",
    "        else x[\"direction\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "keff_table[\"complexes\"] = keff_table[\"complexes\"].apply(lambda x: x.split(\";\"))\n",
    "keff_table[\"complex_keff\"] = keff_table[\"complex_keff\"].apply(lambda x: x.split(\";\"))\n",
    "keff_table = keff_table.explode([\"complexes\", \"complex_keff\"])\n",
    "keff_table[\"complex\"] = keff_table[[\"complexes\", \"compartment\"]].apply(\n",
    "    lambda x: x[\"complexes\"].replace(f\"_{x['compartment']}\", \"\"), axis=1\n",
    ")\n",
    "keff_table = keff_table.groupby([\"enzyme\", \"complex\"], as_index=False).agg(\n",
    "    lambda x: list(x.unique())[0]\n",
    ")\n",
    "keff_table = keff_table.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"enzyme\",\n",
    "        \"enzyme_keff\",\n",
    "        \"complex\",\n",
    "        \"complex_keff\",\n",
    "        \"compartment\",\n",
    "        \"reactions\",\n",
    "        \"direction\",\n",
    "    ],\n",
    "]\n",
    "complex_keff_table = keff_table.drop(\"enzyme_keff\", axis=1).drop_duplicates()\n",
    "enzyme_keff_table = (\n",
    "    keff_table.groupby([\"enzyme\", \"enzyme_keff\"], as_index=False)[\n",
    "        [\"reactions\", \"direction\"]\n",
    "    ]\n",
    "    .agg(lambda x: list(x.unique())[0])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "final_pcmodel_tables[\"complex_keffs\"] = complex_keff_table\n",
    "final_pcmodel_tables[\"enzyme_keffs\"] = enzyme_keff_table\n",
    "\n",
    "n_cplx_keff = len(\n",
    "    complex_keff_table[complex_keff_table[\"complex_keff\"].astype(float) != 0]\n",
    ")\n",
    "print(f\"Number of non-zero complex rate constants: {n_cplx_keff}\")\n",
    "\n",
    "n_enzyme_keff = len(\n",
    "    enzyme_keff_table[enzyme_keff_table[\"enzyme_keff\"].astype(float) != 0]\n",
    ")\n",
    "print(f\"Number of non-zero enzyme rate constants: {n_enzyme_keff}\")\n",
    "\n",
    "\n",
    "for table_type, df_table in final_pcmodel_tables.items():\n",
    "    df_table.to_csv(\n",
    "        model_dirpath / f\"pcmodel_{pcmodel}_{table_type}.tsv\", sep=\"\\t\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7554cd-dbf7-4286-a29e-81281e44f767",
   "metadata": {},
   "source": [
    "### Formulate additional protein constraints\n",
    "#### Address isoforms and compartments with additional constraints\n",
    "For isoforms and/or compartments, place an additional constraint such that the total sum of all isoforms does not exceed the measured concentraiton value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04a412-75e3-4ca8-b629-46f8fafcb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein_table = pcmodel_tables[\"proteins\"]\n",
    "# mapping_key = \"uniprot\"\n",
    "# df_additional_constraints = protein_table[protein_table[mapping_key].duplicated(False)]\n",
    "# df_additional_constraints = df_additional_constraints.groupby(\n",
    "#     [\n",
    "#         \"genes\",\n",
    "#         mapping_key,\n",
    "#     ],\n",
    "#     as_index=False,\n",
    "# ).agg(lambda x: list(x))\n",
    "# if not df_additional_constraints.empty:\n",
    "#     if \"lower_bound\" in df_additional_constraints.columns:\n",
    "#         df_additional_constraints[\"lower_bound\"] = df_additional_constraints[\n",
    "#             \"lower_bound\"\n",
    "#         ].apply(min)\n",
    "#     if \"upper_bound\" in df_additional_constraints.columns:\n",
    "#         df_additional_constraints[\"upper_bound\"] = df_additional_constraints[\n",
    "#             \"upper_bound\"\n",
    "#         ].apply(max)\n",
    "\n",
    "# data = {}\n",
    "# for idx, row in df_additional_constraints.iterrows():\n",
    "#     # Technically, always one gene but refers to genes attribute\n",
    "#     genes = row[\"genes\"]\n",
    "#     uniprot = model.genes.get_by_id(genes).annotation.get(mapping_key, \"\")\n",
    "#     proteins = split_string(row.get(\"proteins\"))\n",
    "#     proteins = pcmodel.metabolites.get_by_any(proteins)\n",
    "#     is_compartment = len({p.compartment for p in proteins}) > 1\n",
    "#     is_isoform = (\n",
    "#         len(\n",
    "#             {\n",
    "#                 p.id.replace(f\"_{p.compartment}\", \"\").split(\n",
    "#                     \"_\",\n",
    "#                 )[-1]\n",
    "#                 for p in proteins\n",
    "#                 if p.id.replace(f\"_{p.compartment}\", \"\")\n",
    "#                 .split(\n",
    "#                     \"_\",\n",
    "#                 )[-1]\n",
    "#                 .isnumeric()\n",
    "#             }\n",
    "#         )\n",
    "#         > 1\n",
    "#     )\n",
    "#     if is_compartment and not is_isoform:\n",
    "#         default_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"constraints\"][\"prefix.compartent\"]\n",
    "#     elif is_isoform and not is_compartment:\n",
    "#         default_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"constraints\"][\"prefix.isoform\"]\n",
    "#     else:\n",
    "#         default_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"constraints\"][\"prefix.constraint\"]\n",
    "#     constraint_id = row.get(\"constraints\", f\"{default_prefix}{genes}\")\n",
    "#     lower_bound = float(row.get(\"lower_bound\")) if row.get(\"lower_bound\") else 0\n",
    "#     upper_bound = (\n",
    "#         float(row.get(\"upper_bound\"))\n",
    "#         if row.get(\"upper_bound\")\n",
    "#         else DEFAULT_CONCENTRATION_BOUND\n",
    "#     )\n",
    "#     protein_dilutions = [\n",
    "#         reaction\n",
    "#         for protein in proteins\n",
    "#         for reaction in list(protein.reactions)\n",
    "#         if reaction.id.endswith(protein.id)\n",
    "#     ]\n",
    "#     # \"ISOCONS\" is short for \"ISOFORM CONSTRAINT\"\n",
    "#     # \"COMPCONS\" is short for \"COMPARTMENT CONSTRAINT\"\n",
    "#     # \"CONS\" for general constraint\n",
    "#     data[idx] = {\n",
    "#         \"constraints\": constraint_id,\n",
    "#         \"genes\": genes,\n",
    "#         \"proteins\": build_string([p.id for p in proteins]),\n",
    "#         \"reactions\": build_string([p.id for p in protein_dilutions]),\n",
    "#         # Assume sum of isoforms is a constant, works well with proteomic measurements that do not distinguish\n",
    "#         \"coefficients\": \";\".join([str(1) for p in protein_dilutions]),\n",
    "#         \"lower_bound\": lower_bound,\n",
    "#         \"upper_bound\": upper_bound,\n",
    "#         \"unit\": \"nmol / gDW\",\n",
    "#         mapping_key: uniprot,\n",
    "#     }\n",
    "# df_additional_constraints = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "# df_additional_constraints.to_csv(\n",
    "#     model_dirpath / f\"pcmodel_{pcmodel.id}_constraints_proteins.tsv\", sep=\"\\t\", index=False\n",
    "# )\n",
    "# df_additional_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f7be1c-67b8-4ebb-92ee-bb53b312d30f",
   "metadata": {},
   "source": [
    "## Add additional protein constraints to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bb685-f825-4f2a-bc0d-66d50606d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     df_additional_constraints = pd.read_csv(\n",
    "#         model_dirpath / f\"pcmodel_{pcmodel.id}_constraints_proteins.tsv\",\n",
    "#         sep=\"\\t\",\n",
    "#         index_col=None,\n",
    "#     )\n",
    "# except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "#     df_additional_constraints = pd.DataFrame()\n",
    "# else:\n",
    "#     if not df_additional_constraints.empty:\n",
    "#         for constraint_id, row in df_additional_constraints.set_index(\n",
    "#             \"constraints\"\n",
    "#         ).iterrows():\n",
    "#             reactions = pcmodel.reactions.get_by_any(row[\"reactions\"].split(\";\"))\n",
    "#             coefficients = row[\"coefficients\"].split(\";\")\n",
    "#             abundance = sum(\n",
    "#                 [\n",
    "#                     int(coeff) * reaction.flux_expression\n",
    "#                     for reaction, coeff in zip(reactions, coefficients)\n",
    "#                 ]\n",
    "#             )\n",
    "#             lower_bound = float(row.get(\"lower_bound\")) if row.get(\"lower_bound\") else 0\n",
    "#             upper_bound = (\n",
    "#                 float(row.get(\"upper_bound\"))\n",
    "#                 if row.get(\"upper_bound\")\n",
    "#                 else DEFAULT_CONCENTRATION_BOUND\n",
    "#             )\n",
    "#             if constraint_id in pcmodel.constraints:\n",
    "#                 # TODO warn\n",
    "#                 pcmodel.remove_cons_vars(pcmodel.constraints[constraint_id])\n",
    "#             additional_constraint = pcmodel.problem.Constraint(\n",
    "#                 abundance,\n",
    "#                 name=constraint_id,\n",
    "#                 lb=lower_bound,\n",
    "#                 ub=upper_bound,\n",
    "#             )\n",
    "#             pcmodel.add_cons_vars(additional_constraint)\n",
    "\n",
    "# df_additional_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ba53d-f212-4358-bf78-d410f3b39182",
   "metadata": {},
   "source": [
    "### Add other additional constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733376b2-7369-4fea-8954-ac8ac428393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints_ratios_filepath = overlay_dirpath / f\"pcmodel_constraints_additional.tsv\"\n",
    "\n",
    "# df_constraints_additional = pd.read_csv(\n",
    "#     constraints_ratios_filepath,\n",
    "#     sep=\"\\t\",\n",
    "#     index_col=\"constraints\",\n",
    "# )\n",
    "\n",
    "# ratio_ids = set()\n",
    "# skipped_constraints = set()\n",
    "# not_found = set()\n",
    "# for constraint_id, row in df_constraints_additional.iterrows():\n",
    "#     subs_dict = {}\n",
    "#     lhs = parse_expr(row[\"lhs\"])\n",
    "#     rhs = parse_expr(row[\"rhs\"])\n",
    "\n",
    "#     csense = row[\"csense\"]\n",
    "#     lb=None if csense == \"<\" else 0\n",
    "#     ub=None if csense == \">\" else 0\n",
    "#     reactions = row[\"reactions\"].split(\";\")\n",
    "#     for reaction in reactions:\n",
    "#         try:\n",
    "#             reaction = model.reactions.get_by_id(reaction)\n",
    "#         except Exception:\n",
    "#             if reaction == str(rhs) or reaction == str(lhs):\n",
    "#                 skipped_constraints.add(constraint_id)\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 not_found.add(reaction)\n",
    "#                 subs_dict[reaction] = 0\n",
    "#         else:\n",
    "#             subs_dict[reaction.id] = reaction.flux_expression\n",
    "#     if (str(rhs) == \"0\" or str(lhs) == \"0\") and len([r for r in reactions if r not in not_found]) <= 1:\n",
    "#         skipped_constraints.add(constraint_id)\n",
    "#     if constraint_id in skipped_constraints:\n",
    "#         continue\n",
    "#     abundance = lhs - rhs\n",
    "#     abundance = abundance.subs(subs_dict)\n",
    "#     if str(abundance) == \"0\":\n",
    "#         print(f\"{constraint_id} is always equal to 0, not including.\")\n",
    "#         skipped_constraints.add(constraint_id)\n",
    "#         continue\n",
    "#     try:\n",
    "#         constraint = model.constraints[constraint_id]\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     else:\n",
    "#         model.remove_cons_vars(constraint)\n",
    "#     constraint = model.problem.Constraint(\n",
    "#         abundance=abundance,\n",
    "#         name=constraint_id,\n",
    "#         lb=float(lb) if lb is not None else lb,\n",
    "#         ub=float(ub) if ub is not None else ub,\n",
    "#     )\n",
    "#     model.add_cons_vars(constraint)\n",
    "#     # Convert units\n",
    "#     if constraint.lb is not None:\n",
    "#         constraint.lb = convert_L_to_gDW(float(constraint.lb))\n",
    "#     if constraint.ub is not None:\n",
    "#         constraint.ub = convert_L_to_gDW(float(constraint.ub))\n",
    "#     df_constraints_additional.loc[constraint_id, \"reactions\"] = \";\".join([r for r in reactions if r not in not_found])\n",
    "#     print(constraint)\n",
    "#     df_constraints_additional.loc[constraint_id, \"lhs\"] = str(lhs)\n",
    "#     df_constraints_additional.loc[constraint_id, \"rhs\"] = str(rhs)\n",
    "\n",
    "\n",
    "# df_constraints_additional = df_constraints_additional.loc[~df_constraints_additional.index.isin(not_found.union(skipped_constraints))]\n",
    "# df_constraints_additional.to_csv(model_dirpath / f\"pcmodel_{pcmodel.id}_constraints_additional.tsv\", sep=\"\\t\", index=False)\n",
    "# df_constraints_additional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398f43f-208a-413a-850b-e78e37a0025f",
   "metadata": {},
   "source": [
    "### Annotate objects for protein constraints\n",
    "Annotating objects that are used for protein constraints will make subsequent analyses easier to perform.\n",
    "#### Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befcc19f-35ac-4090-b384-c969bcfde46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"proteins\"\n",
    "table_cols = [\"genes\", \"uniprot\", \"sequence\"]\n",
    "obj_type = Protein\n",
    "table = protein_table.set_index(table_type)[table_cols]\n",
    "\n",
    "# Rename sequence\n",
    "table = table.rename({\"sequence\": \"uniprot.sequence\"}, axis=1)\n",
    "\n",
    "\n",
    "annotation_mappings = {\n",
    "    table_key: table[table_key].to_dict() for table_key in table.columns\n",
    "}\n",
    "\n",
    "for met in pcmodel.metabolites.query(lambda x: isinstance(x, obj_type)):\n",
    "    annotation_dict = {\n",
    "        table_key: mapping_dict[met.id]\n",
    "        for table_key, mapping_dict in annotation_mappings.items()\n",
    "        if mapping_dict.get(met.id)\n",
    "    }\n",
    "    met.annotation.update(annotation_dict)\n",
    "    rxn = pcmodel.reactions.get_by_id(\n",
    "        f'{DEFAULT_PREFIX_SUFFIX_VALUES[table_type][\"prefix.dilution\"]}{met.id}'\n",
    "    )\n",
    "    rxn.annotation.update(\n",
    "        {\n",
    "            table_key: mapping_dict[met.id]\n",
    "            for table_key, mapping_dict in annotation_mappings.items()\n",
    "            if mapping_dict.get(met.id)\n",
    "        }\n",
    "    )\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fccc456-65b7-4846-93d0-8b881b9d102f",
   "metadata": {},
   "source": [
    "#### Complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca20fc-e146-410a-adeb-75d762b52c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"complexes\"\n",
    "table_cols = [\"genes\"]\n",
    "obj_type = Complex\n",
    "table = complex_table.set_index(table_type)[table_cols]\n",
    "# Add uniprot to table\n",
    "table[\"uniprot\"] = table[\"genes\"].apply(\n",
    "    lambda x: build_string(\n",
    "        [y.annotation[\"uniprot\"] for y in pcmodel.genes.get_by_any(split_string(x))]\n",
    "    )\n",
    ")\n",
    "table\n",
    "\n",
    "\n",
    "annotation_mappings = {\n",
    "    table_key: table[table_key].to_dict() for table_key in table.columns\n",
    "}\n",
    "\n",
    "for met in pcmodel.metabolites.query(lambda x: isinstance(x, obj_type)):\n",
    "    annotation_dict = {\n",
    "        table_key: mapping_dict[met.id]\n",
    "        for table_key, mapping_dict in annotation_mappings.items()\n",
    "        if mapping_dict.get(met.id)\n",
    "    }\n",
    "    met.annotation.update(annotation_dict)\n",
    "    rxn = pcmodel.reactions.get_by_id(\n",
    "        f'{DEFAULT_PREFIX_SUFFIX_VALUES[table_type][\"prefix.dilution\"]}{met.id}'\n",
    "    )\n",
    "    rxn.annotation.update(\n",
    "        {\n",
    "            table_key: mapping_dict[met.id]\n",
    "            for table_key, mapping_dict in annotation_mappings.items()\n",
    "            if mapping_dict.get(met.id)\n",
    "        }\n",
    "    )\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6491fb-eff8-4dd3-b8c9-ac788bbd4bde",
   "metadata": {},
   "source": [
    "#### Enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17932c29-74f1-430f-a746-6789bc30724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_type = \"enzymes\"\n",
    "table_cols = [\"reactions\"]\n",
    "obj_type = Enzyme\n",
    "table = enzyme_table.set_index(table_type)[table_cols]\n",
    "# Add enzyme totals to table\n",
    "table.index = pd.Index(\n",
    "    [\n",
    "        f'{x.rsplit(\"_\", maxsplit=2)[0]}{DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]}_{x.rsplit(\"_\", maxsplit=1)[-1]}'\n",
    "        for x in table.index\n",
    "    ],\n",
    "    name=table.index.name,\n",
    ")\n",
    "table = pd.concat((enzyme_table.set_index(table_type)[table_cols], table))\n",
    "\n",
    "\n",
    "annotation_mappings = {\n",
    "    table_key: table[table_key].to_dict() for table_key in table.columns\n",
    "}\n",
    "\n",
    "for met in pcmodel.metabolites.query(lambda x: isinstance(x, obj_type)):\n",
    "    annotation_dict = {\n",
    "        table_key: mapping_dict[met.id]\n",
    "        for table_key, mapping_dict in annotation_mappings.items()\n",
    "        if mapping_dict.get(met.id)\n",
    "    }\n",
    "    met.annotation.update(annotation_dict)\n",
    "    rxn = pcmodel.reactions.get_by_id(\n",
    "        f'{DEFAULT_PREFIX_SUFFIX_VALUES[table_type][\"prefix.dilution\"]}{met.id}'\n",
    "    )\n",
    "    rxn.annotation.update(\n",
    "        {\n",
    "            table_key: mapping_dict[met.id]\n",
    "            for table_key, mapping_dict in annotation_mappings.items()\n",
    "            if mapping_dict.get(met.id)\n",
    "        }\n",
    "    )\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5ed10-611d-44a1-b924-cf3badb5a39f",
   "metadata": {},
   "source": [
    "### Set budget constraints for low-abundance and high-abundance proteomes\n",
    "* RBCs are enucleated, terminally differentiated cells that are composed of 95% to 98% Hb by dry mass (mass of all the constituents of a cell in the absence of water)\n",
    "    * PMID: 13429433, PMID: 13999462, PMID: 21796773, **PMID: 34378368**\n",
    "* Therefore, remove hemoglobin from the low abundance proteome budget constraint and create a new constraint specific to hemoglobin abundance.\n",
    "* Assume 90-95% minimum of dry mass is hemoglobin, and up to 5-10% of dry mass are other proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2f453-f4e1-430e-8f29-4a104c7b21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split total budget into sectors, one for hemoglobin and one for low abundance proteome\n",
    "budget_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.dilution\"]\n",
    "budget_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.metabolite\"]\n",
    "# Get budget total\n",
    "budget_met_total = pcmodel.metabolites.get_by_id(f\"{budget_met_prefix}total\")\n",
    "budget_rxn_total = pcmodel.reactions.get_by_id(f\"{budget_rxn_prefix}{budget_met_total}\")\n",
    "\n",
    "# Create budget for low abundance proteins\n",
    "budget_rxn_lap = budget_rxn_total.copy()\n",
    "budget_met_lap = list(budget_rxn_lap.metabolites).pop()\n",
    "# Set new IDs and names for metabolites\n",
    "budget_met_lap.id = f\"{budget_met_prefix}proteome\"\n",
    "budget_met_lap.name = \"Budget constraint (Low abundance proteins)\"\n",
    "# Set new IDs and names for reactions\n",
    "budget_rxn_lap.id = f\"{budget_rxn_prefix}{budget_met_lap.id}\"\n",
    "budget_rxn_lap.name = \"Budget demand (Low abundance proteins)\"\n",
    "\n",
    "# Create budget for hemoglobin proteins\n",
    "budget_rxn_hbp = budget_rxn_total.copy()\n",
    "budget_met_hbp = list(budget_rxn_hbp.metabolites).pop()\n",
    "# Set new IDs and names for metabolites\n",
    "budget_met_hbp.id = f\"{budget_met_prefix}hemoglobin\"\n",
    "budget_met_hbp.name = \"Budget constraint (Hemoglobin proteins)\"\n",
    "# Set new IDs and names for reactions\n",
    "budget_rxn_hbp.id = f\"{budget_rxn_prefix}{budget_met_hbp.id}\"\n",
    "budget_rxn_hbp.name = \"Budget demand (Hemoglobin proteins)\"\n",
    "\n",
    "# Budget bounds for generic model\n",
    "budget_rxn_total.bounds = (0, 1000)\n",
    "budget_rxn_hbp.bounds = (900, 1000)\n",
    "budget_rxn_lap.bounds = (0, 100)\n",
    "pcmodel.add_reactions([budget_rxn_lap, budget_rxn_hbp])\n",
    "\n",
    "# Divide total budget into hemoglobin and low abundance\n",
    "budget_reations = pcmodel.reactions.query(lambda x: isinstance(x, BudgetDilution))\n",
    "for reaction in budget_met_total.reactions:\n",
    "    if reaction.id in budget_reations:\n",
    "        continue\n",
    "    # Determine if hemoglobin or low abundance\n",
    "    elif any(\n",
    "        [\n",
    "            f'{DEFAULT_PREFIX_SUFFIX_VALUES[\"proteins\"][\"prefix.metabolite\"]}{gid}'\n",
    "            in reaction.id\n",
    "            for gid in list(hemoglobin_proteins)\n",
    "        ]\n",
    "    ):\n",
    "        budget_met = budget_met_hbp\n",
    "    else:\n",
    "        budget_met = budget_met_lap\n",
    "    coeff = reaction.get_coefficient(budget_met_total)\n",
    "    reaction.add_metabolites(\n",
    "        {\n",
    "            # Add to sector\n",
    "            budget_met: coeff,\n",
    "            budget_met_total: -coeff,\n",
    "        }\n",
    "    )\n",
    "for budget_rxn in budget_reations:\n",
    "    coeff = -1 if budget_rxn_total.id == budget_rxn.id else 1\n",
    "    # Ensure budget total is reactant in its own reaction, otherwise is a product\n",
    "    budget_rxn.add_metabolites({budget_met_total: coeff}, combine=False)\n",
    "    print(budget_rxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b852f8-6444-40e7-bed3-27741a75842e",
   "metadata": {},
   "source": [
    "### Ensure model can be optimized for glucose uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b619-2bf2-4923-96ca-b6136398e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_rxns = [\"NaKt\"]\n",
    "pcmodel.objective = sum(\n",
    "    [pcmodel.reactions.get_by_id(rid).flux_expression for rid in objective_rxns]\n",
    ")\n",
    "pcsol = pcmodel.optimize()\n",
    "pcsol.fluxes.loc[\n",
    "    [r.id for r in model.reactions if r.id in pcsol.fluxes[pcsol.fluxes != 0].index]\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fde0a-9090-4c06-9849-937303d72538",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsol.fluxes.loc[\n",
    "    [\n",
    "        r.id\n",
    "        for r in pcmodel.reactions.query(lambda x: isinstance(x, ProteinDilution))\n",
    "        if r.id in pcsol.fluxes[pcsol.fluxes != 0].index\n",
    "    ]\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91db47-c712-4090-998c-d9e528c40975",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsol.fluxes.loc[\n",
    "    [\n",
    "        r.id\n",
    "        for r in pcmodel.reactions.query(lambda x: isinstance(x, EnzymeDilution))\n",
    "        if r.id in pcsol.fluxes[pcsol.fluxes != 0].index\n",
    "    ]\n",
    "].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a01f53-12d7-464b-b633-762fb818f823",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995d1dc-1355-4ace-b469-3067a9932791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular model\n",
    "write_cobra_model(model, filename=model_dirpath / f\"{model}.xml\")\n",
    "write_cobra_model(model, filename=model_dirpath / f\"{model}.json\")\n",
    "\n",
    "# Protein constrained  without curated keffs\n",
    "write_cobra_model(pcmodel, filename=model_dirpath / f\"{pcmodel}.xml\")\n",
    "write_cobra_model(pcmodel, filename=model_dirpath / f\"{pcmodel}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cb7b4-83fe-4b44-8d15-0e3c4a71a4ed",
   "metadata": {},
   "source": [
    "### Update rate constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778dc096-2677-4dfd-aa7d-058cd8aed1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcmodel_curated = load_overlay_model(filename=model_dirpath / f\"{pcmodel.id}.xml\")\n",
    "# pcmodel_curated.id += \"_keff_curated\"\n",
    "# df_complex_keffs = pd.read_csv(overlay_dirpath / \"pcmodel_complex_keffs.tsv\", sep=\"\\t\", index_col=None)\n",
    "# df_enzyme_keffs = pd.read_csv(overlay_dirpath / \"pcmodel_enzyme_keffs.tsv\", sep=\"\\t\", index_col=None)\n",
    "\n",
    "# cf = 1 / 1e6  # Conversion factor from nmol to mmol\n",
    "# if simplify_compartments:\n",
    "#     df_enzyme_keffs[\"compartment\"] = DEFAULT_PROTEOME_COMPARTMENT\n",
    "#     df_complex_keffs[\"compartment\"] = DEFAULT_PROTEOME_COMPARTMENT\n",
    "\n",
    "# df_enzyme_keffs[\"enzymes\"] = df_enzyme_keffs[[\"enzyme\", \"compartment\"]].apply(lambda x: \"_\".join(x.values), axis=1)\n",
    "# df_complex_keffs[\"enzymes\"] = df_complex_keffs[[\"enzyme\", \"compartment\"]].apply(lambda x: \"_\".join(x.values), axis=1)\n",
    "# df_complex_keffs[\"complexes\"] = df_complex_keffs[[\"complex\", \"compartment\"]].apply(lambda x: \"_\".join(x.values), axis=1)\n",
    "# df_complex_keffs = df_complex_keffs[df_complex_keffs[\"complexes\"].isin(\n",
    "#     pcmodel_curated.metabolites.query(\n",
    "#         lambda x: x.id.startswith(\"cplx_\")).list_attr(\"id\")\n",
    "# )]\n",
    "\n",
    "# df_complex_keffs[\"complex_keff\"] = df_complex_keffs[\"complex_keff\"].astype(float)\n",
    "# df_enzyme_keffs[\"enzyme_keff\"] = df_enzyme_keffs[\"enzyme_keff\"].astype(float)\n",
    "\n",
    "# df_enzyme_keffs = df_enzyme_keffs.drop_duplicates()\n",
    "# df_complex_keffs = df_complex_keffs.drop_duplicates()\n",
    "# for _, row in df_complex_keffs.iterrows():\n",
    "#     enz = row[\"enzymes\"]\n",
    "#     try:\n",
    "#         enz = pcmodel_curated.metabolites.get_by_id(enz)\n",
    "#     except KeyError:\n",
    "#         if enz.replace(DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.reverse\"], \"\") in pcmodel_curated.metabolites:\n",
    "#             enz_other_dir = pcmodel_curated.metabolites.get_by_id(enz.replace(DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.reverse\"], \"\"))\n",
    "#             missing_enz = enz_other_dir.copy()\n",
    "#             missing_enz.id = enz\n",
    "#             pcmodel_curated.add_metabolites([missing_enz])\n",
    "\n",
    "#             enzyme_keff = df_enzyme_keffs[df_enzyme_keffs[\"enzymes\"] == missing_enz.id][\"enzyme_keff\"].item()\n",
    "#             df = df_complex_keffs[df_complex_keffs[\"enzymes\"] == missing_enz.id].copy()\n",
    "#             for _, (enzyme, cplx, complex_keff) in df[[\"enzyme\", \"complexes\", \"complex_keff\"]].iterrows():\n",
    "#                 if complex_keff == 0 or enzyme_keff == 0:\n",
    "#                     continue\n",
    "\n",
    "#                 keff = float(complex_keff) / float(enzyme_keff)\n",
    "#                 formation_rxn = add_complex_formation_reaction(\n",
    "#                     pcmodel_curated,\n",
    "#                     missing_enz,\n",
    "#                     \"enzyme\",\n",
    "#                     coeff_map=f\"{cplx}({keff})\",\n",
    "#                 )\n",
    "#             if enzyme_keff != 0:\n",
    "#                 dilution_rxn = add_dilution_reaction(\n",
    "#                     pcmodel_curated,\n",
    "#                     missing_enz,\n",
    "#                     \"enzyme\",\n",
    "#                 )\n",
    "\n",
    "#                 for r in enz_other_dir.reactions:\n",
    "#                     if not r.id in model.reactions:\n",
    "#                         continue\n",
    "#                     sign = -1 if enz_other_dir in r.reactants else 1\n",
    "#                     pcmodel_curated.reactions.get_by_id(r.id).add_metabolites(\n",
    "#                         {missing_enz: sign * (1 / enzyme_keff / cf)}, combine=False\n",
    "#                     )\n",
    "#     else:\n",
    "#         enzyme_keff = df_enzyme_keffs[df_enzyme_keffs[\"enzymes\"] == enz.id][\"enzyme_keff\"].item()\n",
    "#         df = df_complex_keffs[df_complex_keffs[\"enzymes\"] == enz.id].copy()\n",
    "#         for _, (enzyme, cplx, complex_keff) in df[[\"enzyme\", \"complexes\", \"complex_keff\"]].iterrows():\n",
    "#             if complex_keff == 0 or enzyme_keff == 0:\n",
    "#                 continue\n",
    "#             keff = float(complex_keff) / float(enzyme_keff)\n",
    "#             try:\n",
    "#                 formation_rxn = pcmodel_curated.reactions.get_by_id(f\"ENZFM_{enzyme}_{cplx}\")\n",
    "#             except KeyError:\n",
    "#                 formation_rxn = add_complex_formation_reaction(\n",
    "#                     pcmodel_curated,\n",
    "#                     enz,\n",
    "#                     \"enzyme\",\n",
    "#                     coeff_map=f\"{cplx}({keff})\",\n",
    "#                 )\n",
    "#             else:\n",
    "#                 formation_rxn.add_metabolites({cplx: -keff}, combine=False)\n",
    "#         if enzyme_keff != 0:\n",
    "#             for r in enz.reactions:\n",
    "#                 if not r.id in model.reactions:\n",
    "#                     continue\n",
    "#                 sign = 1 if enz in r.products else -1\n",
    "#                 pcmodel_curated.reactions.get_by_id(r.id).add_metabolites(\n",
    "#                     {enz: sign * (1 / enzyme_keff / cf)}, combine=False\n",
    "#                 )\n",
    "\n",
    "# pcmodel_curated.remove_metabolites(pcmodel_curated.metabolites.query(lambda x: not x.reactions))\n",
    "# df_complex_keffs.to_csv(model_dirpath / f\"complex_keffs_{pcmodel_curated.id}.tsv\", sep=\"\\t\", index=False)\n",
    "# df_enzyme_keffs.to_csv(model_dirpath / f\"enzyme_keffs_{pcmodel_curated.id}.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# # Print summary\n",
    "# for attr, subclass_dict in ATTR_SUBCLASS_DICT.items():\n",
    "#     n = len(getattr(pcmodel_curated, attr).query(lambda x: not isinstance(x, tuple(subclass_dict.values()))))\n",
    "#     print(f\"Number of {attr}: {n}\")\n",
    "#     for key, subcls in subclass_dict.items():\n",
    "#         n = len(getattr(pcmodel_curated, attr).query(lambda x: isinstance(x, subcls)))\n",
    "#         print(f\"Number of {key}: {n}\")\n",
    "#     print()\n",
    "\n",
    "# # Print summary\n",
    "# for attr, subclass_dict in ATTR_SUBCLASS_DICT.items():\n",
    "#     n = len(getattr(pcmodel_curated, attr).query(lambda x: not isinstance(x, tuple(subclass_dict.values()))))\n",
    "#     print(f\"Number of {attr}: {n}\")\n",
    "#     for key, subcls in subclass_dict.items():\n",
    "#         n = len(getattr(pcmodel_curated, attr).query(lambda x: isinstance(x, subcls)))\n",
    "#         print(f\"Number of {key}: {n}\")\n",
    "#     print()\n",
    "\n",
    "\n",
    "# try:\n",
    "#     df_curated_complex_keffs = final_pcmodel_tables[\"complex_keffs\"].set_index(\"enzymes\")[[\"complexes\", \"complex_keff\"]].copy()\n",
    "# except KeyError:\n",
    "#     print(f\"Number of non-zero complex rate constants (curated): 0\")\n",
    "# else:\n",
    "#     df_curated_complex_keffs = df_curated_complex_keffs.explode([\"complexes\", \"complex_keff\"]).reset_index(drop=False).drop_duplicates()\n",
    "#     df_curated_complex_keffs = df_curated_complex_keffs[df_curated_complex_keffs[\"complex_keff\"].astype(float) != 0.]\n",
    "#     print(f\"Number of non-zero complex rate constants (curated): {len(df_curated_complex_keffs)}\")\n",
    "# finally:\n",
    "#     print(f\"Number of non-zero complex rate constants (total): {n_cplx_keff}\")\n",
    "# formation_rxn\n",
    "# try:\n",
    "#     df_curated_enzyme_keffs = final_pcmodel_tables[\"enzyme_keffs\"][[\"enzymes\", \"enzyme_keff\"]].copy()\n",
    "# except KeyError:\n",
    "#     print(f\"Number of non-zero enzyme rate constants (curated): 0\")\n",
    "# else:\n",
    "#     df_curated_enzyme_keffs = df_curated_enzyme_keffs[df_curated_enzyme_keffs[\"enzyme_keff\"].astype(float) != 0.]\n",
    "#     print(f\"Number of non-zero enzyme rate constants (curated): {len(df_curated_enzyme_keffs)}\")\n",
    "# finally:\n",
    "#     print(f\"Number of non-zero enzyme rate constants (total): {n_enzyme_keff}\")\n",
    "\n",
    "# write_cobra_model(pcmodel_curated, filename=model_dirpath / f\"{pcmodel_curated}.xml\")\n",
    "# write_cobra_model(pcmodel_curated, filename=model_dirpath / f\"{pcmodel_curated}.json\")\n",
    "# pcmodel_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c7c65-f808-4970-af4d-fc43f20ab8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec636d-398e-4918-b550-2b96e691ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e962b7-843e-4f2f-872b-de81a71925df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
