{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2537d45b-6871-43b9-81f8-e3639df15ac5",
   "metadata": {},
   "source": [
    "# Simulate models using pcFVA - REDS Recall\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import shutil\n",
    "import zipfile\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import zipfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "from cobra.core import get_solution\n",
    "from cobra.exceptions import OptimizationError\n",
    "from cobra.flux_analysis.variability import flux_variability_analysis, find_blocked_reactions\n",
    "from cobra.manipulation import remove_genes\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    write_cobra_model,\n",
    "    show_versions,\n",
    "    handle_msg\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    DEFAULT_PROTEOME_COMPARTMENT,\n",
    "    BudgetDilution,\n",
    "    ProteinDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    "    Protein,\n",
    ")\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f0e62-ca1f-4201-a29d-dc3221be59c1",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d9475-8441-4f92-b46e-6257c5a7d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-9\n",
    "COBRA_CONFIGURATION.processes = 60 # Cannot exceed number of cores - 1\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae3e11-3327-4a6c-96db-59d70b0d7313",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b691ad-10c0-4081-aa10-8bceceec4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "grouped_data_key = 'Sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0dfee-d2ec-4da0-98e4-ee9277432008",
   "metadata": {},
   "source": [
    "### Set variables for sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c122056-7d54-4f63-873b-41dff10f0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "timepoints = [\"D10\", \"D23\", \"D42\"]\n",
    "genotypes = [\"G6PD_V68M\", \"ATP11C_V972M\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>S(?P<num>\\d+))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "genotype_re = re.compile(rf\"(?P<genotype>({'|'.join(genotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f627bc-4414-4fb6-a7eb-106c7c10fd84",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec77319-ed41-46d3-b22c-0bb35d203e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = \"xml\"  # In our experience, SBML/XML loads faster, but will take up to 4x more space uncompressed as compared to JSON\n",
    "run_computations = True  # Keep off to use previously computed results\n",
    "overwrite = False  # Whether to allow overwriting of previous simulation results\n",
    "verbose = True\n",
    "\n",
    "# Objective reactions\n",
    "objective_reactions = [\"NaKt\"] \n",
    "# Reactions that must have the capability to carry flux, sort for consistency\n",
    "required_flux_reactions = [] # Add reactions to this list\n",
    "required_flux_reactions = sorted(set(objective_reactions + required_flux_reactions))\n",
    "\n",
    "only_flux_abundance_reactions = False # Only simulate reactions necessary for flux-abundance correlations\n",
    "min_relax_budget_for_objectives = True\n",
    "# Remove blocked reactions before pcFVA simulation.\n",
    "# For large models and/or multiple runs at different optimums, will speed up computation and potentially improve results.\n",
    "remove_blocked_reactions = True\n",
    "# Relaxation reactions that should be restricted to inactive\n",
    "protein_relaxations_to_restrict = []\n",
    "# Protein constraints that need lower bounds relaxed to prevent increase of \n",
    "# associated subunits in direct conflict with physiologically known. \n",
    "# Setting the lower bound prevents from being required.\n",
    "protein_constraints_lb_to_relax = []\n",
    "# Expected as percentages (e.g., 0, 50, 90, 99, 100)\n",
    "optimum_percents = [0]\n",
    "# RUn parsimonius FBA\n",
    "pfba_factor = None\n",
    "# Whether to run loopless pcFVA\n",
    "loopless = False\n",
    "\n",
    "zip_kwargs = dict(\n",
    "    compression=zipfile.ZIP_DEFLATED,\n",
    "    compresslevel=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b889ff-6f35-40af-99f1-5f2b7049e4a3",
   "metadata": {},
   "source": [
    "#### Set prefixes/suffixes to expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932d812-6740-46e2-92a1-524ca643bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"proteins\"][\"prefix.dilution\"]\n",
    "protein_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"proteins\"][\"prefix.metabolite\"]\n",
    "relaxation_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"proteins\"][\"prefix.relaxation\"]\n",
    "enzyme_met_suffix_total = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]\n",
    "enzyme_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.dilution\"]\n",
    "enzyme_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.metabolite\"]\n",
    "budget_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.dilution\"]\n",
    "budget_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.metabolite\"]\n",
    "comp_suffix = f\"_{DEFAULT_PROTEOME_COMPARTMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1dacf-75e8-4548-90d6-bb51c9cf1ffa",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a15e9-9848-4c2e-b78d-8538f0d0dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd11ff1-4805-4860-b346-1f5c993b54ac",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a0645-ab37-434d-af5c-d6f3d385b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (get_dirpath(use_temp=\"processed\") / model_id / \"OVERLAY\" / organism / dataset_name / grouped_data_key)\n",
    "pcfva_results_dirpath = (results_dirpath / \"pcFVA\" / \"_\".join((\"REQ\", *required_flux_reactions)) /  \"_\".join((\"OBJ\", *objective_reactions)))\n",
    "pcfva_results_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "# ZIP directories\n",
    "sample_pcmodels_dirpath = results_dirpath / \"pcmodels\"\n",
    "reduced_models_dirpath = pcfva_results_dirpath.parent / \"reduced_pcmodels\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6fa4-161e-4511-bf31-0b75d3b93dcb",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8349c9-7146-48d4-864a-fd56990c670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "# Add relaxation budget to initial PC model to get names of relaxation reactions\n",
    "add_relaxation_budget(pcmodel, 0, verbose=False)\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40da04b-105d-4ffc-9bd3-37c168d0a8dc",
   "metadata": {},
   "source": [
    "### Check settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a833c01-0b19-4286-82a9-66ee906e2c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check settings here\n",
    "invalid = sorted(set([x for x in objective_reactions if x not in pcmodel.reactions]))\n",
    "if invalid:\n",
    "    raise ValueError(f\"Objective reactions not found in model: {invalid}\")\n",
    "invalid = sorted(set([x for x in required_flux_reactions if x not in pcmodel.reactions]))\n",
    "if invalid:\n",
    "    raise ValueError(f\"Required flux capable reactions not found in model: {invalid}\")\n",
    "invalid = sorted(set([x for x in protein_relaxations_to_restrict + protein_constraints_lb_to_relax if x not in pcmodel.genes]))\n",
    "if invalid:\n",
    "    raise ValueError(f\"Genes/Proteins not found in model: {invalid}\")\n",
    "invalid = sorted(set([x for x in optimum_percents if x < 0]))\n",
    "if invalid:\n",
    "    raise ValueError(f\"Optimum values must be non-negative: {invalid}\")\n",
    "if pfba_factor is not None and pfba_factor < 1:\n",
    "    raise ValueError(f\"The pFBA factor should be greater than 1 if set.\")\n",
    "\n",
    "simulation_options_text = \"\\n\".join((\n",
    "    \"Simulation Options\",\n",
    "    \"================================\",\n",
    "    f\"min_relax_budget_for_objectives:\\n\\t{min_relax_budget_for_objectives}\",\n",
    "    f\"only_flux_abundance_reactions:\\n\\t{only_flux_abundance_reactions}\",\n",
    "    f\"remove_blocked_reactions:\\n\\t{remove_blocked_reactions}\",\n",
    "    f\"pFBA_factor:\\n\\t{pfba_factor}\",\n",
    "    F\"loopless:\\n\\t{loopless}\",\n",
    "    f\"objective_reactions:\\n\\t{objective_reactions}\",\n",
    "    f\"required_flux_reactions:\\n\\t{required_flux_reactions}\",\n",
    "    f\"protein_relaxations_to_restrict:\\n\\t{protein_relaxations_to_restrict}\",\n",
    "    f\"protein_constraints_lb_to_relax:\\n\\t{protein_constraints_lb_to_relax}\",\n",
    "))\n",
    "print(simulation_options_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e3c2a-a931-48ff-b5ff-0c5e306524f9",
   "metadata": {},
   "source": [
    "### Define list of PC-models to load for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e404c61-7c0f-479f-9a34-8a8d4279a1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(f'{sample_pcmodels_dirpath}.zip', mode=\"r\") as zfile:\n",
    "    pcmodel_names = sorted([Path(x).name.replace(Path(x).suffix, \"\") for x in zfile.namelist() if x])\n",
    "if sample_pcmodels_dirpath.exists():\n",
    "    pcmodel_names += [filename.name for filename in sample_pcmodels_dirpath.iterdir()]\n",
    "# Check sample directory for existing files\n",
    "if not len(pcmodel_names) == len(set(pcmodel_names)):\n",
    "    raise ValueError(f\"Duplicates found: {[k for k, v in Counter(pcmodel_names).items() if v > 1]}\")\n",
    "pcmodel_names = sorted(set(pcmodel_names))\n",
    "\n",
    "all_sample_ids = [x.replace(f\"{pcmodel.id}_\", \"\") for x in pcmodel_names]\n",
    "operation_ids = [x for x in all_sample_ids if operation_re.match(x)]\n",
    "sample_ids = [x for x in all_sample_ids if sample_id_re.match(x)]\n",
    "\n",
    "handle_msg(f\"Total number of models: {len(all_sample_ids)}\", print_msg=True)\n",
    "handle_msg(f\"Number of measured samples: {len(sample_ids)}\", print_msg=True)\n",
    "handle_msg(f\"Number of operation samples: {len(operation_ids)}\", print_msg=True)\n",
    "\n",
    "models_to_simulate = set(pcmodel_names)\n",
    "\n",
    "# Possible differences performed on datasets\n",
    "exclude_donors = []\n",
    "exclude_by_timepoints = []\n",
    "exclude_by_operation = [\n",
    "    # \"Mean\", \n",
    "    # \"Median\"\n",
    "]\n",
    "for to_exclude, to_search_re in zip(\n",
    "    [\n",
    "        exclude_donors,\n",
    "        exclude_by_timepoints,\n",
    "        exclude_by_operation,\n",
    "    ],\n",
    "    [donor_re, time_re, operation_re],\n",
    "):\n",
    "    if to_exclude:\n",
    "        models_to_simulate = models_to_simulate.difference(\n",
    "            [\n",
    "                x\n",
    "                for item in to_exclude\n",
    "                for x in models_to_simulate\n",
    "                if to_search_re.search(x.replace(f\"{pcmodel.id}_\", \"\"))\n",
    "                and to_search_re.search(x.replace(f\"{pcmodel.id}_\", \"\")).group(1)\n",
    "                == item\n",
    "            ]\n",
    "        )\n",
    "\n",
    "models_to_simulate = sorted(models_to_simulate)\n",
    "handle_msg(f\"Number of models to simulate: {len(models_to_simulate)}\", print_msg=True)\n",
    "\n",
    "models_to_simulate;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4e5e8-eac9-4cbe-871a-56a754751001",
   "metadata": {},
   "source": [
    "### Generate results using pcFVA for context specific models\n",
    "Note that this can take a signficiant amount of time depending on the number of models and their sizes. Best to use a targeted approach in generating results. \n",
    "Alternatively, skip result generation and load the previously generated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc23c8-ffb9-4e1e-bab3-a2765d851180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reactions in addition to the minimum for flux-abundance correlations\n",
    "list_of_reactions = []\n",
    "# # Use to get ALL reactions in the original model\n",
    "list_of_reactions += model.reactions.list_attr(\"id\")\n",
    "# # Use to get ALL reactions in the PC model\n",
    "# list_of_reactions += pcmodel.reactions.list_attr(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95de14b-afc3-4ab7-9e3c-2474a801459f",
   "metadata": {},
   "source": [
    "#### Generate results for subset of PC model reactions\n",
    "##### Reactions necessary for all flux-abundance correlation computations.\n",
    "To reduce computation time, a subset of reactions can be defined. \n",
    "For flux-abundance correlations, the minimum reaction set are reactions associated with genes associated and the corresponding enzyme dilution reaction for total enzyme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b8d5b-dcb8-4e49-aba8-290006484ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_reaction_list = model.reactions.query(lambda x: x.gene_reaction_rule).list_attr(\n",
    "    \"id\"\n",
    ")\n",
    "# Add protein dilutons to see effective protein concentrations used\n",
    "min_reaction_list += pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, ProteinDilution)\n",
    ").list_attr(\"id\")\n",
    "min_reaction_list += pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, BudgetDilution)\n",
    ").list_attr(\"id\")\n",
    "\n",
    "# Already limited to reactions with gene reaction rules\n",
    "enzyme_totals_list = pcmodel.metabolites.query(\n",
    "    lambda x: x.id.startswith(f\"{enzyme_met_prefix}\")\n",
    "    and enzyme_met_suffix_total in x.id\n",
    ")\n",
    "enzyme_reaction_map = {\n",
    "    f\"{enzyme_rxn_prefix}{x}\": x.id.replace(f\"{enzyme_met_prefix}\", \"\").replace(\n",
    "        f\"{enzyme_met_suffix_total}_{x.compartment}\", \"\"\n",
    "    )\n",
    "    for x in enzyme_totals_list\n",
    "}\n",
    "# Combine lists\n",
    "min_reaction_list += list(enzyme_reaction_map)\n",
    "handle_msg(f\"Minimum number of reactions minimize/maximize (minimum): {len(min_reaction_list)} / {len(pcmodel.reactions)}\", print_msg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54897e9c-f167-4d4d-84ad-e1d1d340a621",
   "metadata": {},
   "source": [
    "##### Refined set of PC model reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f77e8-fada-451c-876d-fb3af50ee78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_flux_abundance_reactions:\n",
    "    reaction_list = min_reaction_list.copy()\n",
    "else:\n",
    "    list_of_reactions = [getattr(rid, \"_id\", rid) for rid in list_of_reactions]\n",
    "    reaction_list = sorted(\n",
    "        [getattr(x, \"_id\", x) for x in set(min_reaction_list).union(list_of_reactions)]\n",
    "    )\n",
    "handle_msg(f\"Number of reactions minimize/maximize (chosen): {len(reaction_list)} / {len(pcmodel.reactions)}\", print_msg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a9eec-3342-4cef-a5b5-a2f6601c7025",
   "metadata": {},
   "source": [
    "### Determine previously existing solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279dd443-e0aa-4a29-832d-1c8b7b1b512d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "existing_files = defaultdict(set)\n",
    "handle_msg(\"Format: (zipped + unzipped)/total\", print_msg=True)\n",
    "if remove_blocked_reactions:\n",
    "    reduced_models_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "    if (Path(f'{reduced_models_dirpath}.zip').exists() or Path(f'{reduced_models_dirpath}').exists()) and not overwrite:\n",
    "        # Search reduced model directory and zip file\n",
    "        if Path(f'{reduced_models_dirpath}.zip').exists():\n",
    "            with zipfile.ZipFile(f'{reduced_models_dirpath}.zip', mode=\"r\") as zfile:\n",
    "                existing_files[reduced_models_dirpath.name].update([Path(x).name.replace(f\".{ftype}\", \"\") for x in zfile.namelist() if x])\n",
    "        in_the_zip = len(existing_files[reduced_models_dirpath.name])\n",
    "        existing_files[reduced_models_dirpath.name].update([x.name.replace(f\".{ftype}\", \"\") for x in list(reduced_models_dirpath.iterdir())])\n",
    "        total = len(existing_files[reduced_models_dirpath.name])\n",
    "        handle_msg(f\"Number of existing reduced models: ({in_the_zip} + {total - in_the_zip}) / {total}\\n\", print_msg=True)\n",
    "    else:\n",
    "        existing_files[reduced_models_dirpath.name].update([])\n",
    "\n",
    "for optimum in optimum_percents:\n",
    "    # Replace decimals with hyphens\n",
    "    dirname = (\n",
    "        f\"Opt{optimum}\"\n",
    "        + (f\"_pFBA{pfba_factor}\" if pfba_factor else \"\")\n",
    "        + (\"loopless\" if loopless else \"\")\n",
    "    ).replace(\".\", \"-\")\n",
    "    optimum_dirpath = (pcfva_results_dirpath.parent if optimum == 0 else pcfva_results_dirpath) / dirname\n",
    "    optimum_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "    if (Path(f'{optimum_dirpath}.zip').exists() or Path(f'{optimum_dirpath}').exists()) and not overwrite:\n",
    "        # Search reduced model directory and zip file\n",
    "        if Path(f'{optimum_dirpath}.zip').exists():\n",
    "            with zipfile.ZipFile(f'{optimum_dirpath}.zip', mode=\"r\") as zfile:\n",
    "                existing_files[optimum_dirpath.name].update([Path(x).name for x in zfile.namelist() if x])\n",
    "        in_the_zip = len(existing_files[optimum_dirpath.name])\n",
    "        existing_files[optimum_dirpath.name].update([x.name for x in list(optimum_dirpath.iterdir())])\n",
    "        total = len(existing_files[optimum_dirpath.name])\n",
    "        handle_msg(\n",
    "                '\\t'.join((\n",
    "                    f\"Optimum: {optimum}\" \n",
    "                    + ('' if pfba_factor is None else '\\tpFBA factor: '+ str(pfba_factor)),\n",
    "                    f\"Number of existing solution: ({in_the_zip} + {total - in_the_zip}) / {total}\"\n",
    "                )), \n",
    "            print_msg=True\n",
    "            )\n",
    "    else:\n",
    "        existing_files[optimum_dirpath.name].update([])\n",
    "existing_files;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7bc4d-22b2-4ff5-b34e-84bf9f266871",
   "metadata": {},
   "source": [
    "## Run pcFVA\n",
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3e8e2-29d4-4c41-ad04-adc2fce9c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_remove_blocked_reactions(pcmodel_sample, relaxation_rxns_required=None, prevent_removal=None, verbose=False):\n",
    "    if prevent_removal is None:\n",
    "        prevent_removal = []\n",
    "    pcmodel_sample = pcmodel_sample.copy()\n",
    "    n_reactions_original = len(pcmodel_sample.reactions)\n",
    "    n_genes_original = len(pcmodel_sample.genes)\n",
    "    pcmodel_sample.objective = (\n",
    "        sum(\n",
    "            [\n",
    "                r.flux_expression\n",
    "                for r in pcmodel_sample.reactions.get_by_any(\n",
    "                    required_flux_reactions\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    for relax_rxn in pcmodel_sample.reactions.query(lambda x: x.id.startswith(relaxation_rxn_prefix)):\n",
    "        if relax_rxn.id in relaxation_rxns_required:\n",
    "            continue\n",
    "        else:\n",
    "            relax_rxn.bounds = (0, 0)\n",
    "\n",
    "    reactions_to_remove = find_blocked_reactions(\n",
    "        model=pcmodel_sample,\n",
    "        reaction_list=None,\n",
    "        zero_cutoff=COBRA_CONFIGURATION.tolerance,\n",
    "        open_exchanges=True,\n",
    "        processes=min(60, COBRA_CONFIGURATION.processes),\n",
    "    )\n",
    "    reactions_to_remove = sorted(set(reactions_to_remove).difference([rxn for prot in prevent_removal for rxn in [f\"{protein_rxn_prefix}{protein_met_prefix}{prot}{comp_suffix}\", f\"{relaxation_rxn_prefix}{protein_met_prefix}{prot}{comp_suffix}\"]]))\n",
    "    pcmodel_sample.remove_reactions(reactions_to_remove, remove_orphans=True)\n",
    "    genes_to_remove = [\n",
    "        gene.id for gene in pcmodel_sample.genes\n",
    "        if not pcmodel_sample.reactions.has_id(f\"{protein_rxn_prefix}{protein_met_prefix}{gene.id}{comp_suffix}\") \n",
    "        and not pcmodel_sample.reactions.has_id(f\"{relaxation_rxn_prefix}{protein_met_prefix}{gene.id}{comp_suffix}\")\n",
    "    ]\n",
    "    genes_to_remove = sorted(set(genes_to_remove).difference(prevent_removal))\n",
    "    remove_genes(pcmodel_sample, gene_list=genes_to_remove, remove_reactions=True)\n",
    "    handle_msg(f\"Number of blocked reactions removed: {n_reactions_original - len(pcmodel_sample.reactions)}\", print_msg=verbose)\n",
    "    handle_msg(f\"Number of associated genes removed: {n_genes_original - len(pcmodel_sample.genes)}\", print_msg=verbose)\n",
    "    return pcmodel_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f17a04-c7c6-4b29-a7a2-5ab401c25601",
   "metadata": {},
   "source": [
    "### Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a7b9b-6fb4-43a4-9647-a9287827ce18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = [\"model\", \"reactions\", \"optimum\", \"min\", \"max\"]\n",
    "zip_kwargs = dict(\n",
    "    compression=zipfile.ZIP_DEFLATED,\n",
    "    compresslevel=None\n",
    ")\n",
    "if run_computations:\n",
    "    for idx, pcmodel_sample_id in enumerate(models_to_simulate, start=1):\n",
    "        handle_msg(\n",
    "            \"\\n\".join((\n",
    "                \"====================================================\",\n",
    "                f\"Computing pcFVA results for {pcmodel_sample_id}\",\n",
    "                \"====================================================\",\n",
    "                f\"Loading PC-model for {pcmodel_sample_id}\",\n",
    "            )),\n",
    "            print_msg=verbose\n",
    "        )\n",
    "        # See if a reduced model has already been created for simulation.\n",
    "        if (not overwrite and remove_blocked_reactions and pcmodel_sample_id in existing_files[reduced_models_dirpath.name]):\n",
    "            handle_msg(f\"Previously generated reduced model found.\", print_msg=True)\n",
    "            # Check if all simulations have been performed with reduced modelk\n",
    "            dirnames = [\n",
    "                (\n",
    "                    f\"Opt{optimum}\" \n",
    "                    + (f\"_pFBA{pfba_factor}\" if pfba_factor else \"\")\n",
    "                    + (\"loopless\" if loopless else \"\")\n",
    "                ).replace(\".\", \"-\")\n",
    "                for optimum in optimum_percents\n",
    "            ]\n",
    "            if all([f\"{pcmodel_sample_id}_FVAsol.csv\" in existing_files[dirname] for dirname in dirnames]):\n",
    "                handle_msg(\"All simulations already performed for model\", print_msg=verbose)\n",
    "                continue\n",
    "            else:\n",
    "                # Not all simulations performed, therefore load existing reduced model\n",
    "                try:\n",
    "                    with zipfile.ZipFile(f\"{reduced_models_dirpath}.zip\", 'r') as zfile:\n",
    "                        with zfile.open(f\"{pcmodel_sample_id}.{ftype}\", 'r') as model_file:\n",
    "                            pcmodel_sample = load_overlay_model(filename=io.StringIO(model_file.read().decode(\"utf-8\")), filetype=ftype)\n",
    "                except (KeyError, FileNotFoundError):\n",
    "                    # If file not found, model hasn't been put into zip file yet\n",
    "                    pcmodel_sample = load_overlay_model(filename=reduced_models_dirpath /f\"{pcmodel_sample_id}.{ftype}\")\n",
    "        else:\n",
    "            # Load full model\n",
    "            try:\n",
    "                with zipfile.ZipFile(f'{sample_pcmodels_dirpath}.zip', 'r') as zfile:\n",
    "                    with zfile.open(f\"{pcmodel_sample_id}.{ftype}\", 'r') as model_file:\n",
    "                        pcmodel_sample = load_overlay_model(filename=io.StringIO(model_file.read().decode(\"utf-8\")), filetype=ftype)\n",
    "            except (FileNotFoundError, KeyError):\n",
    "                # If file not found, model hasn't been put into zip file yet\n",
    "                pcmodel_sample = load_overlay_model(filename=sample_pcmodels_dirpath /f\"{pcmodel_sample_id}.{ftype}\")\n",
    "            # Restrict relaxation reactions for specific proteins\n",
    "            for protein in protein_relaxations_to_restrict:\n",
    "                protein_met = pcmodel_sample.metabolites.get_by_id(f\"{protein_met_prefix}{protein}{comp_suffix}\")\n",
    "                relax_prot_rxn = pcmodel_sample.reactions.get_by_id(f\"{relaxation_rxn_prefix}{protein_met.id}\")\n",
    "                relax_prot_rxn.bounds = (0, 0)\n",
    "            # Relax lower bound constraint for specific proteins\n",
    "            for protein in protein_constraints_lb_to_relax:\n",
    "                protein_met = pcmodel_sample.metabolites.get_by_id(f\"{protein_met_prefix}{protein}{comp_suffix}\")\n",
    "                protein_rxn = pcmodel_sample.reactions.get_by_id(f\"{protein_rxn_prefix}{protein_met.id}\")\n",
    "                protein_rxn.lower_bound = 0\n",
    "        \n",
    "            budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\")\n",
    "            # Determine smallest allowable relxation budget that allows flux through objectives and set as upper bound\n",
    "            with pcmodel_sample:\n",
    "                pcmodel_sample.objective = (sum([r.flux_expression for r in pcmodel_sample.reactions.get_by_any(required_flux_reactions)]) - budget_rxn_relaxation.flux_expression)\n",
    "                pcmodel_sample.objective_direction = \"max\"\n",
    "                 # Fail loudly, should not occur unless a restricted relaxation proteins are absolutely necessary\n",
    "                pcmodel_sample.slim_optimize(error_value=None)\n",
    "                relaxation_rxns_required = get_solution(pcmodel_sample, reactions=pcmodel_sample.reactions.query(lambda x: x.id.startswith(relaxation_rxn_prefix)))\n",
    "                relaxation_rxns_required = set(relaxation_rxns_required.fluxes[relaxation_rxns_required.fluxes != 0].index.to_list())\n",
    "                budget_min = budget_rxn_relaxation.flux\n",
    "            if min_relax_budget_for_objectives:\n",
    "                budget_rxn_relaxation.upper_bound = budget_min\n",
    "            \n",
    "            if remove_blocked_reactions:\n",
    "                handle_msg(\"Determining reactions and protein constraints to remove\", print_msg=verbose)\n",
    "                with warnings.catch_warnings(action=\"ignore\"):\n",
    "                    pcmodel_sample = find_and_remove_blocked_reactions(\n",
    "                        pcmodel_sample, \n",
    "                        relaxation_rxns_required=relaxation_rxns_required, \n",
    "                        prevent_removal=list(set(protein_relaxations_to_restrict).union(protein_constraints_lb_to_relax)),\n",
    "                        verbose=verbose\n",
    "                    )\n",
    "                pcmodel_sample.slim_optimize()\n",
    "                # Write reduced model into directory\n",
    "                write_cobra_model(pcmodel_sample, filename=reduced_models_dirpath / f\"{pcmodel_sample.id}.{ftype}\")\n",
    "        # Set objective reaction(s)\n",
    "        pcmodel_sample.objective = sum([r.flux_expression for r in pcmodel_sample.reactions.get_by_any(objective_reactions)])\n",
    "        # Not all reactions exist for reduced models, regenerate list per model\n",
    "        rxn_list = [x for x in reaction_list if x in pcmodel_sample.reactions]\n",
    "        handle_msg(f\"Number of reactions minimize/maximize for sample: {len(rxn_list)} / {len(pcmodel.reactions)}\", print_msg=verbose)\n",
    "        handle_msg(f\"Starting simulations for {pcmodel_sample}\", print_msg=verbose)\n",
    "        for optimum in optimum_percents:\n",
    "            dirname = (f\"Opt{optimum}\" + (f\"_pFBA{pfba_factor}\" if pfba_factor else \"\") + (\"loopless\" if loopless else \"\")).replace(\".\", \"-\")\n",
    "            filename = f\"{pcmodel_sample}_FVAsol.csv\"\n",
    "            if not overwrite and filename in existing_files[dirname]:\n",
    "                handle_msg(f\"Already simulated at optimum: {optimum}\" + ('' if pfba_factor is None else ' pFBA factor: '+ str(pfba_factor)), print_msg=verbose)\n",
    "                continue\n",
    "            fraction_of_optimum = round(optimum / 100, 4)\n",
    "            try:\n",
    "                pcfva_sol = flux_variability_analysis(\n",
    "                    pcmodel_sample,\n",
    "                    reaction_list=rxn_list,\n",
    "                    loopless=loopless,\n",
    "                    pfba_factor=pfba_factor,\n",
    "                    fraction_of_optimum=fraction_of_optimum,\n",
    "                    processes=min(60, COBRA_CONFIGURATION.processes),\n",
    "                )\n",
    "            except OptimizationError as e:\n",
    "                msg = f\"{pcmodel_sample_id} failed due to an exception.\"\n",
    "                handle_msg(msg, print_msg=verbose)\n",
    "                with open(pcfva_results_dirpath / f\"pcFVA-errors-{dirname}.log\", \"a\") as file:\n",
    "                    file.write(f\"{msg} {str(e)}\\n\")\n",
    "            else:\n",
    "                pcfva_sol.index.name = \"reactions\"\n",
    "                pcfva_sol = pcfva_sol.reset_index(drop=False)\n",
    "                pcfva_sol[\"model\"] = pcmodel_sample.id\n",
    "                pcfva_sol[\"optimum\"] = fraction_of_optimum\n",
    "                pcfva_sol = pcfva_sol.rename({\"minimum\": \"min\", \"maximum\": \"max\"}, axis=1)\n",
    "                optimum_dirpath = (pcfva_results_dirpath.parent if optimum == 0 else pcfva_results_dirpath) / dirname\n",
    "                # Save simulation results\n",
    "                pcfva_sol.to_csv(optimum_dirpath / filename, index=False)\n",
    "                handle_msg(f\"Finished pcFVA for optimum: {optimum}\", print_msg=verbose)\n",
    "        handle_msg(f\"Finished pcFVA for {pcmodel_sample_id}\", print_msg=verbose)\n",
    "handle_msg(\"Compressing results\", print_msg=verbose)\n",
    "dirpaths = [reduced_models_dirpath]\n",
    "for optimum in optimum_percents:\n",
    "    dirname = (f\"Opt{optimum}\" + (f\"_pFBA{pfba_factor}\" if pfba_factor else \"\") + (\"loopless\" if loopless else \"\")).replace(\".\", \"-\")\n",
    "    dirpaths += [(pcfva_results_dirpath.parent if optimum == 0 else pcfva_results_dirpath) / dirname]\n",
    "\n",
    "for dirpath in dirpaths:\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        if not overwrite and Path(f\"{dirpath}.zip\").exists():\n",
    "            handle_msg(\"Copying original zip to temporary directory\", print_msg=verbose)\n",
    "            shutil.copy(f\"{dirpath}.zip\", tmpdir)\n",
    "        handle_msg(\"Appending model files to temporary zip file\", print_msg=verbose)\n",
    "        with zipfile.ZipFile(f\"{tmpdir}/{dirpath.name}.zip\", 'a', **zip_kwargs) as zfile:\n",
    "            existing_files = set([Path(x).name for x in zfile.namelist() if x])\n",
    "            for filename in list(dirpath.iterdir()):\n",
    "                if filename.name in existing_files:\n",
    "                    continue\n",
    "                zfile.write(f\"{filename}\", arcname=f\"{filename.name}\")\n",
    "        # Replacing original directory\n",
    "        handle_msg(\"Setting temporary zip file as the new zip file\", print_msg=verbose)\n",
    "        shutil.copy(f\"{tmpdir}/{dirpath.name}.zip\", dirpath.parent)\n",
    "    handle_msg(\"Finished compression, cleaning up files\", print_msg=verbose)\n",
    "    shutil.rmtree(str(dirpath))\n",
    "    handle_msg(\"Finished cleanup\", print_msg=verbose)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d46e0f-a8c4-4aed-8034-e2c0ce5b80ec",
   "metadata": {},
   "source": [
    "### Combine all simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0630901-25ed-4c44-858b-fc9fe95ec749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combine solutions into single DataFrame\n",
    "def read_csv_from_zip(csv_file):\n",
    "    with zfile.open(csv_file) as f:\n",
    "        return pd.read_csv(f)\n",
    "\n",
    "dfs_to_concat = []\n",
    "for optimum in optimum_percents:\n",
    "    dirname = [f\"Opt{optimum}\"]\n",
    "    dirname += [f\"pFBA{pfba_factor}\"] if pfba_factor is not None else []\n",
    "    dirname = \"_\".join(dirname).replace(\".\", \"-\")\n",
    "    dirpath = (pcfva_results_dirpath.parent if optimum == 0 else pcfva_results_dirpath)\n",
    "    with zipfile.ZipFile(dirpath / f'{dirname}.zip', 'a', **zip_kwargs) as zfile:\n",
    "        dfs_to_concat += [read_csv_from_zip(csv_file) for csv_file in zfile.namelist() if csv_file.endswith('.csv')]\n",
    "\n",
    "df_pcfva_all = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "# Fill missing (blocked) reactions with zero values to have all reactions for all models at all optimums\n",
    "df_all_reactions = pd.DataFrame(\n",
    "    index=pd.Index(df_pcfva_all[\"reactions\"].unique(), name=\"reactions\"),\n",
    ")\n",
    "\n",
    "\n",
    "columns_to_fill = [\"reactions\", \"model\", \"optimum\"]\n",
    "for idx, col in enumerate(columns_to_fill[1:], start=2):\n",
    "    # Create initial column\n",
    "    df_all_reactions.loc[:, col] = pd.NA\n",
    "    # Fill unique values\n",
    "    df_all_reactions.loc[:, col] = set(df_pcfva_all[col].unique())\n",
    "    # Explode to propogate\n",
    "    df_all_reactions = df_all_reactions.explode(col).reset_index(drop=False)\n",
    "    df_all_reactions = df_all_reactions.set_index(columns_to_fill[:idx])\n",
    "df_all_reactions = df_all_reactions.sort_index()\n",
    "df_pcfva_all = df_all_reactions.merge(df_pcfva_all.set_index(columns_to_fill), left_index=True, right_index=True, how=\"left\")\n",
    "df_pcfva_all = df_pcfva_all.reset_index(drop=False)\n",
    "# Ensure fill worked as expected\n",
    "assert len(df_pcfva_all.index) == np.prod([df_pcfva_all[col].nunique() for col in columns_to_fill])\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7cefd-e3bb-4240-8b90-d69db8635f42",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a12d9-85cb-4ea7-b2a5-5882debb1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name=f\"{pcmodel.id}_All_FVAsols.csv\")\n",
    "compression_opts.update(zip_kwargs)\n",
    "df_pcfva_all.to_csv(\n",
    "    pcfva_results_dirpath / f\"{pcmodel.id}_All_FVAsols.zip\", \n",
    "    index=False,\n",
    "    compression=compression_opts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca3221-ea3c-463b-af68-bbc6734456b5",
   "metadata": {},
   "source": [
    "## Test load pcFVA generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507a088-4c39-4d8f-a42a-91853c2a5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if results were recently generated in this run, otherwise load DataFrame of generated results\n",
    "df_pcfva_all = pd.read_csv(\n",
    "    pcfva_results_dirpath / f\"{pcmodel.id}_All_FVAsols.zip\",\n",
    "    index_col=None,\n",
    ")\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed358880-b1e7-44c9-a183-db712ca03583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
