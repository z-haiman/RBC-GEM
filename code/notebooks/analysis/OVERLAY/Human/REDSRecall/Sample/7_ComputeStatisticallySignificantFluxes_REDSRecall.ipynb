{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9114c6-b2d1-48a1-8ba3-6686a1ea2449",
   "metadata": {},
   "source": [
    "# Compute statistically significant fluxes between groups - REDS Recall\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d694e76-31c0-4aba-add6-a07a00a5d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    ensure_iterable,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    DEFAULT_PROTEOME_COMPARTMENT,\n",
    "    EnzymeDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    "    plot_correlations,\n",
    ")\n",
    "from rbc_gem_utils.visualization import cmap_map\n",
    "from scipy.stats import false_discovery_control, kruskal, mannwhitneyu, spearmanr\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c972a-9f2f-4b88-a65c-017d1a6561d6",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ddc9c-b48e-400a-b5a1-e4e6bfe73bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-9\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3720a-d637-4115-8960-f48671ee725a",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b08faa-240f-44ee-9d16-ddbdc556852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "grouped_data_key = \"Sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ccb7e-c784-4b63-bfe9-7ebdce0e24b5",
   "metadata": {},
   "source": [
    "### Set variables for sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435bfd2-9c1f-4f09-8a7a-3d0a0efba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"PUBLIC RECALL DONOR ID\"\n",
    "time_key = \"DAY\"\n",
    "timepoints = [\"D10\", \"D23\", \"D42\"]\n",
    "genotypes = [\"G6PD_V68M\", \"ATP11C_V972M\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>S(?P<num>\\d\\d\\d))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "genotype_re = re.compile(rf\"(?P<genotype>({'|'.join(genotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478c85d-b0ed-466c-b6d3-e8dead52f018",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e59494-b23d-4775-8863-1baeb1f46194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = \"xml\"  # In our experience, SBML/XML loads faster, but will take up to 4x more space uncompressed as compared to JSON\n",
    "run_computations = True  # Keep off to use previously computed results\n",
    "overwrite = False  # Whether to allow overwriting of previous simulation results\n",
    "verbose = True\n",
    "\n",
    "# Objective reactions\n",
    "objective_reactions = [\"NaKt\"]\n",
    "# Reactions that must have the capability to carry flux, sort for consistency\n",
    "required_flux_reactions = []  # Add reactions to this list\n",
    "required_flux_reactions = sorted(set(objective_reactions + required_flux_reactions))\n",
    "\n",
    "\n",
    "enzyme_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.dilution\"]\n",
    "enzyme_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.metabolite\"]\n",
    "enzyme_met_suffix_total = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]\n",
    "comp_suffix = f\"_{DEFAULT_PROTEOME_COMPARTMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2f1cf-43bb-4e48-8e56-031b2f14202a",
   "metadata": {},
   "source": [
    "#### Set prefixes/suffixes to expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c451c4-4f3c-4db0-991b-fd56b743f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.dilution\"]\n",
    "enzyme_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.metabolite\"]\n",
    "enzyme_met_suffix_total = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]\n",
    "comp_suffix = f\"_{DEFAULT_PROTEOME_COMPARTMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bb5e1-67d6-4436-af4a-0f34befaa111",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad3312-69a9-4bd9-92c4-a2d467bed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2d514-cb81-4968-95b6-95e758cd3e73",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd462b-0c65-4b33-b745-6a4e74996f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\")\n",
    "    / model_id\n",
    "    / \"OVERLAY\"\n",
    "    / organism\n",
    "    / dataset_name\n",
    "    / grouped_data_key\n",
    ")\n",
    "pcfva_results_dirpath = (\n",
    "    results_dirpath\n",
    "    / \"pcFVA\"\n",
    "    / \"_\".join((\"REQ\", *required_flux_reactions))\n",
    "    / \"_\".join((\"OBJ\", *objective_reactions))\n",
    ")\n",
    "\n",
    "# Objective reaction does not matter since correlations are computed\n",
    "# based on min and max fluxes and abundance, which are obtained when optimum is 0.\n",
    "corr_results_dirpath = results_dirpath / \"correlations\"\n",
    "# Ensure directory  exists\n",
    "corr_results_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b8d0f-8ca2-48e4-9da1-7db464f01407",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f7b2c-ad0d-4404-899b-fa05a0bd7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "# Add relaxation budget to initial PC model to get names of relaxation reactions\n",
    "add_relaxation_budget(pcmodel, 0, verbose=False)\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf0307-bf28-4f10-8784-143d62c669a7",
   "metadata": {},
   "source": [
    "## Load pcFVA generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fccd8-52b6-44c9-83a0-af5c62b7fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame of generated results\n",
    "df_pcfva_all = pd.read_csv(\n",
    "    pcfva_results_dirpath / f\"{pcmodel.id}_All_FVAsols.zip\",\n",
    "    index_col=None,\n",
    ").fillna(0)\n",
    "\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a4524-c95b-4980-a95f-5ba109e75025",
   "metadata": {},
   "source": [
    "## Create DataFrame for calculations and visualizations\n",
    "### Get maximum reaction fluxes and associated abundance values\n",
    "#### Get maximum reaction fluxes and ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efaec1d-6db8-4b96-975b-67303d06d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = model.reactions.query(lambda x: len(x.genes)).list_attr(\"id\")\n",
    "df_max_flux_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "df_max_flux_per_model = df_max_flux_per_model.groupby(\n",
    "    [\"model\", \"reactions\", \"optimum\"]\n",
    ")[[\"min\", \"max\"]].agg(\n",
    "    {\n",
    "        \"min\": \"min\",  # Minimum reaction flux per model\n",
    "        \"max\": \"max\",  # Maximum reaction flux per model\n",
    "    }\n",
    ")\n",
    "# Address issues possibly caused by floating point precision, ideally a value that prevents any negative ranges\n",
    "df_max_flux_per_model.loc[\n",
    "    df_max_flux_per_model[\"max\"] < df_max_flux_per_model[\"min\"], [\"max\", \"min\"]\n",
    "] = [0, 0]\n",
    "atol = COBRA_CONFIGURATION.tolerance * 100\n",
    "df_max_flux_per_model[\"max\"] = df_max_flux_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_flux_per_model[\"min\"] = df_max_flux_per_model[\"min\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_flux_per_model[\"range\"] = (\n",
    "    df_max_flux_per_model[\"max\"] - df_max_flux_per_model[\"min\"]\n",
    ")\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_flux_per_model[df_max_flux_per_model[\"range\"] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000d2d8-7a7c-4b02-b088-867e04ce7dbe",
   "metadata": {},
   "source": [
    "#### Get maximum \"enzyme\" abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6feeea-cfe4-4da9-99db-47f2729bd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, EnzymeDilution)\n",
    "    and x.id.endswith(f\"{enzyme_met_suffix_total}{comp_suffix}\")\n",
    ").list_attr(\"id\")\n",
    "df_max_abundance_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "# Rename dilution reactions to match\n",
    "reaction_enzyme_map = {\n",
    "    enzyme_rid: enzyme_rid.replace(\n",
    "        f\"{enzyme_rxn_prefix}{enzyme_met_prefix}\", \"\"\n",
    "    ).replace(f\"{enzyme_met_suffix_total}{comp_suffix}\", \"\")\n",
    "    for enzyme_rid in df_max_abundance_per_model[\"reactions\"]\n",
    "}\n",
    "df_max_abundance_per_model[\"reactions\"] = df_max_abundance_per_model[\n",
    "    \"reactions\"\n",
    "].replace(reaction_enzyme_map)\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.groupby(\n",
    "    [\"model\", \"reactions\", \"optimum\"]\n",
    ")[[\"max\"]].max()\n",
    "# Address issues possibly caused by floating point precision, atol is ideally a value that prevents any negative ranges\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if x < 0 else x\n",
    ")\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.rename(\n",
    "    {\"max\": \"abundance\"}, axis=1\n",
    ")\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_abundance_per_model[(df_max_abundance_per_model < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95269b45-4f16-4d09-95c5-af4734b23d82",
   "metadata": {},
   "source": [
    "#### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60602d4b-89ba-493b-ae29-55a35c669a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_all = pd.merge(\n",
    "    df_max_flux_per_model,\n",
    "    df_max_abundance_per_model,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "df_data_all = df_data_all.reset_index(drop=False)\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3094239-cea4-4899-8cba-84b0f3969ba3",
   "metadata": {},
   "source": [
    "### Identify donor, timepoints, and genotypes for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04139aab-4c0c-4845-a65f-912ac235da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(\n",
    "    processed_data_dirpath / \"Metadata.csv\",\n",
    "    index_col=[sample_key],\n",
    ").convert_dtypes()\n",
    "df_metadata = df_metadata.loc[:, genotypes]\n",
    "\n",
    "df = df_metadata.reset_index(drop=False)\n",
    "df[sample_key] = df[sample_key].str.split(\"_\", expand=True).iloc[:, 0]\n",
    "df = df.drop_duplicates().set_index(sample_key)\n",
    "for col, series in df.items():\n",
    "    print(series.value_counts().sort_index())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ad86d-3278-43c9-9e41-27b9f358440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\"sample\", \"donor\", \"time\", \"genotype\"]\n",
    "for key, search_re in zip(\n",
    "    metadata_columns, [sample_id_re, donor_re, time_re, genotype_re]\n",
    "):\n",
    "    if key == \"sample\":\n",
    "        df_data_all[key] = df_data_all[\"model\"].apply(\n",
    "            lambda x: x.replace(f\"{pcmodel.id}_\", \"\")\n",
    "        )\n",
    "    else:\n",
    "        df_data_all[key] = df_data_all[\"model\"].apply(\n",
    "            lambda x: search_re.search(x).group(1) if search_re.search(x) else pd.NA\n",
    "        )\n",
    "\n",
    "df_data_all = df_data_all.merge(\n",
    "    df_metadata, left_on=\"sample\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "# Add genotypes alleles\n",
    "for genotype in genotypes:\n",
    "    df = df_data_all[df_data_all[\"genotype\"] == genotype][\"sample\"]\n",
    "    df = df.str.rsplit(\"_\", n=1, expand=True)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df = df.iloc[:, -1]\n",
    "    df_data_all.loc[df.index, genotype] = df.values\n",
    "df_data_all = df_data_all.drop(\"genotype\", axis=1)\n",
    "metadata_columns = metadata_columns[:-1] + genotypes\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902ff15-bf6a-43a9-ad82-d81742231410",
   "metadata": {},
   "source": [
    "## Compute statistically significant results between groups\n",
    "### Remove models based on data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce7d4c-834d-4b2f-b705-059839846fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_samples = df_data_all[\n",
    "    [not bool(operation_re.search(x)) for x in df_data_all[\"model\"]]\n",
    "].reset_index(drop=True)\n",
    "df_data_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa2ba8-3d0e-4e90-b79d-f46cf5940a2a",
   "metadata": {},
   "source": [
    "### Combine sample results based on donor genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4e29e-14bc-4b7e-9642-df0ec2cf7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_key = \"sample\"\n",
    "groupby_operation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ba1d1-7210-4800-897a-02f54455e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if groupby_operation is None:\n",
    "    df_data_for_analyses = df_data_samples.copy()\n",
    "elif groupby_operation == \"mean\":\n",
    "    df_data_for_analyses = df_data_samples.groupby(\n",
    "        [\"reactions\", id_key, \"optimum\"], as_index=False\n",
    "    )[[\"min\", \"max\", \"range\", \"abundance\"] + genotypes].mean()\n",
    "elif groupby_operation == \"median\":\n",
    "    df_data_for_analyses = df_data_samples.groupby(\n",
    "        [\"reactions\", id_key, \"optimum\"], as_index=False\n",
    "    )[[\"min\", \"max\", \"range\", \"abundance\"] + genotypes].median()\n",
    "else:\n",
    "    raise ValueError(f\"Unrecognized operation to perform: '{groupby_operation}'\")\n",
    "df = df_data_for_analyses[genotypes].dropna().astype(int)\n",
    "df_data_for_analyses.loc[df.index, genotypes] = df\n",
    "df_metadata = (\n",
    "    df_data_for_analyses[[id_key] + genotypes].drop_duplicates().set_index(id_key)\n",
    ")\n",
    "df_data_for_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f4389-594f-4c01-8743-94cbef5ffe54",
   "metadata": {},
   "source": [
    "### Create groups of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91c097-af01-425f-a72e-9c3a5df6450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_key = \"ALL\"\n",
    "model_groups = {all_key: list(df_data_for_analyses[id_key].unique())}\n",
    "\n",
    "\n",
    "def create_group_of_models(df, id_key, groupby, verbose=False):\n",
    "    grouped = df.groupby(groupby)[id_key].agg(lambda x: list(x.unique()))\n",
    "    grouped = {\n",
    "        \"_\".join([str(x) for x in ensure_iterable(k)]): v\n",
    "        for k, v in grouped.to_dict().items()\n",
    "    }\n",
    "    if verbose:\n",
    "        max_name_len = max([len(group_name) for group_name in list(grouped)])\n",
    "        for group_name, model_list in grouped.items():\n",
    "            spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "            print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290b56e-0285-4f7a-84b1-0c6376dc545d",
   "metadata": {},
   "source": [
    "#### Based on genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b83f1-abda-4ade-b5bd-098b6885dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genotype in genotypes:\n",
    "    grouped = create_group_of_models(\n",
    "        df_data_for_analyses, id_key=id_key, groupby=genotype, verbose=False\n",
    "    )\n",
    "    grouped = {f\"{genotype}_{str(k)}\": v for k, v in grouped.items()}\n",
    "    if verbose:\n",
    "        max_name_len = max([len(group_name) for group_name in list(grouped)])\n",
    "        for group_name, model_list in grouped.items():\n",
    "            spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "            print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "    model_groups.update(grouped)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f798fa7e-2a9a-4664-afbe-b30fd94b1df0",
   "metadata": {},
   "source": [
    "### View groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1152679-d912-4768-802c-5d365e05c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Possible groups for analyses\\n============================\")\n",
    "max_name_len = max([len(group_name) for group_name in list(model_groups)])\n",
    "for group_name, model_list in model_groups.items():\n",
    "    spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "    print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "\n",
    "df_data_for_analyses = df_data_for_analyses.set_index([\"reactions\", id_key])\n",
    "df_data_for_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2684b9-37c0-462b-98a1-5d20012b4e93",
   "metadata": {},
   "source": [
    "#### Ensure groups exist and setup directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c9396-815f-450e-a20c-d58be95ac66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict = defaultdict(dict)\n",
    "item_list = genotypes\n",
    "groups_dict[all_key].update({item: {} for item in item_list})\n",
    "\n",
    "header = \"Expected directory structure\"\n",
    "print(\"\\n\".join((header, \"=\" * len(header), all_key)))\n",
    "for idx, (group_name, subgroups) in enumerate(sorted(groups_dict[all_key].items())):\n",
    "    print(\"\\u2514\\u2500\\u2500\" + f\" {group_name}\")\n",
    "\n",
    "group_results_dirpath_dict = {all_key: corr_results_dirpath}\n",
    "for group_name, subgroups in groups_dict[all_key].items():\n",
    "    group_results_dirpath_dict[group_name] = (\n",
    "        group_results_dirpath_dict[all_key] / group_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8fc2e6-5be8-4ac8-98ad-92d69335d316",
   "metadata": {},
   "source": [
    "#### Load subsystems and metabolic categories to enrich results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fff7e1-e706-4abf-adc9-6ee5a72bfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsystems_to_exclude = {\"Pseudoreactions\"}\n",
    "use_abbrevs = True\n",
    "abbreviations = {\n",
    "    \"Amino acid metabolism\": \"A\",\n",
    "    \"Carbohydrate metabolism\": \"C\",\n",
    "    \"Lipid metabolism\": \"L\",\n",
    "    \"Metabolism of cofactors and vitamins\": \"V\",\n",
    "    \"Nucleotide metabolism\": \"N\",\n",
    "    \"Reactive species\": \"R\",\n",
    "    \"Transport reactions\": \"T\",\n",
    "    \"Other\": \"O\",\n",
    "}\n",
    "categories_to_keep = list(abbreviations)\n",
    "\n",
    "df_pathways = pd.read_csv(\n",
    "    get_dirpath(\"curation\") / \"subsystems.tsv\", sep=\"\\t\", dtype=str\n",
    ").fillna(\"\")\n",
    "\n",
    "# Rename \"name\" to subsystem to match reaction attribute\n",
    "df_pathways = df_pathways.rename({\"name\": \"subsystem\"}, axis=1)\n",
    "# Group \"Metabolism of other amino acids\" with amino acids rather than treat as \"other\"\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].replace(\n",
    "    \"Metabolism of other amino acids\", \"Amino acid metabolism\"\n",
    ")\n",
    "\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].apply(\n",
    "    lambda x: (\"Other\" if x not in categories_to_keep else x)\n",
    ")\n",
    "df_pathways = df_pathways[~df_pathways[\"subsystem\"].isin(subsystems_to_exclude)].copy()\n",
    "subsystem_to_category_dict = df_pathways.set_index(\"subsystem\")[\"category\"].to_dict()\n",
    "df_pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281f9fb-3124-4f6b-95c6-ccc02b3c6733",
   "metadata": {},
   "source": [
    "## Compute significant results between groups\n",
    "#### Compare all subgroups at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bffd48-9cbd-41c7-9994-7128a2878d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_group = \"ATP11C_V972M\"\n",
    "optimum = 0\n",
    "value_to_compare = \"range\"\n",
    "group_timepoints_by = None\n",
    "compare_pairwise = True\n",
    "compare_all_groups = True\n",
    "if compare_group in genotypes:\n",
    "    ordered_group_to_compare = [f\"{compare_group}_{alleles}\" for alleles in [0, 1, 2]]\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "all_samples_for_comparison = [\n",
    "    value for g in ordered_group_to_compare for value in np.array(model_groups[g])\n",
    "]\n",
    "df_data_for_correlations = df_data_for_analyses.loc[\n",
    "    pd.IndexSlice[:, all_samples_for_comparison], :\n",
    "]\n",
    "df_data_for_correlations = df_data_for_correlations[\n",
    "    df_data_for_correlations[\"optimum\"] == optimum\n",
    "].drop(\"optimum\", axis=1)\n",
    "\n",
    "print(\"Groups to compare\\n=================\")\n",
    "pairwise_group_combos = []\n",
    "if compare_all_groups:\n",
    "    print(tuple(ordered_group_to_compare))\n",
    "if compare_pairwise:\n",
    "    pairwise_group_combos += list(combinations(ordered_group_to_compare, 2))\n",
    "    for group in pairwise_group_combos:\n",
    "        print(group)\n",
    "df_data_for_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba2921-371b-4f2a-83ac-52eab0b6ae13",
   "metadata": {},
   "source": [
    "### Kruskal Wallis H-test (3 or more groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e98727-a180-40bf-a3bc-0795a3c4ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = defaultdict(dict)\n",
    "sample_size_too_small = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5742b8-10fe-42da-a85f-2df06d9dfc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ordered_group_to_compare) > 2:\n",
    "    for rid in df_data_for_correlations.index.get_level_values(\"reactions\").unique():\n",
    "        df_data_rxn = df_data_for_correlations.loc[rid]\n",
    "        df_data_rxn_opt_value = df_data_rxn[value_to_compare].copy()\n",
    "        data_arrays = {\n",
    "            group_name: df_data_rxn_opt_value.loc[model_groups[group_name]].values\n",
    "            for group_name in ordered_group_to_compare\n",
    "        }\n",
    "        values = list(data_arrays.values())\n",
    "        unique_values = set(\n",
    "            [v for value_list in values for v in value_list if not np.isnan(v)]\n",
    "        )\n",
    "        if any([len(v[~np.isnan(v)]) < 6 for v in values]):\n",
    "            sample_size_too_small[tuple(ordered_group_to_compare)].add(rid)\n",
    "            print(rid)\n",
    "            break\n",
    "        if len(unique_values) <= 1:\n",
    "            # Skip variables that do not have any differences\n",
    "            results_dict[tuple(ordered_group_to_compare)][rid] = dict(\n",
    "                zip([\"statistic\", \"pvalue\"], [pd.NA, pd.NA])\n",
    "            )\n",
    "        else:\n",
    "            result = kruskal(*values, nan_policy=\"omit\")\n",
    "            results_dict[tuple(ordered_group_to_compare)][rid] = {\n",
    "                attr: getattr(result, attr) for attr in [\"statistic\", \"pvalue\"]\n",
    "            }\n",
    "dataframes = {\n",
    "    key: pd.DataFrame.from_dict(values, orient=\"index\")\n",
    "    for key, values in results_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05f036-101b-4e2f-9301-e71c65e81f67",
   "metadata": {},
   "source": [
    "### Mann Whiteney U test (2 groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136fe70-1abd-4b17-a351-c5ca42a969be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ordered_group_to_compare) == 2 or compare_pairwise:\n",
    "    for rid in df_data_for_correlations.index.get_level_values(\"reactions\").unique():\n",
    "        df_data_rxn = df_data_for_correlations.loc[rid]\n",
    "        df_data_rxn_opt_value = df_data_rxn[value_to_compare].copy()\n",
    "        data_arrays = {\n",
    "            group_name: df_data_rxn_opt_value.loc[model_groups[group_name]].values\n",
    "            for group_name in ordered_group_to_compare\n",
    "        }\n",
    "        combos = (\n",
    "            [tuple(ordered_group_to_compare)]\n",
    "            if not pairwise_group_combos\n",
    "            else pairwise_group_combos\n",
    "        )\n",
    "        for combo in combos:\n",
    "            values = [data_arrays[group] for group in combo]\n",
    "            unique_values = set(\n",
    "                [v for value_list in values for v in value_list if not np.isnan(v)]\n",
    "            )\n",
    "            if any([len(v[~np.isnan(v)]) < 6 for v in values]):\n",
    "                sample_size_too_small[tuple(combo)].add(rid)\n",
    "                print(rid)\n",
    "            if len(unique_values) <= 1:\n",
    "                # Skip variables that do not have any differences\n",
    "                result = dict(zip([\"statistic\", \"pvalue\"], [pd.NA, pd.NA]))\n",
    "            else:\n",
    "                result = mannwhitneyu(*values, nan_policy=\"omit\", method=\"auto\")\n",
    "                result = {\n",
    "                    attr: getattr(result, attr) for attr in [\"statistic\", \"pvalue\"]\n",
    "                }\n",
    "            results_dict[combo][rid] = result\n",
    "dataframes = {\n",
    "    key: pd.DataFrame.from_dict(values, orient=\"index\")\n",
    "    for key, values in results_dict.items()\n",
    "}\n",
    "print(f\"Number of different comparisons made: {len(dataframes)}\")\n",
    "print(\"Groups compared\\n===============\")\n",
    "for key in list(dataframes):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16a3b4-ff30-4ede-a251-5ef488ed13ab",
   "metadata": {},
   "source": [
    "### Determine significance using p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864a7a5-d2c0-4b80-addf-830f9f36a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_sig = 0.05\n",
    "enzyme_reactions_only = False\n",
    "include_boundary_reactions = False\n",
    "sort_by_subsystem = False\n",
    "standardize_by = \"mean\"\n",
    "use_group_means = False\n",
    "fdr_method = None\n",
    "\n",
    "significant_dataframes = {}\n",
    "for met in model.metabolites.query(lambda x: x.compartment == \"e\"):\n",
    "    met.name += \" (extracellular)\"\n",
    "metadata_columns = [\n",
    "    \"name\",\n",
    "    \"stoichiometry\",\n",
    "    \"proteins\",\n",
    "    \"pvalue\" if not fdr_method else \"adj_pvalue\",\n",
    "    \"subsystem\",\n",
    "    \"category\",\n",
    "]\n",
    "for key, df in dataframes.items():\n",
    "    df = df.dropna().copy()\n",
    "    df[\"pvalue\"] = df[\"pvalue\"].astype(float)\n",
    "    if fdr_method is not None and not fdr_method in {\"bon\", \"bh\", \"by\"}:\n",
    "        raise ValueError(f\"Unrecognized FDR correction method : {fdr_method}\")\n",
    "    elif fdr_method == \"bon\":\n",
    "        pvalue_key = \"adj_pvalue\"\n",
    "        df[pvalue_key] = df[\"pvalue\"] * len(df[\"pvalue\"])\n",
    "    elif fdr_method in {\"bh\", \"by\"}:\n",
    "        pvalue_key = \"adj_pvalue\"\n",
    "        df[pvalue_key] = false_discovery_control(\n",
    "            df[\"pvalue\"].astype(float), method=fdr_method\n",
    "        )\n",
    "    else:\n",
    "        pvalue_key = \"pvalue\"\n",
    "    print(df.loc[\"PSFLIPt\", \"pvalue\"])\n",
    "    pvalue = pvalue_sig if isinstance(pvalue_sig, (float, int)) else pvalue_sig[key]\n",
    "    df = df[df[pvalue_key] <= pvalue].drop(\"statistic\", axis=1)\n",
    "    if enzyme_reactions_only:\n",
    "        df_pivot = df_data_for_correlations.loc[\n",
    "            df.index, [\"abundance\", value_to_compare]\n",
    "        ].dropna(subset=\"abundance\")\n",
    "        df_pivot = df_pivot.drop(\"abundance\", axis=1)\n",
    "    else:\n",
    "        df_pivot = df_data_for_correlations.loc[df.index, value_to_compare]\n",
    "    if not include_boundary_reactions:\n",
    "        df_pivot = df_pivot[\n",
    "            ~df_pivot.index.isin(\n",
    "                model.reactions.query(lambda x: x.boundary).list_attr(\"id\"),\n",
    "                level=\"reactions\",\n",
    "            )\n",
    "        ]\n",
    "    df_pivot = df_pivot.reset_index(drop=False)\n",
    "    df_pivot = df_pivot.pivot(\n",
    "        columns=id_key, index=\"reactions\", values=value_to_compare\n",
    "    )\n",
    "    df = pd.merge(df, df_pivot, left_index=True, right_index=True).sort_values(\n",
    "        pvalue_key\n",
    "    )\n",
    "    df.index.name = \"reactions\"\n",
    "    df = df.reset_index(drop=False).set_index([\"reactions\", pvalue_key]).T\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame([], columns=metadata_columns)\n",
    "    else:\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                # Sort index by donor number and subgroup while concatenating\n",
    "                df.loc[model_groups[g]].sort_index()\n",
    "                for g in key\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "        df = df.T.reset_index(drop=False)\n",
    "        # Enrich results\n",
    "        # df[\"name\"] = [r.name.replace(\",\", \"\") for r in model.reactions.get_by_any(list(df[\"reactions\"].values))]\n",
    "        df[\"name\"] = [\n",
    "            r.name for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "        ]\n",
    "        df[\"stoichiometry\"] = [\n",
    "            r.build_reaction_string(use_metabolite_names=True)\n",
    "            for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "        ]\n",
    "        df[\"subsystem\"] = [\n",
    "            r.subsystem\n",
    "            for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "        ]\n",
    "        df[\"category\"] = df[\"subsystem\"].replace(subsystem_to_category_dict)\n",
    "        df[\"proteins\"] = [\n",
    "            \";\".join(sorted([g.id for g in r.genes]))\n",
    "            for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "        ]\n",
    "        # Replace commas to prevent issues with CSV export\n",
    "        # df[\"subsystem\"] = df[\"subsystem\"].apply(lambda x: x.replace(\",\", \"\"))\n",
    "        # df[\"category\"] = df[\"category\"].apply(lambda x: x.replace(\",\", \"\"))\n",
    "        df[pvalue_key] = df[pvalue_key].apply(lambda x: round(x, 5))\n",
    "\n",
    "        df = df.set_index(\"reactions\")\n",
    "        if sort_by_subsystem:\n",
    "            df = df.sort_values(by=[\"category\", \"subsystem\", \"proteins\"])\n",
    "\n",
    "        df_meta = df.loc[:, metadata_columns].copy()\n",
    "        df_data = df.loc[:, ~df.columns.isin(df_meta.columns)].copy()\n",
    "        if use_group_means:\n",
    "            df_data = pd.concat(\n",
    "                [df_data.loc[:, model_groups[g]].mean(axis=1) for g in key], axis=1\n",
    "            )\n",
    "            df_data.columns = list(key)\n",
    "        if standardize_by == \"mean\":\n",
    "            df_data = (\n",
    "                df_data.sub(df_data.mean(axis=1), axis=0)\n",
    "                .div(df_data.std(axis=1), axis=0)\n",
    "                .dropna(how=\"all\", axis=0)\n",
    "            )\n",
    "        elif standardize_by == \"median\":\n",
    "            df_data = (\n",
    "                (df_data.T - df_data.median(axis=1))\n",
    "                / (df_data.quantile(q=0.75, axis=1) - df_data.quantile(q=0.25, axis=1))\n",
    "            ).T\n",
    "        else:\n",
    "            df_data = df_data.loc[\n",
    "                :, [x for x in df_metadata.index if x in df_data.columns]\n",
    "            ]\n",
    "        # Put dataframes back together for custom reordering\n",
    "        df = df_data.merge(df_meta, left_index=True, right_index=True)\n",
    "    significant_dataframes[key] = df\n",
    "    print(key)\n",
    "    print(f\"Min & Max values: ({df_data.min().min():.4f}, {df_data.max().max():.4f})\")\n",
    "    print()\n",
    "key = tuple(ordered_group_to_compare)\n",
    "# key = ('ATP11C_V972M_0', 'ATP11C_V972M_2')\n",
    "df = significant_dataframes[key]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dc29f-f123-457b-8d29-0d7461a189f7",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd72da-0f5b-47c3-bdf4-0cfdd3c54bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = \"tsv\"\n",
    "for key, df_main in significant_dataframes.items():\n",
    "    df_meta_row = df_main.loc[:, metadata_columns].copy()\n",
    "    df_data = df_main.loc[:, ~df_main.columns.isin(df_meta.columns)].copy()\n",
    "    df_meta_col = df_metadata.copy()\n",
    "    if use_group_means:\n",
    "        df_meta_col = df_meta_col.groupby(compare_group, as_index=False).mean()\n",
    "        df_meta_col.index = [\n",
    "            f\"{genotype}_{x}\" for x in df_meta_col[compare_group].values\n",
    "        ]\n",
    "\n",
    "    df_meta_col = df_meta_col.loc[list(df_data.columns)].copy()\n",
    "    for df_type, df in zip(\n",
    "        [\"data\", \"meta_row\", \"meta_col\"], [df_data, df_meta_row, df_meta_col]\n",
    "    ):\n",
    "        filename = \"_\".join(\n",
    "            [\"MannWhiteney\" if len(key) == 2 else \"Kruskal\"]\n",
    "            + [g.split(\"_\")[-1] for g in key]\n",
    "            + [id_key]\n",
    "            + [df_type]\n",
    "        )\n",
    "        if use_group_means:\n",
    "            filename += \"_mean\"\n",
    "        group_results_dirpath_dict[group_name].mkdir(exist_ok=True)\n",
    "        filename = group_results_dirpath_dict[group_name] / filename\n",
    "        df.to_csv(\n",
    "            f\"{filename}.{ftype}\", sep=\"\\t\" if ftype == \"tsv\" else \",\", index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52dc0c-0d05-4380-bec3-61f8e4e72c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
