{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9114c6-b2d1-48a1-8ba3-6686a1ea2449",
   "metadata": {},
   "source": [
    "# Compute correlations between flux and abundance - REDS Recall\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d694e76-31c0-4aba-add6-a07a00a5d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Package Information\n",
      "-------------------\n",
      "rbc-gem-utils 0.0.3\n",
      "\n",
      "Dependency Information\n",
      "----------------------\n",
      "beautifulsoup4                       4.13.4\n",
      "bio                                   1.8.0\n",
      "cobra                                0.29.1\n",
      "depinfo                               2.2.0\n",
      "gurobipy                             12.0.3\n",
      "matplotlib                           3.10.3\n",
      "matplotlib-venn                       1.1.2\n",
      "memote                               0.17.0\n",
      "networkx                                3.5\n",
      "notebook                              7.4.4\n",
      "openpyxl                              3.1.5\n",
      "pandas                                2.3.1\n",
      "pre-commit                            4.2.0\n",
      "rbc-gem-utils[database,network,vis] missing\n",
      "requests                             2.32.4\n",
      "scikit-learn                          1.7.0\n",
      "scipy                                1.16.0\n",
      "seaborn                              0.13.2\n",
      "\n",
      "Build Tools Information\n",
      "-----------------------\n",
      "pip          25.1\n",
      "setuptools 78.1.1\n",
      "wheel      0.45.1\n",
      "\n",
      "Platform Information\n",
      "--------------------\n",
      "Windows 10-AMD64\n",
      "CPython  3.11.13\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import textwrap\n",
    "import io\n",
    "\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as mpl_venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    build_string,\n",
    "    ensure_iterable,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    split_string,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    DEFAULT_PROTEOME_COMPARTMENT,\n",
    "    EnzymeDilution,\n",
    "    add_relaxation_budget,\n",
    "    classify_reactions_by_abundance_dependence,\n",
    "    load_overlay_model,\n",
    "    plot_correlations,\n",
    "    plot_reaction_counts_for_proteins,\n",
    "    plot_ring_of_category_counts,\n",
    ")\n",
    "from rbc_gem_utils.visualization import cmap_map\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c972a-9f2f-4b88-a65c-017d1a6561d6",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418ddc9c-b48e-400a-b5a1-e4e6bfe73bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <td><strong>Attribute</strong></td>\n",
       "      <td><strong>Description</strong></td>\n",
       "      <td><strong>Value</strong></td>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><pre>solver</pre></td>\n",
       "      <td>Mathematical optimization solver</td>\n",
       "      <td>gurobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>tolerance</pre></td>\n",
       "        <td>General solver tolerance (feasibility, integrality, etc.)</td>\n",
       "        <td>1e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>lower_bound</pre></td>\n",
       "        <td>Default reaction lower bound</td>\n",
       "        <td>-1e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>upper_bound</pre></td>\n",
       "        <td>Default reaction upper bound</td>\n",
       "        <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>processes</pre></td>\n",
       "        <td>Number of parallel processes</td>\n",
       "        <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>cache_directory</pre></td>\n",
       "        <td>Path for the model cache</td>\n",
       "        <td>C:\\Users\\P7875\\AppData\\Local\\opencobra\\cobrapy\\Cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>max_cache_size</pre></td>\n",
       "        <td>Maximum cache size in bytes</td>\n",
       "        <td>104857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>cache_expiration</pre></td>\n",
       "        <td>Model cache expiration time in seconds (if any)</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "\n",
       "solver: gurobi\n",
       "tolerance: 1e-09\n",
       "lower_bound: -1e-08\n",
       "upper_bound: 100000000.0\n",
       "processes: 127\n",
       "cache_directory: C:\\Users\\P7875\\AppData\\Local\\opencobra\\cobrapy\\Cache\n",
       "max_cache_size: 104857600\n",
       "cache_expiration: None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-9\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3720a-d637-4115-8960-f48671ee725a",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b08faa-240f-44ee-9d16-ddbdc556852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "grouped_data_key = 'Sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ccb7e-c784-4b63-bfe9-7ebdce0e24b5",
   "metadata": {},
   "source": [
    "### Set variables for sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6435bfd2-9c1f-4f09-8a7a-3d0a0efba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"PUBLIC RECALL DONOR ID\"\n",
    "time_key = \"DAY\"\n",
    "timepoints = [\"D10\", \"D23\", \"D42\"]\n",
    "genotypes = [\"G6PD_V68M\", \"ATP11C_V972M\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>S(?P<num>\\d+))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "genotype_re = re.compile(rf\"(?P<genotype>({'|'.join(genotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478c85d-b0ed-466c-b6d3-e8dead52f018",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e59494-b23d-4775-8863-1baeb1f46194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = \"xml\"  # In our experience, SBML/XML loads faster, but will take up to 4x more space uncompressed as compared to JSON\n",
    "run_computations = True  # Keep off to use previously computed results\n",
    "overwrite = False  # Whether to allow overwriting of previous simulation results\n",
    "verbose = True\n",
    "\n",
    "# Objective reactions\n",
    "objective_reactions = [\"NaKt\"] \n",
    "# Reactions that must have the capability to carry flux, sort for consistency\n",
    "required_flux_reactions = [] # Add reactions to this list\n",
    "required_flux_reactions = sorted(set(objective_reactions + required_flux_reactions))\n",
    "\n",
    "\n",
    "generate_all_group_visuals = False\n",
    "\n",
    "zip_kwargs = dict(\n",
    "    compression=zipfile.ZIP_DEFLATED,\n",
    "    compresslevel=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf8045-4f96-4709-a5b6-e007bf15f5a2",
   "metadata": {},
   "source": [
    "#### Set prefixes/suffixes to expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d10b0f-d1d6-4f39-b5a7-21d55ce0ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.dilution\"]\n",
    "enzyme_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.metabolite\"]\n",
    "enzyme_met_suffix_total = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]\n",
    "comp_suffix = f\"_{DEFAULT_PROTEOME_COMPARTMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bb5e1-67d6-4436-af4a-0f34befaa111",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ad3312-69a9-4bd9-92c4-a2d467bed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2d514-cb81-4968-95b6-95e758cd3e73",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ccd462b-0c65-4b33-b745-6a4e74996f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (get_dirpath(use_temp=\"processed\") / model_id / \"OVERLAY\" / organism / dataset_name / grouped_data_key)\n",
    "pcfva_results_dirpath = (results_dirpath / \"pcFVA\" / \"_\".join((\"REQ\", *required_flux_reactions)) /  \"_\".join((\"OBJ\", *objective_reactions)))\n",
    "\n",
    "# Objective reaction does not matter since correlations are computed\n",
    "# based on min and max fluxes and abundance, which are obtained when optimum is 0.\n",
    "corr_results_dirpath = results_dirpath / \"correlations\"\n",
    "# Ensure directory  exists\n",
    "corr_results_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b8d0f-8ca2-48e4-9da1-7db464f01407",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541f7b2c-ad0d-4404-899b-fa05a0bd7fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2664191\n",
      "Academic license - for non-commercial use only - expires 2026-05-12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>RBC_GEM_PC</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>108773e7390</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>7785</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>15624</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of genes</strong></td>\n",
       "                <td>723</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>68</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*NaKt - 1.0*NaKt_reverse_db47e</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>cytosol, extracellular space, protein compartment</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model RBC_GEM_PC at 0x108773e7390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "# Add relaxation budget to initial PC model to get names of relaxation reactions\n",
    "add_relaxation_budget(pcmodel, 0, verbose=False)\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf0307-bf28-4f10-8784-143d62c669a7",
   "metadata": {},
   "source": [
    "## Load pcFVA generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "537fccd8-52b6-44c9-83a0-af5c62b7fd2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\P7875\\\\github\\\\RBC-GEM\\\\data\\\\processed\\\\RBC_GEM\\\\OVERLAY\\\\Human\\\\REDSRecall\\\\Sample\\\\pcFVA\\\\REQ_NaKt\\\\OBJ_NaKt\\\\RBC_GEM_PC_All_FVAsols.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Test to see if results were recently generated in this run, otherwise load DataFrame of generated results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_pcfva_all = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpcfva_results_dirpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpcmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_All_FVAsols.zip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df_pcfva_all\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\site-packages\\pandas\\io\\common.py:794\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# ZIP Compression\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m compression == \u001b[33m\"\u001b[39m\u001b[33mzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    791\u001b[39m     \u001b[38;5;66;03m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;00m\n\u001b[32m    792\u001b[39m     \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[32m    793\u001b[39m     \u001b[38;5;66;03m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     handle = \u001b[43m_BytesZipFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompression_args\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m handle.buffer.mode == \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    798\u001b[39m         handles.append(handle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\site-packages\\pandas\\io\\common.py:1037\u001b[39m, in \u001b[36m_BytesZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, archive_name, **kwargs)\u001b[39m\n\u001b[32m   1034\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m, zipfile.ZIP_DEFLATED)\n\u001b[32m   1035\u001b[39m \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"ZipFile\",\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;66;03m# base class \"_BufferedWriter\" defined the type as \"BytesIO\")\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m \u001b[38;5;28mself\u001b[39m.buffer: zipfile.ZipFile = \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\memote-rbc-gem\\Lib\\zipfile.py:1295\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1294\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = io.open(file, filemode)\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1297\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\P7875\\\\github\\\\RBC-GEM\\\\data\\\\processed\\\\RBC_GEM\\\\OVERLAY\\\\Human\\\\REDSRecall\\\\Sample\\\\pcFVA\\\\REQ_NaKt\\\\OBJ_NaKt\\\\RBC_GEM_PC_All_FVAsols.zip'"
     ]
    }
   ],
   "source": [
    "# Test to see if results were recently generated in this run, otherwise load DataFrame of generated results\n",
    "df_pcfva_all = pd.read_csv(\n",
    "    pcfva_results_dirpath / f\"{pcmodel.id}_All_FVAsols.zip\",\n",
    "    index_col=None,\n",
    ")\n",
    "\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a4524-c95b-4980-a95f-5ba109e75025",
   "metadata": {},
   "source": [
    "## Create DataFrame for calculations and visualizations\n",
    "### Get maximum reaction fluxes and associated abundance values\n",
    "#### Get maximum reaction fluxes and ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbb8d3-7fc4-4168-84ad-57f84ee4824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = model.reactions.query(lambda x: len(x.genes))\n",
    "df_max_flux_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "df_max_flux_per_model = df_max_flux_per_model.groupby([\"model\", \"reactions\", \"optimum\"])[[\"min\", \"max\"]].agg(\n",
    "    {\n",
    "        \"min\": \"min\", # Minimum reaction flux per model\n",
    "        \"max\": \"max\", # Maximum reaction flux per model\n",
    "    }\n",
    ")\n",
    "# Address issues possibly caused by floating point precision, ideally a value that prevents any negative ranges\n",
    "df_max_flux_per_model.loc[df_max_flux_per_model[\"max\"] < df_max_flux_per_model[\"min\"], [\"max\", \"min\"]] = [0, 0]\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_flux_per_model[\"max\"] = df_max_flux_per_model[\"max\"].apply(lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol))))\n",
    "df_max_flux_per_model[\"min\"] = df_max_flux_per_model[\"min\"].apply(lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol))))\n",
    "df_max_flux_per_model[\"range\"] = df_max_flux_per_model[\"max\"] - df_max_flux_per_model[\"min\"]\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_flux_per_model[df_max_flux_per_model[\"range\"] < 1e-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f5c535-cdb4-447c-9dba-28163306b3dd",
   "metadata": {},
   "source": [
    "#### Get maximum \"enzyme\" abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128b665-a9d7-424b-8ab3-b2014f6ca5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, EnzymeDilution) and x.id.endswith(f\"{enzyme_met_suffix_total}{comp_suffix}\")\n",
    ").list_attr(\"id\")\n",
    "df_max_abundance_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "# Rename dilution reactions to match \n",
    "reaction_enzyme_map = {\n",
    "    enzyme_rid: enzyme_rid.replace(\n",
    "        f\"{enzyme_rxn_prefix}{enzyme_met_prefix}\", \"\"\n",
    "    ).replace(\n",
    "        f\"{enzyme_met_suffix_total}{comp_suffix}\", \"\"\n",
    "    )\n",
    "    for enzyme_rid in df_max_abundance_per_model[\"reactions\"]\n",
    "}\n",
    "df_max_abundance_per_model[\"reactions\"] = df_max_abundance_per_model[\"reactions\"].replace(reaction_enzyme_map)\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.groupby([\"model\", \"reactions\", \"optimum\"])[[\"max\"]].max()\n",
    "# Address issues possibly caused by floating point precision, atol is ideally a value that prevents any negative ranges\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(lambda x: 0 if x < 0 else x)\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol))))\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.rename({\"max\": \"abundance\"}, axis=1)\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_abundance_per_model[(df_max_abundance_per_model < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899d51b-03d9-4715-ac96-080f55287e6b",
   "metadata": {},
   "source": [
    "#### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1359ca-214f-48d6-9766-5894c97746c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_all = pd.merge(\n",
    "    df_max_flux_per_model,\n",
    "    df_max_abundance_per_model,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "df_data_all = df_data_all.reset_index(drop=False)\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90358fb-0470-484c-b9bd-d5c7bc41b063",
   "metadata": {},
   "source": [
    "### Identify donor, timepoints, and genotypes for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba0947-94ea-48a0-95b2-bde5177fec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_Metadata.csv\",\n",
    "    index_col=[sample_key],\n",
    ").convert_dtypes()\n",
    "df_metadata = df_metadata.loc[:, genotypes]\n",
    "\n",
    "df = df_metadata.reset_index(drop=False)\n",
    "df[sample_key] = df[sample_key].str.split(\"_\", expand=True).iloc[:, 0]\n",
    "df = df.drop_duplicates().set_index(sample_key)\n",
    "for col, series in df.items():\n",
    "    print(series.value_counts().sort_index())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18f108-2ef8-47d0-9a84-6f100e5ae43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\"sample\", \"donor\", \"time\", \"genotype\"]\n",
    "for key, search_re in zip(\n",
    "    metadata_columns, [sample_id_re, donor_re, time_re, genotype_re]\n",
    "):\n",
    "    if key == \"sample\":\n",
    "        df_data_all[key] = df_data_all[\"model\"].apply(\n",
    "            lambda x: x.replace(f\"{pcmodel.id}_\", \"\")\n",
    "        )\n",
    "    else:\n",
    "        df_data_all[key] = df_data_all[\"model\"].apply(\n",
    "            lambda x: search_re.search(x).group(1) if search_re.search(x) else pd.NA\n",
    "        )\n",
    "\n",
    "df_data_all = df_data_all.merge(\n",
    "    df_metadata, left_on=\"sample\", right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "# Add genotypes alleles\n",
    "for genotype in genotypes:\n",
    "    df = df_data_all[df_data_all[\"genotype\"] == genotype][\"sample\"]\n",
    "    df = df.str.rsplit(\"_\", n=1, expand=True)\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df = df.iloc[:, -1]\n",
    "    df_data_all.loc[df.index, genotype] = df.values\n",
    "df_data_all = df_data_all.drop(\"genotype\", axis=1)\n",
    "metadata_columns = metadata_columns[:-1] + genotypes\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902ff15-bf6a-43a9-ad82-d81742231410",
   "metadata": {},
   "source": [
    "## Compute correlations between flux and abundance for samples\n",
    "### Remove models based on data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce7d4c-834d-4b2f-b705-059839846fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_samples = df_data_all[\n",
    "    [not bool(operation_re.search(x)) for x in df_data_all[\"model\"]]\n",
    "].reset_index(drop=True)\n",
    "df_data_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89e4794-c332-44da-9383-5c86484c16eb",
   "metadata": {},
   "source": [
    "### Combine sample results based on donor genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89574303-1c9e-4b66-a0fa-c6e0084f69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_key = \"sample\"\n",
    "groupby_operation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9626cc-1864-4ed4-bb72-f7135df33ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if groupby_operation is None:\n",
    "    df_data_for_analyses = df_data_samples.copy()\n",
    "elif groupby_operation == \"mean\":\n",
    "    df_data_for_analyses = df_data_samples.groupby(\n",
    "        [\"reactions\", id_key, \"optimum\"], as_index=False\n",
    "    )[[\"min\", \"max\", \"range\", \"abundance\"] + genotypes].mean()\n",
    "elif groupby_operation == \"median\":\n",
    "    df_data_for_analyses = df_data_samples.groupby(\n",
    "        [\"reactions\", id_key, \"optimum\"], as_index=False\n",
    "    )[[\"min\", \"max\", \"range\", \"abundance\"] + genotypes].median()\n",
    "else:\n",
    "    raise ValueError(f\"Unrecognized operation to perform: '{groupby_operation}'\")\n",
    "df_data_for_analyses = df_data_for_analyses.dropna(subset=genotypes, axis=0, how=\"any\")\n",
    "df_data_for_analyses[genotypes] = df_data_for_analyses[genotypes].astype(int)\n",
    "\n",
    "df_metadata = (\n",
    "    df_data_for_analyses[[id_key] + genotypes].drop_duplicates().set_index(id_key)\n",
    ")\n",
    "df_data_for_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f4389-594f-4c01-8743-94cbef5ffe54",
   "metadata": {},
   "source": [
    "### Create groups of sample models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f41d9-3091-46ef-9fb9-94e0431bfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_correlations_dict = defaultdict(dict)\n",
    "all_key = \"ALL\"\n",
    "model_groups = {all_key: list(df_data_for_analyses[id_key].unique())}\n",
    "\n",
    "\n",
    "def create_group_of_models(df, id_key, groupby, verbose=False):\n",
    "    grouped = df.groupby(groupby)[id_key].agg(lambda x: list(x.unique()))\n",
    "    grouped = {\n",
    "        \"_\".join([str(x) for x in ensure_iterable(k)]): v\n",
    "        for k, v in grouped.to_dict().items()\n",
    "    }\n",
    "    if verbose:\n",
    "        max_name_len = max([len(group_name) for group_name in list(grouped)])\n",
    "        for group_name, model_list in grouped.items():\n",
    "            spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "            print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325246aa-d8a5-4b14-8792-d1a535a6f017",
   "metadata": {},
   "source": [
    "#### Based on timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c3bc0-d33f-44da-9d85-14fb87ca747c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    id_key=id_key,\n",
    "    groupby=[\"time\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4df9b-353a-4f1c-be3e-2d71bd153201",
   "metadata": {},
   "source": [
    "#### Based on genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe435d5b-7d9a-4244-ba58-afbe9a5136e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genotype in genotypes:\n",
    "    grouped = create_group_of_models(\n",
    "        df_data_for_analyses, id_key=id_key, groupby=genotype, verbose=False\n",
    "    )\n",
    "    grouped = {f\"{genotype}_{str(k)}\": v for k, v in grouped.items()}\n",
    "    grouped[genotype] = [model for values in grouped.values() for model in values]\n",
    "    if verbose:\n",
    "        max_name_len = max([len(group_name) for group_name in list(grouped)])\n",
    "        for group_name, model_list in grouped.items():\n",
    "            spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "            print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "    model_groups.update(grouped)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bdd64-6990-414c-a87e-311c488dee4b",
   "metadata": {},
   "source": [
    "### View model groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0baeb6-60fa-4550-992a-b1ee2c7bd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Possible groups for analyses\\n============================\")\n",
    "max_name_len = max([len(group_name) for group_name in list(model_groups)])\n",
    "for group_name, model_list in model_groups.items():\n",
    "    spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "    print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "\n",
    "df_data_for_analyses = df_data_for_analyses.set_index([\"reactions\", id_key])\n",
    "df_data_for_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6c010-c8ee-48c0-b600-a7e43f7cae3c",
   "metadata": {},
   "source": [
    "### Ensure groups exist and setup directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e5c73-bf22-47d6-91be-105531f024d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict = defaultdict(dict)\n",
    "item_list = [\"D10\", \"D23\", \"D42\"] + genotypes\n",
    "groups_dict[all_key].update({item: {} for item in item_list})\n",
    "\n",
    "header = \"Expected directory structure\"\n",
    "print(\"\\n\".join((header, \"=\" * len(header), all_key)))\n",
    "for idx, (group_name, subgroups) in enumerate(sorted(groups_dict[all_key].items())):\n",
    "    print(\"\\u2514\\u2500\\u2500\" + f\" {group_name}\")\n",
    "\n",
    "group_results_dirpath_dict = {all_key: corr_results_dirpath}\n",
    "for group_name, subgroups in groups_dict[all_key].items():\n",
    "    group_results_dirpath_dict[group_name] = (\n",
    "        group_results_dirpath_dict[all_key] / group_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525893a-c700-4167-9f8c-df398a15ae9a",
   "metadata": {},
   "source": [
    "### Compute spearman rank coefficients and p-values\n",
    "#### Compute correlations for each provided group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea10d4-3ca9-4c87-964b-589971e55da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave empty to use all groups, otherwise pnly calculate correlations for provided group\n",
    "group_names = {\"G6PD_V68M\"}\n",
    "correlations_pairs = [(\"flux\", \"abundance\")]\n",
    "for idx, (group_name, group_results_dirpath) in enumerate(\n",
    "    group_results_dirpath_dict.items(), start=1\n",
    "):\n",
    "    if group_names and group_name not in group_names:\n",
    "        continue\n",
    "    group_results_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "    model_list = model_groups[group_name]\n",
    "    if verbose:\n",
    "        header = \"{}) Computing correlations between for group '{}'\".format(\n",
    "            idx, group_name\n",
    "        )\n",
    "        print(\"\\n\".join((\"=\" * len(header), header, \"=\" * len(header))))\n",
    "    for correlations_pair in correlations_pairs:\n",
    "        filepath = (\n",
    "            group_results_dirpath / f\"{correlations_pair[0]}_{correlations_pair[1]}.tsv\"\n",
    "        )\n",
    "        if run_computations:\n",
    "            if filepath.exists() and not overwrite:\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"Already computed correlations between '{}' and '{}'\".format(\n",
    "                            *correlations_pair\n",
    "                        )\n",
    "                    )\n",
    "                df_correlations = pd.read_csv(filepath, sep=\"\\t\", index_col=0)\n",
    "            else:\n",
    "                correlations_dict = defaultdict(dict)\n",
    "                for reaction in df_data_for_analyses.index.unique(level=\"reactions\"):\n",
    "                    # Extract out values corresponding to the reaction and model list\n",
    "                    df_rxn_per_samples = df_data_for_analyses.loc[\n",
    "                        reaction, list(correlations_pair)\n",
    "                    ].loc[model_list]\n",
    "                    with warnings.catch_warnings(action=\"ignore\"):\n",
    "                        rho, pvalue = spearmanr(df_rxn_per_samples)\n",
    "                    correlations_dict[reaction].update({\"rho\": rho, \"p-value\": pvalue})\n",
    "                    if int(verbose) > 1:\n",
    "                        print(f\"For reaction {reaction}:rho={rho:.4f}, p={pvalue:.4e}\")\n",
    "                df_correlations = pd.DataFrame.from_dict(\n",
    "                    correlations_dict, orient=\"index\"\n",
    "                )\n",
    "                df_correlations.index.name = \"reactions\"\n",
    "                df_correlations.to_csv(filepath, sep=\"\\t\", index=True)\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"Finished computing correlations between '{}' and '{}'\".format(\n",
    "                            *correlations_pair\n",
    "                        )\n",
    "                    )\n",
    "        else:\n",
    "            try:\n",
    "                df_correlations = pd.read_csv(filepath, sep=\"\\t\", index_col=0)\n",
    "            except FileNotFoundError:\n",
    "                df_correlations = pd.DataFrame(\n",
    "                    [], index=df_data_for_analyses.index.unique(level=\"reactions\")\n",
    "                )\n",
    "                print(\n",
    "                    \"No previously computed correlations between '{}' and '{}'\".format(\n",
    "                        *correlations_pair\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Already computed correlationsbetween '{}' and '{}'\".format(\n",
    "                        *correlations_pair\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        spearman_correlations_dict[group_name][correlations_pair] = df_correlations\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5059d0f-b228-428e-beec-35badb2cee53",
   "metadata": {},
   "source": [
    "### Classify reactions based on correlation values for all groups\n",
    "Generate figure results for every group. Results can be overriden with by exploring individual groups and changing options for each individually.\n",
    "#### Load subsystems and metabolic categories to enrich results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64464eea-2622-46b7-bf7e-f3282f22bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsystems_to_exclude = {\"Pseudoreactions\"}\n",
    "use_abbrevs = True\n",
    "abbreviations = {\n",
    "    \"Amino acid metabolism\": \"A\",\n",
    "    \"Carbohydrate metabolism\": \"C\",\n",
    "    \"Lipid metabolism\": \"L\",\n",
    "    \"Metabolism of cofactors and vitamins\": \"V\",\n",
    "    \"Nucleotide metabolism\": \"N\",\n",
    "    \"Reactive species\": \"R\",\n",
    "    \"Transport reactions\": \"T\",\n",
    "    \"Other\": \"O\",\n",
    "}\n",
    "categories_to_keep = list(abbreviations)\n",
    "\n",
    "df_pathways = pd.read_csv(\n",
    "    get_dirpath(\"curation\") / \"subsystems.tsv\", sep=\"\\t\", dtype=str\n",
    ").fillna(\"\")\n",
    "\n",
    "# Rename \"name\" to subsystem to match reaction attribute\n",
    "df_pathways = df_pathways.rename({\"name\": \"subsystem\"}, axis=1)\n",
    "# Group \"Metabolism of other amino acids\" with amino acids rather than treat as \"other\"\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].replace(\n",
    "    \"Metabolism of other amino acids\", \"Amino acid metabolism\"\n",
    ")\n",
    "\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].apply(\n",
    "    lambda x: (\"Other\" if x not in categories_to_keep else x)\n",
    ")\n",
    "df_pathways = df_pathways[~df_pathways[\"subsystem\"].isin(subsystems_to_exclude)].copy()\n",
    "df_pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13903f30-3801-4d98-9e73-13b6e3fe95d6",
   "metadata": {},
   "source": [
    "#### Set visualization options to be applied to all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cc405-c757-4483-b6a7-d6e09dc805d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_dependent_cutoff = 0.8\n",
    "abundance_correlated_cutoff = 0.5\n",
    "\n",
    "lower_abundance_labels = (\n",
    "    False  # Whether abundance labels should be at the top or bottom of the plot\n",
    ")\n",
    "plot_correlation_kwargs = dict(\n",
    "    scatter_inch=5,  # Length x width of scatter plot\n",
    "    hist_inch=1,  # Length or width of histogram addition\n",
    "    hist_pad=0.4,  # Space between scatter and histogram\n",
    "    cmap=\"viridis\",  # Colormap for correlation significance\n",
    "    edgecolor=\"black\",\n",
    "    edgewidth=0.5,\n",
    "    grid=False,\n",
    "    zorder=2,\n",
    "    colorbar=True,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    xpad=0.05,\n",
    "    xtick_major=0.4,\n",
    "    ytick_major=50,\n",
    "    xhist=True,  # Whehter to include a histogram of the x-axis values (rho)\n",
    "    yhist=True,  # Whether to include a histogram of the y-axis values (log10(-p))\n",
    "    xhist_ytick_major=100,  # Major y-tick interval for histogram aligned with x-axis\n",
    "    yhist_xtick_major=600,  # Major x-tick interval for histogram aligned with y-axis\n",
    ")\n",
    "plot_correlation_kwargs.update(\n",
    "    dict(\n",
    "        xtick_minor=(\n",
    "            plot_correlation_kwargs.get(\"xtick_major\") / 4\n",
    "            if plot_correlation_kwargs.get(\"xtick_major\")\n",
    "            else None\n",
    "        ),\n",
    "        xhist_ytick_minor=(\n",
    "            plot_correlation_kwargs.get(\"xhist_ytick_major\") / 2\n",
    "            if plot_correlation_kwargs.get(\"xhist_ytick_major\")\n",
    "            else None\n",
    "        ),  # Major y-tick interval for histogram aligned with x`-axis\n",
    "        ytick_minor=(\n",
    "            plot_correlation_kwargs.get(\"ytick_major\") / 5\n",
    "            if plot_correlation_kwargs.get(\"ytick_major\")\n",
    "            else None\n",
    "        ),\n",
    "        yhist_xtick_minor=(\n",
    "            plot_correlation_kwargs.get(\"yhist_xtick_major\") / 2\n",
    "            if plot_correlation_kwargs.get(\"yhist_xtick_major\")\n",
    "            else None\n",
    "        ),  # Major y-tick interval for histogram aligned with x`-axis\n",
    "    )\n",
    ")\n",
    "# plot_correlation_kwargs.update(\n",
    "#     dict(\n",
    "#         xbinwidth=plot_correlation_kwargs.get(\"xtick_minor\")/2 if plot_correlation_kwargs.get(\"xtick_minor\") else None, # Determined by minor ticks if not otherwise set\n",
    "#         ybinwidth=plot_correlation_kwargs.get(\"ytick_minor\")/2 if plot_correlation_kwargs.get(\"ytick_minor\") else None, # Determined by minor ticks if not otherwise set\n",
    "#     )\n",
    "# )\n",
    "# Vertical lines need in a dict where keys are values for the line,\n",
    "# and values are given as (dict of line properties, dict of text properties)\n",
    "lineprops = dict(linewidth=2)\n",
    "textprops = dict(\n",
    "    rotation=90,\n",
    "    fontsize=\"large\",\n",
    "    va=\"center\",\n",
    "    ha=\"left\",\n",
    ")\n",
    "# Set common line properties\n",
    "labels = [\"Dependent\", \"Correlated\", \"Independent\"]\n",
    "cutoff_values = [\n",
    "    abundance_dependent_cutoff,\n",
    "    abundance_correlated_cutoff,\n",
    "    plot_correlation_kwargs[\"xmin\"],\n",
    "]\n",
    "vertical_lines = {\n",
    "    value: (lineprops.copy(), textprops.copy()) for value in cutoff_values\n",
    "}\n",
    "# Set individual line properties\n",
    "colors = dict(zip(cutoff_values, [\"black\", \"black\", \"white\"]))\n",
    "linestyles = dict(zip(cutoff_values, [\"-\", \"--\", \"\"]))\n",
    "for key, label in zip(cutoff_values, labels):\n",
    "    vertical_lines[key][0].update({\"color\": colors[key], \"linestyle\": linestyles[key]})\n",
    "    vertical_lines[key][1].update({\"s\": label})\n",
    "\n",
    "ring_figsize = 3.6\n",
    "plot_ring_kwargs = dict(\n",
    "    wedgesize=0.43,\n",
    "    radius=1,\n",
    "    linewidth=0.75,\n",
    "    edgecolor=\"k\",\n",
    "    inner_label_dist=2,\n",
    "    outer_label_dist=None,\n",
    "    barsize=0.8,\n",
    "    cmax=0.8,\n",
    "    cmin=0.15,\n",
    "    ring_center_textprops=dict(ha=\"center\", va=\"center\", fontsize=\"medium\"),\n",
    ")\n",
    "category_cmaps = {\n",
    "    \"Amino acid metabolism\": \"spring\",\n",
    "    \"Carbohydrate metabolism\": \"Greens\",\n",
    "    \"Lipid metabolism\": \"Blues\",\n",
    "    \"Metabolism of cofactors and vitamins\": \"summer\",\n",
    "    \"Nucleotide metabolism\": \"winter\",\n",
    "    \"Reactive species\": \"Reds\",\n",
    "    \"Transport reactions\": \"Purples\",\n",
    "    \"Other\": \"Grays\",\n",
    "}\n",
    "\n",
    "plot_reaction_counts_kwargs = dict(\n",
    "    height=0.8, cmax=0.85, ticklabels_on_bars=True, xtick_major=10, xtick_minor=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5154a-08b1-423e-a8ce-198145fe8341",
   "metadata": {},
   "source": [
    "#### Generate all figures\n",
    "Comment this cell out to prevent generation of all figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d7fa0-fc5c-42d2-8859-9200605ab69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, group_name in enumerate(list(spearman_correlations_dict), start=1):\n",
    "    group_results_dirpath = group_results_dirpath_dict[group_name]\n",
    "    print(f\"{idx}) Generating figures for group '{group_name}'\")\n",
    "    nrows, ncols = (1, 1)\n",
    "    correlation_pair = (\"flux\", \"abundance\")\n",
    "    fig = mpl.figure.Figure(\n",
    "        figsize=(\n",
    "            plot_correlation_kwargs[\"scatter_inch\"]\n",
    "            + (\n",
    "                (\n",
    "                    plot_correlation_kwargs[\"hist_inch\"]\n",
    "                    + plot_correlation_kwargs[\"hist_pad\"]\n",
    "                )\n",
    "                if plot_correlation_kwargs[\"yhist\"]\n",
    "                else 0\n",
    "            )\n",
    "            * ncols,\n",
    "            plot_correlation_kwargs[\"scatter_inch\"]\n",
    "            + (\n",
    "                (\n",
    "                    plot_correlation_kwargs[\"hist_inch\"]\n",
    "                    + plot_correlation_kwargs[\"hist_pad\"]\n",
    "                )\n",
    "                if plot_correlation_kwargs[\"xhist\"]\n",
    "                else 0\n",
    "            )\n",
    "            * nrows,\n",
    "        )\n",
    "    )\n",
    "    ax = fig.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "    )\n",
    "\n",
    "    df_correlations = spearman_correlations_dict[group_name][correlation_pair]\n",
    "    log_pvalue_sub_for_inf = np.floor(\n",
    "        np.log10(df_correlations[df_correlations[\"p-value\"] != 0][\"p-value\"].min()) - 1\n",
    "    )\n",
    "\n",
    "    # Vertical lines textprops are dependent on value in loop\n",
    "    for key in list(vertical_lines):\n",
    "        vertical_lines[key][1].update(\n",
    "            {\"y\": -log_pvalue_sub_for_inf * (0.15 if lower_abundance_labels else 0.85)}\n",
    "        )\n",
    "\n",
    "    # Remove all NA values and transform p-values to log10(-p)values\n",
    "    df_corr = df_correlations.dropna(axis=0).copy()\n",
    "    df_corr[\"p-value\"] = (\n",
    "        -df_corr[\"p-value\"]\n",
    "        .apply(np.log10)\n",
    "        .replace(-float(\"inf\"), log_pvalue_sub_for_inf)\n",
    "    )\n",
    "    df_corr = df_corr.sort_values(by=list(df_corr.columns), ascending=False)\n",
    "\n",
    "    ax_scatter, ax_xhist, ax_yhist = plot_correlations(\n",
    "        df_corr,\n",
    "        ax=ax,\n",
    "        vertical_lines=vertical_lines,\n",
    "        **plot_correlation_kwargs,\n",
    "    )\n",
    "\n",
    "    ax_scatter.set_title(\n",
    "        \"Correlates between {} and {}\".format(\n",
    "            *[x.capitalize() for x in correlations_pair]\n",
    "        ),\n",
    "        fontsize=\"large\",\n",
    "    )\n",
    "\n",
    "    if save_figures:\n",
    "        fig.savefig(\n",
    "            group_results_dirpath / f\"FluxAbunCorrelates_{model.id}.{imagetype}\",\n",
    "            transparent=transparent,\n",
    "            format=imagetype,\n",
    "        )\n",
    "\n",
    "    df_classified_reactions = classify_reactions_by_abundance_dependence(\n",
    "        df_correlations,\n",
    "        dependent_cutoff=abundance_dependent_cutoff,\n",
    "        correlated_cutoff=abundance_correlated_cutoff,\n",
    "        spontaneous_reactions=[\n",
    "            r.id\n",
    "            for r in model.reactions.query(lambda x: not x.boundary and not x.genes)\n",
    "        ],\n",
    "    )\n",
    "    # Concat original correlation values to classificaiton Series\n",
    "    df_classified_reactions = pd.concat(\n",
    "        (df_classified_reactions, df_correlations), axis=1\n",
    "    )\n",
    "    df_classified_reactions_categories = pd.concat(\n",
    "        (\n",
    "            df_classified_reactions,\n",
    "            pd.Series(\n",
    "                {\n",
    "                    r.id: r.subsystem\n",
    "                    for r in model.reactions.get_by_any(\n",
    "                        list(df_classified_reactions.index)\n",
    "                    )\n",
    "                }\n",
    "            ),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    df_classified_reactions_categories = df_classified_reactions_categories.reset_index(\n",
    "        drop=False\n",
    "    )\n",
    "    df_classified_reactions_categories.columns = (\n",
    "        [\"reactions\"] + list(df_classified_reactions.columns) + [\"subsystem\"]\n",
    "    )\n",
    "    df_classified_reactions_categories = df_classified_reactions_categories.merge(\n",
    "        df_pathways[[\"subsystem\", \"category\"]],\n",
    "        left_on=\"subsystem\",\n",
    "        right_on=\"subsystem\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_classified_reactions_categories[\"genes\"] = df_classified_reactions_categories[\n",
    "        \"reactions\"\n",
    "    ].apply(\n",
    "        lambda x: build_string(\n",
    "            sorted([g.id for g in model.reactions.get_by_id(x).genes])\n",
    "        )\n",
    "    )\n",
    "    df_classified_reactions_categories.to_csv(\n",
    "        group_results_dirpath / f\"ClassifiedReactionsTable_{model.id}.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    classifications_w_texts = {\n",
    "        \"independent\": rf\"$\\rho  <{abundance_correlated_cutoff}$\",\n",
    "        \"correlated\": rf\"${abundance_correlated_cutoff} \\leq \\rho < {abundance_dependent_cutoff}$\",\n",
    "        \"dependent\": rf\"${abundance_dependent_cutoff} \\leq \\rho$\",\n",
    "    }\n",
    "\n",
    "    all_rings_fig = mpl.figure.Figure(\n",
    "        figsize=(ring_figsize * len(classifications_w_texts), ring_figsize)\n",
    "    )\n",
    "    all_rings_axes = all_rings_fig.subplots(1, len(classifications_w_texts))\n",
    "    for idx, (classification, ring_center_text) in enumerate(\n",
    "        classifications_w_texts.items()\n",
    "    ):\n",
    "        df = df_classified_reactions_categories[\n",
    "            df_classified_reactions_categories[\"classification\"] == classification\n",
    "        ]\n",
    "        fig_ring = mpl.figure.Figure(figsize=(ring_figsize, ring_figsize))\n",
    "        ax_ring = fig_ring.add_subplot()\n",
    "        ax_ring = plot_ring_of_category_counts(\n",
    "            df.loc[:, [\"category\", \"subsystem\"]].copy(),\n",
    "            ax=ax_ring,\n",
    "            ring_center_text=\"\\n\".join((ring_center_text, f\"{len(df)} reactions\")),\n",
    "            cmap_dict_level_0=category_cmaps,\n",
    "        )\n",
    "        fig_ring.tight_layout()\n",
    "        if save_figures:\n",
    "            fig_ring.savefig(\n",
    "                group_results_dirpath\n",
    "                / f\"{classification.capitalize()}Reactions_{model_id}.{imagetype}\",\n",
    "                transparent=transparent,\n",
    "                format=imagetype,\n",
    "            )\n",
    "        fig_bar = mpl.figure.Figure(figsize=(5, 10))\n",
    "        ax_bar = fig_bar.add_subplot()\n",
    "        plot_reaction_counts_for_proteins(\n",
    "            df,\n",
    "            ax=ax_bar,\n",
    "            cutoff_value=5,\n",
    "            seperator_value=20,\n",
    "            seperator_scalar=5,\n",
    "            category_colors=category_cmaps,\n",
    "            **plot_reaction_counts_kwargs,\n",
    "        )\n",
    "        if save_figures:\n",
    "            fig_bar.savefig(\n",
    "                group_results_dirpath\n",
    "                / f\"{classification.capitalize()}ProtRxnCounts_{model_id}.{imagetype}\",\n",
    "                transparent=transparent,\n",
    "                format=imagetype,\n",
    "            )\n",
    "        plot_ring_of_category_counts(\n",
    "            df.loc[:, [\"category\", \"subsystem\"]].copy(),\n",
    "            ax=all_rings_axes[idx],\n",
    "            ring_center_text=\"\\n\".join((ring_center_text, f\"{len(df)} reactions\")),\n",
    "            cmap_dict_level_0=category_cmaps,\n",
    "        )\n",
    "    all_rings_fig.tight_layout()\n",
    "    if save_figures:\n",
    "        all_rings_fig.savefig(\n",
    "            group_results_dirpath / f\"AllClassifiedReactions_{model_id}.{imagetype}\",\n",
    "            transparent=transparent,\n",
    "            format=imagetype,\n",
    "        )\n",
    "\n",
    "    df_venn = df_classified_reactions_categories.copy()\n",
    "    df_venn[\"genes\"] = df_venn[\"genes\"].str.split(\";\")\n",
    "    df_venn = df_venn[[\"classification\", \"genes\"]].explode(\"genes\")\n",
    "    df_venn = (\n",
    "        df_venn[df_venn != \"\"]\n",
    "        .groupby([\"classification\"])\n",
    "        .agg(lambda x: list(set(x.unique())))\n",
    "    )\n",
    "\n",
    "    fig_venn = mpl.figure.Figure(figsize=(4, 4))\n",
    "    ax_venn = fig_venn.add_subplot()\n",
    "    subsets = [\n",
    "        set(df_venn.loc[\"dependent\"].item()),\n",
    "        set(df_venn.loc[\"correlated\"].item()),\n",
    "        set(df_venn.loc[\"independent\"].item()),\n",
    "    ]\n",
    "    venn = mpl_venn.venn3(\n",
    "        subsets=subsets,\n",
    "        set_labels=[\n",
    "            \"Abundance\\ndependent\",\n",
    "            \"Abundance\\ncorrelated\",\n",
    "            \"Abundance\\nindependent\",\n",
    "        ],\n",
    "        set_colors=(\"xkcd:red\", \"xkcd:blue\", \"xkcd:green\"),\n",
    "        alpha=0.5,\n",
    "        ax=ax_venn,\n",
    "    )\n",
    "    circles = mpl_venn.venn3_circles(\n",
    "        ax=ax_venn, subsets=subsets, linestyle=\"-\", color=\"black\", linewidth=1\n",
    "    )\n",
    "    for text in venn.set_labels:\n",
    "        text.set_fontsize(\"x-large\")\n",
    "    for text in venn.subset_labels:\n",
    "        text.set_fontsize(\"x-large\")\n",
    "\n",
    "    fig_venn.tight_layout()\n",
    "    if save_figures:\n",
    "        fig_venn.savefig(\n",
    "            group_results_dirpath / f\"ProteinIntersections_{model_id}.{imagetype}\",\n",
    "            transparent=transparent,\n",
    "            format=imagetype,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba3488-55eb-4e30-9fc6-bf39bb4d2f94",
   "metadata": {},
   "source": [
    "### Classify reactions based on correlation values for one group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d6b82-832b-42dd-aac1-484a487d7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_dependent_cutoff = 0.8\n",
    "abundance_correlated_cutoff = 0.5\n",
    "\n",
    "group_name = \"G6PD_V68M\"\n",
    "if group_name not in spearman_correlations_dict:\n",
    "    raise KeyError(f\"No previously computed correlations found for group {group_name})\")\n",
    "df_correlations = spearman_correlations_dict[group_name][(\"flux\", \"abundance\")]\n",
    "group_results_dirpath = group_results_dirpath_dict[group_name]\n",
    "log_pvalue_sub_for_inf = np.floor(\n",
    "    np.log10(df_correlations[df_correlations[\"p-value\"] != 0][\"p-value\"].min()) - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b7fa8-83b3-4e64-95ca-fd5878276e31",
   "metadata": {},
   "source": [
    "#### Summarize classification results for one group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556a350-0d44-437b-8622-9a8b9c1aad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classified_reactions = classify_reactions_by_abundance_dependence(\n",
    "    df_correlations,\n",
    "    dependent_cutoff=abundance_dependent_cutoff,\n",
    "    correlated_cutoff=abundance_correlated_cutoff,\n",
    "    spontaneous_reactions=[\n",
    "        r.id for r in model.reactions.query(lambda x: not x.boundary and not x.genes)\n",
    "    ],\n",
    ")\n",
    "# Concat original correlation values to classificaiton Series\n",
    "df_classified_reactions = pd.concat((df_classified_reactions, df_correlations), axis=1)\n",
    "\n",
    "labels = [\"independent\", \"correlated\", \"dependent\"]\n",
    "for key, value in (\n",
    "    df_classified_reactions[\"classification\"]\n",
    "    .value_counts()[[\"spontaneous\", \"blocked\"] + labels]\n",
    "    .items()\n",
    "):\n",
    "    if key in labels:\n",
    "        key = f\"abundance-{key}\"\n",
    "    print(f\"Number of {key} reactions: {value}\")\n",
    "\n",
    "df_most_significant = df_classified_reactions.dropna(subset=[\"p-value\"])\n",
    "df_most_significant = (\n",
    "    -df_most_significant[\"p-value\"]\n",
    "    .apply(np.log10)\n",
    "    .replace(-float(\"inf\"), log_pvalue_sub_for_inf)\n",
    ")\n",
    "df_most_significant = df_most_significant[\n",
    "    df_most_significant >= -log_pvalue_sub_for_inf * 0.9\n",
    "]\n",
    "print(f\"Number of reactions >= 90% max pvalue: {df_most_significant.index.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5093877-b66f-49f1-b68d-c76f63de61f2",
   "metadata": {},
   "source": [
    "#### Visualize correlations for one group\n",
    "##### Set visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d742c-e38f-4702-8464-bd147be0b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_abundance_labels = (\n",
    "    True  # Whether abundance labels should be at the top or bottom of the plot\n",
    ")\n",
    "# Start with previous settings, then modify as desired\n",
    "plot_kwargs = plot_correlation_kwargs.copy()\n",
    "plot_kwargs.update(\n",
    "    scatter_inch=5,  # Length x width of scatter plot\n",
    "    hist_inch=1,  # Length or width of histogram addition\n",
    "    hist_pad=0.4,  # Space between scatter and histogram\n",
    "    cmap=\"viridis\",  # Colormap for correlation significance\n",
    "    edgecolor=\"black\",\n",
    "    edgewidth=0.5,\n",
    "    grid=False,\n",
    "    zorder=2,\n",
    "    colorbar=True,\n",
    "    xmin=-1,\n",
    "    xmax=1,\n",
    "    xpad=0.05,\n",
    "    xtick_major=0.4,\n",
    "    ytick_major=50,\n",
    "    xhist=True,  # Whehter to include a histogram of the x-axis values (rho)\n",
    "    yhist=True,  # Whether to include a histogram of the y-axis values (log10(-p))\n",
    "    xhist_ytick_major=100,  # Major y-tick interval for histogram aligned with x-axis\n",
    "    yhist_xtick_major=200,  # Major x-tick interval for histogram aligned with y-axis\n",
    ")\n",
    "plot_kwargs.update(\n",
    "    dict(\n",
    "        xtick_minor=(\n",
    "            plot_kwargs.get(\"xtick_major\") / 4\n",
    "            if plot_kwargs.get(\"xtick_major\")\n",
    "            else None\n",
    "        ),\n",
    "        xhist_ytick_minor=(\n",
    "            plot_kwargs.get(\"xhist_ytick_major\") / 2\n",
    "            if plot_kwargs.get(\"xhist_ytick_major\")\n",
    "            else None\n",
    "        ),  # Major y-tick interval for histogram aligned with x`-axis\n",
    "        ytick_minor=(\n",
    "            plot_kwargs.get(\"ytick_major\") / 5\n",
    "            if plot_kwargs.get(\"ytick_major\")\n",
    "            else None\n",
    "        ),\n",
    "        yhist_xtick_minor=(\n",
    "            plot_kwargs.get(\"yhist_xtick_major\") / 2\n",
    "            if plot_kwargs.get(\"yhist_xtick_major\")\n",
    "            else None\n",
    "        ),  # Major y-tick interval for histogram aligned with x`-axis\n",
    "    )\n",
    ")\n",
    "# plot_kwargs.update(\n",
    "#     dict(\n",
    "#         xbinwidth=plot_kwargs.get(\"xtick_minor\")/2 if plot_kwargs.get(\"xtick_minor\") else None, # Determined by minor ticks if not otherwise set\n",
    "#         ybinwidth=plot_kwargs.get(\"ytick_minor\")/2 if plot_kwargs.get(\"ytick_minor\") else None, # Determined by minor ticks if not otherwise set\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# Vertical lines need in a dict where keys are values for the line,\n",
    "# and values are given as (dict of line properties, dict of text properties)\n",
    "lineprops = dict(linewidth=2)\n",
    "textprops = dict(\n",
    "    y=-log_pvalue_sub_for_inf * (0.15 if lower_abundance_labels else 0.85),\n",
    "    rotation=90,\n",
    "    fontsize=\"large\",\n",
    "    va=\"center\",\n",
    "    ha=\"left\",\n",
    ")\n",
    "# Set common line properties\n",
    "labels = [\"Dependent\", \"Correlated\", \"Independent\"]\n",
    "cutoff_values = [\n",
    "    abundance_dependent_cutoff,\n",
    "    abundance_correlated_cutoff,\n",
    "    plot_kwargs[\"xmin\"],\n",
    "]\n",
    "vertical_lines = {\n",
    "    value: (lineprops.copy(), textprops.copy()) for value in cutoff_values\n",
    "}\n",
    "\n",
    "# Set individual properties\n",
    "colors = dict(zip(cutoff_values, [\"black\", \"black\", \"white\"]))\n",
    "linestyles = dict(zip(cutoff_values, [\"-\", \"--\", \"\"]))\n",
    "for key, label in zip(cutoff_values, labels):\n",
    "    vertical_lines[key][0].update({\"color\": colors[key], \"linestyle\": linestyles[key]})\n",
    "    vertical_lines[key][1].update({\"s\": label})\n",
    "\n",
    "# Remove all NA values and transform p-values to log10(-p)values\n",
    "df_corr = df_correlations.dropna(axis=0).copy()\n",
    "df_corr[\"p-value\"] = (\n",
    "    -df_corr[\"p-value\"].apply(np.log10).replace(-float(\"inf\"), log_pvalue_sub_for_inf)\n",
    ")\n",
    "df_corr = df_corr.sort_values(by=list(df_corr.columns), ascending=False)\n",
    "\n",
    "nrows, ncols = (1, 1)\n",
    "fig = mpl.figure.Figure(\n",
    "    figsize=(\n",
    "        plot_kwargs[\"scatter_inch\"]\n",
    "        + (\n",
    "            (plot_kwargs[\"hist_inch\"] + plot_kwargs[\"hist_pad\"])\n",
    "            if plot_kwargs[\"yhist\"]\n",
    "            else 0\n",
    "        )\n",
    "        * ncols,\n",
    "        plot_kwargs[\"scatter_inch\"]\n",
    "        + (\n",
    "            (plot_kwargs[\"hist_inch\"] + plot_kwargs[\"hist_pad\"])\n",
    "            if plot_kwargs[\"xhist\"]\n",
    "            else 0\n",
    "        )\n",
    "        * nrows,\n",
    "    )\n",
    ")\n",
    "ax = fig.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    ")\n",
    "ax_scatter, ax_xhist, ax_yhist = plot_correlations(\n",
    "    df_corr,\n",
    "    ax=ax,\n",
    "    vertical_lines=vertical_lines,\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "ax_scatter.set_title(\n",
    "    \"Correlates between {} and {}\".format(*[x.capitalize() for x in correlations_pair]),\n",
    "    fontsize=\"large\",\n",
    ")\n",
    "\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        group_results_dirpath / f\"FluxAbunCorrelates_{model.id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "plt.show()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c3633-b5a3-4492-ada8-6d5af858cf8d",
   "metadata": {},
   "source": [
    "### Enrich results with subsystems and metabolic categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd847a4-08c1-4a34-8a33-72c427b92646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classified_reactions_categories = pd.concat(\n",
    "    (\n",
    "        df_classified_reactions,\n",
    "        pd.Series(\n",
    "            {\n",
    "                r.id: r.subsystem\n",
    "                for r in model.reactions.get_by_any(list(df_classified_reactions.index))\n",
    "            }\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df_classified_reactions_categories = df_classified_reactions_categories.reset_index(\n",
    "    drop=False\n",
    ")\n",
    "df_classified_reactions_categories.columns = (\n",
    "    [\"reactions\"] + list(df_classified_reactions.columns) + [\"subsystem\"]\n",
    ")\n",
    "df_classified_reactions_categories = df_classified_reactions_categories.merge(\n",
    "    df_pathways[[\"subsystem\", \"category\"]],\n",
    "    left_on=\"subsystem\",\n",
    "    right_on=\"subsystem\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_classified_reactions_categories[\"genes\"] = df_classified_reactions_categories[\n",
    "    \"reactions\"\n",
    "].apply(\n",
    "    lambda x: build_string(sorted([g.id for g in model.reactions.get_by_id(x).genes]))\n",
    ")\n",
    "df_classified_reactions_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a59e70-a40c-4cd5-b853-ce46f45f6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_classified_reactions.dropna().copy()\n",
    "# df[\"p-value\"] = -df[\"p-value\"].apply(np.log10).replace(-float(\"inf\"), log_pvalue_sub_for_inf)\n",
    "# df.index.name = \"ID\"\n",
    "# df = df.reset_index(drop=False)\n",
    "# df = df.sort_values(by=[\"rho\", \"p-value\", \"ID\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "# df[\"classification\"] = df[\"classification\"].replace(\"blocked\", \"independent\")\n",
    "# df[\"classification\"] = df[\"classification\"].apply(lambda x: f\"abundance-{x}\")\n",
    "# df[\"Proteins\"] = [\n",
    "#     \";\".join(sorted([g.id for g in r.genes]))\n",
    "#     for r in model.reactions.get_by_any(list(df[\"ID\"].values))\n",
    "# ]\n",
    "# model_special = model.copy()\n",
    "# for met in model_special.metabolites.query(lambda x: x.compartment == \"e\"):\n",
    "#     met.name += \" (extracellular)\"\n",
    "# df[\"Name\"] = [model_special.reactions.get_by_id(r).name for r in list(df[\"ID\"].values)]\n",
    "# df[\"Reaction\"] = [model_special.reactions.get_by_id(r).build_reaction_string(use_metabolite_names=True) for r in list(df[\"ID\"].values)]\n",
    "# df = df.rename({\"classification\": \"Classification\", \"rho\": \"Spearman Correlation\", \"p-value\": \"-log10(p-value)\"}, axis=1)\n",
    "# df = df[[\"ID\", \"Name\", \"Reaction\", \"Proteins\", \"Classification\", \"Spearman Correlation\", \"-log10(p-value)\"]]\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf91cff-5a1f-48e0-8c07-ad9fff2f261c",
   "metadata": {},
   "source": [
    "#### Reactions\n",
    "##### Set common visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396432f1-5741-4cd5-abae-addc7c3f6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = plot_ring_kwargs.copy()\n",
    "ring_figsize = 3.6\n",
    "plot_kwargs.update(\n",
    "    dict(\n",
    "        wedgesize=0.43,\n",
    "        radius=1,\n",
    "        linewidth=0.75,\n",
    "        edgecolor=\"k\",\n",
    "        cmax=0.8,\n",
    "        cmin=0.15,\n",
    "        ring_center_textprops=dict(ha=\"center\", va=\"center\", fontsize=\"x-large\"),\n",
    "    )\n",
    ")\n",
    "category_cmap_names = category_cmaps.copy()\n",
    "category_cmap_names.update(\n",
    "    {\n",
    "        \"Amino acid metabolism\": \"spring\",\n",
    "        \"Carbohydrate metabolism\": \"Greens\",\n",
    "        \"Lipid metabolism\": \"Blues\",\n",
    "        \"Metabolism of cofactors and vitamins\": \"summer\",\n",
    "        \"Nucleotide metabolism\": \"winter\",\n",
    "        \"Reactive species\": \"Reds\",\n",
    "        \"Transport reactions\": \"Purples\",\n",
    "        \"Other\": \"Grays\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a7896-e49e-42b3-b05d-2ed1afd5cc3a",
   "metadata": {},
   "source": [
    "##### Plot category rings for abundance dependence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b8ab6-4dc4-4d21-a63a-0ab308a38bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_w_texts = {\n",
    "    \"independent\": rf\"$\\rho  <{abundance_correlated_cutoff}$\",\n",
    "    \"correlated\": rf\"${abundance_correlated_cutoff} \\leq \\rho < {abundance_dependent_cutoff}$\",\n",
    "    \"dependent\": rf\"${abundance_dependent_cutoff} \\leq \\rho$\",\n",
    "}\n",
    "rings = [\n",
    "    \"category\",\n",
    "    # \"subsystem\"\n",
    "]\n",
    "all_rings_fig, all_rings_axes = plt.subplots(\n",
    "    1,\n",
    "    len(classifications_w_texts),\n",
    "    figsize=(ring_figsize * len(classifications_w_texts), ring_figsize),\n",
    ")\n",
    "for idx, (classification, ring_center_text) in enumerate(\n",
    "    classifications_w_texts.items()\n",
    "):\n",
    "    df = df_classified_reactions_categories[\n",
    "        df_classified_reactions_categories[\"classification\"] == classification\n",
    "    ]\n",
    "    df = df.loc[:, rings].copy()\n",
    "    fig_ring = mpl.figure.Figure(figsize=(ring_figsize, ring_figsize))\n",
    "    ax_ring = fig_ring.add_subplot()\n",
    "    ax_ring = plot_ring_of_category_counts(\n",
    "        df,\n",
    "        ax=ax_ring,\n",
    "        ring_center_text=\"\\n\".join((ring_center_text, f\"{len(df)} reactions\")),\n",
    "        cmap_dict_level_0=category_cmap_names,\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "    fig_ring.tight_layout()\n",
    "    if save_figures:\n",
    "        fig_ring.savefig(\n",
    "            group_results_dirpath\n",
    "            / f\"{classification.capitalize()}Reactions_{model_id}.{imagetype}\",\n",
    "            transparent=transparent,\n",
    "            format=imagetype,\n",
    "        )\n",
    "    plot_ring_of_category_counts(\n",
    "        df,\n",
    "        ax=all_rings_axes[idx],\n",
    "        ring_center_text=\"\\n\".join((ring_center_text, f\"{len(df)} reactions\")),\n",
    "        cmap_dict_level_0=category_cmap_names,\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "all_rings_fig.tight_layout()\n",
    "if save_figures:\n",
    "    all_rings_fig.savefig(\n",
    "        group_results_dirpath / f\"AllClassifiedReactions_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "all_rings_fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49289d7-98e0-46a4-be67-9a93d711f156",
   "metadata": {},
   "source": [
    "#### Genes/Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d03a5-ca9a-48b4-a779-41c782873aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 10))\n",
    "plot_kwargs = plot_reaction_counts_kwargs.copy()\n",
    "classification = \"dependent\"\n",
    "df = df_classified_reactions_categories[\n",
    "    df_classified_reactions_categories[\"classification\"] == classification\n",
    "].copy()\n",
    "plot_reaction_counts_for_proteins(\n",
    "    df,\n",
    "    ax=ax,\n",
    "    cutoff_value=5,\n",
    "    seperator_value=20,\n",
    "    seperator_scalar=5,\n",
    "    category_colors=category_cmap_names,\n",
    "    **plot_kwargs,\n",
    ")\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        group_results_dirpath\n",
    "        / f\"{classification.capitalize()}ProtRxnCounts_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c511c9-f57e-4da6-8424-6a0c4092036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 10))\n",
    "plot_kwargs = plot_reaction_counts_kwargs.copy()\n",
    "classification = \"correlated\"\n",
    "df = df_classified_reactions_categories[\n",
    "    df_classified_reactions_categories[\"classification\"] == classification\n",
    "].copy()\n",
    "plot_reaction_counts_for_proteins(\n",
    "    df,\n",
    "    ax=ax,\n",
    "    cutoff_value=5,\n",
    "    seperator_value=0,\n",
    "    seperator_scalar=1,\n",
    "    category_colors=category_cmap_names,\n",
    "    **plot_kwargs,\n",
    ")\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        group_results_dirpath\n",
    "        / f\"{classification.capitalize()}ProtRxnCounts_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3457fc-7368-4a33-b0c7-ba8a30ce7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 10))\n",
    "plot_kwargs = plot_reaction_counts_kwargs.copy()\n",
    "classification = \"independent\"\n",
    "df = df_classified_reactions_categories[\n",
    "    df_classified_reactions_categories[\"classification\"] == classification\n",
    "].copy()\n",
    "plot_reaction_counts_for_proteins(\n",
    "    df,\n",
    "    ax=ax,\n",
    "    cutoff_value=10,\n",
    "    seperator_value=40,\n",
    "    seperator_scalar=2,\n",
    "    category_colors=category_cmap_names,\n",
    "    **plot_kwargs,\n",
    ")\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        group_results_dirpath\n",
    "        / f\"{classification.capitalize()}ProtRxnCounts_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbb21b-fcf3-4082-8853-408539e65573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venn = df_classified_reactions_categories.copy()\n",
    "df_venn[\"genes\"] = df_venn[\"genes\"].str.split(\";\")\n",
    "df_venn = df_venn[[\"classification\", \"genes\"]].explode(\"genes\")\n",
    "df_venn = (\n",
    "    df_venn[df_venn != \"\"]\n",
    "    .groupby([\"classification\"])\n",
    "    .agg(lambda x: list(set(x.unique())))\n",
    ")\n",
    "\n",
    "fig_venn, ax_venn = plt.subplots(1, 1, figsize=(4, 4))\n",
    "dep_genes = set(df_venn.loc[\"dependent\"].item())\n",
    "cor_genes = set(df_venn.loc[\"correlated\"].item())\n",
    "ind_genes = set(df_venn.loc[\"independent\"].item())\n",
    "venn = mpl_venn.venn3(\n",
    "    subsets=[dep_genes, cor_genes, ind_genes],\n",
    "    set_labels=[\n",
    "        \"Abundance\\ndependent\",\n",
    "        \"Abundance\\ncorrelated\",\n",
    "        \"Abundance\\nindependent\",\n",
    "    ],\n",
    "    set_colors=(\"xkcd:red\", \"xkcd:blue\", \"xkcd:green\"),\n",
    "    alpha=0.5,\n",
    "    ax=ax_venn,\n",
    ")\n",
    "circles = mpl_venn.venn3_circles(\n",
    "    ax=ax_venn,\n",
    "    subsets=[dep_genes, cor_genes, ind_genes],\n",
    "    linestyle=\"-\",\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    ")\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "\n",
    "fig_venn.tight_layout()\n",
    "if save_figures:\n",
    "    fig_venn.savefig(\n",
    "        group_results_dirpath / f\"ProteinIntersections_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680eb2b-9fcc-4f55-aeca-a9bebf12409d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ae404-7096-4f41-9637-d2d1e48633ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
