{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d1d32f-ac8f-44a8-b9ad-cacea20f8cf2",
   "metadata": {},
   "source": [
    "# Create context-specific models - REDS Recall\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2664191\n",
      "Academic license - for non-commercial use only - expires 2026-05-12\n",
      "\n",
      "Package Information\n",
      "-------------------\n",
      "rbc-gem-utils 0.0.3\n",
      "\n",
      "Dependency Information\n",
      "----------------------\n",
      "beautifulsoup4                       4.13.4\n",
      "bio                                   1.8.0\n",
      "cobra                                0.29.1\n",
      "depinfo                               2.2.0\n",
      "gurobipy                             12.0.3\n",
      "matplotlib                           3.10.3\n",
      "matplotlib-venn                       1.1.2\n",
      "memote                               0.17.0\n",
      "networkx                                3.5\n",
      "notebook                              7.4.4\n",
      "openpyxl                              3.1.5\n",
      "pandas                                2.3.1\n",
      "pre-commit                            4.2.0\n",
      "rbc-gem-utils[database,network,vis] missing\n",
      "requests                             2.32.4\n",
      "scikit-learn                          1.7.0\n",
      "scipy                                1.16.0\n",
      "seaborn                              0.13.2\n",
      "\n",
      "Build Tools Information\n",
      "-----------------------\n",
      "pip          25.1\n",
      "setuptools 78.1.1\n",
      "wheel      0.45.1\n",
      "\n",
      "Platform Information\n",
      "--------------------\n",
      "Windows 10-AMD64\n",
      "CPython  3.11.13\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "\n",
    "import gurobipy as gp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as mpl_venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    get_dirpath,\n",
    "    handle_msg,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    ProteinDilution,\n",
    "    add_relaxation_budget,\n",
    "    create_protein_dilution_df,\n",
    "    load_overlay_model,\n",
    "    update_slack_value,\n",
    ")\n",
    "from rbc_gem_utils.util import AVOGADRO_NUMBER, DEFAULT_DRY_MASS_PER_CELL\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a9df2-358e-4cb3-bad0-9323be471582",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3adcc9b-af52-4300-8563-221ed441f9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <td><strong>Attribute</strong></td>\n",
       "      <td><strong>Description</strong></td>\n",
       "      <td><strong>Value</strong></td>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><pre>solver</pre></td>\n",
       "      <td>Mathematical optimization solver</td>\n",
       "      <td>gurobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>tolerance</pre></td>\n",
       "        <td>General solver tolerance (feasibility, integrality, etc.)</td>\n",
       "        <td>1e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>lower_bound</pre></td>\n",
       "        <td>Default reaction lower bound</td>\n",
       "        <td>-1e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>upper_bound</pre></td>\n",
       "        <td>Default reaction upper bound</td>\n",
       "        <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>processes</pre></td>\n",
       "        <td>Number of parallel processes</td>\n",
       "        <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>cache_directory</pre></td>\n",
       "        <td>Path for the model cache</td>\n",
       "        <td>C:\\Users\\P7875\\AppData\\Local\\opencobra\\cobrapy\\Cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>max_cache_size</pre></td>\n",
       "        <td>Maximum cache size in bytes</td>\n",
       "        <td>104857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>cache_expiration</pre></td>\n",
       "        <td>Model cache expiration time in seconds (if any)</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "\n",
       "solver: gurobi\n",
       "tolerance: 1e-09\n",
       "lower_bound: -1e-08\n",
       "upper_bound: 100000000.0\n",
       "processes: 127\n",
       "cache_directory: C:\\Users\\P7875\\AppData\\Local\\opencobra\\cobrapy\\Cache\n",
       "max_cache_size: 104857600\n",
       "cache_expiration: None"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-9\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75002349-87e3-497d-bdd4-7b8f0ac40aa8",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ecbb31-18b5-4b6e-a43c-d620b0583fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "grouped_data_key = \"Sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37781f05-550a-4a04-bf53-ee372557dacb",
   "metadata": {},
   "source": [
    "### Set variables for columns keys and sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9726f0a1-9ce6-4457-83d0-f13c43d6fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"PUBLIC RECALL DONOR ID\"\n",
    "time_key = \"DAY\"\n",
    "timepoints = [\"D10\", \"D23\", \"D42\"]\n",
    "genotypes = [\"G6PD_V68M\", \"ATP11C_V972M\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>S(?P<num>\\d\\d\\d))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "genotype_re = re.compile(rf\"(?P<genotype>({'|'.join(genotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa546c-4fc9-4b41-a526-d19d57059d3e",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59eda7a3-74f4-4e1c-bc26-946895ea7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = False  # Keep off to use previously computed results\n",
    "overwrite = False  # Whether to allow overwriting of previous simulation results\n",
    "verbose = True\n",
    "objective_reactions = (\n",
    "    []\n",
    ")  # Objective reactions are used to determine slack variable but not necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd2432-5dec-449d-86a0-f04d764499b0",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec2d846-e887-4c41-9996-4e415ad5c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b91704-70a4-4e24-b621-37cace803985",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57949510-8d98-4225-9b8d-b9718fb71c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\")\n",
    "    / model_id\n",
    "    / \"OVERLAY\"\n",
    "    / organism\n",
    "    / dataset_name\n",
    "    / grouped_data_key\n",
    ")\n",
    "fitting_dirpath = results_dirpath / \"fitting\"\n",
    "# Ensure directories exist\n",
    "results_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "fitting_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "# ZIP directories\n",
    "sample_pcmodels_dirpath = results_dirpath / \"pcmodels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ba860-d5dd-41d0-b70a-fe9bade1a194",
   "metadata": {},
   "source": [
    "### Define hemoglobin proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95333290-76cd-4bb1-85f6-9f44d3f23d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_PROTEINS = {\n",
    "    \"HBA\": \"P69905\",  # Hemoglobin subunit alpha\n",
    "    \"HBB\": \"P68871\",  # Hemoglobin subunit beta\n",
    "    \"HBD\": \"P02042\",  # Hemoglobin subunit delta\n",
    "    \"HBE1\": \"P02100\",  # Hemoglobin subunit beta\n",
    "    \"HBG1\": \"P69891\",  # Hemoglobin subunit gamma-1\n",
    "    \"HBG2\": \"P69892\",  # Hemoglobin subunit gamma-2\n",
    "    \"HBM\": \"Q6B0K9\",  # Hemoglobin subunit mu\n",
    "    \"HBQ1\": \"P09105\",  # Hemoglobin subunit theta-1\n",
    "    \"HBZ\": \"P02008\",  # Hemoglobin subunit zeta\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6fa4-161e-4511-bf31-0b75d3b93dcb",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38de2e8f-e0f3-4e0c-94dd-52ea8edfb863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>RBC_GEM_PC</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>1fffc249f10</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>7814</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>14963</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of genes</strong></td>\n",
       "                <td>723</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>68</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*NaKt - 1.0*NaKt_reverse_db47e</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>cytosol, extracellular space, protein compartment</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model RBC_GEM_PC at 0x1fffc249f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load models\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a75d58-9789-4c76-a376-2db52ac44c2a",
   "metadata": {},
   "source": [
    "## Load copy numbers and protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8539585e-562c-48b8-a9cd-ff9911d16161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of measured samples: 1910\n",
      "Number of operation samples: 18\n",
      "Number of models to generate: 1928\n"
     ]
    }
   ],
   "source": [
    "# Load protein copy numbers\n",
    "df_copy_numbers = pd.read_csv(\n",
    "    processed_data_dirpath / \"ProteinCopyNumbers.csv\",\n",
    "    index_col=sample_key,\n",
    ")\n",
    "\n",
    "# Load MCH for transforming data\n",
    "df_MCH = pd.read_csv(processed_data_dirpath / \"MCH.csv\", index_col=sample_key)\n",
    "# Load protein data\n",
    "df_protein_data = pd.read_csv(\n",
    "    processed_data_dirpath / \"ProteinData.csv\",\n",
    "    index_col=\"Entry\",\n",
    ")\n",
    "\n",
    "all_ids = list(df_copy_numbers.index.unique())\n",
    "operation_ids = [x for x in all_ids if operation_re.match(x)]\n",
    "sample_ids = [x for x in all_ids if sample_id_re.match(x)]\n",
    "handle_msg(f\"Number of measured samples: {len(sample_ids)}\", print_msg=True)\n",
    "handle_msg(f\"Number of operation samples: {len(operation_ids)}\", print_msg=True)\n",
    "handle_msg(f\"Number of models to generate: {len(all_ids)}\", print_msg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0f2b8-c950-44af-a911-124cd4b153db",
   "metadata": {},
   "source": [
    "## Integrate proteomics with model\n",
    "### Scale measurements for proteome budget\n",
    "Note that this step will help ensure its theoretically possible for a perfect fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77177cf-4e29-47ca-8a07-b5837fb4dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hemoglobin budget:\t950.0 mg protein / gDW\n",
      "Low abundance budget:\t50.0 mg protein / gDW\n",
      "Total budget:\t\t1000.0 mg protein / gDW\n"
     ]
    }
   ],
   "source": [
    "HB_PERCENT, LA_PERCENT = (0.95, 0.05)\n",
    "MODELED_PERCENT = HB_PERCENT + LA_PERCENT\n",
    "assert 1 >= MODELED_PERCENT\n",
    "\n",
    "budget_hb_value = 1000 * HB_PERCENT\n",
    "budget_la_value = 1000 * LA_PERCENT\n",
    "budget_total_value = 1000 * MODELED_PERCENT\n",
    "\n",
    "handle_msg(f\"Hemoglobin budget:\\t{budget_hb_value} mg protein / gDW\", print_msg=True)\n",
    "handle_msg(f\"Low abundance budget:\\t{budget_la_value} mg protein / gDW\", print_msg=True)\n",
    "handle_msg(f\"Total budget:\\t\\t{budget_total_value} mg protein / gDW\", print_msg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867652e2-ffa0-4bd5-bc60-56bc95338447",
   "metadata": {},
   "source": [
    "### Convert copy numbers to mg / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9c3bf5-b982-4020-848e-15c2bad52728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0A075B6I0</th>\n",
       "      <th>A0A075B6I9</th>\n",
       "      <th>A0A075B6J9</th>\n",
       "      <th>A0A075B6K4</th>\n",
       "      <th>A0A075B6K5</th>\n",
       "      <th>A0A075B6R2</th>\n",
       "      <th>A0A075B6S5</th>\n",
       "      <th>A0A075B6S9</th>\n",
       "      <th>A0A087WSY6</th>\n",
       "      <th>A0A0A0MRZ8</th>\n",
       "      <th>...</th>\n",
       "      <th>Q9Y639</th>\n",
       "      <th>Q9Y666</th>\n",
       "      <th>Q9Y696</th>\n",
       "      <th>Q9Y6B6</th>\n",
       "      <th>Q9Y6B7</th>\n",
       "      <th>Q9Y6E0</th>\n",
       "      <th>Q9Y6I3</th>\n",
       "      <th>Q9Y6M4</th>\n",
       "      <th>Q9Y6M5</th>\n",
       "      <th>Q9Y6R7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMPLE ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 1827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [A0A075B6I0, A0A075B6I9, A0A075B6J9, A0A075B6K4, A0A075B6K5, A0A075B6R2, A0A075B6S5, A0A075B6S9, A0A087WSY6, A0A0A0MRZ8, A0A0A0MS15, A0A0A0MT36, A0A0B4J1U3, A0A0B4J1U7, A0A0B4J1V0, A0A0B4J1V2, A0A0B4J1X5, A0A0B4J1Y8, A0A0B4J1Y9, A0A0B4J2D9, A0A0C4DH24, A0A0C4DH25, A0A0C4DH34, A0A0C4DH36, A0A0C4DH38, A0A0C4DH67, A0A0C4DH73, A0AVT1, A0FGR8, A0M8Q6, A2RRP1, A4D126, A4D1P6, A4FU01, A5D8V6, A6NDG6, A6NDU8, A6NGG8, A6NHX0, B2RUZ4, E9PAV3, O00154, O00159, O00161, O00178, O00182, O00186, O00187, O00231, O00232, O00233, O00267, O00299, O00303, O00391, O00399, O00410, O00421, O00429, O00442, O00487, O00505, O00571, O00629, O00743, O00764, O14523, O14562, O14602, O14618, O14662, O14735, O14737, O14744, O14745, O14787, O14791, O14818, O14880, O14950, O14964, O14980, O15067, O15084, O15116, O15118, O15127, O15143, O15144, O15145, O15162, O15173, O15212, O15247, O15294, O15305, O15400, O15439, O15440, O15484, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1827 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uniprot_to_mw = df_protein_data[\"Mass\"].astype(float)\n",
    "\n",
    "gDW_total_protein = (\n",
    "    df_MCH  # pgDW HB\n",
    "    * (1 / HB_PERCENT)  # pgDW total protein / pgDW HB\n",
    "    * (1 / 1e12)  #  gDW total protein / pgDW total protein\n",
    ")  # gDW total protein / cell\n",
    "df_mg_prot_per_gDW = (\n",
    "    df_copy_numbers[df_protein_data.index].mul(  # protein copies / cell\n",
    "        1 / gDW_total_protein.squeeze(), axis=0  # cell / gDW total protein\n",
    "    )\n",
    "    * (\n",
    "        1\n",
    "        / AVOGADRO_NUMBER  # mol protein / protein copies\n",
    "        * df_uniprot_to_mw  # gDW protein / mol protein\n",
    "        * 1e3  # mgDW protein / gDW protein\n",
    "    ).copy()\n",
    ")  # mgDW protein / gDW total protein\n",
    "df_mg_prot_per_gDW = df_mg_prot_per_gDW.loc[df_copy_numbers.index]\n",
    "df_mg_prot_per_gDW[df_mg_prot_per_gDW.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b51a37-eb71-43ed-9355-bebae6c6cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     mg protein / gDW / cell Percentage\n",
      "       Perfect total               1000.0000     100.0%\n",
      "       Current total               1000.0000     100.0%\n",
      "    Hemoglobin total                429.2329      42.9%\n",
      " Low abundance total                570.7671      57.1%\n",
      "    Remaining/Excess                  0.0000       0.0%\n",
      "Low abundance scaled                 50.0000       5.0%\n",
      "   Hemoglobin scaled                950.0000      95.0%\n",
      "    Remaining scaled                  0.0000       0.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAMPLE ID\n",
       "S001_D10              1000.0\n",
       "S001_D23              1000.0\n",
       "S001_D42              1000.0\n",
       "S002_D10              1000.0\n",
       "S002_D23              1000.0\n",
       "                       ...  \n",
       "Mean_G6PD_V68M_1      1000.0\n",
       "Mean_G6PD_V68M_2      1000.0\n",
       "Median_G6PD_V68M_0    1000.0\n",
       "Median_G6PD_V68M_1    1000.0\n",
       "Median_G6PD_V68M_2    1000.0\n",
       "Length: 1928, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into hemoglobin and low abundance proteomes\n",
    "budget_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.dilution\"]\n",
    "budget_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.metabolite\"]\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW.loc[\n",
    "    :, df_mg_prot_per_gDW.columns.isin(HB_PROTEINS.values())\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW.loc[\n",
    "    :, ~df_mg_prot_per_gDW.columns.isin(HB_PROTEINS.values())\n",
    "]\n",
    "\n",
    "df_summary = {\n",
    "    \"Perfect total\": 1000,\n",
    "    \"Current total\": df_mg_prot_per_gDW.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Hemoglobin total\": df_mg_prot_per_gDW_hb.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Low abundance total\": df_mg_prot_per_gDW_la.loc[sample_ids]\n",
    "    .sum(axis=1)\n",
    "    .mean()\n",
    "    .item(),\n",
    "}\n",
    "df_summary[\"Remaining/Excess\"] = df_summary[\"Perfect total\"] - (\n",
    "    df_summary[\"Hemoglobin total\"] + df_summary[\"Low abundance total\"]\n",
    ")\n",
    "\n",
    "budget_rxn_proteome = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}proteome\"\n",
    ")\n",
    "budget_rxn_hemoglobin = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}hemoglobin\"\n",
    ")\n",
    "budget_rxn_total = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}total\"\n",
    ")\n",
    "\n",
    "if budget_la_value is None:\n",
    "    budget_la_value = budget_rxn_proteome.upper_bound\n",
    "if budget_hb_value is None:\n",
    "    budget_hb_value = budget_rxn_hemoglobin.upper_bound\n",
    "if budget_total_value is None:\n",
    "    budget_total_value = budget_rxn_total.upper_bound\n",
    "\n",
    "assert budget_total_value >= (budget_la_value + budget_hb_value)\n",
    "\n",
    "budget_rxn_proteome.upper_bound = budget_la_value\n",
    "budget_rxn_hemoglobin.upper_bound = budget_hb_value\n",
    "budget_rxn_total.upper_bound = budget_total_value\n",
    "\n",
    "# Scale values for low abundance proteome\n",
    "budget_value = budget_la_value\n",
    "df_mg_prot_per_gDW_la = (\n",
    "    budget_value * (df_mg_prot_per_gDW_la.T / df_mg_prot_per_gDW_la.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Low abundance scaled\"] = budget_value\n",
    "\n",
    "# Scale values for hemoglobin proteome\n",
    "budget_value = budget_hb_value\n",
    "df_mg_prot_per_gDW_hb = (\n",
    "    budget_value * (df_mg_prot_per_gDW_hb.T / df_mg_prot_per_gDW_hb.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Hemoglobin scaled\"] = budget_value\n",
    "\n",
    "budget_value = budget_total_value - sum([budget_la_value, budget_hb_value])\n",
    "df_summary[\"Remaining scaled\"] = budget_value\n",
    "\n",
    "# Combine dataframes back into one\n",
    "df_mg_prot_per_gDW_normalized = pd.concat(\n",
    "    (df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la), axis=1\n",
    ")\n",
    "df_summary = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \" \" * max(30 - len(k), 0) + k: [f\"{v:.4f}\", f\"{v / 1000 * 100:.1f}%\"]\n",
    "        for k, v in df_summary.items()\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"mg protein / gDW / cell\", \"Percentage\"],\n",
    ")\n",
    "print(df_summary)\n",
    "df_mg_prot_per_gDW_normalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2c529-58f3-4fce-9c7b-d41f11e2f09b",
   "metadata": {},
   "source": [
    "### Convert mg / gDW to nmol / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b5ef09-c5a2-4985-b9c7-9d26d593d680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SAMPLE ID</th>\n",
       "      <th>S001_D10</th>\n",
       "      <th>S001_D23</th>\n",
       "      <th>S001_D42</th>\n",
       "      <th>S002_D10</th>\n",
       "      <th>S002_D23</th>\n",
       "      <th>S002_D42</th>\n",
       "      <th>S003_D10</th>\n",
       "      <th>S003_D23</th>\n",
       "      <th>S003_D42</th>\n",
       "      <th>S004_D10</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_ATP11C_V972M_2</th>\n",
       "      <th>Median_ATP11C_V972M_0</th>\n",
       "      <th>Median_ATP11C_V972M_1</th>\n",
       "      <th>Median_ATP11C_V972M_2</th>\n",
       "      <th>Mean_G6PD_V68M_0</th>\n",
       "      <th>Mean_G6PD_V68M_1</th>\n",
       "      <th>Mean_G6PD_V68M_2</th>\n",
       "      <th>Median_G6PD_V68M_0</th>\n",
       "      <th>Median_G6PD_V68M_1</th>\n",
       "      <th>Median_G6PD_V68M_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P02008</th>\n",
       "      <td>5711.701488</td>\n",
       "      <td>6195.993951</td>\n",
       "      <td>8202.371061</td>\n",
       "      <td>10030.992827</td>\n",
       "      <td>9267.072179</td>\n",
       "      <td>9577.944760</td>\n",
       "      <td>7761.886683</td>\n",
       "      <td>9585.442147</td>\n",
       "      <td>7386.126355</td>\n",
       "      <td>7139.463629</td>\n",
       "      <td>...</td>\n",
       "      <td>7517.880820</td>\n",
       "      <td>7552.220281</td>\n",
       "      <td>7409.037433</td>\n",
       "      <td>7299.912979</td>\n",
       "      <td>7225.845929</td>\n",
       "      <td>6540.293557</td>\n",
       "      <td>7372.242450</td>\n",
       "      <td>7561.610167</td>\n",
       "      <td>6826.602365</td>\n",
       "      <td>7713.013567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P02042</th>\n",
       "      <td>23598.528519</td>\n",
       "      <td>23922.365911</td>\n",
       "      <td>15256.582852</td>\n",
       "      <td>27625.580957</td>\n",
       "      <td>27930.313499</td>\n",
       "      <td>25892.111687</td>\n",
       "      <td>23732.280301</td>\n",
       "      <td>18498.546948</td>\n",
       "      <td>30364.640014</td>\n",
       "      <td>15743.006155</td>\n",
       "      <td>...</td>\n",
       "      <td>26428.768386</td>\n",
       "      <td>24191.792134</td>\n",
       "      <td>25057.943071</td>\n",
       "      <td>27384.083213</td>\n",
       "      <td>24318.374946</td>\n",
       "      <td>23469.947666</td>\n",
       "      <td>24879.851410</td>\n",
       "      <td>24208.307138</td>\n",
       "      <td>23036.957589</td>\n",
       "      <td>24494.073380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P02100</th>\n",
       "      <td>2.705134</td>\n",
       "      <td>3.509404</td>\n",
       "      <td>7.697601</td>\n",
       "      <td>4.510245</td>\n",
       "      <td>289.081171</td>\n",
       "      <td>6.809605</td>\n",
       "      <td>17.970784</td>\n",
       "      <td>4.306167</td>\n",
       "      <td>8.942239</td>\n",
       "      <td>4.057600</td>\n",
       "      <td>...</td>\n",
       "      <td>10.811786</td>\n",
       "      <td>6.089832</td>\n",
       "      <td>6.596276</td>\n",
       "      <td>12.065794</td>\n",
       "      <td>26.481363</td>\n",
       "      <td>18.040539</td>\n",
       "      <td>33.828837</td>\n",
       "      <td>6.092511</td>\n",
       "      <td>6.366363</td>\n",
       "      <td>6.948159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P09105</th>\n",
       "      <td>38.067281</td>\n",
       "      <td>36.529563</td>\n",
       "      <td>42.859252</td>\n",
       "      <td>60.526125</td>\n",
       "      <td>81.707715</td>\n",
       "      <td>52.171248</td>\n",
       "      <td>29.875331</td>\n",
       "      <td>41.622117</td>\n",
       "      <td>38.394597</td>\n",
       "      <td>34.410908</td>\n",
       "      <td>...</td>\n",
       "      <td>36.383281</td>\n",
       "      <td>41.543525</td>\n",
       "      <td>40.026295</td>\n",
       "      <td>34.884825</td>\n",
       "      <td>41.142515</td>\n",
       "      <td>50.710543</td>\n",
       "      <td>41.998024</td>\n",
       "      <td>41.369208</td>\n",
       "      <td>48.758482</td>\n",
       "      <td>44.328675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P68871</th>\n",
       "      <td>9503.146391</td>\n",
       "      <td>10031.605421</td>\n",
       "      <td>11963.335657</td>\n",
       "      <td>5453.197068</td>\n",
       "      <td>5092.491052</td>\n",
       "      <td>6879.143103</td>\n",
       "      <td>9390.955205</td>\n",
       "      <td>11351.030090</td>\n",
       "      <td>9217.858990</td>\n",
       "      <td>11122.192261</td>\n",
       "      <td>...</td>\n",
       "      <td>10498.332083</td>\n",
       "      <td>10253.462686</td>\n",
       "      <td>10043.523153</td>\n",
       "      <td>9778.933017</td>\n",
       "      <td>10246.487314</td>\n",
       "      <td>10406.205152</td>\n",
       "      <td>10492.765620</td>\n",
       "      <td>10248.695218</td>\n",
       "      <td>10761.226833</td>\n",
       "      <td>10593.014145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6E0</th>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.040313</td>\n",
       "      <td>0.054938</td>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.090008</td>\n",
       "      <td>0.072397</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.055560</td>\n",
       "      <td>0.068864</td>\n",
       "      <td>0.042550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048856</td>\n",
       "      <td>0.055080</td>\n",
       "      <td>0.061321</td>\n",
       "      <td>0.054586</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>0.052295</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>0.055423</td>\n",
       "      <td>0.055366</td>\n",
       "      <td>0.056894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6I3</th>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.155896</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>0.011105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6M4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131675</td>\n",
       "      <td>0.289553</td>\n",
       "      <td>0.471490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6M5</th>\n",
       "      <td>0.042697</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.030378</td>\n",
       "      <td>0.124667</td>\n",
       "      <td>0.133595</td>\n",
       "      <td>0.114644</td>\n",
       "      <td>0.050889</td>\n",
       "      <td>0.081279</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>0.036415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069345</td>\n",
       "      <td>0.058095</td>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.067155</td>\n",
       "      <td>0.058422</td>\n",
       "      <td>0.052077</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>0.054389</td>\n",
       "      <td>0.053556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9Y6R7</th>\n",
       "      <td>0.021924</td>\n",
       "      <td>0.021617</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.028078</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.025784</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.021677</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>0.012378</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.011997</td>\n",
       "      <td>0.014950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827 rows × 1928 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SAMPLE ID      S001_D10      S001_D23      S001_D42      S002_D10  \\\n",
       "P02008      5711.701488   6195.993951   8202.371061  10030.992827   \n",
       "P02042     23598.528519  23922.365911  15256.582852  27625.580957   \n",
       "P02100         2.705134      3.509404      7.697601      4.510245   \n",
       "P09105        38.067281     36.529563     42.859252     60.526125   \n",
       "P68871      9503.146391  10031.605421  11963.335657   5453.197068   \n",
       "...                 ...           ...           ...           ...   \n",
       "Q9Y6E0         0.038086      0.040313      0.054938      0.062468   \n",
       "Q9Y6I3         0.023621      0.155896      0.019620      0.000000   \n",
       "Q9Y6M4         0.000000      0.024880      0.025744      0.000000   \n",
       "Q9Y6M5         0.042697      0.040559      0.030378      0.124667   \n",
       "Q9Y6R7         0.021924      0.021617      0.019990      0.028078   \n",
       "\n",
       "SAMPLE ID      S002_D23      S002_D42      S003_D10      S003_D23  \\\n",
       "P02008      9267.072179   9577.944760   7761.886683   9585.442147   \n",
       "P02042     27930.313499  25892.111687  23732.280301  18498.546948   \n",
       "P02100       289.081171      6.809605     17.970784      4.306167   \n",
       "P09105        81.707715     52.171248     29.875331     41.622117   \n",
       "P68871      5092.491052   6879.143103   9390.955205  11351.030090   \n",
       "...                 ...           ...           ...           ...   \n",
       "Q9Y6E0         0.090008      0.072397      0.045219      0.055560   \n",
       "Q9Y6I3         0.000000      0.000000      0.029578      0.000000   \n",
       "Q9Y6M4         0.000000      0.000000      0.000000      0.035888   \n",
       "Q9Y6M5         0.133595      0.114644      0.050889      0.081279   \n",
       "Q9Y6R7         0.009369      0.014330      0.025784      0.020198   \n",
       "\n",
       "SAMPLE ID      S003_D42      S004_D10  ...  Mean_ATP11C_V972M_2  \\\n",
       "P02008      7386.126355   7139.463629  ...          7517.880820   \n",
       "P02042     30364.640014  15743.006155  ...         26428.768386   \n",
       "P02100         8.942239      4.057600  ...            10.811786   \n",
       "P09105        38.394597     34.410908  ...            36.383281   \n",
       "P68871      9217.858990  11122.192261  ...         10498.332083   \n",
       "...                 ...           ...  ...                  ...   \n",
       "Q9Y6E0         0.068864      0.042550  ...             0.048856   \n",
       "Q9Y6I3         0.000000      0.016981  ...             0.015887   \n",
       "Q9Y6M4         0.000000      0.027049  ...             0.851805   \n",
       "Q9Y6M5         0.107624      0.036415  ...             0.069345   \n",
       "Q9Y6R7         0.021677      0.018649  ...             0.015677   \n",
       "\n",
       "SAMPLE ID  Median_ATP11C_V972M_0  Median_ATP11C_V972M_1  \\\n",
       "P02008               7552.220281            7409.037433   \n",
       "P02042              24191.792134           25057.943071   \n",
       "P02100                  6.089832               6.596276   \n",
       "P09105                 41.543525              40.026295   \n",
       "P68871              10253.462686           10043.523153   \n",
       "...                          ...                    ...   \n",
       "Q9Y6E0                  0.055080               0.061321   \n",
       "Q9Y6I3                  0.015218               0.015434   \n",
       "Q9Y6M4                  0.000000               0.000000   \n",
       "Q9Y6M5                  0.058095               0.058108   \n",
       "Q9Y6R7                  0.015001               0.012378   \n",
       "\n",
       "SAMPLE ID  Median_ATP11C_V972M_2  Mean_G6PD_V68M_0  Mean_G6PD_V68M_1  \\\n",
       "P02008               7299.912979       7225.845929       6540.293557   \n",
       "P02042              27384.083213      24318.374946      23469.947666   \n",
       "P02100                 12.065794         26.481363         18.040539   \n",
       "P09105                 34.884825         41.142515         50.710543   \n",
       "P68871               9778.933017      10246.487314      10406.205152   \n",
       "...                          ...               ...               ...   \n",
       "Q9Y6E0                  0.054586          0.054572          0.052295   \n",
       "Q9Y6I3                  0.009900          0.017690          0.022743   \n",
       "Q9Y6M4                  0.000000          0.131675          0.289553   \n",
       "Q9Y6M5                  0.067155          0.058422          0.052077   \n",
       "Q9Y6R7                  0.016181          0.015794          0.012109   \n",
       "\n",
       "SAMPLE ID  Mean_G6PD_V68M_2  Median_G6PD_V68M_0  Median_G6PD_V68M_1  \\\n",
       "P02008          7372.242450         7561.610167         6826.602365   \n",
       "P02042         24879.851410        24208.307138        23036.957589   \n",
       "P02100            33.828837            6.092511            6.366363   \n",
       "P09105            41.998024           41.369208           48.758482   \n",
       "P68871         10492.765620        10248.695218        10761.226833   \n",
       "...                     ...                 ...                 ...   \n",
       "Q9Y6E0             0.056473            0.055423            0.055366   \n",
       "Q9Y6I3             0.012110            0.015184            0.018341   \n",
       "Q9Y6M4             0.471490            0.000000            0.019306   \n",
       "Q9Y6M5             0.057144            0.058385            0.054389   \n",
       "Q9Y6R7             0.014961            0.014982            0.011997   \n",
       "\n",
       "SAMPLE ID  Median_G6PD_V68M_2  \n",
       "P02008            7713.013567  \n",
       "P02042           24494.073380  \n",
       "P02100               6.948159  \n",
       "P09105              44.328675  \n",
       "P68871           10593.014145  \n",
       "...                       ...  \n",
       "Q9Y6E0               0.056894  \n",
       "Q9Y6I3               0.011105  \n",
       "Q9Y6M4               0.000000  \n",
       "Q9Y6M5               0.053556  \n",
       "Q9Y6R7               0.014950  \n",
       "\n",
       "[1827 rows x 1928 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmol_prot_per_gDW = (\n",
    "    df_mg_prot_per_gDW_normalized  # mg / gDW\n",
    "    * (1 / df_uniprot_to_mw)  # mol / g --> mmol / mg\n",
    "    * (1e6 / 1)  # nmol / mmol\n",
    ").loc[:, df_mg_prot_per_gDW_normalized.columns]\n",
    "df_nmol_prot_per_gDW = df_nmol_prot_per_gDW.T\n",
    "df_nmol_prot_per_gDW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce81e95-0e7f-46a4-b1c8-b16e958155cd",
   "metadata": {},
   "source": [
    "## Create DataFrame for protein dilution reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6759c3c-bf2a-4115-953c-9b16f73d00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_protein_dilutions = create_protein_dilution_df(pcmodel)\n",
    "df_model_protein_dilutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a5311-87f7-4d17-a0f2-9eef9c4b52d3",
   "metadata": {},
   "source": [
    "## Organize samples (optional)\n",
    "Use this for organizing samples if time-outs are an issue or multiple runs are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd138d89-256b-424c-9d5a-48e345794e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_nmol_prot_per_gDW.copy()\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fe128-1107-4bbb-a102-0477a5042fd4",
   "metadata": {},
   "source": [
    "### Map samples to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fac1a-e134-438d-942e-d04e61bf5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_key = \"uniprot\"\n",
    "df_samples.index.name = merge_key\n",
    "\n",
    "df_model = (\n",
    "    df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "    .merge(df_samples, left_index=True, right_index=True, how=\"left\")\n",
    "    .set_index(\"PROTDL\")\n",
    "    .sort_index()\n",
    ")\n",
    "no_experimental_measurements = [\n",
    "    protein_dilution\n",
    "    for protein_dilution, has_measurement in df_model.isna().all(axis=1).items()\n",
    "    if has_measurement\n",
    "]\n",
    "handle_msg(\n",
    "    f\"Model proteins mapped to measurements: {len(df_model) - len(no_experimental_measurements)}\",\n",
    "    print_msg=True,\n",
    ")\n",
    "handle_msg(\n",
    "    f\"Model proteins without measurements: {len(no_experimental_measurements)}\",\n",
    "    print_msg=True,\n",
    ")\n",
    "df_model.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dac07-92c5-4c3d-9bfd-90f4d455ff9f",
   "metadata": {},
   "source": [
    "#### Summarize mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad923fc-2763-4b22-917f-dc1c9e95f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_proteins = set(df_samples.index)\n",
    "model_proteins = set(df_model_protein_dilutions.index)\n",
    "\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [\n",
    "        x\n",
    "        for x in df_mg_prot_per_gDW_normalized.columns\n",
    "        if x in list(HB_PROTEINS.values())\n",
    "    ],\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [x for x in df_mg_prot_per_gDW.columns if not x in list(HB_PROTEINS.values())],\n",
    "]\n",
    "\n",
    "df_mapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, ~df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_mapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, ~df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "\n",
    "proteomes = {}\n",
    "round_int = 6\n",
    "for label, df in zip(\n",
    "    [\"hemoglobin\", \"low abundance\"], [df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la]\n",
    "):\n",
    "    df_modeled = df.loc[:, df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    df_remaining = df.loc[:, ~df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    means = (df_modeled.mean(), df_remaining.mean())\n",
    "    stdevs = (df_modeled.std(), df_remaining.std())\n",
    "    proteomes[(label, \"modeled\")] = round(means[0], round_int)\n",
    "    proteomes[(label, \"remaining\")] = round(means[1], round_int)\n",
    "proteomes = pd.Series(proteomes, name=\"Mean value across samples\")\n",
    "proteomes.index = [f\"Mean {k[0]} mass {k[1]}\" for k in proteomes.index]\n",
    "print(proteomes.head())\n",
    "proteomes = proteomes[proteomes != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb813d-d140-4bda-a422-d86c1806fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(3, 6))\n",
    "subsets = (\n",
    "    len(dataset_proteins),\n",
    "    len(model_proteins),\n",
    "    len(dataset_proteins.intersection(model_proteins)),\n",
    ")\n",
    "\n",
    "\n",
    "venn = mpl_venn.venn2(\n",
    "    subsets=subsets,\n",
    "    set_labels=(dataset_name, model.id),\n",
    "    set_colors=(\"red\", \"blue\"),\n",
    "    alpha=0.5,\n",
    "    ax=ax1,\n",
    ")\n",
    "circles = mpl_venn.venn2_circles(\n",
    "    subsets=subsets, linestyle=\"-\", color=\"black\", ax=ax1, linewidth=1\n",
    ")\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "ax1.set_title(\"Modeled proteome\", fontsize=\"xx-large\")\n",
    "\n",
    "\n",
    "label_color_map = {\n",
    "    \"Mean hemoglobin mass modeled\": (\"Hemoglobin\", \"xkcd:dark red\"),\n",
    "    \"Mean low abundance mass modeled\": (\"Low abundance\", \"xkcd:light blue\"),\n",
    "    \"Mean low abundance mass remaining\": (\"Not modeled\", \"xkcd:green\"),\n",
    "}\n",
    "edgecolor = \"black\"\n",
    "linewidth = 1\n",
    "ax2.pie(\n",
    "    x=proteomes.values,\n",
    "    colors=[label_color_map[k][1] for k in proteomes.index],\n",
    "    pctdistance=1.35,\n",
    "    counterclock=False,\n",
    "    autopct=lambda pct: f\"{pct * 1000/100:.2f}\\n\",\n",
    "    textprops=dict(fontsize=\"large\", ha=\"center\", va=\"top\"),\n",
    "    wedgeprops=dict(edgecolor=edgecolor, linewidth=linewidth),\n",
    ")\n",
    "handles = [\n",
    "    mpl.patches.Patch(\n",
    "        edgecolor=edgecolor,\n",
    "        linewidth=linewidth,\n",
    "        label=label_color_map[k][0],\n",
    "        facecolor=label_color_map[k][1],\n",
    "    )\n",
    "    for k in proteomes.index\n",
    "]\n",
    "ax2.legend(\n",
    "    handles=handles,\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    frameon=False,\n",
    ")\n",
    "ax2.set_xlabel(\"Mass (mg/gDW)\", fontsize=\"large\", labelpad=-10)\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        results_dirpath / f\"ModeledProteome.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b212aa-2689-4cd1-b5b8-08c57ad6aaba",
   "metadata": {},
   "source": [
    "## Create QP model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904c726-a9d6-4890-a74f-09a6fd3b9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qp(pcmodel, df):\n",
    "    x = []  # Variables\n",
    "    c = []  # Data * Weights\n",
    "    F = []  # Weights\n",
    "\n",
    "    for protdl, (data_value, weight) in df.iterrows():\n",
    "        protdl = pcmodel.reactions.get_by_id(protdl)\n",
    "        x.append(protdl.flux_expression)\n",
    "        c.append(weight * data_value)\n",
    "        F.append(weight)\n",
    "\n",
    "    x = sympy.Matrix(x)\n",
    "    c = sympy.Matrix(c)\n",
    "    F = sympy.DiagMatrix(sympy.Matrix(F))\n",
    "    # # QP Objective must be in form of 0.5 * x.T * F * x - c.T * x\n",
    "    objective = 0.5 * x.T * F * x - c.T * x\n",
    "    pcmodel.objective = objective[0]\n",
    "    pcmodel.objective_direction = \"min\"\n",
    "    pcmodel.tolerance = COBRA_CONFIGURATION.tolerance\n",
    "\n",
    "    qp_sol = pcmodel.optimize()\n",
    "    return qp_sol\n",
    "\n",
    "\n",
    "def solve_qp_for_sample(\n",
    "    pcmodel,\n",
    "    data_measured,\n",
    "    data_weights=None,\n",
    "    log_zero_replacement=1e-9,\n",
    "    verbose=True,\n",
    "):\n",
    "    # Get protein values\n",
    "    data_measured = data_measured.copy()\n",
    "    data_measured.name = \"Measured\"\n",
    "    if data_weights is None:\n",
    "        data_weights = pd.Series(\n",
    "            [1] * len(data_measured), index=list(data_measured.index)\n",
    "        )\n",
    "    else:\n",
    "        data_weights = data_weights.copy()\n",
    "    data_weights.name = \"Weights\"\n",
    "    df_model_protein_dilutions = create_protein_dilution_df(pcmodel)\n",
    "    # Map to model\n",
    "    df_model_data = (\n",
    "        df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "        .merge(data_measured, left_index=True, right_index=True, how=\"left\")\n",
    "        .merge(data_weights, left_index=True, right_index=True, how=\"left\")\n",
    "        .set_index(\"PROTDL\")\n",
    "        .sort_index()\n",
    "    )\n",
    "    # Drop data without mappings\n",
    "    df = (\n",
    "        df_model_data.loc[:, [data_measured.name, data_weights.name]]\n",
    "        .dropna(axis=0, how=\"all\")\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # Solve QP\n",
    "    with pcmodel:\n",
    "        qp_sol = solve_qp(pcmodel, df)\n",
    "    df_qp_sol = qp_sol.fluxes.loc[\n",
    "        pcmodel.reactions.query(lambda x: isinstance(x, ProteinDilution)).list_attr(\n",
    "            \"id\"\n",
    "        )\n",
    "    ]\n",
    "    df_qp_sol = pd.concat(\n",
    "        (df_model_data.loc[:, data_measured.name], df_qp_sol), axis=1\n",
    "    ).dropna(how=\"all\", axis=0)\n",
    "    df_qp_sol = df_qp_sol.rename(\n",
    "        {data_measured.name: \"Measured\", \"fluxes\": \"Best-Fitted\"}, axis=1\n",
    "    )\n",
    "\n",
    "    # # Fill NA measurements with 0 values for unmeasured model proteins that had a non-zero value in the best-fit.\n",
    "    # # Will result in 0 value relaxation budget\n",
    "    # df = df_qp_sol[df_qp_sol[\"Best-Fitted\"] != 0]\n",
    "    # df_qp_sol.loc[df[df[\"Measured\"].isna()].index] = df_qp_sol.loc[df[df[\"Measured\"].isna()].index].fillna(0)\n",
    "    df_qp_sol = df_qp_sol.dropna(how=\"any\", axis=0)\n",
    "\n",
    "    obj_r2_values = {\"Objective\": qp_sol.objective_value}\n",
    "\n",
    "    # Calculate R2 score\n",
    "    df = df_qp_sol.copy()\n",
    "    obj_r2_values[\"R^2\"] = r2_score(\n",
    "        df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "    )\n",
    "    # Calculate R2 score on log10 transformed data\n",
    "    df = df_qp_sol.apply(\n",
    "        lambda x: [\n",
    "            log_zero_replacement if np.isclose(y, 0, atol=log_zero_replacement) else y\n",
    "            for y in x\n",
    "        ]\n",
    "    ).apply(np.log10)\n",
    "    obj_r2_values[\"R^2 log10\"] = r2_score(\n",
    "        df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "    )\n",
    "    # Calculate R2 score on log10 transformed data after removing 'zero' values\n",
    "    df = df_qp_sol[\n",
    "        ~df_qp_sol.apply(\n",
    "            lambda x: np.isclose(x, 0, atol=log_zero_replacement).any(), axis=1\n",
    "        )\n",
    "    ].apply(np.log10)\n",
    "    obj_r2_values[\"R^2 log10 w/o zeros\"] = r2_score(\n",
    "        df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "    )\n",
    "    # Recall that the objective is designed to try to minimize fitting error via maximizing R2, so R2=1 is a possibility\n",
    "    handle_msg(\n",
    "        \"\\t\".join(\n",
    "            [f\"Sample '{sample_id}'\"]\n",
    "            + [f\"{key}: {value:.4f}\" for key, value in obj_r2_values.items()]\n",
    "            + [f\"#zeros: {len(df_qp_sol) - len(df):d}/{len(df_qp_sol):d}\"]\n",
    "        ),\n",
    "        print_msg=verbose,\n",
    "    )\n",
    "    return (df_qp_sol, obj_r2_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c865bd-1409-400d-9e1f-d8ad5c9c9093",
   "metadata": {},
   "source": [
    "### Set weightings for QP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a9e24-5841-476b-84fd-cfe3d48237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is provided as (Protein IDs x Sample IDs)\n",
    "# Use original copy number values for weights\n",
    "df_weights = df_copy_numbers.T.loc[df_protein_data.index, df_samples.columns]\n",
    "df_weights = 1 / df_weights.infer_objects(copy=False).replace(0, 1)\n",
    "df_weights /= df_weights.mean()\n",
    "df_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43eb92-ceb7-4a3a-bac5-e32438e47f10",
   "metadata": {},
   "source": [
    "### Fit data by solving QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50d7d0-6de9-4d32-96a2-0768a38229fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_zero_replacement = COBRA_CONFIGURATION.tolerance\n",
    "fitting_data = {\"measured\": {}, \"best_fit\": {}, \"r2_objective\": {}}\n",
    "qp_solutions_dict = {}\n",
    "try:\n",
    "    previous_fitting_data = {\n",
    "        key: pd.read_csv(fitting_dirpath / f\"proteome_{key}.csv\", index_col=0)\n",
    "        for key in list(fitting_data)\n",
    "    }\n",
    "except FileNotFoundError:\n",
    "    # No previous data, reset\n",
    "    previous_fitting_data = {key: pd.DataFrame() for key in list(fitting_data)}\n",
    "if run_computations:\n",
    "    for sample_id, data_measured in df_samples.items():\n",
    "        # Key shouldn't matter for checking existance of previous solution\n",
    "        if (\n",
    "            not overwrite\n",
    "            and sample_id in previous_fitting_data[list(fitting_data)[-1]].columns\n",
    "        ):\n",
    "            handle_msg(\n",
    "                f\"QP solution already obtained for {sample_id}\", print_msg=verbose\n",
    "            )\n",
    "            for key, fitting_dict in fitting_data.items():\n",
    "                fitting_dict[sample_id] = (\n",
    "                    previous_fitting_data[key].loc[:, sample_id].to_dict()\n",
    "                )\n",
    "\n",
    "            df_qp_sol = pd.concat(\n",
    "                (\n",
    "                    previous_fitting_data[\"measured\"].loc[:, sample_id],\n",
    "                    previous_fitting_data[\"best_fit\"].loc[:, sample_id],\n",
    "                ),\n",
    "                axis=1,\n",
    "            ).fillna(0)\n",
    "            df_qp_sol.columns = [\"Measured\", \"Best-Fitted\"]\n",
    "            obj_r2_values = previous_fitting_data[\"r2_objective\"].loc[:, sample_id]\n",
    "            qp_solutions_dict[sample_id] = (df_qp_sol, obj_r2_values)\n",
    "        else:\n",
    "            df_qp_sol, obj_r2_values = solve_qp_for_sample(\n",
    "                pcmodel,\n",
    "                data_measured,\n",
    "                data_weights=df_weights.loc[:, sample_id],\n",
    "                log_zero_replacement=COBRA_CONFIGURATION.tolerance,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "            fitting_data[\"measured\"][sample_id] = df_qp_sol[\"Measured\"].to_dict()\n",
    "            fitting_data[\"best_fit\"][sample_id] = df_qp_sol[\"Best-Fitted\"].to_dict()\n",
    "            fitting_data[\"r2_objective\"][sample_id] = obj_r2_values\n",
    "            qp_solutions_dict[sample_id] = (df_qp_sol, obj_r2_values)\n",
    "    # Save solutions to files\n",
    "    for key, data in fitting_data.items():\n",
    "        data = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        data.to_csv(fitting_dirpath / f\"proteome_{key}.csv\", index=True)\n",
    "        fitting_data[key] = data\n",
    "else:\n",
    "    for key in previous_fitting_data.keys():\n",
    "        fitting_data[key] = pd.read_csv(\n",
    "            fitting_dirpath / f\"proteome_{key}.csv\", index_col=0\n",
    "        )\n",
    "    if len(df_samples.columns) != len(fitting_data[list(fitting_data)[-1]].columns):\n",
    "        warn(\n",
    "            \"Number of previous solutions does not match current number of samples! May need to re-run fitting\"\n",
    "        )\n",
    "    for sample_id in fitting_data[list(fitting_data)[-1]].columns:\n",
    "        df_qp_sol = pd.concat(\n",
    "            (\n",
    "                fitting_data[\"measured\"].loc[:, sample_id],\n",
    "                fitting_data[\"best_fit\"].loc[:, sample_id],\n",
    "            ),\n",
    "            axis=1,\n",
    "        ).fillna(0)\n",
    "        df_qp_sol.columns = [\"Measured\", \"Best-Fitted\"]\n",
    "        obj_r2_values = fitting_data[\"r2_objective\"].loc[:, sample_id].to_dict()\n",
    "        qp_solutions_dict[sample_id] = (df_qp_sol, obj_r2_values)\n",
    "handle_msg(f\"Number of QP solutions: {len(qp_solutions_dict)}\", print_msg=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8846cf-1031-4335-b50c-bc97a67b0573",
   "metadata": {},
   "source": [
    "### Plot fitting \n",
    "#### For the mean and median samples of each time point and for each chosen phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013de636-0daf-45ec-9609-43115300d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_plot = np.array(\n",
    "    [\n",
    "        [\n",
    "            x\n",
    "            for x in operation_ids\n",
    "            if (\n",
    "                # time_re.search(x) and\n",
    "                operation_re.search(x).group(\"op\")\n",
    "                == \"Mean\"\n",
    "            )\n",
    "        ],\n",
    "        [\n",
    "            x\n",
    "            for x in operation_ids\n",
    "            if (\n",
    "                # time_re.search(x) and\n",
    "                operation_re.search(x).group(\"op\")\n",
    "                == \"Median\"\n",
    "            )\n",
    "        ],\n",
    "    ]\n",
    ").T\n",
    "samples_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185fc86-7702-44f6-b293-95ab659d9d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_text_loc = \"upper left\"\n",
    "transform = False\n",
    "\n",
    "length = 4\n",
    "nrows, ncols = samples_to_plot.shape\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(length * ncols, length * nrows),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "sns.despine(fig)\n",
    "for idx, (sample_id, ax) in enumerate(zip(samples_to_plot.flatten(), axes.flatten())):\n",
    "    df_qp_sol, obj_r2_values = qp_solutions_dict[sample_id]\n",
    "    # Copy to prevent alterations to the original\n",
    "    df_qp_sol = df_qp_sol.copy()\n",
    "    xlabel, ylabel = df_qp_sol.columns\n",
    "\n",
    "    ticks = 10 ** np.arange(\n",
    "        np.log10(log_zero_replacement), -np.log10(log_zero_replacement), 3\n",
    "    )\n",
    "    if transform:\n",
    "        ticks = np.log10(ticks)\n",
    "        df_qp_sol.iloc[:, 0] = (\n",
    "            df_qp_sol.iloc[:, 0]\n",
    "            .apply(\n",
    "                lambda x: (\n",
    "                    log_zero_replacement\n",
    "                    if np.isclose(x, 0, atol=log_zero_replacement)\n",
    "                    else x\n",
    "                )\n",
    "            )\n",
    "            .apply(np.log10)\n",
    "        )\n",
    "        df_qp_sol.iloc[:, 1] = (\n",
    "            df_qp_sol.iloc[:, 1]\n",
    "            .apply(\n",
    "                lambda x: (\n",
    "                    log_zero_replacement\n",
    "                    if np.isclose(x, 0, atol=log_zero_replacement)\n",
    "                    else x\n",
    "                )\n",
    "            )\n",
    "            .apply(np.log10)\n",
    "        )\n",
    "    perfect_fit_line = ax.plot(\n",
    "        [ticks[0], ticks[-1]],\n",
    "        [ticks[0], ticks[-1]],\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "        linewidth=1,\n",
    "        alpha=1,\n",
    "    )\n",
    "    zero_val = 0 if not transform else np.log10(log_zero_replacement)\n",
    "\n",
    "    df_zeros = df_qp_sol[\n",
    "        (\n",
    "            df_qp_sol.apply(\n",
    "                lambda x: np.isclose(x, zero_val, atol=log_zero_replacement)\n",
    "            )\n",
    "        ).any(axis=1)\n",
    "    ]\n",
    "    df_perfect = df_qp_sol[\n",
    "        np.isclose(\n",
    "            abs(df_qp_sol[\"Measured\"] - df_qp_sol[\"Best-Fitted\"]),\n",
    "            0,\n",
    "            atol=log_zero_replacement,\n",
    "        )\n",
    "    ]\n",
    "    df_perfect = df_perfect[~df_perfect.index.isin(df_zeros.index)]\n",
    "\n",
    "    df_altered = df_qp_sol[\n",
    "        ~np.isclose(\n",
    "            abs(df_qp_sol[\"Measured\"] - df_qp_sol[\"Best-Fitted\"]),\n",
    "            0,\n",
    "            atol=log_zero_replacement,\n",
    "        )\n",
    "    ]\n",
    "    df_altered = df_altered[~df_altered.index.isin(df_zeros.index)]\n",
    "    df_always_zero = df_zeros[(df_zeros == zero_val).all(axis=1)]\n",
    "    df_zeros = df_zeros[~df_zeros.index.isin(df_always_zero.index)]\n",
    "    df_from_zeros = df_zeros[\n",
    "        np.isclose(df_zeros[\"Measured\"], zero_val, atol=log_zero_replacement)\n",
    "    ]\n",
    "    df_to_zeros = df_zeros[\n",
    "        np.isclose(df_zeros[\"Best-Fitted\"], zero_val, atol=log_zero_replacement)\n",
    "    ]\n",
    "\n",
    "    handles = [\n",
    "        ax.scatter(\n",
    "            data=df_perfect.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:blue\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_altered.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:yellow\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_from_zeros.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:green\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_to_zeros.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:red\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_always_zero.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:black\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "    ]\n",
    "    labels = [\n",
    "        f\"Perfect fit\",\n",
    "        f\"Adjusted abundance\",\n",
    "        f\"Unexpressed to expressed\",\n",
    "        f\"Expressed to unexpressed\",\n",
    "        f\"Never expressed\",\n",
    "    ]\n",
    "\n",
    "    sample_label = str(sample_id.replace(f\"{pcmodel.id}_\", \"\").replace(\"_\", \" \"))\n",
    "    if not transform:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "    fontdict = {\"size\": \"xx-large\"}\n",
    "    if idx >= len(samples_to_plot.flatten()) - ncols:\n",
    "        ax.set_xlabel(f\"{xlabel} Proteome\", fontdict=fontdict)\n",
    "\n",
    "    if idx % ncols == 0:\n",
    "        ax.set_ylabel(f\"{ylabel} Proteome\", fontdict=fontdict)\n",
    "\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "\n",
    "    ax.xaxis.set_tick_params(labelsize=\"x-large\")\n",
    "    ax.yaxis.set_tick_params(labelsize=\"x-large\")\n",
    "\n",
    "    r2_format = \" = {:.4f}\"\n",
    "    r2_pos_dict = {\n",
    "        \"lower right\": ((0.95, 1), \"right\"),\n",
    "        \"upper left\": ((0.05, 0.8), \"left\"),\n",
    "    }\n",
    "    if r2_text_loc in r2_pos_dict:\n",
    "        pos, ha = r2_pos_dict[r2_text_loc]\n",
    "        ax.text(\n",
    "            *pos,\n",
    "            \"\\n\".join(\n",
    "                (\n",
    "                    sample_label,\n",
    "                    r\"$R^{2}$\" + r2_format.format(obj_r2_values[\"R^2\"]),\n",
    "                    r\"$R^{2}\\text{log}_{10}$\"\n",
    "                    + r2_format.format(obj_r2_values[\"R^2 log10\"]),\n",
    "                    r\"$R^{2}\\text{log}_{10}\\text{ w/o zeros}$\"\n",
    "                    + r2_format.format(obj_r2_values[\"R^2 log10 w/o zeros\"]),\n",
    "                )\n",
    "            ),\n",
    "            transform=ax.transAxes,\n",
    "            color=\"black\",\n",
    "            fontsize=\"medium\",\n",
    "            ha=ha,\n",
    "        )\n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    loc=\"upper center\",\n",
    "    ncols=len(labels),\n",
    "    frameon=False,\n",
    "    fontsize=\"large\",\n",
    "    markerscale=2,\n",
    "    bbox_to_anchor=(0.5, -0.01),\n",
    ")\n",
    "fig.tight_layout()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath\n",
    "        / f\"QPfitting_{'' if not transform else 'log10_'}{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3095c-dd82-45c1-b076-c51d9f87b200",
   "metadata": {},
   "source": [
    "### Determine best value for slack variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ac734-204f-40bb-97bb-4b1aebd21018",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_determination_models = samples_to_plot.flatten()\n",
    "\n",
    "if run_computations:\n",
    "    list_of_pcmodels = []\n",
    "    for sample_id in slack_determination_models:\n",
    "        df_qp_sol, _ = qp_solutions_dict[sample_id]\n",
    "        # Create a copy of the model\n",
    "        pcmodel_sample = pcmodel.copy()\n",
    "        pcmodel_sample.id = f\"{pcmodel.id}_{sample_id}\"\n",
    "        for protdl in pcmodel_sample.reactions.query(\n",
    "            lambda x: isinstance(x, ProteinDilution)\n",
    "        ):\n",
    "            if protdl.id in df_qp_sol.index:\n",
    "                prot_bound = df_qp_sol.loc[protdl.id][\"Best-Fitted\"]\n",
    "            else:\n",
    "                prot_bound = 0\n",
    "            protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "        # Add the relaxation budget with slack = 0 first\n",
    "        add_relaxation_budget(pcmodel_sample, 0, int(verbose))\n",
    "        list_of_pcmodels += [pcmodel_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45313a7-636a-4be8-80c9-657ec44cf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_min = 1e-5  # Slack %\n",
    "slack_max = 1.5\n",
    "if run_computations:\n",
    "    solutions = {\n",
    "        pcmodel_sample.id: defaultdict(list) for pcmodel_sample in list_of_pcmodels\n",
    "    }\n",
    "    for slack_value in np.geomspace(slack_min, slack_max, 101):\n",
    "        handle_msg(f\"Updating slack variable to {slack_value:.6f}.\", print_msg=verbose)\n",
    "        for pcmodel_sample in list_of_pcmodels:\n",
    "            update_slack_value(pcmodel_sample, slack_value, verbose=False)\n",
    "            budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(\n",
    "                f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\"\n",
    "            )\n",
    "            pcmodel_sample.objective = (\n",
    "                sum(\n",
    "                    [\n",
    "                        r.flux_expression\n",
    "                        for r in pcmodel_sample.reactions.get_by_any(\n",
    "                            objective_reactions\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "                - budget_rxn_relaxation.flux_expression\n",
    "            )\n",
    "            pcmodel_sample.objective_direction = \"max\"\n",
    "            sol = pcmodel_sample.optimize()\n",
    "            obj_value = sol.objective_value\n",
    "            if not obj_value or np.isnan(obj_value):\n",
    "                handle_msg(\n",
    "                    f\"No solution at s = {slack_value:.6f} for model {pcmodel_sample}\",\n",
    "                    print_msg=bool(int(verbose) > 1),\n",
    "                )\n",
    "                continue\n",
    "            else:\n",
    "                demand = budget_rxn_relaxation.flux\n",
    "                budget = budget_rxn_relaxation.upper_bound\n",
    "            solutions[pcmodel_sample.id][\"model\"].append(pcmodel_sample.id)\n",
    "            solutions[pcmodel_sample.id][\"slack\"].append(slack_value)\n",
    "            solutions[pcmodel_sample.id][\"objective\"].append(obj_value)\n",
    "            if objective_reactions:\n",
    "                solutions[pcmodel_sample.id][\"_\".join(objective_reactions)].append(\n",
    "                    sol.fluxes.loc[objective_reactions].sum()\n",
    "                )\n",
    "            solutions[pcmodel_sample.id][\"relaxation_used_mg_per_gDW\"].append(demand)\n",
    "            solutions[pcmodel_sample.id][\"relaxation_budget\"].append(budget)\n",
    "            solutions[pcmodel_sample.id][\"relaxation_used_pct\"].append(\n",
    "                demand / budget * 100\n",
    "            )\n",
    "    solutions = {\n",
    "        pcmodel_sample_id: pd.DataFrame.from_dict(sol)\n",
    "        for pcmodel_sample_id, sol in solutions.items()\n",
    "    }\n",
    "    df_relaxation = pd.concat(list(solutions.values()), axis=0)\n",
    "    df_relaxation.to_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "else:\n",
    "    df_relaxation = pd.read_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.csv\",\n",
    "    )\n",
    "    solutions = {\n",
    "        mid: df_relaxation[df_relaxation[\"model\"] == mid].drop(\"model\", axis=1)\n",
    "        for mid in df_relaxation[\"model\"].unique()\n",
    "    }\n",
    "df_relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d5690-9261-4e16-b079-26324cd3eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_slack_var = 0.03\n",
    "colors = {\"0\": \"xkcd:light blue\", \"1\": \"xkcd:blue\", \"2\": \"xkcd:dark blue\"}\n",
    "colors = {\n",
    "    k: colors.get(k[-1], \"xkcd:black\")\n",
    "    for k in [\n",
    "        pcmodel_sample.replace(f\"{pcmodel.id}_\", \"\").split(\"_\", maxsplit=1)[-1]\n",
    "        for pcmodel_sample in list(solutions)\n",
    "    ]\n",
    "}\n",
    "colors.update(\n",
    "    {\n",
    "        \"D10\": \"xkcd:green\",\n",
    "        \"D23\": \"xkcd:gold\",\n",
    "        \"D42\": \"xkcd:red\",\n",
    "    }\n",
    ")\n",
    "linestyles = {\n",
    "    \"Mean\": \"-\",\n",
    "    \"Median\": \"-.\",\n",
    "}\n",
    "\n",
    "nrows = 3 if objective_reactions else 2\n",
    "fig, axes = plt.subplots(\n",
    "    nrows, 1, figsize=(4, nrows * 4), sharex=True, gridspec_kw=dict(hspace=0.05)\n",
    ")\n",
    "axes = axes.flatten()\n",
    "sns.despine(fig)\n",
    "\n",
    "o_values_min_max = (1000, -1000)\n",
    "r_values_max = -1000\n",
    "rxn_values_min_max = (0, -1000)\n",
    "\n",
    "for pcmodel_sample in list(sorted(list(solutions))):\n",
    "    op, group = pcmodel_sample.replace(f\"{pcmodel.id}_\", \"\").split(\"_\", maxsplit=1)\n",
    "    color = colors.get(group, \"xkcd:black\")\n",
    "    linestyle = linestyles.get(op, \":\")\n",
    "    s_values = solutions[str(pcmodel_sample)][\"slack\"].values\n",
    "    r_values = solutions[str(pcmodel_sample)][\"relaxation_used_pct\"].values\n",
    "    o_values = solutions[str(pcmodel_sample)][\"objective\"].values\n",
    "    r_values_max = max(r_values.max(), r_values_max)\n",
    "    o_values_min_max = (\n",
    "        min(o_values.min(), o_values_min_max[0]),\n",
    "        max(o_values.max(), o_values_min_max[-1]),\n",
    "    )\n",
    "\n",
    "    zorder = 1\n",
    "    lw = 2\n",
    "    axes[0].plot(\n",
    "        s_values,\n",
    "        r_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        s_values,\n",
    "        o_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    if objective_reactions:\n",
    "        rxn_values = solutions[str(pcmodel_sample)][\n",
    "            \"_\".join(objective_reactions)\n",
    "        ].values\n",
    "        rxn_values_min_max = (\n",
    "            min(rxn_values, rxn_values_min_max[0]),\n",
    "            max(rxn_values, rxn_values_min_max[-1]),\n",
    "        )\n",
    "\n",
    "        axes[2].plot(\n",
    "            s_values,\n",
    "            rxn_values,\n",
    "            label=str(pcmodel_sample),\n",
    "            color=color,\n",
    "            linestyle=linestyle,\n",
    "            linewidth=lw,\n",
    "            zorder=zorder,\n",
    "        )\n",
    "\n",
    "fontdict = {\"size\": \"x-large\"}\n",
    "axes[-1].set_xlabel(r\"Slack variable $s$\", fontdict=fontdict)\n",
    "\n",
    "zorder = 2\n",
    "alpha = 0.7\n",
    "limit_pad_sclar = 1.3\n",
    "smin = s_values[0]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i == 0:\n",
    "        ymin, ymax = (-0.001, r_values_max * limit_pad_sclar)\n",
    "    elif i == 1:\n",
    "        ymin, ymax = (\n",
    "            min(0, o_values_min_max[0]) * limit_pad_sclar,\n",
    "            o_values_min_max[-1] * limit_pad_sclar,\n",
    "        )\n",
    "    elif i == 2:\n",
    "        ymin, ymax = (rxn_values_min_max[0] * limit_pad_sclar, rxn_values_min_max[-1])\n",
    "    else:\n",
    "        pass\n",
    "    ax.vlines(chosen_slack_var, ymin=ymin, ymax=ymax, color=\"black\", linestyle=\":\")\n",
    "    ax.vlines(\n",
    "        smin,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.vlines(\n",
    "        1,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    xmin = smin / 2\n",
    "    ax.set_xlim(xmin, slack_max)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xscale(\"log\")\n",
    "    if i == 0:\n",
    "        ax.annotate(\n",
    "            rf\"$s > 0$\",\n",
    "            xy=(smin, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s \\leq 1$\",\n",
    "            xy=(1, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s = {chosen_slack_var}$\",\n",
    "            xy=(chosen_slack_var, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(5, -10),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"left\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "    ax.fill_between((xmin, smin), ymin, ymax, color=\"xkcd:light grey\")\n",
    "    ax.annotate(\n",
    "        \"Infeasible\",\n",
    "        xy=(smin, (ymax + ymin) / 2),\n",
    "        xycoords=\"data\",\n",
    "        rotation=90,\n",
    "        xytext=(-2, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "        fontsize=fontdict[\"size\"],\n",
    "    )\n",
    "\n",
    "\n",
    "handles, labels = axes[-1].get_legend_handles_labels()\n",
    "handles_labels = dict(zip(labels, handles))\n",
    "labels = [label.replace(f\"{pcmodel.id}_\", \"\").replace(\"_\", \" \") for label in labels]\n",
    "axes[-1].legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    ncols=2,\n",
    "    frameon=False,\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    ")\n",
    "\n",
    "\n",
    "axes[0].set_ylabel(\"Relaxation budget used\\n(%)\", fontdict=fontdict)\n",
    "axes[1].set_ylabel(\"Objective\\nvalue\", fontdict=fontdict)\n",
    "if objective_reactions:\n",
    "    axes[2].set_ylabel(\n",
    "        f\"{'+'.join(objective_reactions)}\\n(mmol/gDW/hr)\", fontdict=fontdict\n",
    "    )\n",
    "\n",
    "fig.align_labels()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath / f\"SlackPercentDetermination_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30511058-1ede-48b3-9217-44ec658bb342",
   "metadata": {},
   "source": [
    "### Formulate models from QP solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2effa-8e43-4737-8715-291dbd945960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ftypes = {\n",
    "    \"xml\"\n",
    "    # \"json\",\n",
    "}\n",
    "slack_value = chosen_slack_var  # Slack %\n",
    "ftypes = set([ftypes]) if isinstance(ftypes, str) else set(ftypes)\n",
    "zip_kwargs = dict(compression=zipfile.ZIP_DEFLATED, compresslevel=None)\n",
    "\n",
    "\n",
    "sample_pcmodels_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "existing_files = []\n",
    "if not overwrite:\n",
    "    # Check zip file for existing models\n",
    "    if Path(f\"{sample_pcmodels_dirpath}.zip\").exists():\n",
    "        with zipfile.ZipFile(f\"{sample_pcmodels_dirpath}.zip\", \"r\") as zfile:\n",
    "            existing_files += [Path(x).name for x in zfile.namelist() if x]\n",
    "    existing_files += [x.name for x in list(sample_pcmodels_dirpath.iterdir())]\n",
    "\n",
    "# Check sample directory for existing files\n",
    "if not len(existing_files) == len(set(existing_files)):\n",
    "    raise ValueError(\n",
    "        f\"Duplicates found: {[k for k, v in Counter(existing_files).items() if v > 1]}\"\n",
    "    )\n",
    "existing_files = set(sorted(existing_files))\n",
    "\n",
    "\n",
    "for sample_id, (df_qp_sol, _) in qp_solutions_dict.items():\n",
    "    sample_id = f\"{pcmodel.id}_{sample_id}\"\n",
    "    filenames = [f\"{sample_id}.{ftype}\" for ftype in ftypes]\n",
    "    if all([fname in existing_files for fname in filenames]):\n",
    "        handle_msg(f\"Model(s) already created for {sample_id}\", print_msg=verbose)\n",
    "        continue\n",
    "    pcmodel_sample = pcmodel.copy()\n",
    "    pcmodel_sample.id = sample_id\n",
    "    for protdl in pcmodel_sample.reactions.query(\n",
    "        lambda x: isinstance(x, ProteinDilution)\n",
    "    ):\n",
    "        prot_bound = (\n",
    "            df_qp_sol.loc[protdl.id][\"Best-Fitted\"]\n",
    "            if protdl.id in df_qp_sol.index\n",
    "            else 0\n",
    "        )\n",
    "        protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "\n",
    "    # Add the relaxation budget\n",
    "    add_relaxation_budget(pcmodel_sample, slack_value, verbose=False)\n",
    "    budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(\n",
    "        f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\"\n",
    "    )\n",
    "    # Determine smallest allowable relxation budget for simulation capabilities\n",
    "    with pcmodel_sample:\n",
    "        pcmodel_sample.objective = budget_rxn_relaxation.flux_expression\n",
    "        pcmodel_sample.objective_direction = \"min\"\n",
    "        budget_min = pcmodel_sample.slim_optimize()\n",
    "    budget_rxn_relaxation.lower_bound = budget_min\n",
    "    for filename in filenames:\n",
    "        # Might as well overwrite all files, especially if model needed to be regenerated anyways\n",
    "        write_cobra_model(\n",
    "            pcmodel_sample,\n",
    "            filename=sample_pcmodels_dirpath / filename,\n",
    "        )\n",
    "    handle_msg(f\"Model(s) saved for {pcmodel_sample.id}\", print_msg=verbose)\n",
    "\n",
    "dirpath = sample_pcmodels_dirpath\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    if not overwrite and Path(f\"{dirpath}.zip\").exists():\n",
    "        handle_msg(\"Copying original zip to temporary directory\", print_msg=verbose)\n",
    "        shutil.copy(f\"{dirpath}.zip\", tmpdir)\n",
    "    handle_msg(\"Appending model files to temporary zip file\", print_msg=verbose)\n",
    "    with zipfile.ZipFile(f\"{tmpdir}/{dirpath.name}.zip\", \"a\", **zip_kwargs) as zfile:\n",
    "        existing_files = set([Path(x).name for x in zfile.namelist() if x])\n",
    "        for filename in list(dirpath.iterdir()):\n",
    "            if filename.name in existing_files:\n",
    "                continue\n",
    "            zfile.write(f\"{filename}\", arcname=f\"{filename.name}\")\n",
    "    # Replacing original directory\n",
    "    handle_msg(\"Setting temporary zip file as the new zip file\", print_msg=verbose)\n",
    "    shutil.copy(f\"{tmpdir}/{dirpath.name}.zip\", dirpath.parent)\n",
    "handle_msg(\"Finished compression, cleaning up files\", print_msg=verbose)\n",
    "shutil.rmtree(str(dirpath))\n",
    "handle_msg(\"Finished cleanup\", print_msg=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbbe99-328b-45d2-8f0b-0a05b54c1da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
