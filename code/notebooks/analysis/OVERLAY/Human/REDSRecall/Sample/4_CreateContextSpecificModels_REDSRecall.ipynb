{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d1d32f-ac8f-44a8-b9ad-cacea20f8cf2",
   "metadata": {},
   "source": [
    "# Create context-specific models - REDS Recall\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from warnings import warn\n",
    "\n",
    "import gurobipy as gp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as mpl_venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    get_dirpath,\n",
    "    handle_msg,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    ProteinDilution,\n",
    "    add_relaxation_budget,\n",
    "    create_protein_dilution_df,\n",
    "    load_overlay_model,\n",
    "    update_slack_value,\n",
    ")\n",
    "from rbc_gem_utils.util import AVOGADRO_NUMBER, DEFAULT_DRY_MASS_PER_CELL\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a9df2-358e-4cb3-bad0-9323be471582",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3adcc9b-af52-4300-8563-221ed441f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-9\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75002349-87e3-497d-bdd4-7b8f0ac40aa8",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecbb31-18b5-4b6e-a43c-d620b0583fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "grouped_data_key = \"Sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37781f05-550a-4a04-bf53-ee372557dacb",
   "metadata": {},
   "source": [
    "### Set variables for columns keys and sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726f0a1-9ce6-4457-83d0-f13c43d6fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"PUBLIC RECALL DONOR ID\"\n",
    "time_key = \"DAY\"\n",
    "timepoints = [\"D10\", \"D23\", \"D42\"]\n",
    "genotypes = [\"G6PD_V68M\", \"ATP11C_V972M\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>S(?P<num>\\d\\d\\d))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "genotype_re = re.compile(rf\"(?P<genotype>({'|'.join(genotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa546c-4fc9-4b41-a526-d19d57059d3e",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eda7a3-74f4-4e1c-bc26-946895ea7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = False  # Keep off to use previously computed results\n",
    "overwrite = False  # Whether to allow overwriting of previous simulation results\n",
    "verbose = True\n",
    "objective_reactions = (\n",
    "    []\n",
    ")  # Objective reactions are used to determine slack variable but not necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd2432-5dec-449d-86a0-f04d764499b0",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2d846-e887-4c41-9996-4e415ad5c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b91704-70a4-4e24-b621-37cace803985",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57949510-8d98-4225-9b8d-b9718fb71c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\")\n",
    "    / model_id\n",
    "    / \"OVERLAY\"\n",
    "    / organism\n",
    "    / dataset_name\n",
    "    / grouped_data_key\n",
    ")\n",
    "fitting_dirpath = results_dirpath / \"fitting\"\n",
    "# Ensure directories exist\n",
    "results_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "fitting_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "# ZIP directories\n",
    "sample_pcmodels_dirpath = results_dirpath / \"pcmodels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ba860-d5dd-41d0-b70a-fe9bade1a194",
   "metadata": {},
   "source": [
    "### Define hemoglobin proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95333290-76cd-4bb1-85f6-9f44d3f23d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_PROTEINS = {\n",
    "    \"HBA\": \"P69905\",  # Hemoglobin subunit alpha\n",
    "    \"HBB\": \"P68871\",  # Hemoglobin subunit beta\n",
    "    \"HBD\": \"P02042\",  # Hemoglobin subunit delta\n",
    "    \"HBE1\": \"P02100\",  # Hemoglobin subunit beta\n",
    "    \"HBG1\": \"P69891\",  # Hemoglobin subunit gamma-1\n",
    "    \"HBG2\": \"P69892\",  # Hemoglobin subunit gamma-2\n",
    "    \"HBM\": \"Q6B0K9\",  # Hemoglobin subunit mu\n",
    "    \"HBQ1\": \"P09105\",  # Hemoglobin subunit theta-1\n",
    "    \"HBZ\": \"P02008\",  # Hemoglobin subunit zeta\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6fa4-161e-4511-bf31-0b75d3b93dcb",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de2e8f-e0f3-4e0c-94dd-52ea8edfb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a75d58-9789-4c76-a376-2db52ac44c2a",
   "metadata": {},
   "source": [
    "## Load copy numbers and protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539585e-562c-48b8-a9cd-ff9911d16161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load protein copy numbers\n",
    "df_copy_numbers = pd.read_csv(\n",
    "    processed_data_dirpath / \"ProteinCopyNumbers.csv\",\n",
    "    index_col=sample_key,\n",
    ")\n",
    "\n",
    "# Load MCH for transforming data\n",
    "df_MCH = pd.read_csv(processed_data_dirpath / \"MCH.csv\", index_col=sample_key)\n",
    "# Load protein data\n",
    "df_protein_data = pd.read_csv(\n",
    "    processed_data_dirpath / \"ProteinData.csv\",\n",
    "    index_col=\"Entry\",\n",
    ")\n",
    "\n",
    "all_ids = list(df_copy_numbers.index.unique())\n",
    "operation_ids = [x for x in all_ids if operation_re.match(x)]\n",
    "sample_ids = [x for x in all_ids if sample_id_re.match(x)]\n",
    "handle_msg(f\"Number of measured samples: {len(sample_ids)}\", print_msg=True)\n",
    "handle_msg(f\"Number of operation samples: {len(operation_ids)}\", print_msg=True)\n",
    "handle_msg(f\"Number of models to generate: {len(all_ids)}\", print_msg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0f2b8-c950-44af-a911-124cd4b153db",
   "metadata": {},
   "source": [
    "## Integrate proteomics with model\n",
    "### Scale measurements for proteome budget\n",
    "Note that this step will help ensure its theoretically possible for a perfect fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77177cf-4e29-47ca-8a07-b5837fb4dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_PERCENT, LA_PERCENT = (0.95, 0.05)\n",
    "MODELED_PERCENT = HB_PERCENT + LA_PERCENT\n",
    "assert 1 >= MODELED_PERCENT\n",
    "\n",
    "budget_hb_value = 1000 * HB_PERCENT\n",
    "budget_la_value = 1000 * LA_PERCENT\n",
    "budget_total_value = 1000 * MODELED_PERCENT\n",
    "\n",
    "handle_msg(f\"Hemoglobin budget:\\t{budget_hb_value} mg protein / gDW\", print_msg=True)\n",
    "handle_msg(f\"Low abundance budget:\\t{budget_la_value} mg protein / gDW\", print_msg=True)\n",
    "handle_msg(f\"Total budget:\\t\\t{budget_total_value} mg protein / gDW\", print_msg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867652e2-ffa0-4bd5-bc60-56bc95338447",
   "metadata": {},
   "source": [
    "### Convert copy numbers to mg / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c3bf5-b982-4020-848e-15c2bad52728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_to_mw = df_protein_data[\"Mass\"].astype(float)\n",
    "\n",
    "gDW_total_protein = (\n",
    "    df_MCH  # pgDW HB\n",
    "    * (1 / HB_PERCENT)  # pgDW total protein / pgDW HB\n",
    "    * (1 / 1e12)  #  gDW total protein / pgDW total protein\n",
    ")  # gDW total protein / cell\n",
    "df_mg_prot_per_gDW = (\n",
    "    df_copy_numbers[df_protein_data.index].mul(  # protein copies / cell\n",
    "        1 / gDW_total_protein.squeeze(), axis=0  # cell / gDW total protein\n",
    "    )\n",
    "    * (\n",
    "        1\n",
    "        / AVOGADRO_NUMBER  # mol protein / protein copies\n",
    "        * df_uniprot_to_mw  # gDW protein / mol protein\n",
    "        * 1e3  # mgDW protein / gDW protein\n",
    "    ).copy()\n",
    ")  # mgDW protein / gDW total protein\n",
    "df_mg_prot_per_gDW = df_mg_prot_per_gDW.loc[df_copy_numbers.index]\n",
    "df_mg_prot_per_gDW[df_mg_prot_per_gDW.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b51a37-eb71-43ed-9355-bebae6c6cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into hemoglobin and low abundance proteomes\n",
    "budget_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.dilution\"]\n",
    "budget_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.metabolite\"]\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW.loc[\n",
    "    :, df_mg_prot_per_gDW.columns.isin(HB_PROTEINS.values())\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW.loc[\n",
    "    :, ~df_mg_prot_per_gDW.columns.isin(HB_PROTEINS.values())\n",
    "]\n",
    "\n",
    "df_summary = {\n",
    "    \"Perfect total\": 1000,\n",
    "    \"Current total\": df_mg_prot_per_gDW.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Hemoglobin total\": df_mg_prot_per_gDW_hb.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Low abundance total\": df_mg_prot_per_gDW_la.loc[sample_ids]\n",
    "    .sum(axis=1)\n",
    "    .mean()\n",
    "    .item(),\n",
    "}\n",
    "df_summary[\"Remaining/Excess\"] = df_summary[\"Perfect total\"] - (\n",
    "    df_summary[\"Hemoglobin total\"] + df_summary[\"Low abundance total\"]\n",
    ")\n",
    "\n",
    "budget_rxn_proteome = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}proteome\"\n",
    ")\n",
    "budget_rxn_hemoglobin = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}hemoglobin\"\n",
    ")\n",
    "budget_rxn_total = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}total\"\n",
    ")\n",
    "\n",
    "if budget_la_value is None:\n",
    "    budget_la_value = budget_rxn_proteome.upper_bound\n",
    "if budget_hb_value is None:\n",
    "    budget_hb_value = budget_rxn_hemoglobin.upper_bound\n",
    "if budget_total_value is None:\n",
    "    budget_total_value = budget_rxn_total.upper_bound\n",
    "\n",
    "assert budget_total_value >= (budget_la_value + budget_hb_value)\n",
    "\n",
    "budget_rxn_proteome.upper_bound = budget_la_value\n",
    "budget_rxn_hemoglobin.upper_bound = budget_hb_value\n",
    "budget_rxn_total.upper_bound = budget_total_value\n",
    "\n",
    "# Scale values for low abundance proteome\n",
    "budget_value = budget_la_value\n",
    "df_mg_prot_per_gDW_la = (\n",
    "    budget_value * (df_mg_prot_per_gDW_la.T / df_mg_prot_per_gDW_la.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Low abundance scaled\"] = budget_value\n",
    "\n",
    "# Scale values for hemoglobin proteome\n",
    "budget_value = budget_hb_value\n",
    "df_mg_prot_per_gDW_hb = (\n",
    "    budget_value * (df_mg_prot_per_gDW_hb.T / df_mg_prot_per_gDW_hb.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Hemoglobin scaled\"] = budget_value\n",
    "\n",
    "budget_value = budget_total_value - sum([budget_la_value, budget_hb_value])\n",
    "df_summary[\"Remaining scaled\"] = budget_value\n",
    "\n",
    "# Combine dataframes back into one\n",
    "df_mg_prot_per_gDW_normalized = pd.concat(\n",
    "    (df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la), axis=1\n",
    ")\n",
    "df_summary = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \" \" * max(30 - len(k), 0) + k: [f\"{v:.4f}\", f\"{v / 1000 * 100:.1f}%\"]\n",
    "        for k, v in df_summary.items()\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"mg protein / gDW / cell\", \"Percentage\"],\n",
    ")\n",
    "print(df_summary)\n",
    "df_mg_prot_per_gDW_normalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2c529-58f3-4fce-9c7b-d41f11e2f09b",
   "metadata": {},
   "source": [
    "### Convert mg / gDW to nmol / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5ef09-c5a2-4985-b9c7-9d26d593d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmol_prot_per_gDW = (\n",
    "    df_mg_prot_per_gDW_normalized  # mg / gDW\n",
    "    * (1 / df_uniprot_to_mw)  # mol / g --> mmol / mg\n",
    "    * (1e6 / 1)  # nmol / mmol\n",
    ").loc[:, df_mg_prot_per_gDW_normalized.columns]\n",
    "df_nmol_prot_per_gDW = df_nmol_prot_per_gDW.T\n",
    "df_nmol_prot_per_gDW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce81e95-0e7f-46a4-b1c8-b16e958155cd",
   "metadata": {},
   "source": [
    "## Create DataFrame for protein dilution reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6759c3c-bf2a-4115-953c-9b16f73d00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_protein_dilutions = create_protein_dilution_df(pcmodel)\n",
    "df_model_protein_dilutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a5311-87f7-4d17-a0f2-9eef9c4b52d3",
   "metadata": {},
   "source": [
    "## Organize samples (optional)\n",
    "Use this for organizing samples if time-outs are an issue or multiple runs are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd138d89-256b-424c-9d5a-48e345794e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_nmol_prot_per_gDW.copy()\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fe128-1107-4bbb-a102-0477a5042fd4",
   "metadata": {},
   "source": [
    "### Map samples to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fac1a-e134-438d-942e-d04e61bf5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_key = \"uniprot\"\n",
    "df_samples.index.name = merge_key\n",
    "\n",
    "df_model = (\n",
    "    df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "    .merge(df_samples, left_index=True, right_index=True, how=\"left\")\n",
    "    .set_index(\"PROTDL\")\n",
    "    .sort_index()\n",
    ")\n",
    "no_experimental_measurements = [\n",
    "    protein_dilution\n",
    "    for protein_dilution, has_measurement in df_model.isna().all(axis=1).items()\n",
    "    if has_measurement\n",
    "]\n",
    "handle_msg(\n",
    "    f\"Model proteins mapped to measurements: {len(df_model) - len(no_experimental_measurements)}\",\n",
    "    print_msg=True,\n",
    ")\n",
    "handle_msg(\n",
    "    f\"Model proteins without measurements: {len(no_experimental_measurements)}\",\n",
    "    print_msg=True,\n",
    ")\n",
    "df_model.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dac07-92c5-4c3d-9bfd-90f4d455ff9f",
   "metadata": {},
   "source": [
    "#### Summarize mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad923fc-2763-4b22-917f-dc1c9e95f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_proteins = set(df_samples.index)\n",
    "model_proteins = set(df_model_protein_dilutions.index)\n",
    "\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [\n",
    "        x\n",
    "        for x in df_mg_prot_per_gDW_normalized.columns\n",
    "        if x in list(HB_PROTEINS.values())\n",
    "    ],\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [x for x in df_mg_prot_per_gDW.columns if not x in list(HB_PROTEINS.values())],\n",
    "]\n",
    "\n",
    "df_mapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, ~df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_mapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, ~df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "\n",
    "proteomes = {}\n",
    "round_int = 6\n",
    "for label, df in zip(\n",
    "    [\"hemoglobin\", \"low abundance\"], [df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la]\n",
    "):\n",
    "    df_modeled = df.loc[:, df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    df_remaining = df.loc[:, ~df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    means = (df_modeled.mean(), df_remaining.mean())\n",
    "    stdevs = (df_modeled.std(), df_remaining.std())\n",
    "    proteomes[(label, \"modeled\")] = round(means[0], round_int)\n",
    "    proteomes[(label, \"remaining\")] = round(means[1], round_int)\n",
    "proteomes = pd.Series(proteomes, name=\"Mean value across samples\")\n",
    "proteomes.index = [f\"Mean {k[0]} mass {k[1]}\" for k in proteomes.index]\n",
    "print(proteomes.head())\n",
    "proteomes = proteomes[proteomes != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb813d-d140-4bda-a422-d86c1806fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(3, 6))\n",
    "subsets = (\n",
    "    len(dataset_proteins),\n",
    "    len(model_proteins),\n",
    "    len(dataset_proteins.intersection(model_proteins)),\n",
    ")\n",
    "\n",
    "\n",
    "venn = mpl_venn.venn2(\n",
    "    subsets=subsets,\n",
    "    set_labels=(dataset_name, model.id),\n",
    "    set_colors=(\"red\", \"blue\"),\n",
    "    alpha=0.5,\n",
    "    ax=ax1,\n",
    ")\n",
    "circles = mpl_venn.venn2_circles(\n",
    "    subsets=subsets, linestyle=\"-\", color=\"black\", ax=ax1, linewidth=1\n",
    ")\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "ax1.set_title(\"Modeled proteome\", fontsize=\"xx-large\")\n",
    "\n",
    "\n",
    "label_color_map = {\n",
    "    \"Mean hemoglobin mass modeled\": (\"Hemoglobin\", \"xkcd:dark red\"),\n",
    "    \"Mean low abundance mass modeled\": (\"Low abundance\", \"xkcd:light blue\"),\n",
    "    \"Mean low abundance mass remaining\": (\"Not modeled\", \"xkcd:green\"),\n",
    "}\n",
    "edgecolor = \"black\"\n",
    "linewidth = 1\n",
    "ax2.pie(\n",
    "    x=proteomes.values,\n",
    "    colors=[label_color_map[k][1] for k in proteomes.index],\n",
    "    pctdistance=1.35,\n",
    "    counterclock=False,\n",
    "    autopct=lambda pct: f\"{pct * 1000/100:.2f}\\n\",\n",
    "    textprops=dict(fontsize=\"large\", ha=\"center\", va=\"top\"),\n",
    "    wedgeprops=dict(edgecolor=edgecolor, linewidth=linewidth),\n",
    ")\n",
    "handles = [\n",
    "    mpl.patches.Patch(\n",
    "        edgecolor=edgecolor,\n",
    "        linewidth=linewidth,\n",
    "        label=label_color_map[k][0],\n",
    "        facecolor=label_color_map[k][1],\n",
    "    )\n",
    "    for k in proteomes.index\n",
    "]\n",
    "ax2.legend(\n",
    "    handles=handles,\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    frameon=False,\n",
    ")\n",
    "ax2.set_xlabel(\"Mass (mg/gDW)\", fontsize=\"large\", labelpad=-10)\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        results_dirpath / f\"ModeledProteome.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b212aa-2689-4cd1-b5b8-08c57ad6aaba",
   "metadata": {},
   "source": [
    "## Create QP model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904c726-a9d6-4890-a74f-09a6fd3b9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qp(pcmodel, df):\n",
    "    x = []  # Variables\n",
    "    c = []  # Data * Weights\n",
    "    F = []  # Weights\n",
    "\n",
    "    for protdl, (data_value, weight) in df.iterrows():\n",
    "        protdl = pcmodel.reactions.get_by_id(protdl)\n",
    "        x.append(protdl.flux_expression)\n",
    "        c.append(weight * data_value)\n",
    "        F.append(weight)\n",
    "\n",
    "    x = sympy.Matrix(x)\n",
    "    c = sympy.Matrix(c)\n",
    "    F = sympy.DiagMatrix(sympy.Matrix(F))\n",
    "    # # QP Objective must be in form of 0.5 * x.T * F * x - c.T * x\n",
    "    objective = 0.5 * x.T * F * x - c.T * x\n",
    "    pcmodel.objective = objective[0]\n",
    "    pcmodel.objective_direction = \"min\"\n",
    "    pcmodel.tolerance = COBRA_CONFIGURATION.tolerance\n",
    "\n",
    "    qp_sol = pcmodel.optimize()\n",
    "    return qp_sol\n",
    "\n",
    "\n",
    "def solve_qp_for_sample(\n",
    "    pcmodel,\n",
    "    data_measured,\n",
    "    data_weights=None,\n",
    "    log_zero_replacement=1e-9,\n",
    "    verbose=True,\n",
    "):\n",
    "    # Get protein values\n",
    "    data_measured = data_measured.copy()\n",
    "    data_measured.name = \"Measured\"\n",
    "    if data_weights is None:\n",
    "        data_weights = pd.Series(\n",
    "            [1] * len(data_measured), index=list(data_measured.index)\n",
    "        )\n",
    "    else:\n",
    "        data_weights = data_weights.copy()\n",
    "    data_weights.name = \"Weights\"\n",
    "    df_model_protein_dilutions = create_protein_dilution_df(pcmodel)\n",
    "    # Map to model\n",
    "    df_model_data = (\n",
    "        df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "        .merge(data_measured, left_index=True, right_index=True, how=\"left\")\n",
    "        .merge(data_weights, left_index=True, right_index=True, how=\"left\")\n",
    "        .set_index(\"PROTDL\")\n",
    "        .sort_index()\n",
    "    )\n",
    "    # Drop data without mappings\n",
    "    df = (\n",
    "        df_model_data.loc[:, [data_measured.name, data_weights.name]]\n",
    "        .dropna(axis=0, how=\"all\")\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # Solve QP\n",
    "    with pcmodel:\n",
    "        qp_sol = solve_qp(pcmodel, df)\n",
    "    df_qp_sol = qp_sol.fluxes.loc[\n",
    "        pcmodel.reactions.query(lambda x: isinstance(x, ProteinDilution)).list_attr(\n",
    "            \"id\"\n",
    "        )\n",
    "    ]\n",
    "    df_qp_sol = pd.concat(\n",
    "        (df_model_data.loc[:, data_measured.name], df_qp_sol), axis=1\n",
    "    ).dropna(how=\"all\", axis=0)\n",
    "    df_qp_sol = df_qp_sol.rename(\n",
    "        {data_measured.name: \"Measured\", \"fluxes\": \"Best-Fitted\"}, axis=1\n",
    "    )\n",
    "\n",
    "    # # Fill NA measurements with 0 values for unmeasured model proteins that had a non-zero value in the best-fit.\n",
    "    # # Will result in 0 value relaxation budget\n",
    "    # df = df_qp_sol[df_qp_sol[\"Best-Fitted\"] != 0]\n",
    "    # df_qp_sol.loc[df[df[\"Measured\"].isna()].index] = df_qp_sol.loc[df[df[\"Measured\"].isna()].index].fillna(0)\n",
    "    df_qp_sol = df_qp_sol.dropna(how=\"any\", axis=0)\n",
    "\n",
    "    obj_r2_values = {\"Objective\": qp_sol.objective_value}\n",
    "\n",
    "    # Calculate R2 score\n",
    "    df = df_qp_sol.copy()\n",
    "    obj_r2_values[\"R^2\"] = r2_score(\n",
    "        df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "    )\n",
    "    # Calculate R2 score on log10 transformed data\n",
    "    df = df_qp_sol.apply(\n",
    "        lambda x: [\n",
    "            log_zero_replacement if np.isclose(y, 0, atol=log_zero_replacement) else y\n",
    "            for y in x\n",
    "        ]\n",
    "    ).apply(np.log10)\n",
    "    obj_r2_values[\"R^2 log10\"] = r2_score(\n",
    "        df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "    )\n",
    "    # Calculate R2 score on log10 transformed data after removing 'zero' values\n",
    "    df = df_qp_sol[\n",
    "        ~df_qp_sol.apply(\n",
    "            lambda x: np.isclose(x, 0, atol=log_zero_replacement).any(), axis=1\n",
    "        )\n",
    "    ].apply(np.log10)\n",
    "    obj_r2_values[\"R^2 log10 w/o zeros\"] = r2_score(\n",
    "        df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "    )\n",
    "    # Recall that the objective is designed to try to minimize fitting error via maximizing R2, so R2=1 is a possibility\n",
    "    handle_msg(\n",
    "        \"\\t\".join(\n",
    "            [f\"Sample '{sample_id}'\"]\n",
    "            + [f\"{key}: {value:.4f}\" for key, value in obj_r2_values.items()]\n",
    "            + [f\"#zeros: {len(df_qp_sol) - len(df):d}/{len(df_qp_sol):d}\"]\n",
    "        ),\n",
    "        print_msg=verbose,\n",
    "    )\n",
    "    return (df_qp_sol, obj_r2_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c865bd-1409-400d-9e1f-d8ad5c9c9093",
   "metadata": {},
   "source": [
    "### Set weightings for QP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a9e24-5841-476b-84fd-cfe3d48237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is provided as (Protein IDs x Sample IDs)\n",
    "# Use original copy number values for weights\n",
    "df_weights = df_copy_numbers.T.loc[df_protein_data.index, df_samples.columns]\n",
    "df_weights = 1 / df_weights.infer_objects(copy=False).replace(0, 1)\n",
    "df_weights /= df_weights.mean()\n",
    "df_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43eb92-ceb7-4a3a-bac5-e32438e47f10",
   "metadata": {},
   "source": [
    "### Fit data by solving QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50d7d0-6de9-4d32-96a2-0768a38229fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_zero_replacement = COBRA_CONFIGURATION.tolerance\n",
    "fitting_data = {\"measured\": {}, \"best_fit\": {}, \"r2_objective\": {}}\n",
    "qp_solutions_dict = {}\n",
    "try:\n",
    "    previous_fitting_data = {\n",
    "        key: pd.read_csv(fitting_dirpath / f\"proteome_{key}.csv\", index_col=0)\n",
    "        for key in list(fitting_data)\n",
    "    }\n",
    "except FileNotFoundError:\n",
    "    # No previous data, reset\n",
    "    previous_fitting_data = {key: pd.DataFrame() for key in list(fitting_data)}\n",
    "if run_computations:\n",
    "    for sample_id, data_measured in df_samples.items():\n",
    "        # Key shouldn't matter for checking existance of previous solution\n",
    "        if (\n",
    "            not overwrite\n",
    "            and sample_id in previous_fitting_data[list(fitting_data)[-1]].columns\n",
    "        ):\n",
    "            handle_msg(\n",
    "                f\"QP solution already obtained for {sample_id}\", print_msg=verbose\n",
    "            )\n",
    "            for key, fitting_dict in fitting_data.items():\n",
    "                fitting_dict[sample_id] = (\n",
    "                    previous_fitting_data[key].loc[:, sample_id].to_dict()\n",
    "                )\n",
    "\n",
    "            df_qp_sol = pd.concat(\n",
    "                (\n",
    "                    previous_fitting_data[\"measured\"].loc[:, sample_id],\n",
    "                    previous_fitting_data[\"best_fit\"].loc[:, sample_id],\n",
    "                ),\n",
    "                axis=1,\n",
    "            ).fillna(0)\n",
    "            df_qp_sol.columns = [\"Measured\", \"Best-Fitted\"]\n",
    "            obj_r2_values = previous_fitting_data[\"r2_objective\"].loc[:, sample_id]\n",
    "            qp_solutions_dict[sample_id] = (df_qp_sol, obj_r2_values)\n",
    "        else:\n",
    "            df_qp_sol, obj_r2_values = solve_qp_for_sample(\n",
    "                pcmodel,\n",
    "                data_measured,\n",
    "                data_weights=df_weights.loc[:, sample_id],\n",
    "                log_zero_replacement=COBRA_CONFIGURATION.tolerance,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "            fitting_data[\"measured\"][sample_id] = df_qp_sol[\"Measured\"].to_dict()\n",
    "            fitting_data[\"best_fit\"][sample_id] = df_qp_sol[\"Best-Fitted\"].to_dict()\n",
    "            fitting_data[\"r2_objective\"][sample_id] = obj_r2_values\n",
    "            qp_solutions_dict[sample_id] = (df_qp_sol, obj_r2_values)\n",
    "    # Save solutions to files\n",
    "    for key, data in fitting_data.items():\n",
    "        data = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        data.to_csv(fitting_dirpath / f\"proteome_{key}.csv\", index=True)\n",
    "        fitting_data[key] = data\n",
    "else:\n",
    "    for key in previous_fitting_data.keys():\n",
    "        fitting_data[key] = pd.read_csv(\n",
    "            fitting_dirpath / f\"proteome_{key}.csv\", index_col=0\n",
    "        )\n",
    "    if len(df_samples.columns) != len(fitting_data[list(fitting_data)[-1]].columns):\n",
    "        warn(\n",
    "            \"Number of previous solutions does not match current number of samples! May need to re-run fitting\"\n",
    "        )\n",
    "    for sample_id in fitting_data[list(fitting_data)[-1]].columns:\n",
    "        df_qp_sol = pd.concat(\n",
    "            (\n",
    "                fitting_data[\"measured\"].loc[:, sample_id],\n",
    "                fitting_data[\"best_fit\"].loc[:, sample_id],\n",
    "            ),\n",
    "            axis=1,\n",
    "        ).fillna(0)\n",
    "        df_qp_sol.columns = [\"Measured\", \"Best-Fitted\"]\n",
    "        obj_r2_values = fitting_data[\"r2_objective\"].loc[:, sample_id].to_dict()\n",
    "        qp_solutions_dict[sample_id] = (df_qp_sol, obj_r2_values)\n",
    "handle_msg(f\"Number of QP solutions: {len(qp_solutions_dict)}\", print_msg=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8846cf-1031-4335-b50c-bc97a67b0573",
   "metadata": {},
   "source": [
    "### Plot fitting \n",
    "#### For the mean and median samples of each time point and for each chosen phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013de636-0daf-45ec-9609-43115300d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_plot = np.array(\n",
    "    [\n",
    "        [\n",
    "            x\n",
    "            for x in operation_ids\n",
    "            if (\n",
    "                # time_re.search(x) and\n",
    "                operation_re.search(x).group(\"op\")\n",
    "                == \"Mean\"\n",
    "            )\n",
    "        ],\n",
    "        [\n",
    "            x\n",
    "            for x in operation_ids\n",
    "            if (\n",
    "                # time_re.search(x) and\n",
    "                operation_re.search(x).group(\"op\")\n",
    "                == \"Median\"\n",
    "            )\n",
    "        ],\n",
    "    ]\n",
    ").T\n",
    "samples_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185fc86-7702-44f6-b293-95ab659d9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_text_loc = \"upper left\"\n",
    "transform = False\n",
    "\n",
    "length = 4\n",
    "nrows, ncols = samples_to_plot.shape\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(length * ncols, length * nrows),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "sns.despine(fig)\n",
    "for idx, (sample_id, ax) in enumerate(zip(samples_to_plot.flatten(), axes.flatten())):\n",
    "    df_qp_sol, obj_r2_values = qp_solutions_dict[sample_id]\n",
    "    # Copy to prevent alterations to the original\n",
    "    df_qp_sol = df_qp_sol.copy()\n",
    "    xlabel, ylabel = df_qp_sol.columns\n",
    "\n",
    "    ticks = 10 ** np.arange(\n",
    "        np.log10(log_zero_replacement), -np.log10(log_zero_replacement), 3\n",
    "    )\n",
    "    if transform:\n",
    "        ticks = np.log10(ticks)\n",
    "        df_qp_sol.iloc[:, 0] = (\n",
    "            df_qp_sol.iloc[:, 0]\n",
    "            .apply(\n",
    "                lambda x: (\n",
    "                    log_zero_replacement\n",
    "                    if np.isclose(x, 0, atol=log_zero_replacement)\n",
    "                    else x\n",
    "                )\n",
    "            )\n",
    "            .apply(np.log10)\n",
    "        )\n",
    "        df_qp_sol.iloc[:, 1] = (\n",
    "            df_qp_sol.iloc[:, 1]\n",
    "            .apply(\n",
    "                lambda x: (\n",
    "                    log_zero_replacement\n",
    "                    if np.isclose(x, 0, atol=log_zero_replacement)\n",
    "                    else x\n",
    "                )\n",
    "            )\n",
    "            .apply(np.log10)\n",
    "        )\n",
    "    perfect_fit_line = ax.plot(\n",
    "        [ticks[0], ticks[-1]],\n",
    "        [ticks[0], ticks[-1]],\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "        linewidth=1,\n",
    "        alpha=1,\n",
    "    )\n",
    "    zero_val = 0 if not transform else np.log10(log_zero_replacement)\n",
    "\n",
    "    df_zeros = df_qp_sol[\n",
    "        (\n",
    "            df_qp_sol.apply(\n",
    "                lambda x: np.isclose(x, zero_val, atol=log_zero_replacement)\n",
    "            )\n",
    "        ).any(axis=1)\n",
    "    ]\n",
    "    df_perfect = df_qp_sol[\n",
    "        np.isclose(\n",
    "            abs(df_qp_sol[\"Measured\"] - df_qp_sol[\"Best-Fitted\"]),\n",
    "            0,\n",
    "            atol=log_zero_replacement,\n",
    "        )\n",
    "    ]\n",
    "    df_perfect = df_perfect[~df_perfect.index.isin(df_zeros.index)]\n",
    "\n",
    "    df_altered = df_qp_sol[\n",
    "        ~np.isclose(\n",
    "            abs(df_qp_sol[\"Measured\"] - df_qp_sol[\"Best-Fitted\"]),\n",
    "            0,\n",
    "            atol=log_zero_replacement,\n",
    "        )\n",
    "    ]\n",
    "    df_altered = df_altered[~df_altered.index.isin(df_zeros.index)]\n",
    "    df_always_zero = df_zeros[(df_zeros == zero_val).all(axis=1)]\n",
    "    df_zeros = df_zeros[~df_zeros.index.isin(df_always_zero.index)]\n",
    "    df_from_zeros = df_zeros[\n",
    "        np.isclose(df_zeros[\"Measured\"], zero_val, atol=log_zero_replacement)\n",
    "    ]\n",
    "    df_to_zeros = df_zeros[\n",
    "        np.isclose(df_zeros[\"Best-Fitted\"], zero_val, atol=log_zero_replacement)\n",
    "    ]\n",
    "\n",
    "    handles = [\n",
    "        ax.scatter(\n",
    "            data=df_perfect.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:blue\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_altered.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:yellow\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_from_zeros.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:green\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_to_zeros.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:red\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_always_zero.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:black\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "    ]\n",
    "    labels = [\n",
    "        f\"Perfect fit\",\n",
    "        f\"Adjusted abundance\",\n",
    "        f\"Unexpressed to expressed\",\n",
    "        f\"Expressed to unexpressed\",\n",
    "        f\"Never expressed\",\n",
    "    ]\n",
    "\n",
    "    sample_label = str(sample_id.replace(f\"{pcmodel.id}_\", \"\").replace(\"_\", \" \"))\n",
    "    if not transform:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "    fontdict = {\"size\": \"xx-large\"}\n",
    "    if idx >= len(samples_to_plot.flatten()) - ncols:\n",
    "        ax.set_xlabel(f\"{xlabel} Proteome\", fontdict=fontdict)\n",
    "\n",
    "    if idx % ncols == 0:\n",
    "        ax.set_ylabel(f\"{ylabel} Proteome\", fontdict=fontdict)\n",
    "\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "\n",
    "    ax.xaxis.set_tick_params(labelsize=\"x-large\")\n",
    "    ax.yaxis.set_tick_params(labelsize=\"x-large\")\n",
    "\n",
    "    r2_format = \" = {:.4f}\"\n",
    "    r2_pos_dict = {\n",
    "        \"lower right\": ((0.95, 1), \"right\"),\n",
    "        \"upper left\": ((0.05, 0.8), \"left\"),\n",
    "    }\n",
    "    if r2_text_loc in r2_pos_dict:\n",
    "        pos, ha = r2_pos_dict[r2_text_loc]\n",
    "        ax.text(\n",
    "            *pos,\n",
    "            \"\\n\".join(\n",
    "                (\n",
    "                    sample_label,\n",
    "                    r\"$R^{2}$\" + r2_format.format(obj_r2_values[\"R^2\"]),\n",
    "                    r\"$R^{2}\\text{log}_{10}$\"\n",
    "                    + r2_format.format(obj_r2_values[\"R^2 log10\"]),\n",
    "                    r\"$R^{2}\\text{log}_{10}\\text{ w/o zeros}$\"\n",
    "                    + r2_format.format(obj_r2_values[\"R^2 log10 w/o zeros\"]),\n",
    "                )\n",
    "            ),\n",
    "            transform=ax.transAxes,\n",
    "            color=\"black\",\n",
    "            fontsize=\"medium\",\n",
    "            ha=ha,\n",
    "        )\n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    loc=\"upper center\",\n",
    "    ncols=len(labels),\n",
    "    frameon=False,\n",
    "    fontsize=\"large\",\n",
    "    markerscale=2,\n",
    "    bbox_to_anchor=(0.5, -0.01),\n",
    ")\n",
    "fig.tight_layout()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath\n",
    "        / f\"QPfitting_{'' if not transform else 'log10_'}{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3095c-dd82-45c1-b076-c51d9f87b200",
   "metadata": {},
   "source": [
    "### Determine best value for slack variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ac734-204f-40bb-97bb-4b1aebd21018",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_determination_models = samples_to_plot.flatten()\n",
    "\n",
    "if run_computations:\n",
    "    list_of_pcmodels = []\n",
    "    for sample_id in slack_determination_models:\n",
    "        df_qp_sol, _ = qp_solutions_dict[sample_id]\n",
    "        # Create a copy of the model\n",
    "        pcmodel_sample = pcmodel.copy()\n",
    "        pcmodel_sample.id = f\"{pcmodel.id}_{sample_id}\"\n",
    "        for protdl in pcmodel_sample.reactions.query(\n",
    "            lambda x: isinstance(x, ProteinDilution)\n",
    "        ):\n",
    "            if protdl.id in df_qp_sol.index:\n",
    "                prot_bound = df_qp_sol.loc[protdl.id][\"Best-Fitted\"]\n",
    "            else:\n",
    "                prot_bound = 0\n",
    "            protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "        # Add the relaxation budget with slack = 0 first\n",
    "        add_relaxation_budget(pcmodel_sample, 0, int(verbose))\n",
    "        list_of_pcmodels += [pcmodel_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45313a7-636a-4be8-80c9-657ec44cf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_min = 1e-5  # Slack %\n",
    "slack_max = 1.5\n",
    "if run_computations:\n",
    "    solutions = {\n",
    "        pcmodel_sample.id: defaultdict(list) for pcmodel_sample in list_of_pcmodels\n",
    "    }\n",
    "    for slack_value in np.geomspace(slack_min, slack_max, 101):\n",
    "        handle_msg(f\"Updating slack variable to {slack_value:.6f}.\", print_msg=verbose)\n",
    "        for pcmodel_sample in list_of_pcmodels:\n",
    "            update_slack_value(pcmodel_sample, slack_value, verbose=False)\n",
    "            budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(\n",
    "                f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\"\n",
    "            )\n",
    "            pcmodel_sample.objective = (\n",
    "                sum(\n",
    "                    [\n",
    "                        r.flux_expression\n",
    "                        for r in pcmodel_sample.reactions.get_by_any(\n",
    "                            objective_reactions\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "                - budget_rxn_relaxation.flux_expression\n",
    "            )\n",
    "            pcmodel_sample.objective_direction = \"max\"\n",
    "            sol = pcmodel_sample.optimize()\n",
    "            obj_value = sol.objective_value\n",
    "            if not obj_value or np.isnan(obj_value):\n",
    "                handle_msg(\n",
    "                    f\"No solution at s = {slack_value:.6f} for model {pcmodel_sample}\",\n",
    "                    print_msg=bool(int(verbose) > 1),\n",
    "                )\n",
    "                continue\n",
    "            else:\n",
    "                demand = budget_rxn_relaxation.flux\n",
    "                budget = budget_rxn_relaxation.upper_bound\n",
    "            solutions[pcmodel_sample.id][\"model\"].append(pcmodel_sample.id)\n",
    "            solutions[pcmodel_sample.id][\"slack\"].append(slack_value)\n",
    "            solutions[pcmodel_sample.id][\"objective\"].append(obj_value)\n",
    "            if objective_reactions:\n",
    "                solutions[pcmodel_sample.id][\"_\".join(objective_reactions)].append(\n",
    "                    sol.fluxes.loc[objective_reactions].sum()\n",
    "                )\n",
    "            solutions[pcmodel_sample.id][\"relaxation_used_mg_per_gDW\"].append(demand)\n",
    "            solutions[pcmodel_sample.id][\"relaxation_budget\"].append(budget)\n",
    "            solutions[pcmodel_sample.id][\"relaxation_used_pct\"].append(\n",
    "                demand / budget * 100\n",
    "            )\n",
    "    solutions = {\n",
    "        pcmodel_sample_id: pd.DataFrame.from_dict(sol)\n",
    "        for pcmodel_sample_id, sol in solutions.items()\n",
    "    }\n",
    "    df_relaxation = pd.concat(list(solutions.values()), axis=0)\n",
    "    df_relaxation.to_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "else:\n",
    "    df_relaxation = pd.read_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.csv\",\n",
    "    )\n",
    "    solutions = {\n",
    "        mid: df_relaxation[df_relaxation[\"model\"] == mid].drop(\"model\", axis=1)\n",
    "        for mid in df_relaxation[\"model\"].unique()\n",
    "    }\n",
    "df_relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d5690-9261-4e16-b079-26324cd3eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_slack_var = 0.03\n",
    "colors = {\"0\": \"xkcd:light blue\", \"1\": \"xkcd:blue\", \"2\": \"xkcd:dark blue\"}\n",
    "colors = {\n",
    "    k: colors.get(k[-1], \"xkcd:black\")\n",
    "    for k in [\n",
    "        pcmodel_sample.replace(f\"{pcmodel.id}_\", \"\").split(\"_\", maxsplit=1)[-1]\n",
    "        for pcmodel_sample in list(solutions)\n",
    "    ]\n",
    "}\n",
    "colors.update(\n",
    "    {\n",
    "        \"D10\": \"xkcd:green\",\n",
    "        \"D23\": \"xkcd:gold\",\n",
    "        \"D42\": \"xkcd:red\",\n",
    "    }\n",
    ")\n",
    "linestyles = {\n",
    "    \"Mean\": \"-\",\n",
    "    \"Median\": \"-.\",\n",
    "}\n",
    "\n",
    "nrows = 3 if objective_reactions else 2\n",
    "fig, axes = plt.subplots(\n",
    "    nrows, 1, figsize=(4, nrows * 4), sharex=True, gridspec_kw=dict(hspace=0.05)\n",
    ")\n",
    "axes = axes.flatten()\n",
    "sns.despine(fig)\n",
    "\n",
    "o_values_min_max = (1000, -1000)\n",
    "r_values_max = -1000\n",
    "rxn_values_min_max = (0, -1000)\n",
    "\n",
    "for pcmodel_sample in list(sorted(list(solutions))):\n",
    "    op, group = pcmodel_sample.replace(f\"{pcmodel.id}_\", \"\").split(\"_\", maxsplit=1)\n",
    "    color = colors.get(group, \"xkcd:black\")\n",
    "    linestyle = linestyles.get(op, \":\")\n",
    "    s_values = solutions[str(pcmodel_sample)][\"slack\"].values\n",
    "    r_values = solutions[str(pcmodel_sample)][\"relaxation_used_pct\"].values\n",
    "    o_values = solutions[str(pcmodel_sample)][\"objective\"].values\n",
    "    r_values_max = max(r_values.max(), r_values_max)\n",
    "    o_values_min_max = (\n",
    "        min(o_values.min(), o_values_min_max[0]),\n",
    "        max(o_values.max(), o_values_min_max[-1]),\n",
    "    )\n",
    "\n",
    "    zorder = 1\n",
    "    lw = 2\n",
    "    axes[0].plot(\n",
    "        s_values,\n",
    "        r_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        s_values,\n",
    "        o_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    if objective_reactions:\n",
    "        rxn_values = solutions[str(pcmodel_sample)][\n",
    "            \"_\".join(objective_reactions)\n",
    "        ].values\n",
    "        rxn_values_min_max = (\n",
    "            min(rxn_values, rxn_values_min_max[0]),\n",
    "            max(rxn_values, rxn_values_min_max[-1]),\n",
    "        )\n",
    "\n",
    "        axes[2].plot(\n",
    "            s_values,\n",
    "            rxn_values,\n",
    "            label=str(pcmodel_sample),\n",
    "            color=color,\n",
    "            linestyle=linestyle,\n",
    "            linewidth=lw,\n",
    "            zorder=zorder,\n",
    "        )\n",
    "\n",
    "fontdict = {\"size\": \"x-large\"}\n",
    "axes[-1].set_xlabel(r\"Slack variable $s$\", fontdict=fontdict)\n",
    "\n",
    "zorder = 2\n",
    "alpha = 0.7\n",
    "limit_pad_sclar = 1.3\n",
    "smin = s_values[0]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i == 0:\n",
    "        ymin, ymax = (-0.001, r_values_max * limit_pad_sclar)\n",
    "    elif i == 1:\n",
    "        ymin, ymax = (\n",
    "            min(0, o_values_min_max[0]) * limit_pad_sclar,\n",
    "            o_values_min_max[-1] * limit_pad_sclar,\n",
    "        )\n",
    "    elif i == 2:\n",
    "        ymin, ymax = (rxn_values_min_max[0] * limit_pad_sclar, rxn_values_min_max[-1])\n",
    "    else:\n",
    "        pass\n",
    "    ax.vlines(chosen_slack_var, ymin=ymin, ymax=ymax, color=\"black\", linestyle=\":\")\n",
    "    ax.vlines(\n",
    "        smin,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.vlines(\n",
    "        1,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    xmin = smin / 2\n",
    "    ax.set_xlim(xmin, slack_max)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xscale(\"log\")\n",
    "    if i == 0:\n",
    "        ax.annotate(\n",
    "            rf\"$s > 0$\",\n",
    "            xy=(smin, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s \\leq 1$\",\n",
    "            xy=(1, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s = {chosen_slack_var}$\",\n",
    "            xy=(chosen_slack_var, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(5, -10),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"left\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "    ax.fill_between((xmin, smin), ymin, ymax, color=\"xkcd:light grey\")\n",
    "    ax.annotate(\n",
    "        \"Infeasible\",\n",
    "        xy=(smin, (ymax + ymin) / 2),\n",
    "        xycoords=\"data\",\n",
    "        rotation=90,\n",
    "        xytext=(-2, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "        fontsize=fontdict[\"size\"],\n",
    "    )\n",
    "\n",
    "\n",
    "handles, labels = axes[-1].get_legend_handles_labels()\n",
    "handles_labels = dict(zip(labels, handles))\n",
    "labels = [label.replace(f\"{pcmodel.id}_\", \"\").replace(\"_\", \" \") for label in labels]\n",
    "axes[-1].legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    ncols=2,\n",
    "    frameon=False,\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    ")\n",
    "\n",
    "\n",
    "axes[0].set_ylabel(\"Relaxation budget used\\n(%)\", fontdict=fontdict)\n",
    "axes[1].set_ylabel(\"Objective\\nvalue\", fontdict=fontdict)\n",
    "if objective_reactions:\n",
    "    axes[2].set_ylabel(\n",
    "        f\"{'+'.join(objective_reactions)}\\n(mmol/gDW/hr)\", fontdict=fontdict\n",
    "    )\n",
    "\n",
    "fig.align_labels()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath / f\"SlackPercentDetermination_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30511058-1ede-48b3-9217-44ec658bb342",
   "metadata": {},
   "source": [
    "### Formulate models from QP solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2effa-8e43-4737-8715-291dbd945960",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftypes = {\n",
    "    \"xml\"\n",
    "    # \"json\",\n",
    "}\n",
    "slack_value = chosen_slack_var  # Slack %\n",
    "ftypes = set([ftypes]) if isinstance(ftypes, str) else set(ftypes)\n",
    "zip_kwargs = dict(compression=zipfile.ZIP_DEFLATED, compresslevel=None)\n",
    "\n",
    "\n",
    "sample_pcmodels_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "existing_files = []\n",
    "if not overwrite:\n",
    "    # Check zip file for existing models\n",
    "    if Path(f\"{sample_pcmodels_dirpath}.zip\").exists():\n",
    "        with zipfile.ZipFile(f\"{sample_pcmodels_dirpath}.zip\", \"r\") as zfile:\n",
    "            existing_files += [Path(x).name for x in zfile.namelist() if x]\n",
    "    existing_files += [x.name for x in list(sample_pcmodels_dirpath.iterdir())]\n",
    "\n",
    "# Check sample directory for existing files\n",
    "if not len(existing_files) == len(set(existing_files)):\n",
    "    raise ValueError(\n",
    "        f\"Duplicates found: {[k for k, v in Counter(existing_files).items() if v > 1]}\"\n",
    "    )\n",
    "existing_files = set(sorted(existing_files))\n",
    "\n",
    "\n",
    "for sample_id, (df_qp_sol, _) in qp_solutions_dict.items():\n",
    "    sample_id = f\"{pcmodel.id}_{sample_id}\"\n",
    "    filenames = [f\"{sample_id}.{ftype}\" for ftype in ftypes]\n",
    "    if all([fname in existing_files for fname in filenames]):\n",
    "        handle_msg(f\"Model(s) already created for {sample_id}\", print_msg=verbose)\n",
    "        continue\n",
    "    pcmodel_sample = pcmodel.copy()\n",
    "    pcmodel_sample.id = sample_id\n",
    "    for protdl in pcmodel_sample.reactions.query(\n",
    "        lambda x: isinstance(x, ProteinDilution)\n",
    "    ):\n",
    "        prot_bound = (\n",
    "            df_qp_sol.loc[protdl.id][\"Best-Fitted\"]\n",
    "            if protdl.id in df_qp_sol.index\n",
    "            else 0\n",
    "        )\n",
    "        protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "\n",
    "    # Add the relaxation budget\n",
    "    add_relaxation_budget(pcmodel_sample, slack_value, verbose=False)\n",
    "    budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(\n",
    "        f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\"\n",
    "    )\n",
    "    # Determine smallest allowable relxation budget for simulation capabilities\n",
    "    with pcmodel_sample:\n",
    "        pcmodel_sample.objective = budget_rxn_relaxation.flux_expression\n",
    "        pcmodel_sample.objective_direction = \"min\"\n",
    "        budget_min = pcmodel_sample.slim_optimize()\n",
    "    budget_rxn_relaxation.lower_bound = budget_min\n",
    "    for filename in filenames:\n",
    "        # Might as well overwrite all files, especially if model needed to be regenerated anyways\n",
    "        write_cobra_model(\n",
    "            pcmodel_sample,\n",
    "            filename=sample_pcmodels_dirpath / filename,\n",
    "        )\n",
    "    handle_msg(f\"Model(s) saved for {pcmodel_sample.id}\", print_msg=verbose)\n",
    "\n",
    "dirpath = sample_pcmodels_dirpath\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    if not overwrite and Path(f\"{dirpath}.zip\").exists():\n",
    "        handle_msg(\"Copying original zip to temporary directory\", print_msg=verbose)\n",
    "        shutil.copy(f\"{dirpath}.zip\", tmpdir)\n",
    "    handle_msg(\"Appending model files to temporary zip file\", print_msg=verbose)\n",
    "    with zipfile.ZipFile(f\"{tmpdir}/{dirpath.name}.zip\", \"a\", **zip_kwargs) as zfile:\n",
    "        existing_files = set([Path(x).name for x in zfile.namelist() if x])\n",
    "        for filename in list(dirpath.iterdir()):\n",
    "            if filename.name in existing_files:\n",
    "                continue\n",
    "            zfile.write(f\"{filename}\", arcname=f\"{filename.name}\")\n",
    "    # Replacing original directory\n",
    "    handle_msg(\"Setting temporary zip file as the new zip file\", print_msg=verbose)\n",
    "    shutil.copy(f\"{tmpdir}/{dirpath.name}.zip\", dirpath.parent)\n",
    "handle_msg(\"Finished compression, cleaning up files\", print_msg=verbose)\n",
    "shutil.rmtree(str(dirpath))\n",
    "handle_msg(\"Finished cleanup\", print_msg=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbbe99-328b-45d2-8f0b-0a05b54c1da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
