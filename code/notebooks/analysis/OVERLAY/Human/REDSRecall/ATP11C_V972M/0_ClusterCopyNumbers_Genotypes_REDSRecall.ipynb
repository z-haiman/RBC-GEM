{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ace56d6-e359-414b-a371-e723787462eb",
   "metadata": {},
   "source": [
    "# Cluster Protein Copy Numbers - REDS Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b4c1f-bc09-49a4-b7c8-6d491bb76f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import gurobipy as gp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from rbc_gem_utils import (\n",
    "    GEM_NAME,\n",
    "    get_dirpath,\n",
    "    handle_msg,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    pairwise,\n",
    "    r2_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43d79d-035c-4f23-8579-00f6fbf51e59",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7614b879-d950-4924-b214-eeece7010a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "genotype = \"ATP11C_V972M\"\n",
    "grouped_data_key = \"Sample\"\n",
    "grouped_data_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4c223-5992-48ac-a095-0eb542b15fbb",
   "metadata": {},
   "source": [
    "### Set variables for columns keys and sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ba4a9-3427-4aca-82f6-9c34e1107331",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = \"SAMPLE ID\"\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "donor_re = re.compile(rf\"(?P<donor>S(?P<num>\\d\\d\\d))\")\n",
    "sample_id_re = re.compile(r\"(?!\" + operations + r\")\" + donor_re.pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e8375-8e29-45e7-851a-7a6460bb77df",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51992e16-c6bc-4528-9681-e0c8f0e2d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b597c23-5095-45b8-ae99-c686d7ca9613",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac982a99-6e4d-4b6e-83f2-efd5ed81fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "processed_clusters_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\")\n",
    "    / model_id\n",
    "    / \"Clustering\"\n",
    "    / organism\n",
    "    / dataset_name\n",
    ")\n",
    "# Ensure directories exist\n",
    "processed_clusters_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f6ef7-d98c-44d7-856f-f60ada2dc2f5",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca44b81a-7776-4eb2-b7da-3428ee307840",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirpath = get_dirpath(\"model\")\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{GEM_NAME}.xml\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee7eb4-ceec-45ba-a91d-a333acd665e2",
   "metadata": {},
   "source": [
    "## Load copy numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266d058-3735-44a5-9fd3-03604ed8d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for clustering\n",
    "protein_dtype = \"ProteinIntensities\"\n",
    "df_proteins = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{protein_dtype}.csv\",\n",
    "    index_col=sample_key,\n",
    ")\n",
    "\n",
    "all_ids = list(df_proteins.index.unique())\n",
    "operation_ids = [x for x in all_ids if operation_re.match(x)]\n",
    "sample_ids = [x for x in all_ids if x not in operation_ids]\n",
    "\n",
    "print(f\"Number of measured samples: {len(sample_ids)}\")\n",
    "print(f\"Number of operation samples: {len(operation_ids)}\")\n",
    "print(f\"Number of models to generate: {len(all_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cbf70-07a6-4477-b328-87884fb307bc",
   "metadata": {},
   "source": [
    "### Remove models based on data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11a0e3-1035-40f9-8cda-9f72f5ee87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_samples = df_proteins[\n",
    "    [not bool(operation_re.search(x)) for x in df_proteins.index]\n",
    "].copy()\n",
    "df_data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500ee15-cd9e-4766-80fb-5c2bb35829a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorize_limit = 0.05  # Set as 0 or None to prevent winsorization\n",
    "export_data = True\n",
    "dict_of_normalized_dfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b61b4-dd90-4d02-af53-d04c182cea32",
   "metadata": {},
   "source": [
    "### Normalize protein copy numbers across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fbdc9-d0c7-49a4-9a43-e13b102d67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data_samples.copy()\n",
    "filetag = []\n",
    "\n",
    "if grouped_data_key == \"Donor\":\n",
    "    df.index = [x.split(\"_\")[0] for x in df.index]\n",
    "    df = df.groupby(level=0).mean()\n",
    "filetag = [grouped_data_key]\n",
    "\n",
    "if winsorize_limit:\n",
    "    # Winsorized\n",
    "    df = df.clip(\n",
    "        lower=df.quantile(winsorize_limit, axis=0),\n",
    "        upper=df.quantile(1 - winsorize_limit, axis=0),\n",
    "        axis=1,\n",
    "    )\n",
    "    filetag += [\"WinPCT{:.0f}\".format(100 * winsorize_limit)]\n",
    "\n",
    "# Normalized\n",
    "df_norm = df.sub(df.mean(axis=0), axis=1).div(df.std(ddof=1, axis=0), axis=1)\n",
    "filetag += [\"Z-score\"]\n",
    "filetag = \"_\".join(filetag)\n",
    "print(f\"Filetag: {filetag}\")\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424882c3-60ae-4e2d-8625-34cdfb1c6ed3",
   "metadata": {},
   "source": [
    "#### All proteins in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453939e-5e46-4965-a392-a88fd5d3c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_data:\n",
    "    filepath = processed_clusters_dirpath / f\"{filetag}.csv\"\n",
    "    df_norm.to_csv(filepath, index=True)\n",
    "print(\n",
    "    \"Standardized Range: ({:.4f}, {:.4f})\".format(\n",
    "        df_norm.min().min(), df_norm.max().max()\n",
    "    )\n",
    ")\n",
    "\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52957f9b-4f8c-4f81-9a47-e2eda7d628db",
   "metadata": {},
   "source": [
    "## Split data into subgroups using metadata\n",
    "### Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceef4e5-58f1-4ac6-94f9-96210aa125e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(\n",
    "    processed_data_dirpath / \"Metadata.csv\",\n",
    "    index_col=sample_key,\n",
    ")\n",
    "\n",
    "if grouped_data_key.endswith(\"Donor\"):\n",
    "    df_metadata.index = [x.split(\"_\")[0] for x in df_metadata.index]\n",
    "    df_metadata = df_metadata.groupby(level=0).agg(lambda x: list(x.unique()))\n",
    "    df_metadata = df_metadata.explode(list(df_metadata.columns))\n",
    "\n",
    "for c in df_metadata.columns:\n",
    "    print(c)\n",
    "df_metadata.index.name = sample_key\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d8a11-5e0e-4722-b064-5d5133868aed",
   "metadata": {},
   "source": [
    "### Split by genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feea04c-50df-4ea0-85de-8157dc67c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genotypes\n",
    "verbose = True\n",
    "dict_of_genotype_dfs = {}\n",
    "if genotype not in df_metadata.columns:\n",
    "    handle_msg(f\"No genotype data for Genotype {genotype}\\n\", print_msg=verbose)\n",
    "handle_msg(f\"Splitting data for Genotype {genotype}\", print_msg=verbose)\n",
    "# Make directory\n",
    "genotype_dir = processed_clusters_dirpath / genotype\n",
    "genotype_dir.mkdir(exist_ok=True, parents=True)\n",
    "# Drop NA values and save Genotype MetaData\n",
    "df_genotype = df_metadata[genotype].dropna()\n",
    "if export_data:\n",
    "    df_genotype.to_csv(genotype_dir / f\"{grouped_data_key}_Genotypes.csv\", index=True)\n",
    "# Split data by allele counts for proteins\n",
    "handle_msg(f\"Applying to normalized data for proteins\", print_msg=verbose)\n",
    "# Group samples by allele count for samples with allele count determined\n",
    "df_samples_grouped = (\n",
    "    df_genotype.reset_index(drop=False)\n",
    "    .convert_dtypes()\n",
    "    .groupby(df_genotype.name)\n",
    "    .agg(list)\n",
    ")\n",
    "df_samples_grouped.loc[\"All\"] = [list(df_genotype.index)]\n",
    "handle_msg(\n",
    "    f\"Creating subgroups for allele counts: {list(df_samples_grouped.index)}\",\n",
    "    print_msg=verbose,\n",
    ")\n",
    "for allele_count, sample_ids in df_samples_grouped.iterrows():\n",
    "    allele_key = f\"Alleles{allele_count}\"\n",
    "    df_allele_samples = df_data_samples.loc[\n",
    "        df_data_samples.index.isin(sample_ids.item())\n",
    "    ]\n",
    "    df_allele_samples_norm = df_norm.loc[df_norm.index.isin(sample_ids.item())]\n",
    "    df_allele_samples_norm = df_allele_samples_norm.dropna(how=\"all\", axis=1).fillna(\n",
    "        df_allele_samples_norm.mean(axis=0)\n",
    "    )\n",
    "    # Save data\n",
    "    if export_data:\n",
    "        df_allele_samples.to_csv(\n",
    "            genotype_dir / \"{}.csv\".format(\"_\".join([protein_dtype, allele_key])),\n",
    "            index=True,\n",
    "        )\n",
    "        df_allele_samples_norm.to_csv(\n",
    "            genotype_dir\n",
    "            / \"{}.csv\".format(\"_\".join([protein_dtype, allele_key, filetag])),\n",
    "            index=True,\n",
    "        )\n",
    "\n",
    "    dict_of_genotype_dfs[(genotype, allele_count)] = df_allele_samples_norm.copy()\n",
    "    print(df_allele_samples_norm.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d41030-131c-4318-b991-9660a3dd89c1",
   "metadata": {},
   "source": [
    "## Load data for clustering\n",
    "### Cluster samples pre-grouped by allele count for representative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c939ac5-f7c4-4d47-885e-d47a19fb7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dunn_index(data, labels):\n",
    "    # Calculate pairwise distances\n",
    "    distances = pairwise.euclidean_distances(data)\n",
    "\n",
    "    # Initialize variables for min_intercluster and max_intracluster\n",
    "    min_intercluster = np.inf\n",
    "    max_intracluster = 0\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # Compute maximum intra-cluster distance\n",
    "    for label in unique_labels:\n",
    "        cluster_points_indices = np.where(labels == label)[0]\n",
    "        if len(cluster_points_indices) > 1:\n",
    "            intra_cluster_distances = distances[\n",
    "                np.ix_(cluster_points_indices, cluster_points_indices)\n",
    "            ]\n",
    "            max_intracluster = max(max_intracluster, np.max(intra_cluster_distances))\n",
    "\n",
    "    # Compute minimum inter-cluster distance\n",
    "    for i in range(len(unique_labels)):\n",
    "        for j in range(i + 1, len(unique_labels)):\n",
    "            cluster_i_indices = np.where(labels == unique_labels[i])[0]\n",
    "            cluster_j_indices = np.where(labels == unique_labels[j])[0]\n",
    "            inter_cluster_distances = distances[\n",
    "                np.ix_(cluster_i_indices, cluster_j_indices)\n",
    "            ]\n",
    "            min_intercluster = min(min_intercluster, np.min(inter_cluster_distances))\n",
    "\n",
    "    if (\n",
    "        max_intracluster == 0\n",
    "    ):  # Handle cases of single-point clusters or perfect overlap\n",
    "        return np.inf\n",
    "    else:\n",
    "        return min_intercluster / max_intracluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006db55f-e8ff-458e-8fd7-378bce8bc4dc",
   "metadata": {},
   "source": [
    "#### Allele count: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44018db2-6fce-43dd-8c93-341e17cc536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mapping = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc0edf-26d2-41d1-bb2b-54e5db2d9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_count = 0\n",
    "verbose = True\n",
    "data_original = dict_of_genotype_dfs[(genotype, allele_count)].copy()\n",
    "data_original.index.name = sample_key\n",
    "data_original.columns.name = \"Proteins\"\n",
    "data_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9838430-500a-44f5-abcb-b646b87104fd",
   "metadata": {},
   "source": [
    "#### K-means clustering\n",
    "##### Determine optimal number of clusters for representative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5860f9-066c-44fb-bf88-b040b642b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaulation_metric_scores = defaultdict(dict)\n",
    "dataframes_of_clusters = {}\n",
    "dataframes_of_label_maps = {}\n",
    "kmax = min(50, len(data_original) - 1)\n",
    "verbose = False\n",
    "for n_clusters in range(2, kmax + 1):\n",
    "\n",
    "    kmeans = sklearn.cluster.KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        init=\"k-means++\",\n",
    "        n_init=50,\n",
    "        max_iter=int(1e9),\n",
    "        tol=1e-12,\n",
    "        verbose=0,\n",
    "        random_state=44,\n",
    "        algorithm=\"lloyd\",\n",
    "    )\n",
    "    # Clustering occurs on columns, goal is to reduce sample number so data format is (n_features, n_samples)\n",
    "    data_clustered = kmeans.fit_transform(data_original.values)\n",
    "    # Inertia (Within-cluster sum-of-squares)\n",
    "    inertia = kmeans.inertia_\n",
    "    evaulation_metric_scores[\"Inertia\"][n_clusters] = inertia\n",
    "    # Silhouette Score\n",
    "    evaulation_metric_scores[\"Silhouette Score\"][n_clusters] = silhouette_score(\n",
    "        data_clustered,  # (n_samples, n_features)\n",
    "        kmeans.labels_,\n",
    "        metric=\"euclidean\",\n",
    "        sample_size=None,\n",
    "        random_state=None,\n",
    "    )\n",
    "    # Davies-Bouldin Index\n",
    "    evaulation_metric_scores[\"Davies-Bouldin Index\"][n_clusters] = davies_bouldin_score(\n",
    "        data_clustered, kmeans.labels_\n",
    "    )\n",
    "    # Calinski-Harabasz Index\n",
    "    evaulation_metric_scores[\"Calinski-Harabasz Index\"][n_clusters] = (\n",
    "        calinski_harabasz_score(data_clustered, kmeans.labels_)\n",
    "    )\n",
    "    evaulation_metric_scores[\"Dunn Index\"][n_clusters] = calculate_dunn_index(\n",
    "        data_clustered, kmeans.labels_\n",
    "    )\n",
    "    if verbose:\n",
    "        header = f\"For K-means clustering: K = {n_clusters}\"\n",
    "\n",
    "        print(f\"{header}\\n{'='*len(header)}\")\n",
    "        for metric_key in list(evaulation_metric_scores):\n",
    "            score = evaulation_metric_scores[metric_key][n_clusters]\n",
    "            print(f\"{metric_key}: {score:.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Save as DataFame\n",
    "    data_clustered = pd.DataFrame(data_clustered, index=data_original.index)\n",
    "    data_clustered.index.name = \"Proteins\"\n",
    "    data_clustered.columns.name = \"Cluster\"\n",
    "    dataframes_of_clusters[n_clusters] = data_clustered\n",
    "    dataframes_of_label_maps[n_clusters] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120d523-ee52-4373-b056-a3c2206dcca3",
   "metadata": {},
   "source": [
    "#### Plot evaluation metric scores\n",
    "##### Inertia\n",
    "Measures the compactness of clusters by calculating the sum of squared distances between each data point and its centroid. Lower inertia generally indicates tighter, more cohesive clusters.\n",
    "##### Silhouette Score\n",
    "Measures how well each data point fits within its assigned cluster compared to other clusters. A higher score (closer to 1) indicates better clustering. \n",
    "##### Davies-Bouldin Index\n",
    "Measures the average similarity between each cluster and its most similar cluster. A lower score indicates better separation between clusters. \n",
    "##### Calinski-Harabasz Index\n",
    "Measures the ratio of between-cluster dispersion to within-cluster dispersion. A higher score indicates better clustering. \n",
    "##### Dunn Index:\n",
    "Measures the ratio of the shortest distance between clusters to the largest distance within a cluster. A higher score indicates better separation and compactness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942d746-d21c-428b-91e5-4aeaa804527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    len(evaulation_metric_scores),\n",
    "    1,\n",
    "    figsize=(10, 2 * len(evaulation_metric_scores)),\n",
    "    sharex=True,\n",
    ")\n",
    "major_tick_interval = 4\n",
    "minor_tick_interval = 2\n",
    "chosen_n_clusters = 18\n",
    "print(f\"Number of samples to cluster: {len(data_original.index)}\")\n",
    "# Initialize minimum and maximums\n",
    "for idx, (ax, metric_key) in enumerate(\n",
    "    zip(axes.flatten(), list(evaulation_metric_scores))\n",
    "):\n",
    "    n_clusters = list(evaulation_metric_scores[metric_key].keys())\n",
    "    scores = list(evaulation_metric_scores[metric_key].values())\n",
    "    ax.plot(\n",
    "        n_clusters,\n",
    "        scores,\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"black\",\n",
    "        markeredgecolor=\"black\",\n",
    "        markersize=2,\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(major_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(minor_tick_interval))\n",
    "    ax.set_title(metric_key)\n",
    "    if idx == len(evaulation_metric_scores) - 1:\n",
    "        ax.set_xlabel(\"Number of clusters\", fontsize=\"xx-large\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    if chosen_n_clusters < len(data_original.index):\n",
    "        ax.vlines(\n",
    "            chosen_n_clusters, min(scores), max(scores), linestyle=\"--\", color=\"red\"\n",
    "        )\n",
    "        ax.hlines(\n",
    "            evaulation_metric_scores[metric_key][chosen_n_clusters],\n",
    "            xmin=0,\n",
    "            xmax=n_clusters[-1],\n",
    "            linestyle=\"--\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            chosen_n_clusters,\n",
    "            evaulation_metric_scores[metric_key][chosen_n_clusters],\n",
    "            marker=\"o\",\n",
    "            markerfacecolor=\"red\",\n",
    "            markeredgecolor=\"red\",\n",
    "            markersize=5,\n",
    "        )\n",
    "    ax.set_xlim(0, n_clusters[-1])\n",
    "    ax.set_ylim(min(scores), max(scores))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526a2b2-b844-4093-bcf7-a6235917b645",
   "metadata": {},
   "source": [
    "##### Use clusters to form representative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212ac96-0f30-48d2-b048-cabce108186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_start_num = 1\n",
    "# Load protein copy numbers\n",
    "df_copy_numbers = pd.read_csv(\n",
    "    processed_data_dirpath / \"ProteinCopyNumbers.csv\", index_col=sample_key\n",
    ")\n",
    "# Load MCH for transforming data\n",
    "df_MCH = pd.read_csv(processed_data_dirpath / \"MCH.csv\", index_col=sample_key)\n",
    "\n",
    "df_copy_numbers = df_copy_numbers.loc[list(df_data_samples.index)].copy()\n",
    "df_MCH = df_MCH.loc[list(df_data_samples.index)].copy()\n",
    "if grouped_data_key.endswith(\"Donor\"):\n",
    "    df_copy_numbers.index = [x.split(\"_\")[0] for x in df_copy_numbers.index]\n",
    "    df_copy_numbers = df_copy_numbers.groupby(level=0).mean()\n",
    "\n",
    "    df_MCH.index = [x.split(\"_\")[0] for x in df_MCH.index]\n",
    "    df_MCH = df_MCH.groupby(level=0).mean()\n",
    "\n",
    "\n",
    "(processed_clusters_dirpath / genotype).mkdir(exist_ok=True, parents=True)\n",
    "if chosen_n_clusters < len(data_original.index):\n",
    "    cluster_labels = dataframes_of_label_maps[chosen_n_clusters] + cluster_start_num\n",
    "    cluster_mapping.update(dict(zip(list(data_original.index), cluster_labels)))\n",
    "\n",
    "    df_copy_numbers_clustered = df_copy_numbers.loc[list(data_original.index)].copy()\n",
    "    df_copy_numbers_clustered = df_copy_numbers_clustered.rename(\n",
    "        cluster_mapping, axis=0\n",
    "    )\n",
    "    df_copy_numbers_clustered = df_copy_numbers_clustered.groupby(level=0).mean()\n",
    "    df_copy_numbers_clustered.index = [\n",
    "        f\"Allele{allele_count}_C{int(x)}\" for x in df_copy_numbers_clustered.index\n",
    "    ]\n",
    "    df_copy_numbers_clustered.to_csv(\n",
    "        processed_clusters_dirpath\n",
    "        / genotype\n",
    "        / f\"{grouped_data_key}_Alleles{allele_count}_ClusterCopyNumbers.csv\",\n",
    "        index=True,\n",
    "    )\n",
    "\n",
    "    df_MCH_clustered = df_MCH.loc[list(data_original.index)].copy()\n",
    "    df_MCH_clustered = df_MCH_clustered.rename(cluster_mapping, axis=0)\n",
    "    df_MCH_clustered = df_MCH_clustered.groupby(level=0).mean()\n",
    "    df_MCH_clustered.index = [\n",
    "        f\"Allele{allele_count}_C{int(x)}\" for x in df_MCH_clustered.index\n",
    "    ]\n",
    "    df_MCH_clustered.to_csv(\n",
    "        processed_clusters_dirpath\n",
    "        / genotype\n",
    "        / f\"{grouped_data_key}_Alleles{allele_count}_ClusterMCH.csv\",\n",
    "        index=True,\n",
    "    )\n",
    "    if save_figures:\n",
    "        fig.savefig(\n",
    "            processed_clusters_dirpath\n",
    "            / genotype\n",
    "            / f\"{grouped_data_key}_Alleles{allele_count}_ClusterMetrics.{imagetype}\",\n",
    "            transparent=transparent,\n",
    "            format=imagetype,\n",
    "        )\n",
    "    cluster_start_num += chosen_n_clusters\n",
    "else:\n",
    "    df_copy_numbers_clustered = data_original.copy()\n",
    "df_copy_numbers_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c477b-2013-47a9-9307-a9679f7ff4af",
   "metadata": {},
   "source": [
    "#### Allele count: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93208c-763d-4285-aee3-6aff3767c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_count = 1\n",
    "verbose = True\n",
    "data_original = dict_of_genotype_dfs[(genotype, allele_count)].copy()\n",
    "data_original.index.name = sample_key\n",
    "data_original.columns.name = \"Proteins\"\n",
    "data_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61964615-4fb1-45fe-8592-262d6956ad67",
   "metadata": {},
   "source": [
    "#### K-means clustering\n",
    "##### Determine optimal number of clusters for representative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dff8c5-13df-48b5-9236-91cae3c542b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaulation_metric_scores = defaultdict(dict)\n",
    "dataframes_of_clusters = {}\n",
    "dataframes_of_label_maps = {}\n",
    "kmax = min(50, len(data_original) - 1)\n",
    "verbose = False\n",
    "for n_clusters in range(2, kmax + 1):\n",
    "\n",
    "    kmeans = sklearn.cluster.KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        init=\"k-means++\",\n",
    "        n_init=50,\n",
    "        max_iter=int(1e9),\n",
    "        tol=1e-12,\n",
    "        verbose=0,\n",
    "        random_state=44,\n",
    "        algorithm=\"lloyd\",\n",
    "    )\n",
    "    # Clustering occurs on columns, goal is to reduce sample number so data format is (n_features, n_samples)\n",
    "    data_clustered = kmeans.fit_transform(data_original.values)\n",
    "    # Inertia (Within-cluster sum-of-squares)\n",
    "    inertia = kmeans.inertia_\n",
    "    evaulation_metric_scores[\"Inertia\"][n_clusters] = inertia\n",
    "    # Silhouette Score\n",
    "    evaulation_metric_scores[\"Silhouette Score\"][n_clusters] = silhouette_score(\n",
    "        data_clustered,  # (n_samples, n_features)\n",
    "        kmeans.labels_,\n",
    "        metric=\"euclidean\",\n",
    "        sample_size=None,\n",
    "        random_state=None,\n",
    "    )\n",
    "    # Davies-Bouldin Index\n",
    "    evaulation_metric_scores[\"Davies-Bouldin Index\"][n_clusters] = davies_bouldin_score(\n",
    "        data_clustered, kmeans.labels_\n",
    "    )\n",
    "    # Calinski-Harabasz Index\n",
    "    evaulation_metric_scores[\"Calinski-Harabasz Index\"][n_clusters] = (\n",
    "        calinski_harabasz_score(data_clustered, kmeans.labels_)\n",
    "    )\n",
    "    evaulation_metric_scores[\"Dunn Index\"][n_clusters] = calculate_dunn_index(\n",
    "        data_clustered, kmeans.labels_\n",
    "    )\n",
    "    if verbose:\n",
    "        header = f\"For K-means clustering: K = {n_clusters}\"\n",
    "\n",
    "        print(f\"{header}\\n{'='*len(header)}\")\n",
    "        for metric_key in list(evaulation_metric_scores):\n",
    "            score = evaulation_metric_scores[metric_key][n_clusters]\n",
    "            print(f\"{metric_key}: {score:.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Save as DataFame\n",
    "    data_clustered = pd.DataFrame(data_clustered, index=data_original.index)\n",
    "    data_clustered.index.name = \"Proteins\"\n",
    "    data_clustered.columns.name = \"Cluster\"\n",
    "    dataframes_of_clusters[n_clusters] = data_clustered\n",
    "    dataframes_of_label_maps[n_clusters] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3332d4e7-447f-4803-aa50-1c07a5a2bb01",
   "metadata": {},
   "source": [
    "#### Plot evaluation metric scores\n",
    "##### Inertia\n",
    "Measures the compactness of clusters by calculating the sum of squared distances between each data point and its centroid. Lower inertia generally indicates tighter, more cohesive clusters.\n",
    "##### Silhouette Score\n",
    "Measures how well each data point fits within its assigned cluster compared to other clusters. A higher score (closer to 1) indicates better clustering. \n",
    "##### Davies-Bouldin Index\n",
    "Measures the average similarity between each cluster and its most similar cluster. A lower score indicates better separation between clusters. \n",
    "##### Calinski-Harabasz Index\n",
    "Measures the ratio of between-cluster dispersion to within-cluster dispersion. A higher score indicates better clustering. \n",
    "##### Dunn Index:\n",
    "Measures the ratio of the shortest distance between clusters to the largest distance within a cluster. A higher score indicates better separation and compactness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e7605-61c4-4c55-97f9-1d16e5763443",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    len(evaulation_metric_scores),\n",
    "    1,\n",
    "    figsize=(10, 2 * len(evaulation_metric_scores)),\n",
    "    sharex=True,\n",
    ")\n",
    "major_tick_interval = 2\n",
    "minor_tick_interval = 1\n",
    "chosen_n_clusters = 8\n",
    "print(f\"Number of samples to cluster: {len(data_original.index)}\")\n",
    "# Initialize minimum and maximums\n",
    "\n",
    "for idx, (ax, metric_key) in enumerate(\n",
    "    zip(axes.flatten(), list(evaulation_metric_scores))\n",
    "):\n",
    "    n_clusters = list(evaulation_metric_scores[metric_key].keys())\n",
    "    scores = list(evaulation_metric_scores[metric_key].values())\n",
    "    ax.plot(\n",
    "        n_clusters,\n",
    "        scores,\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"black\",\n",
    "        markeredgecolor=\"black\",\n",
    "        markersize=2,\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(major_tick_interval))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(minor_tick_interval))\n",
    "    ax.set_title(metric_key)\n",
    "    if idx == len(evaulation_metric_scores) - 1:\n",
    "        ax.set_xlabel(\"Number of clusters\", fontsize=\"xx-large\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    if chosen_n_clusters < len(data_original.index):\n",
    "        ax.vlines(\n",
    "            chosen_n_clusters, min(scores), max(scores), linestyle=\"--\", color=\"red\"\n",
    "        )\n",
    "        ax.hlines(\n",
    "            evaulation_metric_scores[metric_key][chosen_n_clusters],\n",
    "            xmin=0,\n",
    "            xmax=n_clusters[-1],\n",
    "            linestyle=\"--\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            chosen_n_clusters,\n",
    "            evaulation_metric_scores[metric_key][chosen_n_clusters],\n",
    "            marker=\"o\",\n",
    "            markerfacecolor=\"red\",\n",
    "            markeredgecolor=\"red\",\n",
    "            markersize=5,\n",
    "        )\n",
    "    ax.set_xlim(0, n_clusters[-1])\n",
    "    ax.set_ylim(min(scores), max(scores))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a8432-9845-413a-a802-27308ec7041d",
   "metadata": {},
   "source": [
    "##### Use clusters to form representative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cf82e-18a5-4f3e-8887-455225d300a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load protein copy numbers\n",
    "df_copy_numbers = pd.read_csv(\n",
    "    processed_data_dirpath / \"ProteinCopyNumbers.csv\", index_col=sample_key\n",
    ")\n",
    "\n",
    "# Load MCH for transforming data\n",
    "df_MCH = pd.read_csv(processed_data_dirpath / \"MCH.csv\", index_col=sample_key)\n",
    "\n",
    "df_copy_numbers = df_copy_numbers.loc[list(df_data_samples.index)].copy()\n",
    "df_MCH = df_MCH.loc[list(df_data_samples.index)].copy()\n",
    "if grouped_data_key.endswith(\"Donor\"):\n",
    "    df_copy_numbers.index = [x.split(\"_\")[0] for x in df_copy_numbers.index]\n",
    "    df_copy_numbers = df_copy_numbers.groupby(level=0).mean()\n",
    "\n",
    "    df_MCH.index = [x.split(\"_\")[0] for x in df_MCH.index]\n",
    "    df_MCH = df_MCH.groupby(level=0).mean()\n",
    "\n",
    "\n",
    "(processed_clusters_dirpath / genotype).mkdir(exist_ok=True, parents=True)\n",
    "if chosen_n_clusters < len(data_original.index):\n",
    "    cluster_labels = dataframes_of_label_maps[chosen_n_clusters] + cluster_start_num\n",
    "    cluster_mapping.update(dict(zip(list(data_original.index), cluster_labels)))\n",
    "\n",
    "    df_copy_numbers_clustered = df_copy_numbers.loc[list(data_original.index)].copy()\n",
    "    df_copy_numbers_clustered = df_copy_numbers_clustered.rename(\n",
    "        cluster_mapping, axis=0\n",
    "    )\n",
    "    df_copy_numbers_clustered = df_copy_numbers_clustered.groupby(level=0).mean()\n",
    "    df_copy_numbers_clustered.index = [\n",
    "        f\"Allele{allele_count}_C{int(x)}\" for x in df_copy_numbers_clustered.index\n",
    "    ]\n",
    "    df_copy_numbers_clustered.to_csv(\n",
    "        processed_clusters_dirpath\n",
    "        / genotype\n",
    "        / f\"{grouped_data_key}_Alleles{allele_count}_ClusterCopyNumbers.csv\",\n",
    "        index=True,\n",
    "    )\n",
    "\n",
    "    df_MCH_clustered = df_MCH.loc[list(data_original.index)].copy()\n",
    "    df_MCH_clustered = df_MCH_clustered.rename(cluster_mapping, axis=0)\n",
    "    df_MCH_clustered = df_MCH_clustered.groupby(level=0).mean()\n",
    "    df_MCH_clustered.index = [\n",
    "        f\"Allele{allele_count}_C{int(x)}\" for x in df_MCH_clustered.index\n",
    "    ]\n",
    "    df_MCH_clustered.to_csv(\n",
    "        processed_clusters_dirpath\n",
    "        / genotype\n",
    "        / f\"{grouped_data_key}_Alleles{allele_count}_ClusterMCH.csv\",\n",
    "        index=True,\n",
    "    )\n",
    "    if save_figures:\n",
    "        fig.savefig(\n",
    "            processed_clusters_dirpath\n",
    "            / genotype\n",
    "            / f\"{grouped_data_key}_Alleles{allele_count}_ClusterMetrics.{imagetype}\",\n",
    "            transparent=transparent,\n",
    "            format=imagetype,\n",
    "        )\n",
    "    cluster_start_num += chosen_n_clusters\n",
    "else:\n",
    "    df_copy_numbers_clustered = data_original.copy()\n",
    "df_copy_numbers_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af068d99-12f5-4141-b3ce-339728662ff1",
   "metadata": {},
   "source": [
    "### Concat data to create final set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38967465-5dcb-43d7-b74b-2775ce177e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = 0\n",
    "allele_counts = [0, 1, 2]\n",
    "df_genotypes = pd.read_csv(\n",
    "    processed_clusters_dirpath / genotype / f\"{grouped_data_key}_Genotypes.csv\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "copy_number_dfs_to_concat = []\n",
    "MCH_dfs_to_concat = []\n",
    "for allele_count in allele_counts:\n",
    "    try:\n",
    "        df_copy_numbers_allele = pd.read_csv(\n",
    "            processed_clusters_dirpath\n",
    "            / genotype\n",
    "            / f\"{grouped_data_key}_Alleles{allele_count}_ClusterCopyNumbers.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "        df_MCH_allele = pd.read_csv(\n",
    "            processed_clusters_dirpath\n",
    "            / genotype\n",
    "            / f\"{grouped_data_key}_Alleles{allele_count}_ClusterMCH.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "        # Count number of existing clusters\n",
    "        cluster_count += len(df_copy_numbers_allele.index)\n",
    "    except FileNotFoundError:\n",
    "        df_copy_numbers_allele = df_copy_numbers.loc[\n",
    "            list(df_genotypes[(df_genotypes == allele_count).values].index)\n",
    "        ]\n",
    "        cluster_mapping.update(\n",
    "            {\n",
    "                sample_id: idx + cluster_count\n",
    "                for idx, sample_id in enumerate(df_copy_numbers_allele.index, start=1)\n",
    "            }\n",
    "        )\n",
    "        df_copy_numbers_allele.index = [\n",
    "            f\"Allele{allele_count}_{x}\" for x in df_copy_numbers_allele.index\n",
    "        ]\n",
    "        # Set cluster for donors with allele count 2 as final cluster\n",
    "\n",
    "        df_MCH_allele = df_MCH.loc[\n",
    "            list(df_genotypes[(df_genotypes == allele_count).values].index)\n",
    "        ]\n",
    "        df_MCH_allele.index = [f\"Allele{allele_count}_{x}\" for x in df_MCH_allele.index]\n",
    "\n",
    "    copy_number_dfs_to_concat += [df_copy_numbers_allele]\n",
    "    MCH_dfs_to_concat += [df_MCH_allele]\n",
    "\n",
    "\n",
    "operations = [\"Mean\", \"Median\"]\n",
    "df_copy_numbers_representative = pd.concat(copy_number_dfs_to_concat)\n",
    "to_concat = []\n",
    "for op in operations:\n",
    "    df = df_copy_numbers_representative.copy()\n",
    "    df.index = [x.split(\"_\")[0] for x in df.index]\n",
    "    df = getattr(df.groupby(level=0), op.lower())()\n",
    "    df.index = [\"_\".join((op.capitalize(), x)) for x in df.index]\n",
    "    to_concat += [df]\n",
    "df_copy_numbers_representative = pd.concat(\n",
    "    (df_copy_numbers_representative, *to_concat), axis=0\n",
    ")\n",
    "\n",
    "df_MCH_representative = pd.concat(MCH_dfs_to_concat)\n",
    "to_concat = []\n",
    "for op in operations:\n",
    "    df = df_MCH_representative.copy()\n",
    "    df.index = [x.split(\"_\")[0] for x in df.index]\n",
    "    df = getattr(df.groupby(level=0), op.lower())()\n",
    "    df.index = [\"_\".join((op.capitalize(), x)) for x in df.index]\n",
    "    to_concat += [df]\n",
    "df_MCH_representative = pd.concat((df_MCH_representative, *to_concat), axis=0)\n",
    "\n",
    "df_cluster_mapping = pd.DataFrame.from_dict(\n",
    "    cluster_mapping, orient=\"index\", columns=[\"CLUSTER\"]\n",
    ")\n",
    "df_cluster_mapping.index.name = sample_key\n",
    "df_cluster_mapping.to_csv(\n",
    "    processed_clusters_dirpath / genotype / f\"{grouped_data_key}_ClusterMapping.csv\",\n",
    "    index=True,\n",
    ")\n",
    "df_copy_numbers_representative.to_csv(\n",
    "    processed_clusters_dirpath\n",
    "    / genotype\n",
    "    / f\"{genotype}_{grouped_data_key}_ClusterCopyNumbers.csv\",\n",
    "    index=True,\n",
    ")\n",
    "df_MCH_representative.to_csv(\n",
    "    processed_clusters_dirpath\n",
    "    / genotype\n",
    "    / f\"{genotype}_{grouped_data_key}_ClusterMCH.csv\",\n",
    "    index=True,\n",
    ")\n",
    "df_copy_numbers_representative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d2c08-f31e-4abc-b280-66165238b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasdasdasdasdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e1ba6-e7ae-4e03-ba84-527c377a33cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6cf1ee-6f8e-45f5-9296-ce9652e48e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = sklearn.manifold.LocallyLinearEmbedding(\n",
    "    n_neighbors=10,\n",
    "    n_components=2,\n",
    "    reg=1e-9,\n",
    "    eigen_solver=\"dense\",\n",
    "    max_iter=int(1e9),\n",
    "    method=\"ltsa\",\n",
    "    hessian_tol=1e-4,\n",
    "    modified_tol=1e-12,\n",
    "    neighbors_algorithm=\"auto\",\n",
    "    # random_state=4,\n",
    "    n_jobs=10,\n",
    ")\n",
    "transformed = umap.fit_transform(data_original.values)\n",
    "# ax = plt.scatter(*transformed.T)\n",
    "df = pd.DataFrame(\n",
    "    transformed,\n",
    "    index=data_original.merge(df_metadata, left_index=True, right_index=True)[\n",
    "        genotype\n",
    "    ].index,\n",
    ")\n",
    "df = df.merge(df_metadata[genotype], left_index=True, right_index=True)\n",
    "df.plot.scatter(x=0, y=1, c=df[genotype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a22589-b1a2-4e84-a329-3e1f2d8935bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = sklearn.manifold.MDS(\n",
    "    n_components=2,\n",
    "    metric=True,\n",
    "    n_init=10,\n",
    "    max_iter=int(1e9),\n",
    "    verbose=0,\n",
    "    eps=1e-6,\n",
    "    n_jobs=10,\n",
    "    random_state=4,\n",
    "    dissimilarity=\"euclidean\",\n",
    ")\n",
    "transformed = umap.fit_transform(data_original.values)\n",
    "# ax = plt.scatter(*transformed.T)\n",
    "df = pd.DataFrame(\n",
    "    transformed,\n",
    "    index=data_original.merge(df_metadata, left_index=True, right_index=True)[\n",
    "        genotype\n",
    "    ].index,\n",
    ")\n",
    "df = df.merge(df_metadata[genotype], left_index=True, right_index=True)\n",
    "df.plot.scatter(x=0, y=1, c=df[genotype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bb663-5dc1-4136-9a42-557f5ad9d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = sklearn.manifold.TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=50,\n",
    "    # reg=1e-9,\n",
    "    # eigen_solver=\"dense\",\n",
    "    # max_iter=int(1e9),\n",
    "    # method=\"standard\",\n",
    "    # hessian_tol=1e-4,\n",
    "    # modified_tol=1e-12,\n",
    "    # neighbors_algorithm=\"auto\",\n",
    "    # random_state=4,\n",
    "    n_jobs=10,\n",
    ")\n",
    "transformed = umap.fit_transform(data_original.values)\n",
    "# ax = plt.scatter(*transformed.T)\n",
    "df = pd.DataFrame(\n",
    "    transformed,\n",
    "    index=data_original.merge(df_metadata, left_index=True, right_index=True)[\n",
    "        genotype\n",
    "    ].index,\n",
    ")\n",
    "df = df.merge(df_metadata[genotype], left_index=True, right_index=True)\n",
    "df.plot.scatter(x=0, y=1, c=df[genotype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b03a0-9052-459a-8123-f04ff3a48cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg_dict = {}\n",
    "wcss_dict = {}\n",
    "for n_clusters in range(2, 50):\n",
    "\n",
    "    kmeans = sklearn.cluster.KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        init=\"k-means++\",\n",
    "        n_init=10,\n",
    "        max_iter=int(1e6),\n",
    "        tol=1e-9,\n",
    "        verbose=0,\n",
    "        random_state=4,\n",
    "        algorithm=\"lloyd\",\n",
    "    )\n",
    "    # Shape is (n_samples, n_features), goal is to reduce sample number to transpose data\n",
    "    data_original = data.T\n",
    "    data_clustered = kmeans.fit_transform(data_original.values)\n",
    "    data_clustered = pd.DataFrame(data_clustered.T, columns=data.columns)\n",
    "\n",
    "    wcss_dict[n_clusters] = kmeans.inertia_\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    silhouette_avg = sklearn.metrics.silhouette_score(\n",
    "        data_original.values, kmeans.labels_\n",
    "    )\n",
    "    silhouette_avg_dict[n_clusters] = silhouette_avg\n",
    "    # fig, ax1 = plt.subplots(1, 1)\n",
    "    # fig.set_size_inches(4, 4)\n",
    "\n",
    "    # # The 1st subplot is the silhouette plot\n",
    "    # # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # # lie within [-0.1, 1]\n",
    "    # ax1.set_xlim([-0.1, 1])\n",
    "    # # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # # plots of individual clusters, to demarcate them clearly.\n",
    "    # ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    # y_lower = 10\n",
    "    # for i in range(n_clusters):\n",
    "    #     # Aggregate the silhouette scores for samples belonging to\n",
    "    #     # cluster i, and sort them\n",
    "    #     ith_cluster_silhouette_values = sample_silhouette_values[kmeans.labels_ == i]\n",
    "\n",
    "    #     ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    #     size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    #     y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    #     color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    #     ax1.fill_betweenx(\n",
    "    #         np.arange(y_lower, y_upper),\n",
    "    #         0,\n",
    "    #         ith_cluster_silhouette_values,\n",
    "    #         facecolor=color,\n",
    "    #         edgecolor=color,\n",
    "    #         alpha=0.7,\n",
    "    #     )\n",
    "\n",
    "    #     # Label the silhouette plots with their cluster numbers at the middle\n",
    "    #     ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    #     # Compute the new y_lower for next plot\n",
    "    #     y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    # ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    # ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    # ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # # The vertical line for average silhouette score of all the values\n",
    "    # ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    # ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    # ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314a0b0-b564-46a7-b216-21ea3ed3fffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
