{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9114c6-b2d1-48a1-8ba3-6686a1ea2449",
   "metadata": {},
   "source": [
    "# Visualize ranges of fluxes across samples - Mouse G6PD Variants Omics\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d694e76-31c0-4aba-add6-a07a00a5d04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Package Information\n",
      "-------------------\n",
      "rbc-gem-utils 0.0.3\n",
      "\n",
      "Dependency Information\n",
      "----------------------\n",
      "beautifulsoup4                       4.13.4\n",
      "bio                                   1.8.0\n",
      "cobra                                0.29.1\n",
      "depinfo                               2.2.0\n",
      "gurobipy                             12.0.3\n",
      "matplotlib                           3.10.3\n",
      "matplotlib-venn                       1.1.2\n",
      "memote                               0.17.0\n",
      "networkx                                3.5\n",
      "notebook                              7.4.4\n",
      "openpyxl                              3.1.5\n",
      "pandas                                2.3.1\n",
      "pre-commit                            4.2.0\n",
      "rbc-gem-utils[database,network,vis] missing\n",
      "requests                             2.32.4\n",
      "scikit-learn                          1.7.0\n",
      "scipy                                1.16.0\n",
      "seaborn                              0.13.2\n",
      "\n",
      "Build Tools Information\n",
      "-----------------------\n",
      "pip          25.1\n",
      "setuptools 78.1.1\n",
      "wheel      0.45.1\n",
      "\n",
      "Platform Information\n",
      "--------------------\n",
      "Windows 10-AMD64\n",
      "CPython  3.11.13\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import textwrap\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    ensure_iterable,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    DEFAULT_PROTEOME_COMPARTMENT,\n",
    "    EnzymeDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    "    plot_correlations,\n",
    ")\n",
    "from rbc_gem_utils.visualization import cmap_map\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c972a-9f2f-4b88-a65c-017d1a6561d6",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "418ddc9c-b48e-400a-b5a1-e4e6bfe73bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <td><strong>Attribute</strong></td>\n",
       "      <td><strong>Description</strong></td>\n",
       "      <td><strong>Value</strong></td>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><pre>solver</pre></td>\n",
       "      <td>Mathematical optimization solver</td>\n",
       "      <td>gurobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>tolerance</pre></td>\n",
       "        <td>General solver tolerance (feasibility, integrality, etc.)</td>\n",
       "        <td>1e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>lower_bound</pre></td>\n",
       "        <td>Default reaction lower bound</td>\n",
       "        <td>-1e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>upper_bound</pre></td>\n",
       "        <td>Default reaction upper bound</td>\n",
       "        <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>processes</pre></td>\n",
       "        <td>Number of parallel processes</td>\n",
       "        <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>cache_directory</pre></td>\n",
       "        <td>Path for the model cache</td>\n",
       "        <td>C:\\Users\\P7875\\AppData\\Local\\opencobra\\cobrapy\\Cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>max_cache_size</pre></td>\n",
       "        <td>Maximum cache size in bytes</td>\n",
       "        <td>104857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td><pre>cache_expiration</pre></td>\n",
       "        <td>Model cache expiration time in seconds (if any)</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "\n",
       "solver: gurobi\n",
       "tolerance: 1e-07\n",
       "lower_bound: -1e-08\n",
       "upper_bound: 100000000.0\n",
       "processes: 127\n",
       "cache_directory: C:\\Users\\P7875\\AppData\\Local\\opencobra\\cobrapy\\Cache\n",
       "max_cache_size: 104857600\n",
       "cache_expiration: None"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-7\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3720a-d637-4115-8960-f48671ee725a",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b08faa-240f-44ee-9d16-ddbdc556852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Mouse\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"G6PDvariants\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ccb7e-c784-4b63-bfe9-7ebdce0e24b5",
   "metadata": {},
   "source": [
    "### Set variables for sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6435bfd2-9c1f-4f09-8a7a-3d0a0efba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "timepoints = [\"Pre\", \"Post\", \"TD\"]\n",
    "phenotypes = [\"HumCan\", \"A\", \"MED\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>({'|'.join(phenotypes)})(?P<num>\\d+))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "phenotype_re = re.compile(rf\"(?P<phenotype>({'|'.join(phenotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478c85d-b0ed-466c-b6d3-e8dead52f018",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e59494-b23d-4775-8863-1baeb1f46194",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "objective_reactions = [\"NaKt\"]\n",
    "\n",
    "enzyme_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.dilution\"]\n",
    "enzyme_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.metabolite\"]\n",
    "enzyme_met_suffix_total = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]\n",
    "comp_suffix = f\"_{DEFAULT_PROTEOME_COMPARTMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bb5e1-67d6-4436-af4a-0f34befaa111",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ad3312-69a9-4bd9-92c4-a2d467bed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2d514-cb81-4968-95b6-95e758cd3e73",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd462b-0c65-4b33-b745-6a4e74996f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\") / model_id / \"OVERLAY\" / organism / dataset_name\n",
    ")\n",
    "sample_pcmodels_dirpath = results_dirpath / \"sample_pcmodels\"\n",
    "pcfva_results_dirpath = (\n",
    "    results_dirpath / \"pcFVA\" / \"_\".join((\"OBJ\", *objective_reactions))\n",
    ")\n",
    "# Objective reaction does not matter since correlations are computed\n",
    "# based on min and max fluxes and abundance, which are obtained when optimum is 0.\n",
    "corr_results_dirpath = results_dirpath / \"correlations\"\n",
    "# Ensure directory  exists\n",
    "corr_results_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b8d0f-8ca2-48e4-9da1-7db464f01407",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f7b2c-ad0d-4404-899b-fa05a0bd7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "# Add relaxation budget to initial PC model to get names of relaxation reactions\n",
    "add_relaxation_budget(pcmodel, 0, verbose=False)\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf0307-bf28-4f10-8784-143d62c669a7",
   "metadata": {},
   "source": [
    "## Load pcFVA generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fccd8-52b6-44c9-83a0-af5c62b7fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame of generated results\n",
    "df_pcfva_all = pd.read_csv(\n",
    "    pcfva_results_dirpath / f\"{pcmodel.id}_All_FVAsols.csv\",\n",
    "    index_col=None,\n",
    ")\n",
    "\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a4524-c95b-4980-a95f-5ba109e75025",
   "metadata": {},
   "source": [
    "## Create DataFrame for visualization\n",
    "### Get maximum reaction fluxes and associated abundance values\n",
    "#### Define reactions that are always abundance-independent (no genes/proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969126f8-224e-468e-85f7-ab3cdb558ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "always_abundance_independent = [\n",
    "    r.id for r in model.reactions.query(lambda x: not x.boundary and not x.genes)\n",
    "]\n",
    "print(\n",
    "    f\"Number of reactions w/o genes, always abundance independent: {len(always_abundance_independent)}\"\n",
    ")\n",
    "always_abundance_independent;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12567c73-2d39-49d7-a96d-7fb8f96a0fe4",
   "metadata": {},
   "source": [
    "#### Get maximum reaction fluxes and flux ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbb8d3-7fc4-4168-84ad-57f84ee4824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = model.reactions.list_attr(\"id\")\n",
    "df_max_flux_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "df_max_flux_per_model = df_max_flux_per_model.groupby(\n",
    "    [\"model\", \"reactions\", \"optimum\"]\n",
    ")[[\"min\", \"max\"]].agg(\n",
    "    {\n",
    "        \"min\": \"min\",  # Minimum reaction flux per model\n",
    "        \"max\": \"max\",  # Maximum reaction flux per model\n",
    "    }\n",
    ")\n",
    "# Address issues possibly caused by floating point precision, ideally a value that prevents any negative ranges\n",
    "df_max_flux_per_model.loc[\n",
    "    df_max_flux_per_model[\"max\"] < df_max_flux_per_model[\"min\"], [\"max\", \"min\"]\n",
    "] = [0, 0]\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_flux_per_model[\"max\"] = df_max_flux_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_flux_per_model[\"min\"] = df_max_flux_per_model[\"min\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_flux_per_model[\"range\"] = (\n",
    "    df_max_flux_per_model[\"max\"] - df_max_flux_per_model[\"min\"]\n",
    ")\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_flux_per_model[df_max_flux_per_model[\"range\"] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea38c15-2a68-42a4-b9b8-6772a7a8fc2f",
   "metadata": {},
   "source": [
    "#### Get maximum \"enzyme\" abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766d0df-120f-4968-9b8f-b610af420a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, EnzymeDilution)\n",
    "    and x.id.endswith(f\"{enzyme_met_suffix_total}{comp_suffix}\")\n",
    ").list_attr(\"id\")\n",
    "df_max_abundance_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "# Rename dilution reactions to match\n",
    "reaction_enzyme_map = {\n",
    "    enzyme_rid: enzyme_rid.replace(\n",
    "        f\"{enzyme_rxn_prefix}{enzyme_met_prefix}\", \"\"\n",
    "    ).replace(f\"{enzyme_met_suffix_total}{comp_suffix}\", \"\")\n",
    "    for enzyme_rid in df_max_abundance_per_model[\"reactions\"]\n",
    "}\n",
    "df_max_abundance_per_model[\"reactions\"] = df_max_abundance_per_model[\n",
    "    \"reactions\"\n",
    "].replace(reaction_enzyme_map)\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.groupby(\n",
    "    [\"model\", \"reactions\", \"optimum\"]\n",
    ")[[\"max\"]].max()\n",
    "# Address issues possibly caused by floating point precision, atol is ideally a value that prevents any negative ranges\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if x < 0 else x\n",
    ")\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.rename(\n",
    "    {\"max\": \"abundance\"}, axis=1\n",
    ")\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_abundance_per_model[(df_max_abundance_per_model < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a1b613-8a09-4f72-8342-909fd2b02bff",
   "metadata": {},
   "source": [
    "#### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be484e01-700b-47b1-9b3e-8b037fcfd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_all = pd.merge(\n",
    "    df_max_flux_per_model,\n",
    "    df_max_abundance_per_model,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "df_data_all = df_data_all.reset_index(drop=False)\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afec28e-5b30-42a1-bee5-278ac78af25f",
   "metadata": {},
   "source": [
    "### Identify donor, timepoints, and phenotypes for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e605cb3-eb57-416c-83dd-09de89657388",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\"donor\", \"time\", \"phenotype\"]\n",
    "for key, search_re in zip(metadata_columns, [donor_re, time_re, phenotype_re]):\n",
    "    df_data_all[key] = df_data_all[\"model\"].apply(\n",
    "        lambda x: search_re.search(x).group(1) if search_re.search(x) else pd.NA\n",
    "    )\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902ff15-bf6a-43a9-ad82-d81742231410",
   "metadata": {},
   "source": [
    "## Visualize flux ranges\n",
    "### Remove models based on data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce7d4c-834d-4b2f-b705-059839846fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_samples = df_data_all[\n",
    "    [not bool(operation_re.search(x)) for x in df_data_all[\"model\"]]\n",
    "].copy()\n",
    "df_data_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f4389-594f-4c01-8743-94cbef5ffe54",
   "metadata": {},
   "source": [
    "### Create groups of sample models\n",
    "Note: Order matters in how groups are divided for naming purposes. Group \"TIME_PHENOTYPE\" and group \"PHENOTYPE_TIME\" may use identical models, but get categorized and stored seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f41d9-3091-46ef-9fb9-94e0431bfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_key = \"ALL\"\n",
    "model_groups = {all_key: list(df_data_samples[\"model\"].unique())}\n",
    "\n",
    "\n",
    "def create_group_of_models(df, groupby, verbose=False):\n",
    "    grouped = df.groupby(groupby)[\"model\"].agg(lambda x: list(x.unique()))\n",
    "    grouped = {\"_\".join(ensure_iterable(k)): v for k, v in grouped.to_dict().items()}\n",
    "    max_name_len = max([len(group_name) for group_name in list(grouped)])\n",
    "    if verbose:\n",
    "        for group_name, model_list in grouped.items():\n",
    "            spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "            print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325246aa-d8a5-4b14-8792-d1a535a6f017",
   "metadata": {},
   "source": [
    "#### Based on timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc0a34-dc33-44c0-8624-044effe099ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns], groupby=[\"time\"], verbose=verbose\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d67c5a-308b-4413-a627-763c470fe929",
   "metadata": {},
   "source": [
    "##### Based on timepoint and phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172e247-7031-4ecd-84a2-6d1bae9e6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    groupby=[\"time\", \"phenotype\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b883d6d-0132-4420-9b98-32e6e192d201",
   "metadata": {},
   "source": [
    "#### Based on phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a100f-bbbf-4eda-82e3-ab71fc12210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    groupby=[\"phenotype\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48100fb2-53b2-47f1-aac7-c90a6d53ca4e",
   "metadata": {},
   "source": [
    "##### Based on phenotype and timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9b7bf-8d5d-4731-ac18-f649be7561b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    groupby=[\"phenotype\", \"time\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59052f82-4e3e-4547-b17e-dcffaf96e6f7",
   "metadata": {},
   "source": [
    "### View model groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0baeb6-60fa-4550-992a-b1ee2c7bd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Possible groups for analyses\\n============================\")\n",
    "max_name_len = max([len(group_name) for group_name in list(model_groups)])\n",
    "for group_name, model_list in model_groups.items():\n",
    "    spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "    print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "\n",
    "df_data_for_analyses = df_data_samples.set_index([\"reactions\", \"model\"]).drop(\n",
    "    metadata_columns, axis=1\n",
    ")\n",
    "df_data_for_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b2cd0-3cfc-4ff7-8f7e-bb259ed1ce00",
   "metadata": {},
   "source": [
    "### Ensure groups exist and setup directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4d7fb-5c55-4752-a3f1-7c9b259962cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New directories are created for main groups\n",
    "groups_dict = defaultdict(dict)\n",
    "group_items_list = [\n",
    "    [\"Pre\", \"Post\", \"TD\"],\n",
    "    [\"HumCan\", \"A\", \"MED\"],\n",
    "]\n",
    "# All main groups are created under the \"All\" directory, subgroups are created under each main group\n",
    "for item_list in group_items_list:\n",
    "    groups_dict[all_key].update({item: {} for item in item_list})\n",
    "    groups_dict[all_key].update(\n",
    "        {\n",
    "            item: sorted(\n",
    "                [\n",
    "                    group_name\n",
    "                    for group_name in model_groups\n",
    "                    if group_name.split(\"_\")[0] == item and group_name != item\n",
    "                ]\n",
    "            )\n",
    "            for item in item_list\n",
    "        }\n",
    "    )\n",
    "groups_dict[all_key].update(\n",
    "    {k: groups_dict[all_key][k] for k in sorted(sorted(groups_dict[all_key]))}\n",
    ")\n",
    "invalid_groups = [\n",
    "    group_name for group_name in groups_dict[all_key] if group_name not in model_groups\n",
    "]\n",
    "if any(invalid_groups):\n",
    "    raise KeyError(\n",
    "        f\"No group(s) found for `{invalid_groups}`. Model groups must be created first before correlation computations\"\n",
    "    )\n",
    "invalid_subgroups = [\n",
    "    subgroup\n",
    "    for group_values in groups_dict[all_key].values()\n",
    "    for subgroup in group_values\n",
    "    if subgroup not in model_groups\n",
    "]\n",
    "if any(invalid_subgroups):\n",
    "    raise KeyError(\n",
    "        f\"No subgroup(s) found for `{invalid_subgroups}`. Model groups must be created first before correlation computations\"\n",
    "    )\n",
    "\n",
    "\n",
    "header = \"Expected directory structure\"\n",
    "print(\"\\n\".join((header, \"=\" * len(header), all_key)))\n",
    "for idx, (group_name, subgroups) in enumerate(sorted(groups_dict[all_key].items())):\n",
    "    print(\"\\u2514\\u2500\\u2500\" + f\" {group_name}\")\n",
    "    vertical = \"\\u2502\" if idx != len(groups_dict[all_key]) - 1 else \" \"\n",
    "    for subgroup_name in sorted(subgroups):\n",
    "        print(vertical + \"   \\u2514\\u2500\\u2500\" + subgroup_name)\n",
    "\n",
    "group_results_dirpath_dict = {all_key: corr_results_dirpath}\n",
    "for group_name, subgroups in groups_dict[all_key].items():\n",
    "    group_results_dirpath_dict[group_name] = (\n",
    "        group_results_dirpath_dict[all_key] / group_name\n",
    "    )\n",
    "    group_results_dirpath_dict.update(\n",
    "        {\n",
    "            subgroup_name: group_results_dirpath_dict[group_name] / subgroup_name\n",
    "            for subgroup_name in subgroups\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642c3b8-d529-4da8-9b11-715718adcd4c",
   "metadata": {},
   "source": [
    "### Visualize selected flux results\n",
    "#### Set groups to compare and filter data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cffec8-c36d-447f-bcba-1ad43af758e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_group_name = \"Pre\"\n",
    "ordered_groups_to_compare = [\n",
    "    f\"{main_group_name}_{phenotype}\" for phenotype in phenotypes\n",
    "]\n",
    "# Set list of samples for comparison, filter out irrelevant samples, and sort samples by sample number\n",
    "df_data_groups_to_compare = pd.concat(\n",
    "    [\n",
    "        df_data_for_analyses.loc[pd.IndexSlice[:, model_groups[group]], :].sort_index(\n",
    "            key=lambda x: [int(donor_re.search(v).group(\"num\")) for v in x.values],\n",
    "            level=1,\n",
    "        )\n",
    "        for group in ordered_groups_to_compare\n",
    "    ],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0386d-90f9-44f8-88cd-c6fd5f6fbf12",
   "metadata": {},
   "source": [
    "#### Load previous correlations if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0494f69-9d88-4be7-ab2e-e003981e1632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlations_pair = (\"flux\", \"abundance\")\n",
    "filepath = (\n",
    "    group_results_dirpath_dict[main_group_name]\n",
    "    / f\"{correlations_pair[0]}_{correlations_pair[1]}.tsv\"\n",
    ")\n",
    "try:\n",
    "    df_correlations = pd.read_csv(\n",
    "        filepath, sep=\"\\t\", index_col=\"reactions\", usecols=[\"reactions\", \"rho\"]\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    reaction_correlations = {}\n",
    "    print(\n",
    "        \"No previously computed correlations between '{}' and '{}' for group '{}'.\".format(\n",
    "            *correlations_pair, main_group_name\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    reaction_correlations = df_correlations.squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd47afd-a4d3-4b01-85db-6638d94b9285",
   "metadata": {},
   "source": [
    "### Set common visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ade39-2fca-466f-aaea-b329fd916470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dict where keys are columns to sort by and values are whether to sort as ascending or descending,\n",
    "# or a list where values are columns to sort by, and all values are sorted as ascending.\n",
    "rank_order_results = {col: True for col in [\"range\", \"max\", \"min\", \"abundance\"]}\n",
    "optimum_colors = {\n",
    "    0.00: \"xkcd:green\",\n",
    "    0.50: \"xkcd:dark yellow\",\n",
    "    0.90: \"xkcd:orange\",\n",
    "    0.99: \"xkcd:red\",\n",
    "}\n",
    "\n",
    "plot_as_bar = True\n",
    "ypad_percent = 0.1\n",
    "# Kwargs for each individual panel\n",
    "panel_kwargs = dict(\n",
    "    # Only for bar plot\n",
    "    width=1,  # Bar width\n",
    "    linewidth=0.0,  # Edgewidth of bars\n",
    "    edgecolor=\"black\",  # Color of edge width\n",
    "    # Both plots\n",
    "    alpha=0.5,\n",
    "    zorder=2,\n",
    "    maxnum_yticks=3,\n",
    "    # Equilibrium line\n",
    "    equilibrium_lineprops=dict(\n",
    "        color=\"black\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=1,\n",
    "    ),\n",
    ")\n",
    "flux_label_color = \"xkcd:dark red\"\n",
    "abundance_label_color = \"xkcd:dark blue\"\n",
    "abundance_kwargs = dict(\n",
    "    maxnum_yticks=panel_kwargs.get(\"maxnum_yticks\", 3),\n",
    "    lineprops=dict(\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"\",\n",
    "        linewidth=1,\n",
    "        markersize=4,\n",
    "        zorder=2,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a54078-801c-4892-b6d7-f6caa9e7c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flux_range_panel(\n",
    "    x, min_values, max_values, ax, bar=True, equilibrium_lineprops=None, **kwargs\n",
    "):\n",
    "    # Pop problematic kwargs\n",
    "    xlim_pad = kwargs.pop(\"xlim_pad\") if kwargs.get(\"xlim_pad\") is not None else 1\n",
    "    ylim_pad = kwargs.pop(\"ylim_pad\") if kwargs.get(\"ylim_pad\") is not None else 0\n",
    "    maxnum_yticks = (\n",
    "        kwargs.pop(\"maxnum_yticks\") if kwargs.get(\"maxnum_yticks\") is not None else 0\n",
    "    )\n",
    "    width = kwargs.pop(\"width\") if kwargs.get(\"width\") else 1\n",
    "    if bar:\n",
    "        ax.bar(\n",
    "            x, height=max_values - min_values, bottom=min_values, width=width, **kwargs\n",
    "        )\n",
    "    else:\n",
    "        # Fill between limits\n",
    "        ax.fill_between(x, min_values, max_values, **kwargs)\n",
    "\n",
    "    if equilibrium_lineprops:\n",
    "        defaults = dict(\n",
    "            linestyle=\":\",\n",
    "            linewidth=1.5,\n",
    "            color=\"black\",\n",
    "            zorder=3,\n",
    "            label=\"equilibrium\",\n",
    "        )\n",
    "        equilibrium_lineprops.update(\n",
    "            {k: v for k, v in defaults.items() if k not in equilibrium_lineprops}\n",
    "        )\n",
    "        ax.hlines(0, x[0] - 2 * xlim_pad, x[-1] + 2 * xlim_pad, **equilibrium_lineprops)\n",
    "\n",
    "    if maxnum_yticks:\n",
    "        ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(maxnum_yticks))\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_abundance_line(x, y, ax, xlims=None, ylims=None, lineprops=None, **kwargs):\n",
    "    default_lineprops = dict(\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"o\",\n",
    "        linewidth=1,\n",
    "        zorder=3,\n",
    "    )\n",
    "    lineprops = {} if lineprops is None else lineprops\n",
    "    lineprops.update({k: v for k, v in default_lineprops.items() if k not in lineprops})\n",
    "\n",
    "    ax.plot(x, y, **lineprops)\n",
    "    ax.set_xlim(xlims)\n",
    "    ax.set_ylim(ylims)\n",
    "    if kwargs.get(\"maxnum_yticks\"):\n",
    "        ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(kwargs.get(\"maxnum_yticks\")))\n",
    "    return ax\n",
    "\n",
    "\n",
    "def format_panel_for_group(\n",
    "    ax_panel, xaxis_dict, yaxis_dict, fontsizes_dict, panel_idx=0, **kwargs\n",
    "):\n",
    "    # Format x axis\n",
    "    ax_panel.set_xticks([])\n",
    "    ax_panel.set_xlim(xaxis_dict.get(\"lim\"))\n",
    "    ax_panel.set_xlabel(\n",
    "        xaxis_dict.get(\"label\"), fontsize=fontsizes_dict.get(\"xlabel\", \"large\")\n",
    "    )\n",
    "    ax_panel.xaxis.set_tick_params(\n",
    "        labelsize=fontsizes_dict.get(\"xticks\", \"large\"), labelbottom=False\n",
    "    )\n",
    "    # Format y axis\n",
    "    ax_panel.set_ylim(yaxis_dict.get(\"lim\"))\n",
    "    if panel_idx == 0:\n",
    "        ax_panel.set_ylabel(\n",
    "            yaxis_dict.get(\"label\"),\n",
    "            fontsize=fontsizes_dict.get(\"ylabel\", \"large\"),\n",
    "            va=yaxis_dict.get(\"va\", \"center\"),\n",
    "            labelpad=yaxis_dict.get(\"labelpad\"),\n",
    "            color=yaxis_dict.get(\"color\", \"black\"),\n",
    "        )\n",
    "        if kwargs.get(\"min_max_norm_flux\"):\n",
    "            ax_panel.set_yticks(np.linspace(0, 1, kwargs.get(\"maxnum_yticks\", 3)))\n",
    "        elif yaxis_dict.get(\"maxnum_yticks\"):\n",
    "            ax_panel.set_yticks(\n",
    "                np.linspace(\n",
    "                    ax_panel.get_ybound()[0],\n",
    "                    ax_panel.get_ybound()[1],\n",
    "                    panel_kwargs.get(\"maxnum_yticks\", 3),\n",
    "                )\n",
    "            )\n",
    "        ax_panel.yaxis.set_tick_params(\n",
    "            labelsize=fontsizes_dict.get(\"yticks\", \"large\"),\n",
    "            labelleft=True,\n",
    "            colors=yaxis_dict.get(\"color\", \"black\"),\n",
    "        )\n",
    "        if yaxis_dict.get(\"ticklabel_format\"):\n",
    "            ax_panel.ticklabel_format(\n",
    "                axis=\"y\", **yaxis_dict.get(\"ticklabel_format\", {})\n",
    "            )\n",
    "\n",
    "    seperator_spine_color = kwargs.get(\"seperator_spine_color\")\n",
    "    if panel_idx != 0:\n",
    "        ax_panel.set_ylabel(None)\n",
    "        ax_panel.set_yticks([])\n",
    "        ax_panel.yaxis.set_tick_params(labelleft=False)\n",
    "        (\n",
    "            ax_panel.spines[\"left\"].set_color(seperator_spine_color)\n",
    "            if seperator_spine_color\n",
    "            else ax_panel.spines[\"left\"].set_visible(False)\n",
    "        )\n",
    "\n",
    "    if panel_idx != (len(ordered_model_groups) - 1):\n",
    "        (\n",
    "            ax_panel.spines[\"right\"].set_color(seperator_spine_color)\n",
    "            if seperator_spine_color\n",
    "            else ax_panel.spines[\"right\"].set_visible(False)\n",
    "        )\n",
    "\n",
    "\n",
    "def create_flux_range_figure_axes(nrows, ncols, ngroups, **kwargs):\n",
    "    fig = mpl.figure.Figure(\n",
    "        figsize=kwargs.get(\n",
    "            \"figsize\",\n",
    "            (\n",
    "                (ncols + kwargs.get(\"wspace\", 1))\n",
    "                * ngroups\n",
    "                * kwargs.get(\"width_scalar\", 1),\n",
    "                (nrows + kwargs.get(\"hspace\", 1)) * kwargs.get(\"height_scalar\", 1),\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    outer_grid = fig.add_gridspec(\n",
    "        nrows, ncols, hspace=kwargs.get(\"hspace\", 1), wspace=kwargs.get(\"wspace\", 1)\n",
    "    )\n",
    "    axes = np.zeros((nrows, ncols, ngroups)).astype(object)\n",
    "    for row_idx in range(nrows):\n",
    "        for col_idx in range(ncols):\n",
    "            inner_grid = outer_grid[row_idx, col_idx].subgridspec(\n",
    "                1, ngroups, hspace=0, wspace=0\n",
    "            )\n",
    "            axes[row_idx, col_idx, :] = inner_grid.subplots()\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c815c63-e305-488c-96c4-a3e746f39ffc",
   "metadata": {},
   "source": [
    "#### Visualize groups for one or more reaction fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66342a9a-fad0-41fb-8e8e-45ee26992cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes_to_plot = np.atleast_2d(\n",
    "    np.array(\n",
    "        [\n",
    "            # [\"2HBt2\", \"2HBO\",],\n",
    "            # [\"LDOPAt\", \"DOPADC_L\"],\n",
    "            # [\"G6PDH2\", \"GND\"],\n",
    "            # [\"G6PDH2\", \"GND\"],\n",
    "            # [\"O2t\", \"CO2t\"],\n",
    "            # [\"L_LACt2\", \"D_LACt2\"],\n",
    "            # [\"LGTHL\", \"GLYOX\"],\n",
    "            # [\"G6PM\", \"PGMT\"],\n",
    "            # [\"GALK\", \"GAL1PP\"],\n",
    "            [\"O2t\", \"CO2t\"],\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "optimums = [0]\n",
    "sharex = True\n",
    "sharey = \"row\"\n",
    "supylabel = False\n",
    "plot_as_bar = False\n",
    "min_max_norm_flux = False\n",
    "min_max_norm_abundance = True\n",
    "include_abundance_line = True\n",
    "width_scalar = 1.4\n",
    "height_scalar = 0.8\n",
    "fontsizes_dict = dict(\n",
    "    xlabel=10,\n",
    "    xticks=10,\n",
    "    ylabel=10,\n",
    "    yticks=10,\n",
    "    title=12,\n",
    ")\n",
    "panel_kwargs = dict(\n",
    "    # Only for bar plot\n",
    "    width=1,  # Bar width\n",
    "    linewidth=0.5,  # Edgewidth of bars\n",
    "    edgecolor=\"black\",  # Color of edge width\n",
    "    # Both plots\n",
    "    alpha=0.5,\n",
    "    zorder=2,\n",
    "    maxnum_yticks=3,\n",
    "    # Equilibrium line\n",
    "    equilibrium_lineprops=dict(\n",
    "        color=\"black\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=1,\n",
    "    ),\n",
    ")\n",
    "flux_str = \"Normalized\\nFlux\" if min_max_norm_flux else \"Flux\\n(mmol/gDW/hr)\"\n",
    "abundance_str = (\n",
    "    \"Normalized\\nAbundance\" if min_max_norm_abundance else \"Abundance\\n(nmol/gDW)\"\n",
    ")\n",
    "ordered_model_groups = {\n",
    "    group: model_groups[group] for group in ordered_groups_to_compare\n",
    "}\n",
    "xlabels_dict = {\n",
    "    group: group.replace(main_group_name, \"\").strip(\"_\")\n",
    "    for group in list(ordered_model_groups)\n",
    "}\n",
    "ylabels_dict = (\n",
    "    {reaction: flux_str for reaction in fluxes_to_plot.flatten() if reaction}\n",
    "    if not supylabel\n",
    "    else {}\n",
    ")\n",
    "ylabels_dict = {}\n",
    "titles_dict = {\n",
    "    reaction: reaction\n",
    "    + (\n",
    "        \" ($\\\\rho$ = \" + \"{})\".format(round(reaction_correlations[reaction], 4))\n",
    "        if reaction_correlations and reaction_correlations.get(reaction)\n",
    "        else \"\"\n",
    "    )\n",
    "    for reaction in fluxes_to_plot.flatten()\n",
    "    if reaction\n",
    "}\n",
    "# titles_dict = {}\n",
    "fig, all_axes = create_flux_range_figure_axes(\n",
    "    *fluxes_to_plot.shape,\n",
    "    len(ordered_model_groups),\n",
    "    width_scalar=width_scalar,  # * (fluxes_to_plot.shape[0]),\n",
    "    height_scalar=height_scalar,  # * (fluxes_to_plot.shape[1] + hspace),\n",
    "    hspace=0.5 if sharex else 1,\n",
    "    wspace=0.05 if sharey else 0.5,\n",
    ")\n",
    "\n",
    "for row_idx, (row_rxns, row_axes) in enumerate(zip(fluxes_to_plot, all_axes)):\n",
    "    for col_idx, (reaction, axes) in enumerate(zip(row_rxns, row_axes)):\n",
    "        df_data_reaction = df_data_groups_to_compare.loc[reaction].copy()\n",
    "        if min_max_norm_flux:\n",
    "            df_data_reaction[\"norm_range\"] = (\n",
    "                (df_data_reaction[\"range\"] - df_data_reaction[\"range\"].min())\n",
    "                / (df_data_reaction[\"range\"].max() - df_data_reaction[\"range\"].min())\n",
    "            ).fillna(0)\n",
    "            ylims = (0, 1 + ypad_percent)\n",
    "        elif sharey:\n",
    "            rxn_list = row_rxns if sharey == \"row\" else fluxes_to_plot.flatten()\n",
    "            df_ylim = df_data_groups_to_compare.loc[[x for x in rxn_list if x]]\n",
    "            ylims = (\n",
    "                df_ylim[\"min\"].min() - (df_ylim[\"min\"].min() * ypad_percent),\n",
    "                df_ylim[\"max\"].max() + (df_ylim[\"max\"].max() * ypad_percent),\n",
    "            )\n",
    "        else:\n",
    "            ylims = (\n",
    "                df_data_reaction[\"min\"].min()\n",
    "                - (df_data_reaction[\"min\"].min() * ypad_percent),\n",
    "                df_data_reaction[\"max\"].max()\n",
    "                + (df_data_reaction[\"max\"].max() * ypad_percent),\n",
    "            )\n",
    "        for panel_idx, ((group, sample_list), ax_panel) in enumerate(\n",
    "            zip(ordered_model_groups.items(), axes)\n",
    "        ):\n",
    "            # Get samples for group and order by donor number\n",
    "            df_data_group = df_data_reaction.loc[sample_list]\n",
    "            # Get data for optimums\n",
    "            xlims = (0, len(df_data_group.index.unique()))\n",
    "            for optimum in optimums:\n",
    "                df = df_data_group[df_data_group[\"optimum\"] == optimum].drop(\n",
    "                    \"optimum\", axis=1\n",
    "                )\n",
    "                # Rank order results within the optimum if desired\n",
    "                df = df.sort_values(\n",
    "                    by=list(rank_order_results),\n",
    "                    ascending=(\n",
    "                        list(rank_order_results.values())\n",
    "                        if isinstance(rank_order_results, dict)\n",
    "                        else True\n",
    "                    ),\n",
    "                )\n",
    "                ax_panel = plot_flux_range_panel(\n",
    "                    x=np.arange(*xlims),\n",
    "                    min_values=(\n",
    "                        df[\"min\"].values\n",
    "                        if not min_max_norm_flux\n",
    "                        else df[\"min\"].values - df[\"min\"].values\n",
    "                    ),\n",
    "                    max_values=(\n",
    "                        df[\"max\"].values\n",
    "                        if not min_max_norm_flux\n",
    "                        else df[\"norm_range\"].values\n",
    "                    ),\n",
    "                    ax=ax_panel,\n",
    "                    bar=plot_as_bar,\n",
    "                    color=optimum_colors.get(optimum, \"xkcd:light green\"),\n",
    "                    **panel_kwargs,\n",
    "                )\n",
    "\n",
    "            if include_abundance_line:\n",
    "                abundance_values = df_data_reaction.groupby(level=0)[\"abundance\"].max()\n",
    "                if min_max_norm_abundance:\n",
    "                    abundance_values = (\n",
    "                        (abundance_values - abundance_values.min())\n",
    "                        / (abundance_values.max() - abundance_values.min())\n",
    "                    ).fillna(0)\n",
    "                    aylims = (0, 1)\n",
    "                elif sharey:\n",
    "                    rxn_list = row_rxns if sharey == \"row\" else fluxes_to_plot.flatten()\n",
    "                    aylims = (\n",
    "                        df_data_groups_to_compare.loc[[x for x in rxn_list if x]][\n",
    "                            \"abundance\"\n",
    "                        ].min(),\n",
    "                        df_data_groups_to_compare.loc[[x for x in rxn_list if x]][\n",
    "                            \"abundance\"\n",
    "                        ].max(),\n",
    "                    )\n",
    "                    aylims = (\n",
    "                        aylims[0] - (aylims[0] * ypad_percent),\n",
    "                        aylims[1] + (aylims[1] * ypad_percent),\n",
    "                    )\n",
    "                else:\n",
    "                    aylims = (\n",
    "                        0 - (df_data_reaction[\"abundance\"].max() * ypad_percent),\n",
    "                        df_data_reaction[\"abundance\"].max()\n",
    "                        + (df_data_reaction[\"abundance\"].max() * ypad_percent),\n",
    "                    )\n",
    "\n",
    "                ax_abundance = plot_abundance_line(\n",
    "                    x=np.arange(*xlims),\n",
    "                    y=abundance_values.loc[df.index].copy(),\n",
    "                    ax=ax_panel.twinx(),\n",
    "                    xlims=(\n",
    "                        xlims[0] - panel_kwargs.get(\"xlim_pad\", 1),\n",
    "                        xlims[1] + panel_kwargs.get(\"xlim_pad\", 1),\n",
    "                    ),\n",
    "                    ylims=aylims,\n",
    "                    **abundance_kwargs,\n",
    "                )\n",
    "                if (panel_idx == len(ordered_model_groups) - 1) and (\n",
    "                    (sharey and col_idx == fluxes_to_plot.shape[1] - 1) or not sharey\n",
    "                ):\n",
    "                    ylabel = abundance_str if not supylabel else None\n",
    "                    if min_max_norm_abundance:\n",
    "                        ax_abundance.set_yticks(\n",
    "                            np.linspace(0, 1, panel_kwargs.get(\"maxnum_yticks\", 3))\n",
    "                        )\n",
    "                    elif panel_kwargs.get(\"maxnum_yticks\"):\n",
    "                        ax_abundance.set_yticks(\n",
    "                            np.linspace(\n",
    "                                ax_abundance.get_ybound()[0],\n",
    "                                ax_abundance.get_ybound()[1],\n",
    "                                panel_kwargs.get(\"maxnum_yticks\", 3),\n",
    "                            )\n",
    "                        )\n",
    "                    ax_abundance.set_ylabel(\n",
    "                        ylabel,\n",
    "                        fontsize=fontsizes_dict.get(\"ylabel\", \"large\"),\n",
    "                        va=\"center\",\n",
    "                        labelpad=15,\n",
    "                        color=abundance_label_color,\n",
    "                    )\n",
    "                    ax_abundance.yaxis.set_tick_params(\n",
    "                        labelsize=fontsizes_dict.get(\"yticks\", \"large\"),\n",
    "                        labelright=True,\n",
    "                        colors=abundance_label_color,\n",
    "                    )\n",
    "                else:\n",
    "                    ax_abundance.set_ylabel(None)\n",
    "                    ax_abundance.set_yticks([])\n",
    "                    ax_abundance.yaxis.set_tick_params(labelright=False)\n",
    "\n",
    "            # Format panel, lot of conditional inputs depending on where panel is and whether multiple rows/columns are present.\n",
    "            format_panel_for_group(\n",
    "                ax_panel,\n",
    "                panel_idx=panel_idx,\n",
    "                xaxis_dict=dict(\n",
    "                    # Add extra padding for limits\n",
    "                    lim=(\n",
    "                        xlims[0] - panel_kwargs.get(\"xlim_pad\", 1),\n",
    "                        xlims[1] + panel_kwargs.get(\"xlim_pad\", 1),\n",
    "                    ),\n",
    "                    label=(\n",
    "                        xlabels_dict.get(group)\n",
    "                        if (\n",
    "                            (row_idx == fluxes_to_plot.shape[0] - 1 and sharex)\n",
    "                            or not sharex\n",
    "                        )\n",
    "                        else None\n",
    "                    ),\n",
    "                ),\n",
    "                yaxis_dict=dict(\n",
    "                    lim=ylims,\n",
    "                    label=(\n",
    "                        ylabels_dict.get(reaction, flux_str)\n",
    "                        if (not supylabel and ((col_idx == 0 and sharey) or not sharey))\n",
    "                        else None\n",
    "                    ),\n",
    "                    va=\"center\",\n",
    "                    labelpad=15,\n",
    "                    color=flux_label_color if include_abundance_line else \"black\",\n",
    "                    maxnum_yticks=panel_kwargs.get(\"maxnum_yticks\", 3),\n",
    "                    ticklabel_format=dict(style=\"sci\", scilimits=(0, 0)),\n",
    "                ),\n",
    "                fontsizes_dict=fontsizes_dict,\n",
    "                seperator_spine_color=\"xkcd:grey\",\n",
    "                min_max_norm_flux=min_max_norm_flux,\n",
    "            )\n",
    "            if panel_idx == 0 and ((col_idx != 0 and sharey) or not sharey):\n",
    "                ax_panel.yaxis.set_tick_params(labelleft=False)\n",
    "            if panel_idx == (len(ordered_model_groups) - 1) / 2 or (\n",
    "                len(ordered_model_groups) % 2 == 0 and panel_idx % 2 == 0\n",
    "            ):\n",
    "                if (\n",
    "                    panel_idx == (len(ordered_model_groups) - 1) / 2\n",
    "                ):  # Odd number of panels\n",
    "                    ax_panel.set_title(\n",
    "                        titles_dict.get(reaction, reaction),\n",
    "                        fontsize=fontsizes_dict.get(\"title\", \"xx-large\"),\n",
    "                    )\n",
    "                else:  # Even number of panels\n",
    "                    ax_panel.text(\n",
    "                        x=1,\n",
    "                        y=1.1,\n",
    "                        s=titles_dict.get(reaction, reaction),\n",
    "                        transform=ax_panel.transAxes,\n",
    "                        ha=\"center\",\n",
    "                    )\n",
    "if supylabel:\n",
    "    # Adjust manually\n",
    "    text = fig.text(\n",
    "        x=0.02 + 0.025 * fluxes_to_plot.shape[1],\n",
    "        y=0.5,\n",
    "        s=flux_str,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=fontsizes_dict.get(\"supylabel\", \"xx-large\"),\n",
    "        color=flux_label_color if include_abundance_line else \"black\",\n",
    "        rotation=\"vertical\",\n",
    "    )\n",
    "    if include_abundance_line:\n",
    "        fig.text(\n",
    "            x=1.0 - 0.025 * fluxes_to_plot.shape[1],\n",
    "            y=0.5,\n",
    "            s=abundance_str,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontsize=fontsizes_dict.get(\"supylabel\", \"xx-large\"),\n",
    "            color=abundance_label_color,\n",
    "            rotation=\"vertical\",\n",
    "        )\n",
    "\n",
    "fig.align_xlabels()\n",
    "fig.align_ylabels()\n",
    "plt.show()\n",
    "if save_figures:\n",
    "    rxns = \"_\".join(fluxes_to_plot.flatten())\n",
    "    fig_dirpath = (\n",
    "        group_results_dirpath_dict[main_group_name]\n",
    "        / \"fluxranges\"\n",
    "        / \"_\".join(ordered_groups_to_compare)\n",
    "    )\n",
    "    fig_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(\n",
    "        fig_dirpath / f\"fluxes_{rxns}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc716ed7-6727-4ec6-9642-ea0fc4583497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
