{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9114c6-b2d1-48a1-8ba3-6686a1ea2449",
   "metadata": {},
   "source": [
    "# Compute statistically significant fluxes between groups - Mouse G6PD variants omics data\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d694e76-31c0-4aba-add6-a07a00a5d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    ensure_iterable,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    DEFAULT_PROTEOME_COMPARTMENT,\n",
    "    EnzymeDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    "    plot_correlations,\n",
    ")\n",
    "from rbc_gem_utils.visualization import cmap_map\n",
    "from scipy.stats import kruskal, mannwhitneyu, spearmanr\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c972a-9f2f-4b88-a65c-017d1a6561d6",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ddc9c-b48e-400a-b5a1-e4e6bfe73bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-7\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3720a-d637-4115-8960-f48671ee725a",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b08faa-240f-44ee-9d16-ddbdc556852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Mouse\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"G6PDvariants\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ccb7e-c784-4b63-bfe9-7ebdce0e24b5",
   "metadata": {},
   "source": [
    "### Set variables for sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435bfd2-9c1f-4f09-8a7a-3d0a0efba741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sample IDs\n",
    "timepoints = [\"Pre\", \"Post\", \"TD\"]\n",
    "phenotypes = [\"HumCan\", \"A\", \"MED\"]\n",
    "donor_re = re.compile(rf\"(?P<donor>({'|'.join(phenotypes)})(?P<num>\\d+))\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "phenotype_re = re.compile(rf\"(?P<phenotype>({'|'.join(phenotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478c85d-b0ed-466c-b6d3-e8dead52f018",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e59494-b23d-4775-8863-1baeb1f46194",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = True\n",
    "verbose = True\n",
    "objective_reactions = [\"NaKt\"]\n",
    "\n",
    "enzyme_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.dilution\"]\n",
    "enzyme_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"prefix.metabolite\"]\n",
    "enzyme_met_suffix_total = DEFAULT_PREFIX_SUFFIX_VALUES[\"enzymes\"][\"suffix.total\"]\n",
    "comp_suffix = f\"_{DEFAULT_PROTEOME_COMPARTMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bb5e1-67d6-4436-af4a-0f34befaa111",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad3312-69a9-4bd9-92c4-a2d467bed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2d514-cb81-4968-95b6-95e758cd3e73",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd462b-0c65-4b33-b745-6a4e74996f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "results_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\") / model_id / \"OVERLAY\" / organism / dataset_name\n",
    ")\n",
    "\n",
    "sample_pcmodels_dirpath = results_dirpath / \"sample_pcmodels\"\n",
    "pcfva_results_dirpath = (\n",
    "    results_dirpath / \"pcFVA\" / \"_\".join((\"OBJ\", *objective_reactions))\n",
    ")\n",
    "# Objective reaction does not matter since correlations are computed\n",
    "# based on min and max fluxes and abundance, which are obtained when optimum is 0.\n",
    "corr_results_dirpath = results_dirpath / \"correlations\"\n",
    "# Ensure directory  exists\n",
    "corr_results_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b8d0f-8ca2-48e4-9da1-7db464f01407",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f7b2c-ad0d-4404-899b-fa05a0bd7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "# Add relaxation budget to initial PC model to get names of relaxation reactions\n",
    "add_relaxation_budget(pcmodel, 0, verbose=False)\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf0307-bf28-4f10-8784-143d62c669a7",
   "metadata": {},
   "source": [
    "## Load pcFVA generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fccd8-52b6-44c9-83a0-af5c62b7fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame of generated results\n",
    "df_pcfva_all = pd.read_csv(\n",
    "    pcfva_results_dirpath / f\"{pcmodel.id}_All_FVAsols.csv\",\n",
    "    index_col=None,\n",
    ")\n",
    "\n",
    "df_pcfva_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a4524-c95b-4980-a95f-5ba109e75025",
   "metadata": {},
   "source": [
    "## Create DataFrame for calculations and visualizations\n",
    "### Get maximum reaction fluxes and associated abundance values\n",
    "#### Get maximum reaction fluxes and ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efaec1d-6db8-4b96-975b-67303d06d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = model.reactions.list_attr(\"id\")\n",
    "df_max_flux_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "df_max_flux_per_model = df_max_flux_per_model.groupby(\n",
    "    [\"model\", \"reactions\", \"optimum\"]\n",
    ")[[\"min\", \"max\"]].agg(\n",
    "    {\n",
    "        \"min\": \"min\",  # Minimum reaction flux per model\n",
    "        \"max\": \"max\",  # Maximum reaction flux per model\n",
    "    }\n",
    ")\n",
    "# Address issues possibly caused by floating point precision, ideally a value that prevents any negative ranges\n",
    "df_max_flux_per_model.loc[\n",
    "    df_max_flux_per_model[\"max\"] < df_max_flux_per_model[\"min\"], [\"max\", \"min\"]\n",
    "] = [0, 0]\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_flux_per_model[\"max\"] = df_max_flux_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_flux_per_model[\"min\"] = df_max_flux_per_model[\"min\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_flux_per_model[\"range\"] = (\n",
    "    df_max_flux_per_model[\"max\"] - df_max_flux_per_model[\"min\"]\n",
    ")\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_flux_per_model[df_max_flux_per_model[\"range\"] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e000d2d8-7a7c-4b02-b088-867e04ce7dbe",
   "metadata": {},
   "source": [
    "#### Get maximum \"enzyme\" abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6feeea-cfe4-4da9-99db-47f2729bd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxns = pcmodel.reactions.query(\n",
    "    lambda x: isinstance(x, EnzymeDilution)\n",
    "    and x.id.endswith(f\"{enzyme_met_suffix_total}{comp_suffix}\")\n",
    ").list_attr(\"id\")\n",
    "df_max_abundance_per_model = df_pcfva_all[df_pcfva_all[\"reactions\"].isin(rxns)].copy()\n",
    "# Rename dilution reactions to match\n",
    "reaction_enzyme_map = {\n",
    "    enzyme_rid: enzyme_rid.replace(\n",
    "        f\"{enzyme_rxn_prefix}{enzyme_met_prefix}\", \"\"\n",
    "    ).replace(f\"{enzyme_met_suffix_total}{comp_suffix}\", \"\")\n",
    "    for enzyme_rid in df_max_abundance_per_model[\"reactions\"]\n",
    "}\n",
    "df_max_abundance_per_model[\"reactions\"] = df_max_abundance_per_model[\n",
    "    \"reactions\"\n",
    "].replace(reaction_enzyme_map)\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.groupby(\n",
    "    [\"model\", \"reactions\", \"optimum\"]\n",
    ")[[\"max\"]].max()\n",
    "# Address issues possibly caused by floating point precision, atol is ideally a value that prevents any negative ranges\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if x < 0 else x\n",
    ")\n",
    "atol = COBRA_CONFIGURATION.tolerance\n",
    "df_max_abundance_per_model[\"max\"] = df_max_abundance_per_model[\"max\"].apply(\n",
    "    lambda x: 0 if np.isclose(x, 0, atol=atol) else round(x, -int(np.log10(atol)))\n",
    ")\n",
    "df_max_abundance_per_model = df_max_abundance_per_model.rename(\n",
    "    {\"max\": \"abundance\"}, axis=1\n",
    ")\n",
    "# Ensure no negative values, if results appear then tolerance should be adjusted\n",
    "df_max_abundance_per_model[(df_max_abundance_per_model < 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95269b45-4f16-4d09-95c5-af4734b23d82",
   "metadata": {},
   "source": [
    "#### Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60602d4b-89ba-493b-ae29-55a35c669a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_all = pd.merge(\n",
    "    df_max_flux_per_model,\n",
    "    df_max_abundance_per_model,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "df_data_all = df_data_all.reset_index(drop=False)\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3094239-cea4-4899-8cba-84b0f3969ba3",
   "metadata": {},
   "source": [
    "### Identify donor, timepoints, and phenotypes for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04139aab-4c0c-4845-a65f-912ac235da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [\"donor\", \"time\", \"phenotype\"]\n",
    "for key, search_re in zip(metadata_columns, [donor_re, time_re, phenotype_re]):\n",
    "    df_data_all[key] = df_data_all[\"model\"].apply(\n",
    "        lambda x: search_re.search(x).group(1) if search_re.search(x) else pd.NA\n",
    "    )\n",
    "df_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902ff15-bf6a-43a9-ad82-d81742231410",
   "metadata": {},
   "source": [
    "## Compute statistically significant results between groups\n",
    "### Remove models based on data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce7d4c-834d-4b2f-b705-059839846fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_samples = df_data_all[\n",
    "    [not bool(operation_re.search(x)) for x in df_data_all[\"model\"]]\n",
    "].copy()\n",
    "df_data_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f4389-594f-4c01-8743-94cbef5ffe54",
   "metadata": {},
   "source": [
    "### Create groups of sample models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f41d9-3091-46ef-9fb9-94e0431bfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_key = \"ALL\"\n",
    "model_groups = {all_key: list(df_data_samples[\"model\"].unique())}\n",
    "\n",
    "\n",
    "def create_group_of_models(df, groupby, verbose=False):\n",
    "    grouped = df.groupby(groupby)[\"model\"].agg(lambda x: list(x.unique()))\n",
    "    grouped = {\"_\".join(ensure_iterable(k)): v for k, v in grouped.to_dict().items()}\n",
    "    max_name_len = max([len(group_name) for group_name in list(grouped)])\n",
    "    if verbose:\n",
    "        for group_name, model_list in grouped.items():\n",
    "            spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "            print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325246aa-d8a5-4b14-8792-d1a535a6f017",
   "metadata": {},
   "source": [
    "#### Based on timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc0a34-dc33-44c0-8624-044effe099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns], groupby=[\"time\"], verbose=verbose\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290b56e-0285-4f7a-84b1-0c6376dc545d",
   "metadata": {},
   "source": [
    "##### Based on timepoint and phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b83f1-abda-4ade-b5bd-098b6885dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    groupby=[\"time\", \"phenotype\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472fbd2-8a5f-4e1e-a93e-901a30ee98ae",
   "metadata": {},
   "source": [
    "#### Based on phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb437bf3-7040-4c20-9eb4-8c73c574d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    groupby=[\"phenotype\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa0118-d6f0-4b5c-ba1c-a242cd7d0f7f",
   "metadata": {},
   "source": [
    "##### Based on phenotype and timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db8d24-a91a-4031-b3c6-c398c068f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = create_group_of_models(\n",
    "    df_data_samples[[\"model\"] + metadata_columns],\n",
    "    groupby=[\"phenotype\", \"time\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "model_groups.update(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f798fa7e-2a9a-4664-afbe-b30fd94b1df0",
   "metadata": {},
   "source": [
    "### View model groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1152679-d912-4768-802c-5d365e05c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Possible groups for analyses\\n============================\")\n",
    "max_name_len = max([len(group_name) for group_name in list(model_groups)])\n",
    "for group_name, model_list in model_groups.items():\n",
    "    spacepad = \"\".join([\" \"] * (max_name_len - len(group_name)))\n",
    "    print(f\"{group_name}:{spacepad}\\t{len(model_list)} samples\")\n",
    "\n",
    "df_data_for_analyses = df_data_samples.set_index([\"reactions\", \"model\"]).drop(\n",
    "    metadata_columns, axis=1\n",
    ")\n",
    "df_data_for_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2684b9-37c0-462b-98a1-5d20012b4e93",
   "metadata": {},
   "source": [
    "#### Ensure groups exist and setup directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c9396-815f-450e-a20c-d58be95ac66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New directories are created for main groups\n",
    "groups_dict = defaultdict(dict)\n",
    "group_items_list = [\n",
    "    [\"Pre\", \"Post\", \"TD\"],\n",
    "    [\"HumCan\", \"A\", \"MED\"],\n",
    "]\n",
    "# All main groups are created under the \"All\" directory, subgroups are created under each main group\n",
    "for item_list in group_items_list:\n",
    "    groups_dict[all_key].update({item: {} for item in item_list})\n",
    "    groups_dict[all_key].update(\n",
    "        {\n",
    "            item: sorted(\n",
    "                [\n",
    "                    group_name\n",
    "                    for group_name in model_groups\n",
    "                    if group_name.split(\"_\")[0] == item and group_name != item\n",
    "                ]\n",
    "            )\n",
    "            for item in item_list\n",
    "        }\n",
    "    )\n",
    "groups_dict[all_key].update(\n",
    "    {k: groups_dict[all_key][k] for k in sorted(sorted(groups_dict[all_key]))}\n",
    ")\n",
    "invalid_groups = [\n",
    "    group_name for group_name in groups_dict[all_key] if group_name not in model_groups\n",
    "]\n",
    "if any(invalid_groups):\n",
    "    raise KeyError(\n",
    "        f\"No group(s) found for `{invalid_groups}`. Model groups must be created first before correlation computations\"\n",
    "    )\n",
    "invalid_subgroups = [\n",
    "    subgroup\n",
    "    for group_values in groups_dict[all_key].values()\n",
    "    for subgroup in group_values\n",
    "    if subgroup not in model_groups\n",
    "]\n",
    "if any(invalid_subgroups):\n",
    "    raise KeyError(\n",
    "        f\"No subgroup(s) found for `{invalid_subgroups}`. Model groups must be created first before correlation computations\"\n",
    "    )\n",
    "\n",
    "\n",
    "header = \"Expected directory structure\"\n",
    "print(\"\\n\".join((header, \"=\" * len(header), all_key)))\n",
    "for idx, (group_name, subgroups) in enumerate(sorted(groups_dict[all_key].items())):\n",
    "    print(\"\\u2514\\u2500\\u2500\" + f\" {group_name}\")\n",
    "    vertical = \"\\u2502\" if idx != len(groups_dict[all_key]) - 1 else \" \"\n",
    "    for subgroup_name in sorted(subgroups):\n",
    "        print(vertical + \"   \\u2514\\u2500\\u2500\" + subgroup_name)\n",
    "\n",
    "group_results_dirpath_dict = {all_key: corr_results_dirpath}\n",
    "for group_name, subgroups in groups_dict[all_key].items():\n",
    "    group_results_dirpath_dict[group_name] = (\n",
    "        group_results_dirpath_dict[all_key] / group_name\n",
    "    )\n",
    "    group_results_dirpath_dict.update(\n",
    "        {\n",
    "            subgroup_name: group_results_dirpath_dict[group_name] / subgroup_name\n",
    "            for subgroup_name in subgroups\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8fc2e6-5be8-4ac8-98ad-92d69335d316",
   "metadata": {},
   "source": [
    "#### Load subsystems and metabolic categories to enrich results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fff7e1-e706-4abf-adc9-6ee5a72bfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsystems_to_exclude = {\"Pseudoreactions\"}\n",
    "use_abbrevs = True\n",
    "abbreviations = {\n",
    "    \"Amino acid metabolism\": \"A\",\n",
    "    \"Carbohydrate metabolism\": \"C\",\n",
    "    \"Lipid metabolism\": \"L\",\n",
    "    \"Metabolism of cofactors and vitamins\": \"V\",\n",
    "    \"Nucleotide metabolism\": \"N\",\n",
    "    \"Reactive species\": \"R\",\n",
    "    \"Transport reactions\": \"T\",\n",
    "    \"Other\": \"O\",\n",
    "}\n",
    "categories_to_keep = list(abbreviations)\n",
    "\n",
    "df_pathways = pd.read_csv(\n",
    "    get_dirpath(\"curation\") / \"subsystems.tsv\", sep=\"\\t\", dtype=str\n",
    ").fillna(\"\")\n",
    "\n",
    "# Rename \"name\" to subsystem to match reaction attribute\n",
    "df_pathways = df_pathways.rename({\"name\": \"subsystem\"}, axis=1)\n",
    "# Group \"Metabolism of other amino acids\" with amino acids rather than treat as \"other\"\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].replace(\n",
    "    \"Metabolism of other amino acids\", \"Amino acid metabolism\"\n",
    ")\n",
    "\n",
    "df_pathways[\"category\"] = df_pathways[\"category\"].apply(\n",
    "    lambda x: (\"Other\" if x not in categories_to_keep else x)\n",
    ")\n",
    "df_pathways = df_pathways[~df_pathways[\"subsystem\"].isin(subsystems_to_exclude)].copy()\n",
    "subsystem_to_category_dict = df_pathways.set_index(\"subsystem\")[\"category\"].to_dict()\n",
    "df_pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281f9fb-3124-4f6b-95c6-ccc02b3c6733",
   "metadata": {},
   "source": [
    "## Compute significant results between groups\n",
    "#### Compare all subgroups at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37f27e-c5ab-4403-9bca-ec37a7208c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = \"Pre\"\n",
    "optimum = 0\n",
    "value_to_compare = \"range\"\n",
    "compare_pairwise = True\n",
    "compare_all_groups = True\n",
    "ordered_group_to_compare = [f\"{group_name}_{phenotype}\" for phenotype in phenotypes]\n",
    "\n",
    "all_samples_for_comparison = [\n",
    "    value for g in ordered_group_to_compare for value in np.array(model_groups[g])\n",
    "]\n",
    "df_data_for_correlations = df_data_for_analyses.loc[\n",
    "    pd.IndexSlice[:, all_samples_for_comparison], :\n",
    "]\n",
    "df_data_for_correlations = df_data_for_correlations[\n",
    "    df_data_for_correlations[\"optimum\"] == optimum\n",
    "].drop(\"optimum\", axis=1)\n",
    "\n",
    "if value_to_compare == \"max\":\n",
    "    df_data_for_correlations[\"max\"] = (\n",
    "        df_data_for_correlations[[\"min\", \"max\"]].abs().max(axis=1)\n",
    "    )\n",
    "    df_data_for_correlations = df_data_for_correlations.drop(\"min\", axis=1)\n",
    "\n",
    "print(\"Groups to compare\\n=================\")\n",
    "if compare_all_groups:\n",
    "    print(tuple(ordered_group_to_compare))\n",
    "if compare_pairwise:\n",
    "    pairwise_group_combos = list(combinations(ordered_group_to_compare, 2))\n",
    "    for group in pairwise_group_combos:\n",
    "        print(group)\n",
    "df_data_for_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03749c24-92f5-4819-bf70-77778085e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = defaultdict(dict)\n",
    "mannwhitneyu_for_pairs = True\n",
    "for rid in df_data_for_correlations.index.get_level_values(\"reactions\").unique():\n",
    "    df_data_rxn = df_data_for_correlations.loc[rid]\n",
    "    df_data_rxn_opt_value = df_data_rxn[value_to_compare].copy()\n",
    "    data_arrays = {\n",
    "        group_name: df_data_rxn_opt_value.loc[model_groups[group_name]].values\n",
    "        for group_name in ordered_group_to_compare\n",
    "    }\n",
    "    if compare_all_groups:\n",
    "        values = list(data_arrays.values())\n",
    "        unique_values = set(\n",
    "            [v for value_list in values for v in value_list if not np.isnan(v)]\n",
    "        )\n",
    "        if len(unique_values) <= 1:\n",
    "            # Skip variables that do not have any differences\n",
    "            results_dict[tuple(ordered_group_to_compare)][rid] = dict(\n",
    "                zip([\"statistic\", \"pvalue\"], [pd.NA, pd.NA])\n",
    "            )\n",
    "        else:\n",
    "            result = kruskal(*values, nan_policy=\"omit\")\n",
    "            results_dict[tuple(ordered_group_to_compare)][rid] = {\n",
    "                attr: getattr(result, attr) for attr in [\"statistic\", \"pvalue\"]\n",
    "            }\n",
    "    if compare_pairwise:\n",
    "        for combo in pairwise_group_combos:\n",
    "            values = [data_arrays[group] for group in combo]\n",
    "            unique_values = set(\n",
    "                [v for value_list in values for v in value_list if not np.isnan(v)]\n",
    "            )\n",
    "            if len(unique_values) <= 1:\n",
    "                # Skip variables that do not have any differences\n",
    "                result = dict(zip([\"statistic\", \"pvalue\"], [pd.NA, pd.NA]))\n",
    "            elif mannwhitneyu_for_pairs:\n",
    "                result = mannwhitneyu(*values, nan_policy=\"omit\")\n",
    "                result = {\n",
    "                    attr: getattr(result, attr) for attr in [\"statistic\", \"pvalue\"]\n",
    "                }\n",
    "            else:\n",
    "                result = kruskal(*values, nan_policy=\"omit\")\n",
    "                result = {\n",
    "                    attr: getattr(result, attr) for attr in [\"statistic\", \"pvalue\"]\n",
    "                }\n",
    "            results_dict[combo][rid] = result\n",
    "dataframes = {\n",
    "    key: pd.DataFrame.from_dict(values, orient=\"index\")\n",
    "    for key, values in results_dict.items()\n",
    "}\n",
    "print(f\"Number of different comparisons made: {len(dataframes)}\")\n",
    "print(\"Groups compared\\n===============\")\n",
    "for key in list(dataframes):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16a3b4-ff30-4ede-a251-5ef488ed13ab",
   "metadata": {},
   "source": [
    "### Determine significance using p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864a7a5-d2c0-4b80-addf-830f9f36a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_sig = 0.05\n",
    "enzyme_reactions_only = False\n",
    "include_boundary_reactions = False\n",
    "remove_group_name_from_samples = True\n",
    "sort_by_subsystem = True\n",
    "standardize_by = \"mean\"\n",
    "use_group_means = False\n",
    "\n",
    "significant_dataframes = {}\n",
    "for met in model.metabolites.query(lambda x: x.compartment == \"e\"):\n",
    "    met.name += \" (extracellular)\"\n",
    "metadata_columns = [\n",
    "    \"name\",\n",
    "    \"stoichiometry\",\n",
    "    \"proteins\",\n",
    "    \"pvalue\",\n",
    "    \"subsystem\",\n",
    "    \"category\",\n",
    "]\n",
    "for key, df in dataframes.items():\n",
    "    df = df.dropna()\n",
    "    df = df[df[\"pvalue\"] <= pvalue_sig].drop(\"statistic\", axis=1)\n",
    "    if enzyme_reactions_only:\n",
    "        df_pivot = df_data_for_correlations.loc[\n",
    "            df.index, [\"abundance\", value_to_compare]\n",
    "        ].dropna(subset=\"abundance\")\n",
    "        df_pivot = df_pivot.drop(\"abundance\", axis=1)\n",
    "    else:\n",
    "        df_pivot = df_data_for_correlations.loc[df.index, value_to_compare]\n",
    "    if not include_boundary_reactions:\n",
    "        df_pivot = df_pivot[\n",
    "            ~df_pivot.index.isin(\n",
    "                model.reactions.query(lambda x: x.boundary).list_attr(\"id\"),\n",
    "                level=\"reactions\",\n",
    "            )\n",
    "        ]\n",
    "    df_pivot = df_pivot.reset_index(drop=False)\n",
    "    df_pivot = df_pivot.pivot(\n",
    "        columns=\"model\", index=\"reactions\", values=value_to_compare\n",
    "    )\n",
    "    df = pd.merge(df, df_pivot, left_index=True, right_index=True).sort_values(\"pvalue\")\n",
    "    df.index.name = \"reactions\"\n",
    "    df = df.reset_index(drop=False).set_index([\"reactions\", \"pvalue\"]).T\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            # Sort index by donor number and subgroup while concatenating\n",
    "            df.loc[model_groups[g]].sort_index(\n",
    "                key=lambda x: [int(donor_re.search(v).group(\"num\")) for v in x.values]\n",
    "            )\n",
    "            for g in key\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    # Remove pcmodel ID from sample names\n",
    "    df.index = [sample_id.replace(f\"{pcmodel.id}_\", \"\") for sample_id in df.index]\n",
    "    if remove_group_name_from_samples:\n",
    "        df.index = [\n",
    "            \"_\".join([x for x in sample_id.split(\"_\") if x != group_name])\n",
    "            for sample_id in df.index\n",
    "        ]\n",
    "\n",
    "    df = df.T.reset_index(drop=False)\n",
    "    # Enrich results\n",
    "    df[\"name\"] = [\n",
    "        r.name for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "    ]\n",
    "    df[\"stoichiometry\"] = [\n",
    "        r.build_reaction_string(use_metabolite_names=True)\n",
    "        for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "    ]\n",
    "    df[\"subsystem\"] = [\n",
    "        r.subsystem for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "    ]\n",
    "    df[\"category\"] = df[\"subsystem\"].replace(subsystem_to_category_dict)\n",
    "    df[\"proteins\"] = [\n",
    "        \";\".join(sorted([g.id for g in r.genes]))\n",
    "        for r in model.reactions.get_by_any(list(df[\"reactions\"].values))\n",
    "    ]\n",
    "    # Replace commas to prevent issues with CSV export\n",
    "    df[\"subsystem\"] = df[\"subsystem\"].apply(lambda x: x.replace(\",\", \"\"))\n",
    "    df[\"category\"] = df[\"category\"].apply(lambda x: x.replace(\",\", \"\"))\n",
    "    df[\"pvalue\"] = df[\"pvalue\"].apply(lambda x: round(x, 5))\n",
    "\n",
    "    df = df.set_index(\"reactions\")\n",
    "    if sort_by_subsystem:\n",
    "        df = df.sort_values(by=[\"category\", \"subsystem\", \"proteins\"])\n",
    "\n",
    "    df_meta = df.loc[:, metadata_columns].copy()\n",
    "    df_data = df.loc[:, ~df.columns.isin(df_meta.columns)].copy()\n",
    "\n",
    "    if use_group_means:\n",
    "        phenotypes_for_key = [k.split(\"_\")[-1] for k in key]\n",
    "        df_data = pd.concat(\n",
    "            [\n",
    "                df_data.loc[\n",
    "                    :,\n",
    "                    [\n",
    "                        phenotype_re.search(sample_id).group(\"phenotype\") == phenotype\n",
    "                        for sample_id in df_data.columns\n",
    "                    ],\n",
    "                ].mean(axis=1)\n",
    "                for phenotype in phenotypes_for_key\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        df_data.columns = phenotypes_for_key\n",
    "    if standardize_by == \"mean\":\n",
    "        df_data = (\n",
    "            df_data.sub(df_data.mean(axis=1), axis=0)\n",
    "            .div(df_data.std(axis=1), axis=0)\n",
    "            .dropna(how=\"all\", axis=0)\n",
    "        )\n",
    "    elif standardize_by == \"median\":\n",
    "        df_data = (\n",
    "            (df_data.T - df_data.median(axis=1))\n",
    "            / (df_data.quantile(q=0.75, axis=1) - df_data.quantile(q=0.25, axis=1))\n",
    "        ).T\n",
    "    else:\n",
    "        pass\n",
    "    # Put dataframes back together for custom reordering\n",
    "    significant_dataframes[key] = df_data.merge(\n",
    "        df_meta, left_index=True, right_index=True\n",
    "    )\n",
    "    print(key)\n",
    "\n",
    "key = tuple(ordered_group_to_compare)\n",
    "# key = ('Pre_HumCan', 'Pre_A')\n",
    "significant_dataframes[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ac8fd-5bc2-412b-8c8e-0f418d73bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = tuple(ordered_group_to_compare)\n",
    "# df = significant_dataframes[key]\n",
    "# df = df.loc[:, ~df.columns.isin([\"proteins\", \"pvalue\", \"subsystem\", \"category\", \"name\", \"stoichiometry\"])].T\n",
    "# df.index = pd.MultiIndex.from_tuples([(x, phenotype_re.search(x).group(1)) for x in df.index])\n",
    "# df = df.groupby(level=1).mean().T\n",
    "# df = df[[\"HumCan\", \"A\", \"MED\"]]\n",
    "\n",
    "# print(df.min().min(), df.max().max())\n",
    "# df = df.merge(df_meta, left_index=True, right_index=True)\n",
    "# ordered_subsystems = [\n",
    "#     \"Pentose phosphate pathway\",\n",
    "#     \"Galactose metabolism\",\n",
    "#     \"Glycolysis / Gluconeogenesis\",\n",
    "#     \"Transport extracellular\",\n",
    "#     \"Alanine aspartate and glutamate metabolism\",\n",
    "#     \"Miscellaneous\",\n",
    "#     \"Protein modification\",\n",
    "# ]\n",
    "# df = pd.concat(\n",
    "#     [\n",
    "#         df[df[\"subsystem\"] == subsystem].sort_values(by=\"pvalue\")\n",
    "#         for subsystem in ordered_subsystems\n",
    "#     ],\n",
    "#     axis=0,\n",
    "# )\n",
    "# significant_dataframes[key] = df\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59521b3e-ab82-42aa-aae1-9df6fe676d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = (\"Pre_HumCan\", \"Pre_A\")\n",
    "# df_main = significant_dataframes[key]\n",
    "# df_main.loc[[\"O2t\", \"O2St\", \"NOt\", \"H2Ot\", \"NH4t\", \"NH3t\", \"CO2t\"], \"subsystem\"] = (\n",
    "#     \"Transport gas\"\n",
    "# )\n",
    "# df_main.loc[\n",
    "#     [\n",
    "#         \"FAt_hs_3_0\",\n",
    "#         \"3DGt\",\n",
    "#         \"HEMATINABCte\",\n",
    "#         \"E217BGLCRABCte\",\n",
    "#         \"5FLURAABCte\",\n",
    "#         \"URATEABCte\",\n",
    "#         \"Clt\",\n",
    "#         \"NO3t\",\n",
    "#         \"LDOPAt\",\n",
    "#         \"5FLURAt\",\n",
    "#         \"E217BGLCRte\",\n",
    "#     ],\n",
    "#     \"subsystem\",\n",
    "# ] = \"Transport other\"\n",
    "# ordered_subsystems = [\n",
    "#     \"Pentose phosphate pathway\",\n",
    "#     \"Galactose metabolism\",\n",
    "#     \"Glycolysis / Gluconeogenesis\",\n",
    "#     \"Pyruvate metabolism\",\n",
    "#     \"Protein modification\",\n",
    "#     \"Reactive species formation and detoxification\",\n",
    "#     \"Miscellaneous\",\n",
    "#     \"Cysteine and methionine metabolism\",\n",
    "#     \"Glutathione metabolism\",\n",
    "#     \"Phenylalanine tyrosine and tryptophan metabolism\",\n",
    "#     \"Transport other\",\n",
    "#     \"Transport gas\",\n",
    "#     \"Transport extracellular\",\n",
    "# ]\n",
    "# df_main = pd.concat(\n",
    "#     [\n",
    "#         (\n",
    "#             df_main[df_main[\"subsystem\"] == subsystem]\n",
    "#             if subsystem != \"Protein modification\"\n",
    "#             else df_main[df_main[\"subsystem\"] == subsystem].iloc[::-1]\n",
    "#         )\n",
    "#         for subsystem in ordered_subsystems\n",
    "#     ],\n",
    "#     axis=0,\n",
    "# )\n",
    "# significant_dataframes[key] = df_main.copy()\n",
    "# df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dc29f-f123-457b-8d29-0d7461a189f7",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd72da-0f5b-47c3-bdf4-0cfdd3c54bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = \"csv\"\n",
    "for key, df_main in significant_dataframes.items():\n",
    "    df_meta = df_main.loc[:, metadata_columns].copy()\n",
    "    df_data = df_main.loc[:, ~df_main.columns.isin(df_meta.columns)].copy()\n",
    "    for df_type, df in zip([\"data\", \"meta\"], [df_data, df_meta]):\n",
    "        filename = \"_\".join(\n",
    "            [\"MannWhiteney\" if mannwhitneyu_for_pairs and len(key) == 2 else \"Kruskal\"]\n",
    "            + [g.split(\"_\")[-1] for g in key]\n",
    "            + [df_type]\n",
    "        )\n",
    "        if use_group_means:\n",
    "            filename += \"_mean\"\n",
    "        filename = group_results_dirpath_dict[group_name] / filename\n",
    "        df.to_csv(\n",
    "            f\"{filename}.{ftype}\", sep=\"\\t\" if ftype == \"tsv\" else \",\", index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe84078-6a73-41ee-80b2-568bf120839c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
