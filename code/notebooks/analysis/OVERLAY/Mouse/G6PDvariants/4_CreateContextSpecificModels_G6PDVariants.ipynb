{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2537d45b-6871-43b9-81f8-e3639df15ac5",
   "metadata": {},
   "source": [
    "# Create context-specific models - Mouse G6PD variants omics data\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import gurobipy as gp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as mpl_venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.analysis.overlay import (\n",
    "    DEFAULT_PREFIX_SUFFIX_VALUES,\n",
    "    ProteinDilution,\n",
    "    add_relaxation_budget,\n",
    "    load_overlay_model,\n",
    "    update_slack_value,\n",
    ")\n",
    "from rbc_gem_utils.util import AVOGADRO_NUMBER, DEFAULT_DRY_MASS_PER_CELL\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)\n",
    "gp.setParam(\"LogToConsole\", 0)\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f0e62-ca1f-4201-a29d-dc3221be59c1",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d9475-8441-4f92-b46e-6257c5a7d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION.solver = \"gurobi\"\n",
    "# Set bound defaults much larger to prevent model loading issues\n",
    "COBRA_CONFIGURATION.bounds = (-1e-8, 1e8)\n",
    "COBRA_CONFIGURATION.tolerance = 1e-7\n",
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75002349-87e3-497d-bdd4-7b8f0ac40aa8",
   "metadata": {},
   "source": [
    "### Define organism, model, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecbb31-18b5-4b6e-a43c-d620b0583fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Mouse\"\n",
    "model_id = \"RBC_GEM\"\n",
    "dataset_name = \"G6PDvariants\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ac5ae-ade6-487d-8f40-f2ee138f967f",
   "metadata": {},
   "source": [
    "### Set variables for columns keys and sample identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd66aab-afb7-4423-8302-ff1a80eea6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"MOUSE ID\"\n",
    "time_key = \"TIME\"\n",
    "\n",
    "timepoints = [\"Pre\", \"Post\", \"TD\"]\n",
    "phenotypes = [\"HumCan\", \"A\", \"MED\"]\n",
    "\n",
    "# For sample IDs\n",
    "donor_re = re.compile(rf\"(?P<donor>({'|'.join(phenotypes)})\\d+)\")\n",
    "time_re = re.compile(rf\"(?P<time>{'|'.join(timepoints)})\")\n",
    "phenotype_re = re.compile(rf\"(?P<phenotype>({'|'.join(phenotypes)}))\")\n",
    "\n",
    "operations = \"|\".join([x.capitalize() for x in [\"mean\", \"median\"]])\n",
    "\n",
    "operation_re = re.compile(r\"(?P<op>\" + operations + r\")\\_(?P<group>\\w+)\")\n",
    "sample_id_re = re.compile(\n",
    "    r\"(?!\" + operations + r\")\" + donor_re.pattern + r\"\\_\" + time_re.pattern\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc902ad-241d-48dc-a759-f3009e4010ec",
   "metadata": {},
   "source": [
    "### Set computation options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16fa346-9a48-42af-b72a-b614c8684e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_computations = False\n",
    "overwrite = False\n",
    "verbose = True\n",
    "objective_reactions = [\"NaKt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd2432-5dec-449d-86a0-f04d764499b0",
   "metadata": {},
   "source": [
    "### Set figure options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df60689-6021-4568-b734-f3cc8a0c7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "transparent = False\n",
    "imagetype = \"svg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dcb034-0990-4d42-8b98-0b59fa946dcc",
   "metadata": {},
   "source": [
    "### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65ffb2-a375-4df8-b911-8e80d0430cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "overlay_dirpath = get_dirpath(\"analysis\") / \"OVERLAY\" / organism\n",
    "model_dirpath = overlay_dirpath / model_id\n",
    "\n",
    "results_dirpath = (\n",
    "    get_dirpath(use_temp=\"processed\") / model_id / \"OVERLAY\" / organism / dataset_name\n",
    ")\n",
    "\n",
    "fitting_dirpath = results_dirpath / \"fitting\"\n",
    "sample_pcmodels_dirpath = results_dirpath / \"sample_pcmodels\"\n",
    "# Ensure directories exist\n",
    "results_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "fitting_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "sample_pcmodels_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eef9a-a381-4843-bb72-7652ae4dd219",
   "metadata": {},
   "source": [
    "### Define hemoglobin proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f05d96-d857-472f-89fc-1efc1373f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify hemoglobin proteins\n",
    "HB_PROTEINS = {\n",
    "    k.replace(\"-\", \"_\"): v\n",
    "    for k, v in {\n",
    "        \"Hba\": \"P01942\",  # Hemoglobin subunit alpha\n",
    "        \"Hba-a1\": \"P01942\",\n",
    "        \"Hbb-b1\": \"P02088\",  # Hemoglobin subunit beta-1\n",
    "        \"Hbb-b2\": \"P02089\",  # Hemoglobin subunit beta-2\n",
    "        \"Hbb-bh0\": \"P04443\",  # Hemoglobin subunit beta-H0\n",
    "        \"Hbb-bh1\": \"P04444\",  # Hemoglobin subunit beta-H1\n",
    "        \"Hbz\": \"P06467\",  # Hemoglobin subunit zeta\n",
    "        \"Hba-x\": \"P06467\",\n",
    "        \"Hbz1\": \"P06467\",\n",
    "        \"Hbb-y\": \"P02104\",  # Hemoglobin subunit epsilon-Y2\n",
    "    }.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc6fa4-161e-4511-bf31-0b75d3b93dcb",
   "metadata": {},
   "source": [
    "## Load RBC-GEM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de2e8f-e0f3-4e0c-94dd-52ea8edfb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{model_id}.xml\")\n",
    "pcmodel = load_overlay_model(filename=model_dirpath / f\"{model_id}_PC.xml\")\n",
    "\n",
    "pcmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870bde99-df06-40b0-9faa-7ecf995af67c",
   "metadata": {},
   "source": [
    "## Load copy numbers and protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773d2fe-5020-443a-b2dd-f3bbf9dffd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load protein copy numbers\n",
    "df_copy_numbers = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_ProteinCopyNumbers.csv\",\n",
    "    index_col=sample_key,\n",
    ")\n",
    "\n",
    "# Load MCH for transforming data\n",
    "df_MCH = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_MCH.csv\", index_col=sample_key\n",
    ")\n",
    "# Load intensity data as weighting matrix\n",
    "df_weighting_mat = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_ProteinIntensities.csv\",\n",
    "    index_col=sample_key,\n",
    ")\n",
    "\n",
    "# Load protein data\n",
    "df_protein_data = pd.read_csv(\n",
    "    processed_data_dirpath / f\"{dataset_name}_ProteinData.csv\",\n",
    "    index_col=\"Entry\",\n",
    ")\n",
    "\n",
    "all_ids = list(df_copy_numbers.index.unique())\n",
    "operation_ids = [x for x in all_ids if operation_re.match(x)]\n",
    "sample_ids = [x for x in all_ids if sample_id_re.match(x)]\n",
    "\n",
    "print(f\"Number of measured samples: {len(sample_ids)}\")\n",
    "print(f\"Number of operation samples: {len(operation_ids)}\")\n",
    "print(f\"Number of models to generate: {len(all_ids)}\")\n",
    "print(f\"\\nNumber of timepoints across samples: {len(timepoints)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0f2b8-c950-44af-a911-124cd4b153db",
   "metadata": {},
   "source": [
    "## Integrate proteomics with model\n",
    "### Scale measurements for proteome budget\n",
    "Note that this step will help ensure its theoretically possible for a perfect fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b89002-1f78-4f61-85d9-d825fe6cd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_PERCENT, LA_PERCENT = (0.95, 0.05)\n",
    "MODELED_PERCENT = HB_PERCENT + LA_PERCENT\n",
    "assert 1 >= MODELED_PERCENT\n",
    "\n",
    "budget_hb_value = 1000 * HB_PERCENT\n",
    "budget_la_value = 1000 * LA_PERCENT\n",
    "budget_total_value = 1000 * MODELED_PERCENT\n",
    "\n",
    "print(f\"Hemoglobin budget:\\t{budget_hb_value} mg protein / gDW\")\n",
    "print(f\"Low abundance budget:\\t{budget_la_value} mg protein / gDW\")\n",
    "print(f\"Total budget:\\t\\t{budget_total_value} mg protein / gDW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722b2f4-d349-4053-a6c7-95965361315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_to_mw = df_protein_data[\"Mass\"].astype(float)\n",
    "\n",
    "gDW_total_protein = (\n",
    "    df_MCH  # pgDW HB\n",
    "    * (1 / HB_PERCENT)  # pgDW total protein / pgDW HB\n",
    "    * (1 / 1e12)  #  gDW total protein / pgDW total protein\n",
    ")\n",
    "gDW_total_protein\n",
    "\n",
    "# protein copies / cell\n",
    "df_mg_prot_per_gDW = (\n",
    "    df_copy_numbers[df_protein_data.index].mul(\n",
    "        1 / gDW_total_protein.squeeze(), axis=0  # cell / gDW\n",
    "    )\n",
    "    * (\n",
    "        1\n",
    "        / AVOGADRO_NUMBER  # mol / protein copies\n",
    "        * df_uniprot_to_mw  # g / mol\n",
    "        * 1e3  # mg / g\n",
    "    ).copy()\n",
    ")\n",
    "df_mg_prot_per_gDW = df_mg_prot_per_gDW.loc[df_copy_numbers.index]\n",
    "df_mg_prot_per_gDW[df_mg_prot_per_gDW.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b51a37-eb71-43ed-9355-bebae6c6cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into hemoglobin and low abundance proteomes\n",
    "budget_rxn_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.dilution\"]\n",
    "budget_met_prefix = DEFAULT_PREFIX_SUFFIX_VALUES[\"budgets\"][\"prefix.metabolite\"]\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW.loc[\n",
    "    :, df_mg_prot_per_gDW.columns.isin(HB_PROTEINS.values())\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW.loc[\n",
    "    :, ~df_mg_prot_per_gDW.columns.isin(HB_PROTEINS.values())\n",
    "]\n",
    "\n",
    "df_summary = {\n",
    "    \"Perfect total\": 1000,\n",
    "    \"Current total\": df_mg_prot_per_gDW.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Hemoglobin total\": df_mg_prot_per_gDW_hb.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Low abundance total\": df_mg_prot_per_gDW_la.loc[sample_ids]\n",
    "    .sum(axis=1)\n",
    "    .mean()\n",
    "    .item(),\n",
    "}\n",
    "df_summary[\"Remaining/Excess\"] = df_summary[\"Perfect total\"] - (\n",
    "    df_summary[\"Hemoglobin total\"] + df_summary[\"Low abundance total\"]\n",
    ")\n",
    "\n",
    "budget_rxn_proteome = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}proteome\"\n",
    ")\n",
    "budget_rxn_hemoglobin = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}hemoglobin\"\n",
    ")\n",
    "budget_rxn_total = pcmodel.reactions.get_by_id(\n",
    "    f\"{budget_rxn_prefix}{budget_met_prefix}total\"\n",
    ")\n",
    "\n",
    "if budget_la_value is None:\n",
    "    budget_la_value = budget_rxn_proteome.upper_bound\n",
    "if budget_hb_value is None:\n",
    "    budget_hb_value = budget_rxn_hemoglobin.upper_bound\n",
    "if budget_total_value is None:\n",
    "    budget_total_value = budget_rxn_total.upper_bound\n",
    "\n",
    "assert budget_total_value >= (budget_la_value + budget_hb_value)\n",
    "\n",
    "budget_rxn_proteome.upper_bound = budget_la_value\n",
    "budget_rxn_hemoglobin.upper_bound = budget_hb_value\n",
    "budget_rxn_total.upper_bound = budget_total_value\n",
    "\n",
    "# Scale values for low abundance proteome\n",
    "budget_value = budget_la_value\n",
    "df_mg_prot_per_gDW_la = (\n",
    "    budget_value * (df_mg_prot_per_gDW_la.T / df_mg_prot_per_gDW_la.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Low abundance scaled\"] = budget_value\n",
    "\n",
    "# Scale values for hemoglobin proteome\n",
    "budget_value = budget_hb_value\n",
    "df_mg_prot_per_gDW_hb = (\n",
    "    budget_value * (df_mg_prot_per_gDW_hb.T / df_mg_prot_per_gDW_hb.sum(axis=1)).T\n",
    ")\n",
    "df_summary[\"Hemoglobin scaled\"] = budget_value\n",
    "\n",
    "budget_value = budget_total_value - sum([budget_la_value, budget_hb_value])\n",
    "df_summary[\"Remaining scaled\"] = budget_value\n",
    "\n",
    "# Combine dataframes back into one\n",
    "df_mg_prot_per_gDW_normalized = pd.concat(\n",
    "    (df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la), axis=1\n",
    ")\n",
    "df_summary = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \" \" * max(30 - len(k), 0) + k: [f\"{v:.4f}\", f\"{v / 1000 * 100:.1f}%\"]\n",
    "        for k, v in df_summary.items()\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"mg protein / gDW / cell\", \"Percentage\"],\n",
    ")\n",
    "print(df_summary)\n",
    "df_mg_prot_per_gDW_normalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2c529-58f3-4fce-9c7b-d41f11e2f09b",
   "metadata": {},
   "source": [
    "### Convert mg / gDW to nmol / gDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5ef09-c5a2-4985-b9c7-9d26d593d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmol_prot_per_gDW = (\n",
    "    df_mg_prot_per_gDW_normalized  # mg / gDW\n",
    "    * (1 / df_uniprot_to_mw)  # mol / g --> mmol / mg\n",
    "    * (1e6 / 1)  # nmol / mmol\n",
    ").loc[:, df_mg_prot_per_gDW_normalized.columns]\n",
    "df_nmol_prot_per_gDW = df_nmol_prot_per_gDW.T\n",
    "df_nmol_prot_per_gDW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce81e95-0e7f-46a4-b1c8-b16e958155cd",
   "metadata": {},
   "source": [
    "## Create DataFrame for protein dilution reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7d9d3-4a84-4840-98f9-d080c6cf7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_protein_dilutions = pd.concat(\n",
    "    (\n",
    "        pd.Series(\n",
    "            {g.annotation.get(\"uniprot\"): g.id for g in model.genes}, name=\"genes\"\n",
    "        ),\n",
    "        pd.Series(\n",
    "            {\n",
    "                protdl.annotation.get(\"uniprot\"): protdl.id\n",
    "                for protdl in pcmodel.reactions.query(\n",
    "                    lambda x: isinstance(x, ProteinDilution)\n",
    "                )\n",
    "            },\n",
    "            name=\"PROTDL\",\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ").dropna()\n",
    "df_model_protein_dilutions.index.name = \"uniprot\"\n",
    "df_model_protein_dilutions = df_model_protein_dilutions[\n",
    "    df_model_protein_dilutions[\"genes\"].isin(model.genes.list_attr(\"id\"))\n",
    "].sort_values(\"PROTDL\")\n",
    "df_model_protein_dilutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a5311-87f7-4d17-a0f2-9eef9c4b52d3",
   "metadata": {},
   "source": [
    "## Organize samples (optional)\n",
    "Use this for organizing samples if time-outs are an issue or multiple runs are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dec939-1e59-44da-bf9c-bda1f2273ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_nmol_prot_per_gDW.copy()\n",
    "df_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fe128-1107-4bbb-a102-0477a5042fd4",
   "metadata": {},
   "source": [
    "### Map samples to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fac1a-e134-438d-942e-d04e61bf5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_key = \"uniprot\"\n",
    "df_samples.index.name = merge_key\n",
    "\n",
    "df_model = (\n",
    "    df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "    .merge(df_samples, left_index=True, right_index=True, how=\"left\")\n",
    "    .set_index(\"PROTDL\")\n",
    "    .sort_index()\n",
    ")\n",
    "no_experimental_measurements = [\n",
    "    protein_dilution\n",
    "    for protein_dilution, has_measurement in df_model.isna().all(axis=1).items()\n",
    "    if has_measurement\n",
    "]\n",
    "print(\n",
    "    f\"Model proteins mapped to measurements: {len(df_model) - len(no_experimental_measurements)}\"\n",
    ")\n",
    "print(f\"Model proteins without measurements: {len(no_experimental_measurements)}\")\n",
    "df_model[~df_model.isna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dac07-92c5-4c3d-9bfd-90f4d455ff9f",
   "metadata": {},
   "source": [
    "#### Summarize mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad923fc-2763-4b22-917f-dc1c9e95f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_proteins = set(df_samples.index)\n",
    "model_proteins = set(df_model_protein_dilutions.index)\n",
    "\n",
    "df_mg_prot_per_gDW_hb = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [\n",
    "        x\n",
    "        for x in df_mg_prot_per_gDW_normalized.columns\n",
    "        if x in list(HB_PROTEINS.values())\n",
    "    ],\n",
    "]\n",
    "df_mg_prot_per_gDW_la = df_mg_prot_per_gDW_normalized.loc[\n",
    "    [\n",
    "        x for x in df_mg_prot_per_gDW_normalized.index if x in sample_ids\n",
    "    ],  # Don't include operation IDs\n",
    "    [x for x in df_mg_prot_per_gDW.columns if not x in list(HB_PROTEINS.values())],\n",
    "]\n",
    "\n",
    "df_mapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_la = df_mg_prot_per_gDW_la.loc[\n",
    "    :, ~df_mg_prot_per_gDW_la.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_mapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "df_unmapped_mass_hb = df_mg_prot_per_gDW_hb.loc[\n",
    "    :, ~df_mg_prot_per_gDW_hb.columns.isin(model_proteins)\n",
    "].sum(axis=1)\n",
    "\n",
    "proteomes = {}\n",
    "round_int = 6\n",
    "for label, df in zip(\n",
    "    [\"hemoglobin\", \"low abundance\"], [df_mg_prot_per_gDW_hb, df_mg_prot_per_gDW_la]\n",
    "):\n",
    "    df_modeled = df.loc[:, df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    df_remaining = df.loc[:, ~df.columns.isin(model_proteins)].sum(axis=1)\n",
    "    means = (df_modeled.mean(), df_remaining.mean())\n",
    "    stdevs = (df_modeled.std(), df_remaining.std())\n",
    "    proteomes[(label, \"modeled\")] = round(means[0], round_int)\n",
    "    proteomes[(label, \"remaining\")] = round(means[1], round_int)\n",
    "proteomes = pd.Series(proteomes, name=\"Mean value across samples\")\n",
    "proteomes.index = [f\"Mean {k[0]} mass {k[1]}\" for k in proteomes.index]\n",
    "print(proteomes.head())\n",
    "proteomes = proteomes[proteomes != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb813d-d140-4bda-a422-d86c1806fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(3, 6))\n",
    "subsets = (\n",
    "    len(dataset_proteins),\n",
    "    len(model_proteins),\n",
    "    len(dataset_proteins.intersection(model_proteins)),\n",
    ")\n",
    "\n",
    "\n",
    "venn = mpl_venn.venn2(\n",
    "    subsets=subsets,\n",
    "    set_labels=(dataset_name, model.id),\n",
    "    set_colors=(\"red\", \"blue\"),\n",
    "    alpha=0.5,\n",
    "    ax=ax1,\n",
    ")\n",
    "circles = mpl_venn.venn2_circles(\n",
    "    subsets=subsets, linestyle=\"-\", color=\"black\", ax=ax1, linewidth=1\n",
    ")\n",
    "for text in venn.set_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "for text in venn.subset_labels:\n",
    "    text.set_fontsize(\"x-large\")\n",
    "ax1.set_title(\"Modeled proteome\", fontsize=\"xx-large\")\n",
    "\n",
    "\n",
    "label_color_map = {\n",
    "    \"Mean hemoglobin mass modeled\": (\"Hemoglobin\", \"xkcd:dark red\"),\n",
    "    \"Mean low abundance mass modeled\": (\"Low abundance\", \"xkcd:light blue\"),\n",
    "    \"Mean low abundance mass remaining\": (\"Not modeled\", \"xkcd:green\"),\n",
    "}\n",
    "edgecolor = \"black\"\n",
    "linewidth = 1\n",
    "ax2.pie(\n",
    "    x=proteomes.values,\n",
    "    colors=[label_color_map[k][1] for k in proteomes.index],\n",
    "    pctdistance=1.35,\n",
    "    counterclock=False,\n",
    "    autopct=lambda pct: f\"{pct * 1000/100:.2f}\\n\",\n",
    "    textprops=dict(fontsize=\"large\", ha=\"center\", va=\"top\"),\n",
    "    wedgeprops=dict(edgecolor=edgecolor, linewidth=linewidth),\n",
    ")\n",
    "handles = [\n",
    "    mpl.patches.Patch(\n",
    "        edgecolor=edgecolor,\n",
    "        linewidth=linewidth,\n",
    "        label=label_color_map[k][0],\n",
    "        facecolor=label_color_map[k][1],\n",
    "    )\n",
    "    for k in proteomes.index\n",
    "]\n",
    "ax2.legend(\n",
    "    handles=handles,\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.5, 0),\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    frameon=False,\n",
    ")\n",
    "ax2.set_xlabel(\"Mass (mg/gDW)\", fontsize=\"large\", labelpad=-10)\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        results_dirpath / f\"ModeledProteome.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )\n",
    "fig;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b212aa-2689-4cd1-b5b8-08c57ad6aaba",
   "metadata": {},
   "source": [
    "## Create QP model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904c726-a9d6-4890-a74f-09a6fd3b9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_qp(pcmodel, df):\n",
    "    x = []  # Variables\n",
    "    c = []  # Data * Weights\n",
    "    F = []  # Weights\n",
    "\n",
    "    for protdl, (data_value, weight) in df.iterrows():\n",
    "        protdl = pcmodel.reactions.get_by_id(protdl)\n",
    "        x.append(protdl.flux_expression)\n",
    "        c.append(weight * data_value)\n",
    "        F.append(weight)\n",
    "\n",
    "    x = sympy.Matrix(x)\n",
    "    c = sympy.Matrix(c)\n",
    "    F = sympy.DiagMatrix(sympy.Matrix(F))\n",
    "    # # QP Objective must be in form of 0.5 * x.T * F * x - c.T * x\n",
    "    objective = 0.5 * x.T * F * x - c.T * x\n",
    "    pcmodel.objective = objective[0]\n",
    "    pcmodel.objective_direction = \"min\"\n",
    "    pcmodel.tolerance = 1e-9\n",
    "\n",
    "    qp_sol = pcmodel.optimize()\n",
    "    return qp_sol\n",
    "\n",
    "\n",
    "def solve_qp_for_samples(\n",
    "    pcmodel, df_samples, df_weights=None, log_zero_replacement=1e-6, verbose=False\n",
    "):\n",
    "    qp_solutions_dict = {}\n",
    "    for sample_id, data_series in df_samples.items():\n",
    "        # Get protein values\n",
    "        data_series.name = \"Data\"\n",
    "        if df_weights is None:\n",
    "            data_weights = 1 / data_series.replace(0, 1)\n",
    "            data_weights = data_weights / data_weights.mean()\n",
    "        else:\n",
    "            data_weights = df_weights.loc[:, sample_id]\n",
    "        # Get protein weights\n",
    "        data_weights.name = \"Weights\"\n",
    "\n",
    "        # Map to model, currently model mapping DataFrame generated outside scope of function\n",
    "        df_model_data_weights = (\n",
    "            df_model_protein_dilutions[[\"PROTDL\"]]\n",
    "            .merge(data_series, left_index=True, right_index=True, how=\"left\")\n",
    "            .merge(data_weights, left_index=True, right_index=True, how=\"left\")\n",
    "            .set_index(\"PROTDL\")\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "        df = (\n",
    "            df_model_data_weights.loc[:, [data_series.name, data_weights.name]]\n",
    "            .dropna(axis=0, how=\"all\")\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "        with pcmodel:\n",
    "            qp_sol = solve_qp(pcmodel, df)\n",
    "\n",
    "        df_qp_sol = qp_sol.fluxes.loc[\n",
    "            pcmodel.reactions.query(lambda x: isinstance(x, ProteinDilution)).list_attr(\n",
    "                \"id\"\n",
    "            )\n",
    "        ]\n",
    "        df_qp_sol = (\n",
    "            pd.concat((df_model_data_weights, df_qp_sol), axis=1).dropna().sort_index()\n",
    "        )\n",
    "        # data_weights = df_qp_sol.loc[:, \"Weights\"]\n",
    "\n",
    "        df_qp_sol = df_qp_sol.rename(\n",
    "            {\"Data\": \"Measured Proteome\", \"fluxes\": \"Best-Fitted Proteome\"}, axis=1\n",
    "        )\n",
    "        df_qp_sol = df_qp_sol.loc[:, [\"Measured Proteome\", \"Best-Fitted Proteome\"]]\n",
    "\n",
    "        df = df_qp_sol.copy()\n",
    "        r2 = r2_score(\n",
    "            df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "        )\n",
    "\n",
    "        df = df_qp_sol.apply(\n",
    "            lambda x: [\n",
    "                log_zero_replacement if np.isclose(y, 0, atol=1e-12) else y for y in x\n",
    "            ]\n",
    "        ).apply(np.log10)\n",
    "        r2_log10_w_outliers = r2_score(\n",
    "            df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "        )\n",
    "\n",
    "        df = df_qp_sol[\n",
    "            ~df_qp_sol.apply(lambda x: np.isclose(x, 0).any(), axis=1)\n",
    "        ].apply(np.log10)\n",
    "        r2_log10_wo_outliers = r2_score(\n",
    "            df.iloc[:, 0].values, df.iloc[:, 1].values, multioutput=\"uniform_average\"\n",
    "        )\n",
    "        r2_values = (r2, r2_log10_w_outliers, r2_log10_wo_outliers)\n",
    "        qp_solutions_dict[sample_id] = (df_qp_sol, qp_sol.objective_value, r2_values)\n",
    "        if verbose:\n",
    "            # Recall that the objective is designed to try to minimize fitting error via maximizing R2, so 1 is a possibility\n",
    "            print(\n",
    "                \"Sample '{}'\\tR^2: {:.4f}\\tR^2 log10 w/outliers: {:.4f}\\tR^2 log10 wo/outliers: {:.4f}\\tObjective: {:.5f}\".format(\n",
    "                    sample_id, *r2_values, qp_sol.objective_value\n",
    "                )\n",
    "            )\n",
    "        # TODO catch bad fits\n",
    "\n",
    "    return qp_solutions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c865bd-1409-400d-9e1f-d8ad5c9c9093",
   "metadata": {},
   "source": [
    "### Set weightings for QP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9a9e24-5841-476b-84fd-cfe3d48237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is provided as (Protein IDs x Sample IDs)\n",
    "# Use original copy number values for weights\n",
    "df_weights = df_weighting_mat.T.loc[df_protein_data.index, df_samples.columns]\n",
    "df_weights = 1 / df_weights.infer_objects(copy=False).replace(0, 1)\n",
    "df_weights /= df_weights.mean()\n",
    "df_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26650249-5e1d-4f13-98a6-5529d91fd21f",
   "metadata": {},
   "source": [
    "### Fit data by solving QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7609232-c234-4f93-b438-d3cfbe8d36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_zero_replacement = 1e-9\n",
    "fitting_data = {\"measured\": {}, \"best_fit\": {}, \"r2_objective\": {}}\n",
    "if run_computations:\n",
    "    qp_solutions_dict = solve_qp_for_samples(\n",
    "        pcmodel,\n",
    "        df_samples,\n",
    "        df_weights=df_weights,\n",
    "        log_zero_replacement=log_zero_replacement,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    for sample_id, (\n",
    "        df_qp_sol,\n",
    "        objective_value,\n",
    "        r2_values,\n",
    "    ) in qp_solutions_dict.items():\n",
    "        fitting_data[\"measured\"][sample_id] = df_qp_sol[\"Measured Proteome\"].to_dict()\n",
    "        fitting_data[\"best_fit\"][sample_id] = df_qp_sol[\n",
    "            \"Best-Fitted Proteome\"\n",
    "        ].to_dict()\n",
    "        fitting_data[\"r2_objective\"][sample_id] = {\n",
    "            \"Objective\": objective_value,\n",
    "            \"R^2\": r2_values[0],\n",
    "            \"R^2 log10 w/ outliers\": r2_values[1],\n",
    "            \"R^2 log10 w/o outliers\": r2_values[2],\n",
    "        }\n",
    "    for key, data in fitting_data.items():\n",
    "        data = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        data.to_csv(fitting_dirpath / f\"proteome_{key}.csv\", index=True)\n",
    "        fitting_data[key] = data\n",
    "else:\n",
    "    for key in fitting_data.keys():\n",
    "        fitting_data[key] = pd.read_csv(\n",
    "            fitting_dirpath / f\"proteome_{key}.csv\", index_col=0\n",
    "        )\n",
    "    qp_solutions_dict = {}\n",
    "    for sample_id in df_samples.columns:\n",
    "        df_qp_sol = pd.concat(\n",
    "            (\n",
    "                fitting_data[\"measured\"].loc[:, sample_id],\n",
    "                fitting_data[\"best_fit\"].loc[:, sample_id],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        df_qp_sol.columns = [\"Measured Proteome\", \"Best-Fitted Proteome\"]\n",
    "        r2_values = fitting_data[\"r2_objective\"].loc[:, sample_id].values\n",
    "        objective_value, r2_values = r2_values[0], r2_values[1:]\n",
    "        qp_solutions_dict[sample_id] = (df_qp_sol, objective_value, r2_values)\n",
    "print(f\"Number of QP solutions: {len(qp_solutions_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8846cf-1031-4335-b50c-bc97a67b0573",
   "metadata": {},
   "source": [
    "### Plot fitting \n",
    "#### For the mean and median samples of each time point and for each chosen phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013de636-0daf-45ec-9609-43115300d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_plot = np.array(\n",
    "    [\n",
    "        # Best for 1 or 3 columns\n",
    "        [x for x in operation_ids if (timepoint in x and phenotype in x)]\n",
    "        for phenotype in phenotypes\n",
    "        for timepoint in timepoints\n",
    "    ]\n",
    ").T\n",
    "samples_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185fc86-7702-44f6-b293-95ab659d9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_text_loc = \"upper left\"\n",
    "transform = False\n",
    "\n",
    "length = 4\n",
    "nrows, ncols = samples_to_plot.shape\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(length * ncols, length * nrows),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "sns.despine(fig)\n",
    "for idx, (sample_id, ax) in enumerate(zip(samples_to_plot.flatten(), axes.flatten())):\n",
    "    df_qp_sol, objective_value, r2_values = qp_solutions_dict[sample_id]\n",
    "    # Copy to prevent alterations to the original\n",
    "    df_qp_sol = df_qp_sol.copy()\n",
    "    xlabel, ylabel = df_qp_sol.columns\n",
    "\n",
    "    ticks = 10 ** np.arange(*np.log10([log_zero_replacement, 1e8]), 3)\n",
    "    if transform:\n",
    "        ticks = np.log10(ticks)\n",
    "        df_qp_sol.iloc[:, 0] = (\n",
    "            df_qp_sol.iloc[:, 0]\n",
    "            .apply(lambda x: log_zero_replacement if np.isclose(x, 0) else x)\n",
    "            .apply(np.log10)\n",
    "        )\n",
    "        df_qp_sol.iloc[:, 1] = (\n",
    "            df_qp_sol.iloc[:, 1]\n",
    "            .apply(lambda x: log_zero_replacement if np.isclose(x, 0) else x)\n",
    "            .apply(np.log10)\n",
    "        )\n",
    "    perfect_fit_line = ax.plot(\n",
    "        [ticks[0], ticks[-1]],\n",
    "        [ticks[0], ticks[-1]],\n",
    "        linestyle=\":\",\n",
    "        color=\"black\",\n",
    "        linewidth=1,\n",
    "        alpha=1,\n",
    "    )\n",
    "\n",
    "    zero_val = 0 if not transform else np.log10(log_zero_replacement)\n",
    "\n",
    "    df_zeros = df_qp_sol[\n",
    "        (df_qp_sol.apply(lambda x: np.isclose(x, zero_val))).any(axis=1)\n",
    "    ]\n",
    "    df_perfect = df_qp_sol[\n",
    "        np.isclose(\n",
    "            abs(df_qp_sol[\"Measured Proteome\"] - df_qp_sol[\"Best-Fitted Proteome\"]), 0\n",
    "        )\n",
    "    ]\n",
    "    df_perfect = df_perfect[~df_perfect.index.isin(df_zeros.index)]\n",
    "\n",
    "    df_altered = df_qp_sol[\n",
    "        ~np.isclose(\n",
    "            abs(df_qp_sol[\"Measured Proteome\"] - df_qp_sol[\"Best-Fitted Proteome\"]), 0\n",
    "        )\n",
    "    ]\n",
    "    df_altered = df_altered[~df_altered.index.isin(df_zeros.index)]\n",
    "    df_always_zero = df_zeros[(df_zeros == zero_val).all(axis=1)]\n",
    "    df_zeros = df_zeros[~df_zeros.index.isin(df_always_zero.index)]\n",
    "    df_from_zeros = df_zeros[np.isclose(df_zeros[\"Measured Proteome\"], zero_val)]\n",
    "    df_to_zeros = df_zeros[np.isclose(df_zeros[\"Best-Fitted Proteome\"], zero_val)]\n",
    "\n",
    "    handles = [\n",
    "        ax.scatter(\n",
    "            data=df_perfect.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:blue\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_altered.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:yellow\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_from_zeros.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:green\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_to_zeros.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:red\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "        ax.scatter(\n",
    "            data=df_always_zero.replace(0, ticks[0]),\n",
    "            x=xlabel,\n",
    "            y=ylabel,\n",
    "            color=\"xkcd:black\",\n",
    "            alpha=0.5,\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1,\n",
    "        ),\n",
    "    ]\n",
    "    labels = [\n",
    "        f\"Perfect fit\",\n",
    "        f\"Adjusted abundance\",\n",
    "        f\"Unexpressed to expressed\",\n",
    "        f\"Expressed to unexpressed\",\n",
    "        f\"Never expressed\",\n",
    "    ]\n",
    "\n",
    "    op, time, phenotype = str(sample_id.replace(f\"{pcmodel.id}_\", \"\")).split(\"_\")\n",
    "    sample_label = \" \".join((op, time, phenotype))\n",
    "\n",
    "    if not transform:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "    fontdict = {\"size\": \"xx-large\"}\n",
    "    if idx >= len(samples_to_plot.flatten()) - ncols:\n",
    "        ax.set_xlabel(xlabel, fontdict=fontdict)\n",
    "    fig.legend(\n",
    "        handles=handles,\n",
    "        labels=labels,\n",
    "        loc=\"upper center\",\n",
    "        ncols=len(labels),\n",
    "        frameon=False,\n",
    "        fontsize=\"large\",\n",
    "        markerscale=2,\n",
    "        bbox_to_anchor=(0.5, -0.01),\n",
    "    )\n",
    "    if idx % ncols == 0:\n",
    "        ax.set_ylabel(ylabel, fontdict=fontdict)\n",
    "\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "\n",
    "    ax.xaxis.set_tick_params(labelsize=\"x-large\")\n",
    "    ax.yaxis.set_tick_params(labelsize=\"x-large\")\n",
    "\n",
    "    r2_format = \" = {:.4f}\"\n",
    "    if r2_text_loc == \"lower right\":\n",
    "        ax.text(\n",
    "            0.95,\n",
    "            0.1,\n",
    "            \"\\n\".join(\n",
    "                (\n",
    "                    sample_label,\n",
    "                    r\"$R^{2}$\" + r2_format.format(r2_values[0]),\n",
    "                    r\"$R^{2}\\text{log}_{10}\\text{ w/  outliers}$\"\n",
    "                    + r2_format.format(r2_values[1]),\n",
    "                    r\"$R^{2}\\text{log}_{10}\\text{ w/o outliers}$\"\n",
    "                    + r2_format.format(r2_values[2]),\n",
    "                )\n",
    "            ),\n",
    "            transform=ax.transAxes,\n",
    "            color=\"black\",\n",
    "            fontsize=\"medium\",\n",
    "            ha=\"right\",\n",
    "        )\n",
    "    elif r2_text_loc == \"upper left\":\n",
    "        ax.text(\n",
    "            0.05,\n",
    "            0.8,\n",
    "            \"\\n\".join(\n",
    "                (\n",
    "                    sample_label,\n",
    "                    r\"$R^{2}$\" + r2_format.format(r2_values[0]),\n",
    "                    r\"$R^{2}\\text{log}_{10}\\text{ w/  outliers}$\"\n",
    "                    + r2_format.format(r2_values[1]),\n",
    "                    r\"$R^{2}\\text{log}_{10}\\text{ w/o outliers}$\"\n",
    "                    + r2_format.format(r2_values[2]),\n",
    "                )\n",
    "            ),\n",
    "            transform=ax.transAxes,\n",
    "            color=\"black\",\n",
    "            fontsize=\"medium\",\n",
    "            ha=\"left\",\n",
    "        )\n",
    "    else:\n",
    "        pass\n",
    "fig.tight_layout()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath\n",
    "        / f\"QPfitting_{'' if not transform else 'log10_'}{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3095c-dd82-45c1-b076-c51d9f87b200",
   "metadata": {},
   "source": [
    "### Determine best value for slack variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186a162-7be4-4a53-812d-cfd18e012316",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_determination_models = samples_to_plot.flatten()\n",
    "list_of_pcmodels = []\n",
    "for sample_id in slack_determination_models:\n",
    "    df_qp_sol, objective_value, r2_values = qp_solutions_dict[sample_id]\n",
    "    # Create a copy of the model\n",
    "    pcmodel_sample = pcmodel.copy()\n",
    "    pcmodel_sample.id = f\"{pcmodel.id}_{sample_id}\"\n",
    "    for protdl in pcmodel_sample.reactions.query(\n",
    "        lambda x: isinstance(x, ProteinDilution)\n",
    "    ):\n",
    "        if protdl.id in df_qp_sol.index:\n",
    "            prot_bound = df_qp_sol.loc[protdl.id][\"Best-Fitted Proteome\"]\n",
    "        else:\n",
    "            prot_bound = 0\n",
    "        protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "    # Add the relaxation budget with slack = 0 first\n",
    "    add_relaxation_budget(pcmodel_sample, 0, int(verbose))\n",
    "    list_of_pcmodels += [pcmodel_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9031c0-89d3-474a-800d-0138c7ce341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_min = 1e-5  # Slack %\n",
    "slack_max = 1.5\n",
    "if run_computations:\n",
    "    solutions = {\n",
    "        pcmodel_sample.id: defaultdict(list) for pcmodel_sample in list_of_pcmodels\n",
    "    }\n",
    "    for slack_value in np.geomspace(slack_min, slack_max, 101):\n",
    "        if int(verbose):\n",
    "            print(f\"Updating slack variable to {slack_value:.4%}.\")\n",
    "        for pcmodel_sample in list_of_pcmodels:\n",
    "            update_slack_value(pcmodel_sample, slack_value, verbose=False)\n",
    "            budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(\n",
    "                f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\"\n",
    "            )\n",
    "            pcmodel_sample.objective = (\n",
    "                sum(\n",
    "                    [\n",
    "                        r.flux_expression\n",
    "                        for r in pcmodel_sample.reactions.get_by_any(\n",
    "                            objective_reactions\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "                - budget_rxn_relaxation.flux_expression\n",
    "            )\n",
    "            pcmodel_sample.objective_direction = \"max\"\n",
    "            sol = pcmodel_sample.optimize()\n",
    "            obj_value = sol.objective_value\n",
    "            if not obj_value or np.isnan(obj_value):\n",
    "                if int(verbose) > 1:\n",
    "                    print(f\"No solution for {slack_value:.4%}%\\n.\")\n",
    "                continue\n",
    "            else:\n",
    "                demand = budget_rxn_relaxation.flux\n",
    "                budget = budget_rxn_relaxation.upper_bound\n",
    "            solutions[pcmodel_sample.id][\"model\"].append(pcmodel_sample.id)\n",
    "            solutions[pcmodel_sample.id][\"slack\"].append(slack_value)\n",
    "            solutions[pcmodel_sample.id][\"objective\"].append(obj_value)\n",
    "            solutions[pcmodel_sample.id][\"_\".join(objective_reactions)].append(\n",
    "                obj_value + demand\n",
    "            )\n",
    "            solutions[pcmodel_sample.id][\"relaxation\"].append(demand / budget)\n",
    "    solutions = {\n",
    "        pcmodel_sample_id: pd.DataFrame.from_dict(sol)\n",
    "        for pcmodel_sample_id, sol in solutions.items()\n",
    "    }\n",
    "    df_relaxation = pd.concat(list(solutions.values()), axis=0)\n",
    "    df_relaxation.to_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "else:\n",
    "    df_relaxation = pd.read_csv(\n",
    "        fitting_dirpath / f\"SlackPercentDeterminationData_{model_id}.csv\",\n",
    "    )\n",
    "    solutions = {\n",
    "        mid: df_relaxation[df_relaxation[\"model\"] == mid].drop(\"model\", axis=1)\n",
    "        for mid in df_relaxation[\"model\"].unique()\n",
    "    }\n",
    "df_relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af66c52-b294-4cb2-8961-5d9560d9caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_slack_var = 0.03\n",
    "colors = {\n",
    "    \"Pre_HumCan\": \"xkcd:light green\",\n",
    "    \"Pre_MED\": \"xkcd:light blue\",\n",
    "    \"Pre_A\": \"xkcd:light red\",\n",
    "    \"Post_HumCan\": \"xkcd:green\",\n",
    "    \"Post_MED\": \"xkcd:blue\",\n",
    "    \"Post_A\": \"xkcd:red\",\n",
    "    \"TD_HumCan\": \"xkcd:dark green\",\n",
    "    \"TD_MED\": \"xkcd:dark blue\",\n",
    "    \"TD_A\": \"xkcd:dark red\",\n",
    "}\n",
    "linestyles = {\n",
    "    \"Mean\": \"--\",\n",
    "    \"Median\": \"-.\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    3, 1, figsize=(4, 10), sharex=True, gridspec_kw=dict(hspace=0.05)\n",
    ")\n",
    "axes = axes.flatten()\n",
    "sns.despine(fig)\n",
    "for pcmodel_sample in list(solutions):\n",
    "    op, group = pcmodel_sample.replace(f\"{pcmodel.id}_\", \"\").split(\"_\", maxsplit=1)\n",
    "    color = colors.get(group, \"xkcd:black\")\n",
    "    linestyle = linestyles.get(op, \":\")\n",
    "    s_values = solutions[str(pcmodel_sample)][\"slack\"].values\n",
    "    r_values = solutions[str(pcmodel_sample)][\"relaxation\"].values\n",
    "    o_values = solutions[str(pcmodel_sample)][\"objective\"].values\n",
    "    rxn_values = solutions[str(pcmodel_sample)][\"_\".join(objective_reactions)].values\n",
    "\n",
    "    zorder = 1\n",
    "    lw = 2\n",
    "    axes[0].plot(\n",
    "        s_values,\n",
    "        r_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        s_values,\n",
    "        o_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "    axes[2].plot(\n",
    "        s_values,\n",
    "        rxn_values,\n",
    "        label=str(pcmodel_sample),\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=lw,\n",
    "        zorder=zorder,\n",
    "    )\n",
    "\n",
    "fontdict = {\"size\": \"x-large\"}\n",
    "axes[-1].set_xlabel(r\"Slack variable $s$\", fontdict=fontdict)\n",
    "\n",
    "zorder = 2\n",
    "alpha = 0.7\n",
    "limit_pad_sclar = 1.2\n",
    "smin = s_values[0]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i == 0:\n",
    "        ymin, ymax = (\n",
    "            -0.001,\n",
    "            max(r_values) * limit_pad_sclar,\n",
    "        )\n",
    "    elif i == 1:\n",
    "        ymin, ymax = (\n",
    "            min(0, min(o_values) * 2) * limit_pad_sclar,\n",
    "            max(o_values) * limit_pad_sclar,\n",
    "        )\n",
    "    elif i == 2:\n",
    "        ymin, ymax = (0, max(rxn_values) * limit_pad_sclar)\n",
    "    else:\n",
    "        pass\n",
    "    ax.vlines(chosen_slack_var, ymin=ymin, ymax=ymax, color=\"black\", linestyle=\":\")\n",
    "    ax.vlines(\n",
    "        smin,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.vlines(\n",
    "        1,\n",
    "        ymin=ymin,\n",
    "        ymax=ymax,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=zorder,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    ax.set_xlim(smin / 2, slack_max)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xscale(\"log\")\n",
    "    if i == 0:\n",
    "        ax.annotate(\n",
    "            rf\"$s > 0$\",\n",
    "            xy=(smin, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s \\leq 1$\",\n",
    "            xy=(1, ymax),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(10, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"center\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "        ax.annotate(\n",
    "            rf\"$s = {chosen_slack_var}$\",\n",
    "            xy=(chosen_slack_var, 0),\n",
    "            xycoords=\"data\",\n",
    "            xytext=(5, 0),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"left\",\n",
    "            fontsize=fontdict[\"size\"],\n",
    "        )\n",
    "    ax.fill_between((smin / 2, smin), ymin, ymax, color=\"xkcd:light grey\")\n",
    "    ax.annotate(\n",
    "        \"Infeasible\",\n",
    "        xy=(smin, (ymax + ymin) / 2),\n",
    "        xycoords=\"data\",\n",
    "        rotation=90,\n",
    "        xytext=(-2, 0),\n",
    "        textcoords=\"offset points\",\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "        fontsize=fontdict[\"size\"],\n",
    "    )\n",
    "\n",
    "\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "labels = [label.replace(f\"{pcmodel.id}_\", \"\").replace(\"_\", \" \") for label in labels]\n",
    "axes[2].legend(\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    "    ncols=2,\n",
    "    frameon=False,\n",
    "    loc=\"upper center\",\n",
    "    fontsize=\"large\",\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    ")\n",
    "\n",
    "\n",
    "axes[0].set_ylabel(\"Relaxation budget used (%)\", fontdict=fontdict)\n",
    "axes[1].set_ylabel(\"Objective value\", fontdict=fontdict)\n",
    "axes[2].set_ylabel(f\"{'+'.join(objective_reactions)} (mmol/gDW/hr)\", fontdict=fontdict)\n",
    "\n",
    "fig.align_labels()\n",
    "if save_figures:\n",
    "    fig.savefig(\n",
    "        fitting_dirpath / f\"SlackPercentDetermination_{model_id}.{imagetype}\",\n",
    "        transparent=transparent,\n",
    "        format=imagetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44927e48-3ffc-4429-b7b5-737e6e597a5b",
   "metadata": {},
   "source": [
    "### Formulate models from QP solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e22910-d710-4539-b300-193821b896ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBML/XML loads faster, but will take up to 4x more space uncompressed as compared to JSON\n",
    "ftypes = {\n",
    "    \"xml\"\n",
    "    # \"json\",\n",
    "}\n",
    "\n",
    "slack_value = chosen_slack_var  # Slack %\n",
    "ftypes = set([ftypes]) if isinstance(ftypes, str) else set(ftypes)\n",
    "for sample_id, (df_qp_sol, objective_value, r2_values) in qp_solutions_dict.items():\n",
    "    # Create a copy of the model\n",
    "    sample_id = f\"{pcmodel.id}_{sample_id}\"\n",
    "    filenames = [sample_pcmodels_dirpath / f\"{sample_id}.{ftype}\" for ftype in ftypes]\n",
    "    if not overwrite and all([filename.exists() for filename in filenames]):\n",
    "        print(f\"Model already created for {sample_id}\")\n",
    "        continue\n",
    "    pcmodel_sample = pcmodel.copy()\n",
    "    pcmodel_sample.id = sample_id\n",
    "    for protdl in pcmodel_sample.reactions.query(\n",
    "        lambda x: isinstance(x, ProteinDilution)\n",
    "    ):\n",
    "        if protdl.id in df_qp_sol.index:\n",
    "            prot_bound = df_qp_sol.loc[protdl.id][\"Best-Fitted Proteome\"]\n",
    "        else:\n",
    "            prot_bound = 0\n",
    "        protdl.bounds = (float(prot_bound), float(prot_bound))\n",
    "    # Add the relaxation budget\n",
    "    add_relaxation_budget(pcmodel_sample, slack_value, verbose)\n",
    "    budget_rxn_relaxation = pcmodel_sample.reactions.get_by_id(\n",
    "        f\"{budget_rxn_prefix}{budget_met_prefix}relaxation\"\n",
    "    )\n",
    "    with pcmodel_sample:\n",
    "        pcmodel_sample.objective = budget_rxn_relaxation.flux_expression\n",
    "        pcmodel_sample.objective_direction = \"min\"\n",
    "        budget_min = pcmodel_sample.slim_optimize()\n",
    "        pcmodel_sample.objective_direction = \"max\"\n",
    "        budget_max = pcmodel_sample.slim_optimize()\n",
    "    budget_rxn_relaxation.bounds = (budget_min, budget_max)\n",
    "    # # Store model for later use\n",
    "    # list_of_relaxed_models += [pcmodel_sample]\n",
    "    for filename in filenames:\n",
    "        # Might as well overwrite all files, especially if model needed to be regenerated anyways\n",
    "        write_cobra_model(\n",
    "            pcmodel_sample,\n",
    "            filename=filename,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
