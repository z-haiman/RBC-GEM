{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6998b1a1-4fa9-44b4-9fce-03c832930b06",
   "metadata": {},
   "source": [
    "# Extract annotations and data from UniProtKB\n",
    "\n",
    "The purpose of this notebook is to extract and format UniProt data for subsequent model annotation.\n",
    "\n",
    "Additionally, the purpose of this notebook is to extract data and other annotations related to model proteins.\n",
    "\n",
    "## Notebook Requirements:\n",
    "*  Model genes **must** have the at least one of following annotations stored in the `object.annotation`. Values are expected to be seperated by semicolons. Accepted keys currently include:\n",
    "    * `\"uniprot\"`\n",
    "* Note: Requires internet connection to download information from the [Universal Protein Resource (UniProt)](https://www.uniprot.org/).\n",
    "    *  [UniProt Knowledgebase (UniProtKB)](https://www.uniprot.org/help/uniprotkb)\n",
    "\n",
    "### Citation\n",
    "UniProt Consortium. UniProt: the Universal Protein Knowledgebase in 2023. Nucleic Acids Res. 2023 Jan 6;51(D1):D523-D531. doi: 10.1093/nar/gkac1052. PMID: 36408920; PMCID: PMC9825514.\n",
    "\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce44ed-0166-4475-8553-ef1386860271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from warnings import warn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from rbc_gem_utils import (\n",
    "    GEM_NAME,\n",
    "    build_string,\n",
    "    check_database_release_online,\n",
    "    compare_tables,\n",
    "    get_annotation_df,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    split_string,\n",
    "    visualize_comparison,\n",
    ")\n",
    "from rbc_gem_utils.database.uniprot import (\n",
    "    UNIPROT_DB_TAG,\n",
    "    UNIPROT_RELEASE_EXPECTED,\n",
    "    get_annotation_to_from_db_UniProt,\n",
    "    get_isoform_value_from_entry_UniProt,\n",
    "    get_label_miriam_mapping_UniProt,\n",
    "    get_query_fields_UniProt,\n",
    "    parse_chains_UniProt,\n",
    "    parse_isoforms_UniProt,\n",
    "    query_UniProt,\n",
    ")\n",
    "\n",
    "# Display versions of last time notebook ran and worked\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bfc4f2-c893-4ed4-a4d4-baf467f48189",
   "metadata": {},
   "source": [
    "## Set notebook options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9d673-8056-46f6-8e4d-414e2c86fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tag = UNIPROT_DB_TAG\n",
    "expected_release = UNIPROT_RELEASE_EXPECTED\n",
    "\n",
    "compare_figsize = (5, 20)\n",
    "compare = True\n",
    "display_nunique = True\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211b3ea-a5ff-44c1-8f77-c8b462f3bd83",
   "metadata": {},
   "source": [
    "## Check UniProt release\n",
    "If the release does not match the expected release, it is because database has been updated since the last time this code was utilized. \n",
    "\n",
    "* According to [UniProt](https://www.uniprot.org/help/downloads), updates to the database are made every eight weeks.\n",
    "* If the current release does not match the expected release, it is because database has been updated since the last time this code was utilized.\n",
    "    * If the notebook works without needing any significant modifications, the only update needed is to the release in the [uniprot.py](../../src/rbc_gem_utils/database/uniprot.py) source code file to resolve the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4bcad-d09f-4ba8-9ea0-6fd1ea5e504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_interim = not check_database_release_online(db_tag, verbose=True, **{})\n",
    "# Use different directory paths for unexpected behavior\n",
    "if use_interim:\n",
    "    warn(\n",
    "        \"Online release of database has been updated since the last time notebook was used.\"\n",
    "    )\n",
    "\n",
    "\n",
    "database_dirpath = get_dirpath(\n",
    "    \"database\", db_tag, use_temp=\"interim\" if use_interim else None\n",
    ")\n",
    "annotation_dirpath = get_dirpath(\n",
    "    \"annotation\", use_temp=\"interim\" if use_interim else None\n",
    ")\n",
    "\n",
    "# Ensure directories exist\n",
    "database_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "annotation_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959dd950-5eb1-43c6-ad62-9845e1092c8c",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883c1ba-7456-4577-a312-93f6e64b4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirpath = get_dirpath(\"model\")\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{GEM_NAME}.xml\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163e266-4e4c-46ba-b3d2-954e809761e2",
   "metadata": {},
   "source": [
    "## Download data from UniProt\n",
    "\n",
    "### Get IDs for query\n",
    "#### Using an existing annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56491f-fa77-4a02-8ef3-873a256cd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "annotation_cols = [\"uniprot\"]\n",
    "mapping_key = \"uniprot\"\n",
    "\n",
    "df_model_mappings = (\n",
    "    get_annotation_df(model.genes, annotation_cols)\n",
    "    .rename({\"id\": annotation_type}, axis=1)\n",
    "    .dropna(subset=[mapping_key])\n",
    ")\n",
    "for col in df_model_mappings.columns:\n",
    "    df_model_mappings[col] = df_model_mappings[col].apply(lambda x: split_string(x))\n",
    "    df_model_mappings = df_model_mappings.explode(col).drop_duplicates().dropna()\n",
    "df_model_mappings = df_model_mappings.sort_values(annotation_type)\n",
    "\n",
    "print(df_model_mappings.nunique(dropna=True))\n",
    "df_model_mappings = df_model_mappings.reset_index(drop=True)\n",
    "df_model_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f4b35-8a7e-4ad7-b527-c8bd94d609ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_to_from_db = get_annotation_to_from_db_UniProt(miriam_only=True)\n",
    "\n",
    "from_db = annotation_to_from_db[mapping_key]\n",
    "query_ids = df_model_mappings[mapping_key].dropna().unique()\n",
    "assert len(set(query_ids)) == len(query_ids), \"Duplicate IDs in list to query\"\n",
    "model_search_mapping = df_model_mappings.set_index(annotation_type)[\n",
    "    mapping_key\n",
    "].to_dict()\n",
    "print(f\"Number of model genes associated with query: {len(model_search_mapping)}\")\n",
    "print(f\"Number of unique IDs to query: {len(query_ids)}\")\n",
    "df_model_mappings[[annotation_type, mapping_key]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0289e-d2cc-4049-89bb-5092b0745869",
   "metadata": {},
   "source": [
    "## Run queries\n",
    "### Set universal query parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb070231-0928-42a4-95bb-fae51692f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4e9ba-f7bf-4d7d-9666-3e9c6da4ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "miriam_query_fields = get_query_fields_UniProt(miriam_only=True)\n",
    "query_fields = miriam_query_fields + [\n",
    "    # Add additional non-miriam fields if desired\n",
    "    # Complex composition\n",
    "    \"cc_subunit\",\n",
    "    # Specific isoforms to include/avoid\n",
    "    \"cc_tissue_specificity\",\n",
    "    \"cc_subcellular_location\",\n",
    "    # Chromosome\n",
    "    \"xref_proteomes\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671ab8b-2533-41c9-9439-92bf4e50f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all relevant information for now and save\n",
    "query_parameters = {\n",
    "    \"query\": \" && \".join(\n",
    "        [\n",
    "            \"(reviewed:true)\",\n",
    "            \"(organism_id:9606)\",  # Homo sapiens (Human)\n",
    "        ]\n",
    "    ),\n",
    "    \"format\": \"tsv\",\n",
    "    \"size\": 500,\n",
    "    \"compressed\": True,\n",
    "    \"fields\": \",\".join(query_fields),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600afe7-ee56-4cdb-a1c8-f961c4a693ea",
   "metadata": {},
   "source": [
    "### Initial query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cd4e5-8e65-4df8-8c22-ceb2b30ec5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_key = \"initial\"\n",
    "df_results, uniparc, failed_ids, obselete_counts = query_UniProt(\n",
    "    list(query_ids),\n",
    "    query_parameters=query_parameters,\n",
    "    to_db=\"UniProtKB\",\n",
    "    from_db=from_db,\n",
    "    return_failed=True,\n",
    ")\n",
    "if failed_ids:\n",
    "    print(failed_ids)\n",
    "all_query_results[query_key] = df_results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c860d66-0b1f-448b-affc-4af6d4f6cabd",
   "metadata": {},
   "source": [
    "### Address failed IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa937d38-8515-4861-b894-793816c2fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retry_ids = {}\n",
    "# query_key = \"retry_1\"\n",
    "# df_results, failed_ids = query_UniProt(\n",
    "#     list(sorted(retry_ids.values())),\n",
    "#     from_db=\"UniProtKB\",\n",
    "#     query_parameters=query_parameters\n",
    "# )\n",
    "# if failed_ids:\n",
    "#     print(failed_ids)\n",
    "# all_query_results[query_key] = df_results\n",
    "# model_search_mapping.update({\n",
    "#     k: retry_ids[v] for k, v in model_search_mapping.items()\n",
    "#     if v in retry_ids and v not in failed_ids\n",
    "# })\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc698c3-d1e9-425b-9f7e-f4fe76e3e3fb",
   "metadata": {},
   "source": [
    "## Concat, cleanup, and save query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a9942-8a01-4756-9ade-09a12f948f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique queries: {len(all_query_results)}\")\n",
    "df_query_results = pd.concat(tuple(all_query_results.values()))\n",
    "df_query_results = df_query_results.set_index(\"From\").drop_duplicates()\n",
    "df_query_results = df_query_results.replace(\"\", pd.NA)\n",
    "df_query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fb93d-7ee3-4cfe-94e5-93b618aba809",
   "metadata": {},
   "source": [
    "### Save extracted data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316c163-b8dc-4e70-bd28-9f3db2bd731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save query results to external database\n",
    "df_database = df_query_results.reset_index(drop=True).drop_duplicates()\n",
    "if compare:\n",
    "    compare_on_index = [\"Entry\"]\n",
    "    try:\n",
    "        df_previous = pd.read_csv(\n",
    "            database_dirpath / f\"{db_tag}_{GEM_NAME}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df_previous = df_previous.replace(float(\"nan\"), pd.NA)\n",
    "    except FileNotFoundError:\n",
    "        df_previous = pd.DataFrame([], columns=compare_on_index)\n",
    "    df_comparision = compare_tables(\n",
    "        df_previous.set_index(compare_on_index), df_database.set_index(compare_on_index)\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=compare_figsize)\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    ax = visualize_comparison(df_comparision)\n",
    "\n",
    "\n",
    "if overwrite:\n",
    "    df_database.to_csv(\n",
    "        database_dirpath / f\"{db_tag}_{GEM_NAME}.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "\n",
    "df_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07d64c-8124-4cd8-bfd3-8f505596e78b",
   "metadata": {},
   "source": [
    "## Format UniProt information for annotation files\n",
    "### Genes\n",
    "#### Map to chosen MIRIAMs\n",
    "As formatting may be needed for some MIRIAMS, keep it simple for now until formatting methods are developed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf7e6e-171d-427e-b88c-52d5c9c80cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "\n",
    "# Keeping it simple for now, group items regardless of isoforms for the time being\n",
    "uniprot_miriam_mapping = get_label_miriam_mapping_UniProt(\n",
    "    get_query_fields_UniProt(miriam_only=True)\n",
    ")\n",
    "uniprot_miriam_mapping[\"Proteomes\"] = \"chromosome\"\n",
    "\n",
    "merge_key = {\n",
    "    v: k for k, v in uniprot_miriam_mapping.items() if v in df_model_mappings.columns\n",
    "}[mapping_key]\n",
    "df_annotations = df_model_mappings.set_index(mapping_key).merge(\n",
    "    df_database, left_index=True, right_on=merge_key, how=\"left\"\n",
    ")\n",
    "df_annotations = (\n",
    "    df_annotations.set_index(annotation_type)\n",
    "    .loc[:, list(uniprot_miriam_mapping)]\n",
    "    .rename(uniprot_miriam_mapping, axis=1)\n",
    ")\n",
    "uniprot_columns = [\"uniprot\", \"uniprot.isoform\", \"uniprot.chain\"]\n",
    "# For the most part, these columns do not require any reformatting or are easy to work with.\n",
    "annotation_columns = [\n",
    "    \"hgnc.symbol\",\n",
    "    \"ec-code\",\n",
    "    \"taxonomy\",\n",
    "    \"uniparc\",\n",
    "    # Reactions\n",
    "    \"rhea\",\n",
    "    # Gene Ontology (GO)\n",
    "    \"go\",\n",
    "    # Sequence\n",
    "    \"ccds\",\n",
    "    \"ena.embl\",\n",
    "    \"refseq\",\n",
    "    # 3D Structure\n",
    "    \"bmrb\",\n",
    "    \"pdb\",\n",
    "    \"sasbdb\",\n",
    "    \"smr\",\n",
    "    # Protein-protein interaction\n",
    "    \"biogrid\",\n",
    "    \"complexportal\",\n",
    "    \"dip\",\n",
    "    \"intact\",\n",
    "    # Chemistry databases\n",
    "    \"chembl.target\",\n",
    "    \"drugbank\",\n",
    "    \"iuphar.receptor\",\n",
    "    # Protein family/group databases\n",
    "    \"cazy\",\n",
    "    \"ideal\",\n",
    "    \"merops\",\n",
    "    \"peroxibase\",\n",
    "    \"tcdb\",\n",
    "    # Genetic variation/Polymorphism and mutation databases\n",
    "    \"dbsnp\",\n",
    "    # Proteomic databases\n",
    "    \"proteomicsdb.protein\",\n",
    "    # Genome annotation databases\n",
    "    \"ensembl\",\n",
    "    \"ncbigene\",\n",
    "    ## Organism-specific\n",
    "    \"kegg.genes\",\n",
    "    \"genecards\",\n",
    "    \"hgnc\",\n",
    "    \"hpa\",\n",
    "    \"mim\",\n",
    "    \"nextprot\",\n",
    "    \"orphanet\",\n",
    "    \"pharmgkb.gene\",\n",
    "    # Phylogenomic databases\n",
    "    \"eggnog\",\n",
    "    \"genetree\",\n",
    "    \"hogenom\",\n",
    "    \"oma.grp\",\n",
    "    \"orthodb\",\n",
    "    \"treefam\",\n",
    "    # Enzyme and pathway databases\n",
    "    \"biocyc\",\n",
    "    \"brenda\",\n",
    "    \"reactome\",\n",
    "    # Miscellaneous databases\n",
    "    \"genewiki\",\n",
    "    # Gene expression databases\n",
    "    \"bgee.gene\",\n",
    "    ## Family and domain databases\n",
    "    \"cdd\",\n",
    "    \"disprot\",\n",
    "    \"hamap\",\n",
    "    \"interpro\",\n",
    "    \"panther.family\",\n",
    "    \"pfam\",\n",
    "    \"pirsf\",\n",
    "    \"prints\",\n",
    "    \"prosite\",\n",
    "    \"smart\",\n",
    "    \"supfam\",\n",
    "    \"chromosome\",\n",
    "]\n",
    "df_annotations[\"chromosome\"] = df_annotations[\"chromosome\"].apply(\n",
    "    lambda x: x.split(\" \")[-1]\n",
    ")\n",
    "df_annotations = df_annotations.loc[:, uniprot_columns + annotation_columns]\n",
    "print(f\"Fields searched: {df_annotations.shape[1]}\")\n",
    "all_na = df_annotations.T[df_annotations.isna().all(axis=0)].index\n",
    "annotation_columns = [x for x in annotation_columns if x not in all_na]\n",
    "df_annotations = df_annotations.dropna(how=\"all\", axis=1)\n",
    "print(f\"Empty dropped: {len(all_na)}\")\n",
    "print(f\"Remaining: {df_annotations.shape[1]}\")\n",
    "df_annotations = df_annotations.reset_index(drop=False).replace(pd.NA, \"\")\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfc22e-b501-4665-b36e-ff0195f8ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isoforms = parse_isoforms_UniProt(\n",
    "    df_annotations.loc[:, [\"uniprot\", \"uniprot.isoform\"]].copy(), add_canonical=True\n",
    ")\n",
    "\n",
    "df_canonical = df_isoforms[df_isoforms[\"uniprot.canonical\"].apply(bool)].set_index(\n",
    "    \"uniprot\"\n",
    ")\n",
    "df_canonical = df_canonical.apply(\n",
    "    lambda x: x[\"uniprot.isoform\"] if x[\"uniprot.isoform\"] else x.name, axis=1\n",
    ")\n",
    "df_isoforms = df_isoforms.groupby(\"uniprot\")[[\"uniprot.isoform\"]].agg(\n",
    "    lambda x: build_string(x)\n",
    ")\n",
    "\n",
    "df_chains = parse_chains_UniProt(\n",
    "    df_annotations.loc[:, [\"uniprot\", \"uniprot.chain\"]].copy()\n",
    ")\n",
    "df_isoforms_chains = df_chains.merge(df_isoforms, right_index=True, left_on=\"uniprot\")\n",
    "df_isoforms_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166ddf2-0b80-4964-818b-aaadb0e2bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, series in df_isoforms_chains.items():\n",
    "    df_annotations[col] = series\n",
    "\n",
    "for idx, row in df_annotations.loc[:, annotation_columns].iterrows():\n",
    "    uniprot_id, isoform_id = df_isoforms_chains.loc[idx, [\"uniprot\", \"uniprot.isoform\"]]\n",
    "    if isoform_id and len(isoform_id.split(\";\")) != 1:\n",
    "        isoform_id = None\n",
    "    # No isoform ID set, just aggregate all without regards to isoform.\n",
    "    row = row.apply(\n",
    "        lambda x: (\n",
    "            get_isoform_value_from_entry_UniProt(x, isoform_id)\n",
    "            if get_isoform_value_from_entry_UniProt(x, isoform_id).strip()\n",
    "            else x\n",
    "        )\n",
    "    )\n",
    "    row = row.apply(lambda x: x.strip().rstrip(\";\"))\n",
    "    # A duplicate reindexing error may here may mean duplicate columns in annotation column values\n",
    "    df_annotations.loc[idx, annotation_columns] = row.values\n",
    "# Clean up other annotations\n",
    "keys = [\"rhea\", \"go\", \"hgnc\"]\n",
    "for key in keys:\n",
    "    if key in df_annotations.columns:\n",
    "        df_annotations[key] = (\n",
    "            df_annotations[key]\n",
    "            .fillna(\"\")\n",
    "            .apply(\n",
    "                lambda x: build_string(\n",
    "                    [s.lstrip(f\"{key.upper()}:\") for s in split_string(x)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "df_annotations = df_annotations.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "if compare:\n",
    "    compare_on_index = [annotation_type]\n",
    "    try:\n",
    "        df_previous = pd.read_csv(\n",
    "            annotation_dirpath / f\"{annotation_type}_{db_tag}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df_previous = df_previous.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "    except FileNotFoundError:\n",
    "        df_previous = pd.DataFrame([], columns=compare_on_index)\n",
    "    df_comparision = compare_tables(\n",
    "        df_previous.set_index(compare_on_index),\n",
    "        df_annotations.set_index(compare_on_index),\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=compare_figsize)\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    ax = visualize_comparison(df_comparision)\n",
    "\n",
    "if display_nunique:\n",
    "    for col in df_annotations.columns:\n",
    "        df = (\n",
    "            df_annotations[col]\n",
    "            .apply(lambda x: split_string(x))\n",
    "            .explode(col)\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        print(f\"{df.name}: {df.nunique()}\")\n",
    "if overwrite:\n",
    "    df_annotations.to_csv(\n",
    "        annotation_dirpath / f\"{annotation_type}_{db_tag}.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91a7f2-62e5-455e-8d04-f4a5509cbad9",
   "metadata": {},
   "source": [
    "## Format Complex Table\n",
    "### Complexes and stoichiometry\n",
    "Information extracted here can be useful for protein constrained modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41679c7-262a-4276-8dd1-dbd434fb7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_mapping = {\n",
    "    \"Entry\": \"uniprot\",\n",
    "    \"Gene Names (primary)\": \"hgnc.symbol\",\n",
    "    \"Organism (ID)\": \"taxonomy\",\n",
    "    \"Subunit structure\": \"subunit_text\",\n",
    "}\n",
    "df_complex_results = (\n",
    "    df_query_results.loc[:, list(rename_mapping)].rename(rename_mapping, axis=1).copy()\n",
    ")\n",
    "\n",
    "if compare:\n",
    "    compare_on_index = [\"uniprot\"]\n",
    "    try:\n",
    "        df_previous = pd.read_csv(\n",
    "            database_dirpath / \"uniprot_complexes.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df_previous = df_previous.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "    except FileNotFoundError:\n",
    "        df_previous = pd.DataFrame([], columns=compare_on_index)\n",
    "    df_comparision = compare_tables(\n",
    "        df_previous.set_index(compare_on_index),\n",
    "        df_complex_results.set_index(compare_on_index),\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    ax = visualize_comparison(df_comparision)\n",
    "\n",
    "if display_nunique:\n",
    "    print(f\"{df_complex_results.nunique()}\")\n",
    "\n",
    "if overwrite:\n",
    "    df_complex_results.to_csv(\n",
    "        database_dirpath / \"uniprot_complexes.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278ad7f-41f2-4e21-97a0-25aca65bcb20",
   "metadata": {},
   "source": [
    "#### Parse complexes keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebc832-e542-407a-a356-a1df33a721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO finish automation component\n",
    "# subunit_terms_mapping_dict = {\n",
    "#     # Contains terms for subunit mapping.\n",
    "#     # Additional parsing needed for terms associated with more than one key and/or heteromultimeric complexes\n",
    "#     # May occur for complexes that have overlapping terms (e.g., decamer and undecamer)\n",
    "#     # A value of `0` indicates specific parsing or manual mappping is needed and can be determined from just the term.\n",
    "# #     0: {\"polypeptide\", \"oligomer\", \"complex\", \"catalytic subunit\", \"multisubunit\", \"regulatory subunit\", \"auxillary subunit\", \"alpha subunit\", \"beta subunit\", \"gamma subunit\", \"delta subunit\", \"proteasome\", \"multimer\", \"polymers\"},\n",
    "# #     1: {\"1 subunit\", \"monomer\"},\n",
    "# #     2: {\"2 subunits\", \"dimer\"},\n",
    "# #     3: {\"3 subunits\", \"trimer\"},\n",
    "# #     4: {\"4 subunits\", \"tetramer\"},\n",
    "# #     5: {\"5 subunits\", \"pentamer\"},\n",
    "# #     6: {\"6 subunits\", \"hexamer\"},\n",
    "# #     7: {\"7 subunits\", \"heptamer\"},\n",
    "# #     8: {\"8 subunits\", \"octamer\"},\n",
    "# #     9: {\"9 subunits\", \"nonomer\"},\n",
    "# #     10: {\"10 subunits\", \"decamer\"},\n",
    "# #     11: {\"11 subunits\", \"undecamer\"},\n",
    "# #     12: {\"12 subunits\", \"dodecamer\"},\n",
    "# #     13: {\"13 subunits\", \"tridecamer\"},\n",
    "# #     14: {\"14 subunits\", \"tetradecamer\"},\n",
    "# #     15: {\"15 subunits\", \"pentadecamer\"},\n",
    "# #     16: {\"16 subunits\", \"hexadecamer\"},\n",
    "# #     17: {\"17 subunits\", \"heptadecamer\"},\n",
    "# #     18: {\"18 subunits\", \"octaadecamer\"},\n",
    "# #     19: {\"19 subunits\", \"nonadecamer\"},\n",
    "# #     20: {\"20 subunits\", \"didecamer\"},\n",
    "# #     22: {\"22 subunits\"},\n",
    "# #     24: {\"24 subunits\"},\n",
    "# #     26: {\"26 subunits\"},\n",
    "# # }\n",
    "\n",
    "# data = {}\n",
    "# for uniprot_id, subunit_text in df_complex_results[\"subunit_text\"].dropna().items():\n",
    "#     data[uniprot_id] = {\n",
    "#         \"subunit_text\": subunit_text\n",
    "#     }\n",
    "#     # First determine if any subunit matches can be made.\n",
    "#     matches = set()\n",
    "#     for n_subunits, search_terms in subunit_terms_mapping_dict.items():\n",
    "#         matches.update([match.lower() for term in search_terms for match in re.findall(term, subunit_text, re.IGNORECASE)])\n",
    "#     if not matches:\n",
    "#         data[uniprot_id].update({\n",
    "#             \"matches\": pd.NA,\n",
    "#             \"manual\": True,\n",
    "#         })\n",
    "#         continue\n",
    "#     elif matches:\n",
    "\n",
    "#     break\n",
    "\n",
    "\n",
    "# # df_model_complexes = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "\n",
    "\n",
    "# # # if overwrite:\n",
    "# # #     df_isoforms_final.to_csv(database_dirpath / \"uniprot_isoforms.tsv\", sep=\"\\t\", index=False)\n",
    "# # #     df_erythroid.to_csv(database_dirpath / \"uniprot_isoforms_erythroid.tsv\", sep=\"\\t\", index=False)\n",
    "# # # else:\n",
    "# # #     df_isoforms_final.to_csv(ROOT_PATH / INTERIM_PATH / \"uniprot_isoforms.tsv\", sep=\"\\t\", index=False)\n",
    "# # #     df_erythroid.to_csv(ROOT_PATH / INTERIM_PATH / \"uniprot_isoforms_erythroid.tsv\", sep=\"\\t\", index=False)\n",
    "# # # df_erythroid\n",
    "# # df_model_complexes = df_model_mappings.merge(df_model_complexes, left_on=\"uniprot\", right_index=True, how=\"inner\")\n",
    "# # df_model_complexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476174cd-1a99-4d0b-a653-f705fccb4164",
   "metadata": {},
   "source": [
    "## Load Isoforms and Sequences\n",
    "### Isoforms\n",
    "#### Parse data into initial table of isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87600bd5-36e2-48e2-ae88-bf790243150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "erythro_keywords = [\n",
    "    \"erythro\",\n",
    "    \"erythrocyte\",\n",
    "    \"erythroid\",\n",
    "    \"red blood cell\",\n",
    "    \"rbc\",\n",
    "    \"R-type\",\n",
    "    \"P5N-I\",\n",
    "    \"reticulocyte\",\n",
    "]\n",
    "backup_keywords = [\"cyto\", \"retic\", \"cell membrane\"]\n",
    "avoid_keywords = [\"non-erythro\", \"mito\", \"not detected\", \"synaptic\", \"testis\"]\n",
    "\n",
    "rename_mapping = {\n",
    "    \"Entry\": \"uniprot\",\n",
    "    \"Gene Names (primary)\": \"hgnc.symbol\",\n",
    "    \"Organism (ID)\": \"taxonomy\",\n",
    "    \"Alternative products (isoforms)\": \"uniprot.isoform\",\n",
    "    \"Tissue specificity\": \"tissue_specificity\",\n",
    "    \"Subcellular location [CC]\": \"subcellular_location\",\n",
    "}\n",
    "columns_to_search = [\"tissue_specificity\", \"subcellular_location\"]\n",
    "\n",
    "df_tissue_specificity = (\n",
    "    df_query_results.loc[:, list(rename_mapping)].rename(rename_mapping, axis=1).copy()\n",
    ")\n",
    "df_isoforms = parse_isoforms_UniProt(\n",
    "    df_tissue_specificity.loc[:, [\"uniprot\", \"uniprot.isoform\"]].copy(),\n",
    "    add_canonical=True,\n",
    ")\n",
    "df_isoforms = df_isoforms.merge(\n",
    "    df_tissue_specificity[columns_to_search],\n",
    "    left_on=\"uniprot\",\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_isoforms[\"erythroid\"] = pd.NA\n",
    "df_isoforms[\"backup\"] = pd.NA\n",
    "df_isoforms[\"avoid\"] = pd.NA\n",
    "df_isoforms[\"keywords.erythroid\"] = pd.NA\n",
    "df_isoforms[\"keywords.backup\"] = pd.NA\n",
    "df_isoforms[\"keywords.avoid\"] = pd.NA\n",
    "all_names = sorted(\n",
    "    df_isoforms[\"uniprot.isoform.name\"].replace(\"\", pd.NA).dropna().unique()\n",
    ")\n",
    "all_synonyms = sorted(\n",
    "    df_isoforms[\"uniprot.isoform.synonyms\"].replace(\"\", pd.NA).dropna().unique()\n",
    ")\n",
    "for col_to_search in columns_to_search:\n",
    "    for idx, value_string in df_isoforms[col_to_search].dropna().items():\n",
    "        if not re.search(r\"\\[Isoform (.+?(?=\\]))\", value_string):\n",
    "            continue\n",
    "        for isoform_entry in value_string.split(\";\"):\n",
    "            match = re.search(r\"\\[Isoform (.+?(?=\\]))\", isoform_entry)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            isoform_name_or_synonym = match.group(1)\n",
    "            if not (\n",
    "                df_isoforms.loc[idx, \"uniprot.isoform.name\"] == isoform_name_or_synonym\n",
    "                or df_isoforms.loc[idx, \"uniprot.isoform.synonyms\"]\n",
    "                == isoform_name_or_synonym\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            for col, keywords in zip(\n",
    "                [\"erythroid\", \"backup\", \"avoid\"],\n",
    "                [erythro_keywords, backup_keywords, avoid_keywords],\n",
    "            ):\n",
    "                found_keywords = set()\n",
    "                for k in keywords:\n",
    "                    found_keywords.update(\n",
    "                        re.findall(k, isoform_entry.strip(), re.IGNORECASE)\n",
    "                    )\n",
    "                if df_isoforms.fillna(\"\").loc[idx, f\"keywords.{col}\"]:\n",
    "                    found_keywords.update(\n",
    "                        split_string(df_isoforms.loc[idx, f\"keywords.{col}\"])\n",
    "                    )\n",
    "                df_isoforms.loc[idx, f\"keywords.{col}\"] = build_string(found_keywords)\n",
    "\n",
    "for col, keywords in zip(\n",
    "    [\"erythroid\", \"backup\", \"avoid\"],\n",
    "    [erythro_keywords, backup_keywords, avoid_keywords],\n",
    "):\n",
    "    df_isoforms[f\"keywords.{col}\"] = df_isoforms[f\"keywords.{col}\"].apply(\n",
    "        lambda x: set(split_string(x)) if isinstance(x, str) else set()\n",
    "    )\n",
    "    for k in keywords:\n",
    "        df_isoforms[f\"keywords.{col}\"] = (\n",
    "            df_isoforms[[f\"keywords.{col}\", \"uniprot.isoform.name\"]]\n",
    "            .fillna(\"\")\n",
    "            .apply(\n",
    "                lambda x: x[f\"keywords.{col}\"].union(\n",
    "                    set(re.findall(k, x[\"uniprot.isoform.name\"], re.IGNORECASE))\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "        df_isoforms[f\"keywords.{col}\"] = (\n",
    "            df_isoforms[[f\"keywords.{col}\", \"uniprot.isoform.synonyms\"]]\n",
    "            .fillna(\"\")\n",
    "            .apply(\n",
    "                lambda x: x[f\"keywords.{col}\"].union(\n",
    "                    set(re.findall(k, x[\"uniprot.isoform.synonyms\"], re.IGNORECASE))\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "    df_isoforms[f\"keywords.{col}\"] = df_isoforms[f\"keywords.{col}\"].apply(\n",
    "        lambda x: build_string([s for s in x if s])\n",
    "    )\n",
    "df_isoforms = df_isoforms.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "df_isoforms[\"erythroid\"] = df_isoforms[\"keywords.erythroid\"].notna()\n",
    "df_isoforms[\"backup\"] = df_isoforms[\"keywords.backup\"].notna()\n",
    "df_isoforms[\"avoid\"] = df_isoforms[\"keywords.avoid\"].notna()\n",
    "# Remove those found in both categories from \"erythroid\", usually caused by words like `non-erythro`\n",
    "df_isoforms.loc[\n",
    "    df_isoforms[df_isoforms[[\"erythroid\", \"avoid\"]].all(axis=1)].index,\n",
    "    \"erythroid\",\n",
    "] = False\n",
    "# Erythroid easily serves as a backup option\n",
    "df_isoforms.loc[\n",
    "    df_isoforms[df_isoforms[[\"erythroid\"]].all(axis=1)].index,\n",
    "    \"backup\",\n",
    "] = True\n",
    "\n",
    "df_isoforms[\"canonical\"] = df_isoforms[\"uniprot.canonical\"]\n",
    "df_isoforms[\"sequence.id\"] = df_isoforms.fillna(\"\").apply(\n",
    "    lambda x: x[\"uniprot.isoform\"] if x[\"uniprot.isoform\"] else x[\"uniprot\"], axis=1\n",
    ")\n",
    "df_isoforms = df_isoforms.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "df_isoforms = (\n",
    "    df_isoforms.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"uniprot\",\n",
    "            \"uniprot.isoform\",\n",
    "            \"sequence.id\",\n",
    "            \"canonical\",\n",
    "            \"erythroid\",\n",
    "            \"backup\",\n",
    "            \"avoid\",\n",
    "            \"keywords.erythroid\",\n",
    "            \"keywords.backup\",\n",
    "            \"keywords.avoid\",\n",
    "        ],\n",
    "    ]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2af75f-52ae-4b07-8938-8ade661a63ec",
   "metadata": {},
   "source": [
    "### Sequences\n",
    "#### Extract sequences using UniParc Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee7faa-83ec-4668-888a-73719e5ed50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isoforms_sequences = df_isoforms[\n",
    "    df_isoforms.apply(lambda x: x[\"sequence.id\"].startswith(x[\"uniprot\"]), axis=1)\n",
    "].copy()\n",
    "query_ids = df_isoforms_sequences[\"sequence.id\"].unique()\n",
    "\n",
    "query_parameters = {\n",
    "    \"format\": \"tsv\",\n",
    "    \"size\": 500,\n",
    "    \"compressed\": True,\n",
    "    \"fields\": \",\".join(\n",
    "        [\n",
    "            \"sequence\",\n",
    "            \"length\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "query_key = \"initial\"\n",
    "df_results, uniparc, failed_ids, obselete_counts = query_UniProt(\n",
    "    list(query_ids),\n",
    "    query_parameters=query_parameters,\n",
    "    from_db=\"UniProtKB_AC-ID\",\n",
    "    to_db=\"UniParc\",\n",
    "    return_failed=True,\n",
    ")\n",
    "\n",
    "if failed_ids:\n",
    "    print(failed_ids)\n",
    "\n",
    "df_isoforms_sequences = df_isoforms_sequences.merge(\n",
    "    df_results.set_index(\"From\").rename(\n",
    "        {\n",
    "            \"Sequence\": \"sequence\",\n",
    "            \"Length\": \"sequence.length\",\n",
    "            \"mass\": \"sequence.mass\",\n",
    "        },\n",
    "        axis=1,\n",
    "    ),\n",
    "    left_on=\"sequence.id\",\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "# #  The following code can be used to address entries with issues in extractions. LDHB example.\n",
    "# df_isoforms_sequences = pd.concat(\n",
    "#     (\n",
    "#         df_isoforms_sequences,\n",
    "#         pd.DataFrame.from_dict(\n",
    "#             {\n",
    "#                 \"uniprot\": \"P07195\",\n",
    "#                 \"sequence.id\": \"P07195\",\n",
    "#                 \"canonical\": True,\n",
    "#                 \"erythroid\": False,\n",
    "#                 \"backup\": False,\n",
    "#                 \"avoid\": False,\n",
    "#                 \"sequence\": \"MATLKEKLIAPVAEEEATVPNNKITVVGVGQVGMACAISILGKSLADELALVDVLEDKLKGEMMDLQHGSLFLQTPKIVADKDYSVTANSKIVVVTAGVRQQEGESRLNLVQRNVNVFKFIIPQIVKYSPDCIIIVVSNPVDILTYVTWKLSGLPKHRVIGSGCNLDSARFRYLMAEKLGIHPSSCHGWILGEHGDSSVAVWSGVNVAGVSLQELNPEMGTDNDSENWKEVHKMVVESAYEVIKLKGYTNWAIGLSVADLIESMLKNLSRIHPVSTMVKGMYGIENEVFLSLPCILNARGLTSVINQKLKDDEVAQLKKSADTLWDIQKDLKDL\",\n",
    "#                 \"sequence.length\": \"334\",\n",
    "#             },\n",
    "#             orient=\"index\",\n",
    "#         ).T,\n",
    "#     ),\n",
    "#     axis=0,\n",
    "# ).convert_dtypes()\n",
    "\n",
    "df_isoforms_sequences = df_isoforms_sequences.reset_index(drop=True)\n",
    "\n",
    "if overwrite:\n",
    "    df_isoforms_sequences.to_csv(\n",
    "        database_dirpath / f\"{UNIPROT_DB_TAG}_isoforms_sequences.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "df_isoforms_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a46de-708d-44f4-b9c3-fdffdf997685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_mappings.merge(df_isoforms_sequences[df_isoforms_sequences[\"erythroid\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
