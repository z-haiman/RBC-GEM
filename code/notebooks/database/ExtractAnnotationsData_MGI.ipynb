{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d9860f-08fc-4040-bcbe-199487bde7ef",
   "metadata": {},
   "source": [
    "# Extract annotations and data from Mouse Genome Informatics database\n",
    "\n",
    "The purpose of this notebook is to extract and format data for subsequent model annotation. \n",
    "\n",
    "Additionally, the purpose of this notebook is to extract relevant data to map between mouse and human homologs.\n",
    "\n",
    "## Notebook Requirements:\n",
    "*  Model genes **must** have the at least one of following annotations stored in the `object.annotation`. Values are expected to be seperated by semicolons. Accepted keys currently include:\n",
    "    * `\"uniprot\"`\n",
    "*  Note: Requires internet connection to download information from [MGI](https://www.informatics.jax.org/).\n",
    "\n",
    "### Citations\n",
    "Baldarelli RM, Smith CL, Ringwald M, Richardson JE, Bult CJ; Mouse Genome Informatics Group. Mouse Genome Informatics: an integrated knowledgebase system for the laboratory mouse. Genetics. 2024 May 7;227(1):iyae031. doi: 10.1093/genetics/iyae031. PMID: 38531069; PMCID: PMC11075557.\n",
    "\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2b7c0-6487-413b-852e-8a31eb1f40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from warnings import warn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from cobra.core.gene import GPR\n",
    "from cobra.manipulation import remove_genes\n",
    "from rbc_gem_utils import (\n",
    "    GEM_NAME,\n",
    "    build_string,\n",
    "    check_database_release_online,\n",
    "    compare_tables,\n",
    "    get_annotation_df,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    show_versions,\n",
    "    split_string,\n",
    "    visualize_comparison,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.database.mgi import (\n",
    "    MGI_DB_TAG,\n",
    "    MGI_RELEASE_EXPECTED,\n",
    "    download_database_MGI,\n",
    ")\n",
    "from sympy import parse_expr\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93c99e-8709-41c9-a4e0-47e70e3ddcc9",
   "metadata": {},
   "source": [
    "## Set notebook options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce5a9e-e0ad-4c52-8eb7-ec7b8a0b69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tag = MGI_DB_TAG\n",
    "expected_release = MGI_RELEASE_EXPECTED\n",
    "download_database = True\n",
    "\n",
    "compare_figsize = (5, 5)\n",
    "compare = True\n",
    "display_nunique = True\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43370036-e69d-46a0-8c4b-147d9d94f1b2",
   "metadata": {},
   "source": [
    "## Check MGI release\n",
    "* If the current release does not match the expected release, it is because database has been updated since the last time this code was utilized.\n",
    "    * If the notebook works without needing any significant modifications, the only update needed is to the release in the [mgi.py](../../src/rbc_gem_utils/database/complexportal.py) source code file to resolve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd1050-b913-4d81-a4a4-722a5e193c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_interim = not check_database_release_online(\n",
    "    db_tag,\n",
    "    verbose=True,\n",
    ")\n",
    "# Use different directory paths for unexpected behavior\n",
    "if use_interim:\n",
    "    warn(\n",
    "        \"Online release of database has been updated since the last time notebook was used.\"\n",
    "    )\n",
    "\n",
    "database_dirpath = get_dirpath(\n",
    "    \"database\", db_tag, use_temp=\"interim\" if use_interim else None\n",
    ")\n",
    "annotation_dirpath = get_dirpath(\n",
    "    \"annotation\", use_temp=\"interim\" if use_interim else None\n",
    ")\n",
    "\n",
    "# Ensure directories exist\n",
    "database_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "annotation_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6896f8aa-fa35-4c73-8a08-4f8e033f0bba",
   "metadata": {},
   "source": [
    "## Load Human-Mouse mapping tables\n",
    "### Download from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67257a47-f5f4-439a-a702-0d0dbc500e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_database:\n",
    "    download_database_MGI(\n",
    "        [\n",
    "            \"HGNC_AllianceHomology.rpt\",\n",
    "            \"MRK_SwissProt.rpt\",  # Only reviewed proteins included\n",
    "            \"MRK_SwissProt_TrEMBL.rpt\",  # Unreviewed proteins included\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c2814-d8d5-4f09-a76d-2e4c0f49f435",
   "metadata": {},
   "source": [
    "### Set MIRIAM keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c92ee-3d8d-4743-9f24-840a84147482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgi_key = \"mgi\"\n",
    "hgnc_key = \"hgnc\"\n",
    "hgnc_sym_key = f\"{hgnc_key}.symbol\"\n",
    "mgnc_sym_key = \"mgnc.symbol\"  # Not currently a true miriam mapping\n",
    "uniprot_key = \"uniprot\"\n",
    "only_reviewed_proteins = True\n",
    "\n",
    "header_len = 30\n",
    "column_map = {\n",
    "    \"MGI Accession ID\": mgi_key,\n",
    "    \"Marker Symbol\": mgnc_sym_key,\n",
    "    \"HGNC ID\": hgnc_key,\n",
    "    \"UniProt\": f\"{uniprot_key}.mouse\",  # To distinguish from human,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d1cd3-6acc-4b5d-825c-a087d4d0aced",
   "metadata": {},
   "source": [
    "### Load homology table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70170a-b36c-40e7-9eb6-244f25dad9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_homology = pd.read_csv(\n",
    "    database_dirpath / \"HGNC_AllianceHomology.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    # TODO map additional columns for annotations\n",
    "    index_col=False,\n",
    ")\n",
    "df_homology = df_homology[[x for x in column_map if x in df_homology.columns]]\n",
    "df_homology = df_homology.rename(column_map, axis=1)\n",
    "print(df_homology.nunique())\n",
    "df_homology.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcc96a-b8b8-46f6-a323-8492d106b3c8",
   "metadata": {},
   "source": [
    "### Load protein table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fbaab-78af-4570-b73f-eff2709a958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_reviewed_proteins:\n",
    "    prot_file = \"MRK_SwissProt.tsv\"\n",
    "else:\n",
    "    prot_file = \"MRK_SwissProt_TrEMBL.tsv\"\n",
    "\n",
    "df_proteins = pd.read_csv(\n",
    "    database_dirpath / prot_file,\n",
    "    sep=\"\\t\",\n",
    "    # TODO map additional columns for annotations\n",
    "    index_col=False,\n",
    "    header=None,\n",
    ")\n",
    "# Headers are not included, so label them using the website it from\n",
    "df_proteins.columns = [\n",
    "    \"MGI Accession ID\",\n",
    "    \"Marker Symbol\",\n",
    "    \"Status\",\n",
    "    \"Marker Name\",\n",
    "    \"cM position\",\n",
    "    \"Chromosome\",\n",
    "    \"UniProt\",  # SWISS-PROT Protein Accession IDs\n",
    "]\n",
    "df_proteins = df_proteins[[x for x in column_map if x in df_proteins.columns]]\n",
    "df_proteins = df_proteins.rename(column_map, axis=1)\n",
    "\n",
    "print(df_proteins.nunique())\n",
    "df_proteins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182bca6-d31e-4f4b-8eb7-e9816f249f73",
   "metadata": {},
   "source": [
    "### Create mapping table for all mouse genes/proteins to human genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a906408-c773-44dd-8cbe-47875ad9599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mouse_prots = df_homology.merge(\n",
    "    df_proteins, left_on=mgi_key, right_on=mgi_key, how=\"left\", suffixes=[None, \"_drop\"]\n",
    ")\n",
    "df_mouse_prots = df_mouse_prots.drop(\n",
    "    [c for c in df_mouse_prots.columns if c.endswith(\"_drop\")], axis=1\n",
    ")\n",
    "df_mouse_prots[f\"{uniprot_key}.mouse\"] = df_mouse_prots[\n",
    "    f\"{uniprot_key}.mouse\"\n",
    "].str.split(\" \")\n",
    "df_mouse_prots = df_mouse_prots.explode(f\"{uniprot_key}.mouse\")\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        (\"Initial data table\", \"=\" * header_len, str(df_mouse_prots.nunique()), \"\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Original mapping is 1 mouse gene to 1+ human genes\n",
    "# Drop entries without human gene mappings and rename Marker Symbol column\n",
    "df_mouse_prots = df_mouse_prots[df_mouse_prots[hgnc_key].notna()]\n",
    "\n",
    "# Remove prefixes from the IDs\n",
    "df_mouse_prots[hgnc_key] = df_mouse_prots[hgnc_key].str.replace(\"HGNC:\", \"\")\n",
    "df_mouse_prots[mgi_key] = df_mouse_prots[mgi_key].str.replace(\"MGI:\", \"\")\n",
    "df_mouse_prots[hgnc_key] = df_mouse_prots[hgnc_key].str.split(\"|\")\n",
    "df_mouse_prots = df_mouse_prots.explode(hgnc_key).sort_values(hgnc_key)\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        (\n",
    "            \"Genes with human homologs\",\n",
    "            \"=\" * header_len,\n",
    "            str(df_mouse_prots.nunique()),\n",
    "            \"\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df_mouse_prots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d70d8-f177-4c89-b286-2cbcf00cc564",
   "metadata": {},
   "source": [
    "#### Summarize general mapping results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6c415-890c-4122-bd57-76ad06a47d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_count = df_mouse_prots[[hgnc_key, mgnc_sym_key]].drop_duplicates()\n",
    "duplicated_count = duplicated_count[hgnc_key].duplicated(keep=False).value_counts()\n",
    "\n",
    "duplicated_count = duplicated_count.rename(\n",
    "    {False: \"One to One map \", True: \"One to Many map \"}, axis=0\n",
    ")\n",
    "duplicated_count.index.name = None\n",
    "duplicated_count.name = None\n",
    "print(\n",
    "    \"\\n\".join((\"Human to Mouse mapping\", \"=\" * header_len, str(duplicated_count), \"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f17f6-f726-465d-bd53-e7abe148aee0",
   "metadata": {},
   "source": [
    "## Map to RBC-GEM\n",
    "### Load RBC-GEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea3158-e256-4935-ae88-d6d204943435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirpath = get_dirpath(\"model\")\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{GEM_NAME}.xml\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e45048-22d1-43d5-9013-d79015db3808",
   "metadata": {},
   "source": [
    "### Create model mapping table from annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905e902-616a-4359-ab5b-7d3feb8eb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = get_annotation_df(model.genes, [uniprot_key, hgnc_key, hgnc_sym_key]).rename(\n",
    "    {\"id\": \"genes\"}, axis=1\n",
    ")\n",
    "df_model[hgnc_key] = df_model[hgnc_key].str.split(\";\")\n",
    "df_model = df_model.explode(hgnc_key).sort_values(hgnc_key)\n",
    "df_model = df_model.merge(\n",
    "    df_mouse_prots, left_on=hgnc_key, right_on=hgnc_key, how=\"left\"\n",
    ")\n",
    "print(\"\\n\".join((\"Mapped to model\", \"=\" * header_len, str(df_model.nunique()), \"\")))\n",
    "\n",
    "duplicated_count = df_model[[hgnc_key, mgnc_sym_key]].drop_duplicates()\n",
    "duplicated_count = duplicated_count[hgnc_key].duplicated(keep=False).value_counts()\n",
    "\n",
    "duplicated_count = duplicated_count.rename(\n",
    "    {False: \"One to One map \", True: \"One to Many map \"}, axis=0\n",
    ")\n",
    "duplicated_count.index.name = None\n",
    "duplicated_count.name = None\n",
    "print(\n",
    "    \"\\n\".join((\"Human to Mouse mapping\", \"=\" * header_len, str(duplicated_count), \"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176a16d-62d4-4fff-a0fb-14332d1609db",
   "metadata": {},
   "source": [
    "### Format for human model annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397e463-ec01-49b4-9cec-c3b9e14d137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = df_model.replace(pd.NA, \"\")\n",
    "df_annotations = df_annotations.groupby(\"genes\", as_index=False)[\n",
    "    [uniprot_key, hgnc_key, hgnc_sym_key, mgi_key]\n",
    "].agg(lambda x: build_string(sorted(x)))\n",
    "df_annotations = df_annotations.replace(\"\", pd.NA)\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5af532-5239-4e21-a227-4637f98a9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "if compare:\n",
    "    compare_on_index = [annotation_type]\n",
    "    try:\n",
    "        df_previous = pd.read_csv(\n",
    "            annotation_dirpath / f\"{annotation_type}_{db_tag}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df_previous = df_previous.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "    except FileNotFoundError:\n",
    "        df_previous = pd.DataFrame([], columns=compare_on_index)\n",
    "    df_comparision = compare_tables(\n",
    "        df_previous.set_index(compare_on_index),\n",
    "        df_annotations.set_index(compare_on_index),\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=compare_figsize)\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    ax = visualize_comparison(df_comparision)\n",
    "\n",
    "if display_nunique:\n",
    "    for col in df_annotations.columns:\n",
    "        df = (\n",
    "            df_annotations[col]\n",
    "            .apply(lambda x: split_string(x))\n",
    "            .explode(col)\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        print(f\"{df.name}: {df.nunique()}\")\n",
    "if overwrite:\n",
    "    df_annotations.to_csv(\n",
    "        annotation_dirpath / f\"{annotation_type}_{db_tag}.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2923960-d1cb-4156-99e5-eaeba11c2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_na_gene = df_model[df_model[mgnc_sym_key].isna()]\n",
    "map_to_na_gene = map_to_na_gene[\n",
    "    [\"genes\", mgnc_sym_key, f\"{uniprot_key}.mouse\"]\n",
    "].drop_duplicates()\n",
    "map_to_na_gene = map_to_na_gene.sort_values([mgnc_sym_key, f\"{uniprot_key}.mouse\"])\n",
    "\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        (\n",
    "            \"No identified mouse gene\",\n",
    "            \"=\" * header_len,\n",
    "            str(map_to_na_gene.nunique()),\n",
    "            \"\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "map_to_na_protein = df_model[df_model[f\"{uniprot_key}.mouse\"].isna()]\n",
    "map_to_na_protein = map_to_na_protein[\n",
    "    [\"genes\", mgnc_sym_key, f\"{uniprot_key}.mouse\"]\n",
    "].drop_duplicates()\n",
    "map_to_na_protein = map_to_na_protein.sort_values(\n",
    "    [mgnc_sym_key, f\"{uniprot_key}.mouse\"]\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\n\".join(\n",
    "        (\n",
    "            \"No identified mouse protein\",\n",
    "            \"=\" * header_len,\n",
    "            str(map_to_na_protein.nunique()),\n",
    "            \"\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df_model = df_model.dropna(subset=[mgnc_sym_key, f\"{uniprot_key}.mouse\"])\n",
    "gene_mapping = df_model.groupby([\"genes\"])[mgnc_sym_key].agg(lambda x: list(x))\n",
    "gene_mapping = gene_mapping.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780ff50-605f-4a2e-98ea-44d7494274bd",
   "metadata": {},
   "source": [
    "### Update gene reaction rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec429ab1-a0af-4a38-9d5e-ac776af42ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_model = model.copy()\n",
    "new_gprs = {}\n",
    "for i, reaction in enumerate(\n",
    "    mouse_model.reactions.query(lambda x: x.gene_reaction_rule)\n",
    "):\n",
    "    gene_reaction_rule = reaction.gene_reaction_rule\n",
    "    for gene in reaction.genes:\n",
    "        try:\n",
    "            replacements = gene_mapping[gene.id]\n",
    "        except KeyError as e:\n",
    "            replacements = \"TO_REMOVE\"\n",
    "        else:\n",
    "            replacements = \" or \".join(replacements)\n",
    "        # Replace all matches, be mindful of partial gene ID replacements by searching by ensuring no trailing alphanumeric characters\n",
    "        gene_reaction_rule = re.subn(\n",
    "            f\"{gene.id}(?![a-zA-Z0-9_])\", replacements, gene_reaction_rule\n",
    "        )[0]\n",
    "\n",
    "    gene_reaction_rule = (\n",
    "        gene_reaction_rule.replace(\"-\", \"_\")\n",
    "        .replace(\" or \", \"|\")\n",
    "        .replace(\" and \", \" & \")\n",
    "    )\n",
    "    gene_reaction_rule = parse_expr(gene_reaction_rule)\n",
    "    reaction.gpr = GPR.from_symbolic(gene_reaction_rule)\n",
    "\n",
    "# Remove old model genes\n",
    "remove_genes(\n",
    "    mouse_model,\n",
    "    gene_list=[\"TO_REMOVE\"] + model.genes.list_attr(\"id\"),\n",
    "    remove_reactions=False,\n",
    ")\n",
    "mouse_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664e18f-646c-441a-a8c2-35a021621c61",
   "metadata": {},
   "source": [
    "### Update annotations for new genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40870bcc-177c-470f-903e-d3a7ca57bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mouse_annotations = df_model.groupby(mgnc_sym_key)[\n",
    "    [mgi_key, f\"{uniprot_key}.mouse\", hgnc_key, hgnc_sym_key]\n",
    "].agg(lambda x: build_string(x))\n",
    "df_mouse_annotations = df_mouse_annotations.rename(\n",
    "    {f\"{uniprot_key}.mouse\": uniprot_key}, axis=1\n",
    ")\n",
    "df_mouse_annotations.index = df_mouse_annotations.index.str.replace(\"-\", \"_\")\n",
    "for gene in mouse_model.genes:\n",
    "    annotation = {mgnc_sym_key: gene.id}\n",
    "    annotation.update(df_mouse_annotations.loc[gene.id].to_dict())\n",
    "    gene.annotation.update(annotation)\n",
    "df_mouse_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0139314-5ce7-4238-bd02-e4a5a19621a3",
   "metadata": {},
   "source": [
    "## Export model and data mapping tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8812645-d2f2-4a85-8d44-a8b658d49668",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cobra_model(mouse_model, filename=database_dirpath / f\"{GEM_NAME}.xml\")\n",
    "df_model.to_csv(database_dirpath / \"HumanMouseMapping.tsv\", sep=\"\\t\", index=False)\n",
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e74b65-06fe-4be6-9d89-65835ed0eb61",
   "metadata": {},
   "source": [
    "## Download sequence data from UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c80bd0-bee1-408d-a7af-4fa6c1554b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbc_gem_utils import GEM_NAME\n",
    "from rbc_gem_utils.database.uniprot import (\n",
    "    UNIPROT_API_URL,\n",
    "    UNIPROT_DB_TAG,\n",
    "    UNIPROT_PATH,\n",
    "    UNIPROT_RELEASE_EXPECTED,\n",
    "    get_annotation_to_from_db_UniProt,\n",
    "    get_isoform_value_from_entry_UniProt,\n",
    "    get_label_miriam_mapping_UniProt,\n",
    "    get_query_fields_UniProt,\n",
    "    get_release_UniProt,\n",
    "    parse_chains_UniProt,\n",
    "    parse_isoforms_UniProt,\n",
    "    query_UniProt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a894b-64d7-4065-b033-5af87d928fc5",
   "metadata": {},
   "source": [
    "### Get IDs for query\n",
    "#### Using an existing annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1e5ff-ec7a-4f08-9598-d83b8bcfff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "annotation_cols = [\"uniprot\"]\n",
    "mapping_key = \"uniprot\"\n",
    "\n",
    "df_model_mappings = (\n",
    "    get_annotation_df(mouse_model.genes, annotation_cols)\n",
    "    .rename({\"id\": annotation_type}, axis=1)\n",
    "    .dropna(subset=[mapping_key])\n",
    ")\n",
    "for col in df_model_mappings.columns:\n",
    "    df_model_mappings[col] = df_model_mappings[col].apply(lambda x: split_string(x))\n",
    "    df_model_mappings = df_model_mappings.explode(col).drop_duplicates().dropna()\n",
    "df_model_mappings = df_model_mappings.sort_values(annotation_type)\n",
    "\n",
    "print(df_model_mappings.nunique(dropna=True))\n",
    "df_model_mappings = df_model_mappings.reset_index(drop=True)\n",
    "df_model_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd2fc9-5634-4268-afe7-87d14fd14a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_to_from_db = get_annotation_to_from_db_UniProt(miriam_only=True)\n",
    "\n",
    "from_db = annotation_to_from_db[mapping_key]\n",
    "query_ids = df_model_mappings[mapping_key].dropna().unique()\n",
    "assert len(set(query_ids)) == len(query_ids), \"Duplicate IDs in list to query\"\n",
    "model_search_mapping = df_model_mappings.set_index(annotation_type)[\n",
    "    mapping_key\n",
    "].to_dict()\n",
    "print(f\"Number of model genes associated with query: {len(model_search_mapping)}\")\n",
    "print(f\"Number of unique IDs to query: {len(query_ids)}\")\n",
    "df_model_mappings[[annotation_type, mapping_key]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126973ed-5fe0-4de8-8082-18f857c48150",
   "metadata": {},
   "source": [
    "### Run queries\n",
    "#### Set universal query parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855e067-8417-4ec3-a1b8-93bddc75580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_results = {}\n",
    "miriam_query_fields = get_query_fields_UniProt(miriam_only=True)\n",
    "query_fields = miriam_query_fields + [\n",
    "    # Add additional non-miriam fields if desired\n",
    "    # Complex composition\n",
    "    \"cc_subunit\",\n",
    "    # Specific isoforms to include/avoid\n",
    "    \"cc_tissue_specificity\",\n",
    "    \"cc_subcellular_location\",\n",
    "    # Chromosome\n",
    "    \"xref_proteomes\",\n",
    "]\n",
    "\n",
    "# Extract all relevant information for now and save\n",
    "query_parameters = {\n",
    "    \"query\": \" && \".join(\n",
    "        [\n",
    "            \"(reviewed:true)\",\n",
    "            \"(organism_id:10090)\",  # Homo sapiens (Human)\n",
    "        ]\n",
    "    ),\n",
    "    \"format\": \"tsv\",\n",
    "    \"size\": 500,\n",
    "    \"compressed\": True,\n",
    "    \"fields\": \",\".join(query_fields),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404eb5a7-db4d-446a-a495-fd91d0819d4a",
   "metadata": {},
   "source": [
    "#### Initial query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0a492-cecc-4f47-87a8-a0caca30bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_key = \"initial\"\n",
    "df_results, uniparc, failed_ids, obselete_counts = query_UniProt(\n",
    "    list(query_ids),\n",
    "    query_parameters=query_parameters,\n",
    "    to_db=\"UniProtKB\",\n",
    "    from_db=from_db,\n",
    "    return_failed=True,\n",
    ")\n",
    "if failed_ids:\n",
    "    print(failed_ids)\n",
    "all_query_results[query_key] = df_results\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0295e2-1214-436f-a7dc-35336d85a8f2",
   "metadata": {},
   "source": [
    "### Address failed IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05982c-c027-41e1-bebe-aab702f0571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retry_ids = {}\n",
    "# query_key = \"retry_1\"\n",
    "# df_results, failed_ids = query_UniProt(\n",
    "#     list(sorted(retry_ids.values())),\n",
    "#     from_db=\"UniProtKB\",\n",
    "#     query_parameters=query_parameters\n",
    "# )\n",
    "# if failed_ids:\n",
    "#     print(failed_ids)\n",
    "# all_query_results[query_key] = df_results\n",
    "# model_search_mapping.update({\n",
    "#     k: retry_ids[v] for k, v in model_search_mapping.items()\n",
    "#     if v in retry_ids and v not in failed_ids\n",
    "# })\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9dd20-f9c2-4bf6-a13b-b278b46cdea5",
   "metadata": {},
   "source": [
    "## Concat, cleanup, and save query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ca9a4-6c5c-44ae-b329-034c4ac7430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique queries: {len(all_query_results)}\")\n",
    "df_query_results = pd.concat(tuple(all_query_results.values()))\n",
    "df_query_results = df_query_results.set_index(\"From\").drop_duplicates()\n",
    "df_query_results = df_query_results.replace(\"\", pd.NA)\n",
    "df_query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2228f6f-9f66-4956-8ee7-e11729715df6",
   "metadata": {},
   "source": [
    "#### Save extracted data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c5f8f-8449-407c-8b24-6f6ec82fc8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save query results to external database\n",
    "df_database = df_query_results.reset_index(drop=True).drop_duplicates()\n",
    "if compare:\n",
    "    compare_on_index = [\"Entry\"]\n",
    "    try:\n",
    "        df_previous = pd.read_csv(\n",
    "            database_dirpath / f\"{db_tag}_{GEM_NAME}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df_previous = df_previous.replace(float(\"nan\"), pd.NA)\n",
    "    except FileNotFoundError:\n",
    "        df_previous = pd.DataFrame([], columns=compare_on_index)\n",
    "    df_comparision = compare_tables(\n",
    "        df_previous.set_index(compare_on_index), df_database.set_index(compare_on_index)\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=compare_figsize)\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    ax = visualize_comparison(df_comparision)\n",
    "\n",
    "\n",
    "if overwrite:\n",
    "    df_database.to_csv(\n",
    "        database_dirpath / f\"{db_tag}_{GEM_NAME}.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "\n",
    "df_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590416c-d7e8-4997-b161-08bcf1898c53",
   "metadata": {},
   "source": [
    "## Format UniProt information for annotation files\n",
    "### Genes\n",
    "#### Map to chosen MIRIAMs\n",
    "As formatting may be needed for some MIRIAMS, keep it simple for now until formatting methods are developed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37a3eb-68a3-4617-9c84-1c11275a1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_type = \"genes\"\n",
    "\n",
    "# Keeping it simple for now, group items regardless of isoforms for the time being\n",
    "uniprot_miriam_mapping = get_label_miriam_mapping_UniProt(\n",
    "    get_query_fields_UniProt(miriam_only=True)\n",
    ")\n",
    "uniprot_miriam_mapping[\"Proteomes\"] = \"chromosome\"\n",
    "\n",
    "merge_key = {\n",
    "    v: k for k, v in uniprot_miriam_mapping.items() if v in df_model_mappings.columns\n",
    "}[mapping_key]\n",
    "df_annotations = df_model_mappings.set_index(mapping_key).merge(\n",
    "    df_database, left_index=True, right_on=merge_key, how=\"inner\"\n",
    ")\n",
    "df_annotations = (\n",
    "    df_annotations.set_index(annotation_type)\n",
    "    .loc[:, list(uniprot_miriam_mapping)]\n",
    "    .rename(uniprot_miriam_mapping, axis=1)\n",
    ")\n",
    "uniprot_columns = [\"uniprot\", \"uniprot.isoform\", \"uniprot.chain\"]\n",
    "# For the most part, these columns do not require any reformatting or are easy to work with.\n",
    "annotation_columns = [\n",
    "    \"hgnc.symbol\",\n",
    "    \"ec-code\",\n",
    "    \"taxonomy\",\n",
    "    \"uniparc\",\n",
    "    # Reactions\n",
    "    \"rhea\",\n",
    "    # Gene Ontology (GO)\n",
    "    \"go\",\n",
    "    # Sequence\n",
    "    \"ccds\",\n",
    "    \"ena.embl\",\n",
    "    \"refseq\",\n",
    "    # 3D Structure\n",
    "    \"bmrb\",\n",
    "    \"pdb\",\n",
    "    \"sasbdb\",\n",
    "    \"smr\",\n",
    "    # Protein-protein interaction\n",
    "    \"biogrid\",\n",
    "    \"complexportal\",\n",
    "    \"dip\",\n",
    "    \"intact\",\n",
    "    # Chemistry databases\n",
    "    \"chembl.target\",\n",
    "    \"drugbank\",\n",
    "    \"iuphar.receptor\",\n",
    "    # Protein family/group databases\n",
    "    \"cazy\",\n",
    "    \"ideal\",\n",
    "    \"merops\",\n",
    "    \"peroxibase\",\n",
    "    \"tcdb\",\n",
    "    # Genetic variation/Polymorphism and mutation databases\n",
    "    \"dbsnp\",\n",
    "    # Proteomic databases\n",
    "    \"proteomicsdb.protein\",\n",
    "    # Genome annotation databases\n",
    "    \"ensembl\",\n",
    "    \"ncbigene\",\n",
    "    ## Organism-specific\n",
    "    \"kegg.genes\",\n",
    "    \"genecards\",\n",
    "    \"hgnc\",\n",
    "    \"hpa\",\n",
    "    \"mim\",\n",
    "    \"nextprot\",\n",
    "    \"orphanet\",\n",
    "    \"pharmgkb.gene\",\n",
    "    # Phylogenomic databases\n",
    "    \"eggnog\",\n",
    "    \"genetree\",\n",
    "    \"hogenom\",\n",
    "    \"oma.grp\",\n",
    "    \"orthodb\",\n",
    "    \"treefam\",\n",
    "    # Enzyme and pathway databases\n",
    "    \"biocyc\",\n",
    "    \"brenda\",\n",
    "    \"reactome\",\n",
    "    # Miscellaneous databases\n",
    "    \"genewiki\",\n",
    "    # Gene expression databases\n",
    "    \"bgee.gene\",\n",
    "    ## Family and domain databases\n",
    "    \"cdd\",\n",
    "    \"disprot\",\n",
    "    \"hamap\",\n",
    "    \"interpro\",\n",
    "    \"panther.family\",\n",
    "    \"pfam\",\n",
    "    \"pirsf\",\n",
    "    \"prints\",\n",
    "    \"prosite\",\n",
    "    \"smart\",\n",
    "    \"supfam\",\n",
    "    \"chromosome\",\n",
    "]\n",
    "df_annotations[\"chromosome\"] = df_annotations[\"chromosome\"].apply(\n",
    "    lambda x: x.split(\" \")[-1]\n",
    ")\n",
    "df_annotations = df_annotations.loc[:, uniprot_columns + annotation_columns].rename(\n",
    "    {\n",
    "        \"hgnc.symbol\": \"mgnc.symbol\",  # Rename for mouse\n",
    "    },\n",
    "    axis=1,\n",
    ")\n",
    "annotation_columns[annotation_columns.index(\"hgnc.symbol\")] = \"mgnc.symbol\"\n",
    "print(f\"Fields searched: {df_annotations.shape[1]}\")\n",
    "all_na = df_annotations.T[df_annotations.isna().all(axis=0)].index\n",
    "annotation_columns = [x for x in annotation_columns if x not in all_na]\n",
    "df_annotations = df_annotations.dropna(how=\"all\", axis=1)\n",
    "print(f\"Empty dropped: {len(all_na)}\")\n",
    "print(f\"Remaining: {df_annotations.shape[1]}\")\n",
    "df_annotations = df_annotations.reset_index(drop=False).replace(pd.NA, \"\")\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d345c-10dc-4b7d-b484-8b468c5781c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isoforms = parse_isoforms_UniProt(\n",
    "    df_annotations.loc[:, [\"uniprot\", \"uniprot.isoform\"]].copy(), add_canonical=True\n",
    ")\n",
    "\n",
    "df_canonical = df_isoforms[df_isoforms[\"uniprot.canonical\"].apply(bool)].set_index(\n",
    "    \"uniprot\"\n",
    ")\n",
    "df_canonical = df_canonical.apply(\n",
    "    lambda x: x[\"uniprot.isoform\"] if x[\"uniprot.isoform\"] else x.name, axis=1\n",
    ")\n",
    "df_isoforms = df_isoforms.groupby(\"uniprot\")[[\"uniprot.isoform\"]].agg(\n",
    "    lambda x: build_string(x)\n",
    ")\n",
    "\n",
    "df_chains = parse_chains_UniProt(\n",
    "    df_annotations.loc[:, [\"uniprot\", \"uniprot.chain\"]].copy()\n",
    ")\n",
    "df_isoforms_chains = df_chains.merge(df_isoforms, right_index=True, left_on=\"uniprot\")\n",
    "df_isoforms_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de4a26-6ed0-4a2f-9f90-80abdcab8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, series in df_isoforms_chains.items():\n",
    "    df_annotations[col] = series\n",
    "\n",
    "for idx, row in df_annotations.loc[:, annotation_columns].iterrows():\n",
    "    uniprot_id, isoform_id = df_isoforms_chains.loc[idx, [\"uniprot\", \"uniprot.isoform\"]]\n",
    "    if isoform_id and len(isoform_id.split(\";\")) != 1:\n",
    "        isoform_id = None\n",
    "    # No isoform ID set, just aggregate all without regards to isoform.\n",
    "    row = row.apply(\n",
    "        lambda x: (\n",
    "            get_isoform_value_from_entry_UniProt(x, isoform_id)\n",
    "            if get_isoform_value_from_entry_UniProt(x, isoform_id).strip()\n",
    "            else x\n",
    "        )\n",
    "    )\n",
    "    row = row.apply(lambda x: x.strip().rstrip(\";\"))\n",
    "    # A duplicate reindexing error may here may mean duplicate columns in annotation column values\n",
    "    df_annotations.loc[idx, annotation_columns] = row.values\n",
    "# Clean up other annotations\n",
    "keys = [\"rhea\", \"go\", \"hgnc\"]\n",
    "for key in keys:\n",
    "    if key in df_annotations.columns:\n",
    "        df_annotations[key] = (\n",
    "            df_annotations[key]\n",
    "            .fillna(\"\")\n",
    "            .apply(\n",
    "                lambda x: build_string(\n",
    "                    [s.lstrip(f\"{key.upper()}:\") for s in split_string(x)]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "df_annotations = df_annotations.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "if compare:\n",
    "    compare_on_index = [annotation_type]\n",
    "    try:\n",
    "        df_previous = pd.read_csv(\n",
    "            database_dirpath / f\"{annotation_type}_{db_tag}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "            dtype=str,\n",
    "        )\n",
    "        df_previous = df_previous.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "    except FileNotFoundError:\n",
    "        df_previous = pd.DataFrame([], columns=compare_on_index)\n",
    "    df_comparision = compare_tables(\n",
    "        df_previous.set_index(compare_on_index),\n",
    "        df_annotations.set_index(compare_on_index),\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=compare_figsize)\n",
    "    ax.yaxis.set_tick_params(labelsize=8)\n",
    "    ax = visualize_comparison(df_comparision)\n",
    "\n",
    "if display_nunique:\n",
    "    for col in df_annotations.columns:\n",
    "        df = (\n",
    "            df_annotations[col]\n",
    "            .apply(lambda x: split_string(x))\n",
    "            .explode(col)\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        print(f\"{df.name}: {df.nunique()}\")\n",
    "if overwrite:\n",
    "    df_annotations.to_csv(\n",
    "        database_dirpath / f\"{annotation_type}_{db_tag}.tsv\", sep=\"\\t\", index=False\n",
    "    )\n",
    "\n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22accd6e-a1d9-4e2f-a423-3da147ad2c87",
   "metadata": {},
   "source": [
    "## Load Isoforms and Sequences\n",
    "### Isoforms\n",
    "#### Parse data into initial table of isoforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bde72c-4ab7-42dc-8e32-21c67aac980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "erythro_keywords = [\n",
    "    \"erythro\",\n",
    "    \"erythrocyte\",\n",
    "    \"erythroid\",\n",
    "    \"red blood cell\",\n",
    "    \"rbc\",\n",
    "    \"R-type\",\n",
    "    \"P5N-I\",\n",
    "    \"reticulocyte\",\n",
    "]\n",
    "backup_keywords = [\"cyto\", \"retic\", \"cell membrane\"]\n",
    "avoid_keywords = [\"non-erythro\", \"mito\", \"not detected\", \"synaptic\", \"testis\"]\n",
    "\n",
    "rename_mapping = {\n",
    "    \"Entry\": \"uniprot\",\n",
    "    \"Gene Names (primary)\": \"hgnc.symbol\",\n",
    "    \"Organism (ID)\": \"taxonomy\",\n",
    "    \"Alternative products (isoforms)\": \"uniprot.isoform\",\n",
    "    \"Tissue specificity\": \"tissue_specificity\",\n",
    "    \"Subcellular location [CC]\": \"subcellular_location\",\n",
    "}\n",
    "columns_to_search = [\"tissue_specificity\", \"subcellular_location\"]\n",
    "\n",
    "df_tissue_specificity = (\n",
    "    df_query_results.loc[:, list(rename_mapping)].rename(rename_mapping, axis=1).copy()\n",
    ")\n",
    "df_isoforms = parse_isoforms_UniProt(\n",
    "    df_tissue_specificity.loc[:, [\"uniprot\", \"uniprot.isoform\"]].copy(),\n",
    "    add_canonical=True,\n",
    ")\n",
    "df_isoforms = df_isoforms.merge(\n",
    "    df_tissue_specificity[columns_to_search],\n",
    "    left_on=\"uniprot\",\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_isoforms[\"erythroid\"] = pd.NA\n",
    "df_isoforms[\"backup\"] = pd.NA\n",
    "df_isoforms[\"avoid\"] = pd.NA\n",
    "df_isoforms[\"keywords.erythroid\"] = pd.NA\n",
    "df_isoforms[\"keywords.backup\"] = pd.NA\n",
    "df_isoforms[\"keywords.avoid\"] = pd.NA\n",
    "all_names = sorted(\n",
    "    df_isoforms[\"uniprot.isoform.name\"].replace(\"\", pd.NA).dropna().unique()\n",
    ")\n",
    "all_synonyms = sorted(\n",
    "    df_isoforms[\"uniprot.isoform.synonyms\"].replace(\"\", pd.NA).dropna().unique()\n",
    ")\n",
    "for col_to_search in columns_to_search:\n",
    "    for idx, value_string in df_isoforms[col_to_search].dropna().items():\n",
    "        if not re.search(r\"\\[Isoform (.+?(?=\\]))\", value_string):\n",
    "            continue\n",
    "        for isoform_entry in value_string.split(\";\"):\n",
    "            match = re.search(r\"\\[Isoform (.+?(?=\\]))\", isoform_entry)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            isoform_name_or_synonym = match.group(1)\n",
    "            if not (\n",
    "                df_isoforms.loc[idx, \"uniprot.isoform.name\"] == isoform_name_or_synonym\n",
    "                or df_isoforms.loc[idx, \"uniprot.isoform.synonyms\"]\n",
    "                == isoform_name_or_synonym\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            for col, keywords in zip(\n",
    "                [\"erythroid\", \"backup\", \"avoid\"],\n",
    "                [erythro_keywords, backup_keywords, avoid_keywords],\n",
    "            ):\n",
    "                found_keywords = set()\n",
    "                for k in keywords:\n",
    "                    found_keywords.update(\n",
    "                        re.findall(k, isoform_entry.strip(), re.IGNORECASE)\n",
    "                    )\n",
    "                if df_isoforms.fillna(\"\").loc[idx, f\"keywords.{col}\"]:\n",
    "                    found_keywords.update(\n",
    "                        split_string(df_isoforms.loc[idx, f\"keywords.{col}\"])\n",
    "                    )\n",
    "                df_isoforms.loc[idx, f\"keywords.{col}\"] = build_string(found_keywords)\n",
    "\n",
    "for col, keywords in zip(\n",
    "    [\"erythroid\", \"backup\", \"avoid\"],\n",
    "    [erythro_keywords, backup_keywords, avoid_keywords],\n",
    "):\n",
    "    df_isoforms[f\"keywords.{col}\"] = df_isoforms[f\"keywords.{col}\"].apply(\n",
    "        lambda x: set(split_string(x)) if isinstance(x, str) else set()\n",
    "    )\n",
    "    for k in keywords:\n",
    "        df_isoforms[f\"keywords.{col}\"] = (\n",
    "            df_isoforms[[f\"keywords.{col}\", \"uniprot.isoform.name\"]]\n",
    "            .fillna(\"\")\n",
    "            .apply(\n",
    "                lambda x: x[f\"keywords.{col}\"].union(\n",
    "                    set(re.findall(k, x[\"uniprot.isoform.name\"], re.IGNORECASE))\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "        df_isoforms[f\"keywords.{col}\"] = (\n",
    "            df_isoforms[[f\"keywords.{col}\", \"uniprot.isoform.synonyms\"]]\n",
    "            .fillna(\"\")\n",
    "            .apply(\n",
    "                lambda x: x[f\"keywords.{col}\"].union(\n",
    "                    set(re.findall(k, x[\"uniprot.isoform.synonyms\"], re.IGNORECASE))\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "    df_isoforms[f\"keywords.{col}\"] = df_isoforms[f\"keywords.{col}\"].apply(\n",
    "        lambda x: build_string([s for s in x if s])\n",
    "    )\n",
    "df_isoforms = df_isoforms.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "df_isoforms[\"erythroid\"] = df_isoforms[\"keywords.erythroid\"].notna()\n",
    "df_isoforms[\"backup\"] = df_isoforms[\"keywords.backup\"].notna()\n",
    "df_isoforms[\"avoid\"] = df_isoforms[\"keywords.avoid\"].notna()\n",
    "# Remove those found in both categories from \"erythroid\", usually caused by words like `non-erythro`\n",
    "df_isoforms.loc[\n",
    "    df_isoforms[df_isoforms[[\"erythroid\", \"avoid\"]].all(axis=1)].index,\n",
    "    \"erythroid\",\n",
    "] = False\n",
    "# Erythroid easily serves as a backup option\n",
    "df_isoforms.loc[\n",
    "    df_isoforms[df_isoforms[[\"erythroid\"]].all(axis=1)].index,\n",
    "    \"backup\",\n",
    "] = True\n",
    "\n",
    "df_isoforms[\"canonical\"] = df_isoforms[\"uniprot.canonical\"]\n",
    "df_isoforms[\"sequence.id\"] = df_isoforms.fillna(\"\").apply(\n",
    "    lambda x: x[\"uniprot.isoform\"] if x[\"uniprot.isoform\"] else x[\"uniprot\"], axis=1\n",
    ")\n",
    "df_isoforms = df_isoforms.replace(float(\"nan\"), pd.NA).replace(\"\", pd.NA)\n",
    "df_isoforms = (\n",
    "    df_isoforms.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"uniprot\",\n",
    "            \"uniprot.isoform\",\n",
    "            \"sequence.id\",\n",
    "            \"canonical\",\n",
    "            \"erythroid\",\n",
    "            \"backup\",\n",
    "            \"avoid\",\n",
    "            \"keywords.erythroid\",\n",
    "            \"keywords.backup\",\n",
    "            \"keywords.avoid\",\n",
    "        ],\n",
    "    ]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be6d3f-7508-46b1-a461-3313e1c0be75",
   "metadata": {},
   "source": [
    "### Sequences\n",
    "#### Extract sequences using UniParc Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7ad83-f79b-45ae-80c7-6d9d81564c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isoforms_sequences = df_isoforms[\n",
    "    df_isoforms.apply(lambda x: x[\"sequence.id\"].startswith(x[\"uniprot\"]), axis=1)\n",
    "].copy()\n",
    "query_ids = df_isoforms_sequences[\"sequence.id\"].unique()\n",
    "\n",
    "query_parameters = {\n",
    "    \"format\": \"tsv\",\n",
    "    \"size\": 500,\n",
    "    \"compressed\": True,\n",
    "    \"fields\": \",\".join(\n",
    "        [\n",
    "            \"sequence\",\n",
    "            \"length\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "query_key = \"initial\"\n",
    "df_results, uniparc, failed_ids, obselete_counts = query_UniProt(\n",
    "    list(query_ids),\n",
    "    query_parameters=query_parameters,\n",
    "    from_db=\"UniProtKB_AC-ID\",\n",
    "    to_db=\"UniParc\",\n",
    "    return_failed=True,\n",
    ")\n",
    "\n",
    "if failed_ids:\n",
    "    print(failed_ids)\n",
    "\n",
    "df_isoforms_sequences = df_isoforms_sequences.merge(\n",
    "    df_results.set_index(\"From\").rename(\n",
    "        {\n",
    "            \"Sequence\": \"sequence\",\n",
    "            \"Length\": \"sequence.length\",\n",
    "            \"mass\": \"sequence.mass\",\n",
    "        },\n",
    "        axis=1,\n",
    "    ),\n",
    "    left_on=\"sequence.id\",\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "# #  The following code can be used to address entries with issues in extractions. LDHB example.\n",
    "# df_isoforms_sequences = pd.concat(\n",
    "#     (\n",
    "#         df_isoforms_sequences,\n",
    "#         pd.DataFrame.from_dict(\n",
    "#             {\n",
    "#                 \"uniprot\": \"P07195\",\n",
    "#                 \"sequence.id\": \"P07195\",\n",
    "#                 \"canonical\": True,\n",
    "#                 \"erythroid\": False,\n",
    "#                 \"backup\": False,\n",
    "#                 \"avoid\": False,\n",
    "#                 \"sequence\": \"MATLKEKLIAPVAEEEATVPNNKITVVGVGQVGMACAISILGKSLADELALVDVLEDKLKGEMMDLQHGSLFLQTPKIVADKDYSVTANSKIVVVTAGVRQQEGESRLNLVQRNVNVFKFIIPQIVKYSPDCIIIVVSNPVDILTYVTWKLSGLPKHRVIGSGCNLDSARFRYLMAEKLGIHPSSCHGWILGEHGDSSVAVWSGVNVAGVSLQELNPEMGTDNDSENWKEVHKMVVESAYEVIKLKGYTNWAIGLSVADLIESMLKNLSRIHPVSTMVKGMYGIENEVFLSLPCILNARGLTSVINQKLKDDEVAQLKKSADTLWDIQKDLKDL\",\n",
    "#                 \"sequence.length\": \"334\",\n",
    "#             },\n",
    "#             orient=\"index\",\n",
    "#         ).T,\n",
    "#     ),\n",
    "#     axis=0,\n",
    "# ).convert_dtypes()\n",
    "\n",
    "df_isoforms_sequences = df_isoforms_sequences.reset_index(drop=True)\n",
    "\n",
    "if overwrite:\n",
    "    df_isoforms_sequences.to_csv(\n",
    "        database_dirpath / f\"{UNIPROT_DB_TAG}_isoforms_sequences.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "df_isoforms_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a17fae-02f6-441f-9edc-e6dcbc1b3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_mappings.merge(df_isoforms_sequences[df_isoforms_sequences[\"erythroid\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0d10b-c748-48f6-a49e-65eec662216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
