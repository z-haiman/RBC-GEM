{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba9c3d2c-72da-416c-8612-8a3f91eee20a",
   "metadata": {},
   "source": [
    "# RBC-GEM 1.3.0 Updates\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c1f88-6d9b-40d5-b468-86da5bc66f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cobra.core import Gene, Metabolite, Reaction\n",
    "from rbc_gem_utils import (\n",
    "    COBRA_CONFIGURATION,\n",
    "    GEM_NAME,\n",
    "    build_string,\n",
    "    get_dirpath,\n",
    "    read_cobra_model,\n",
    "    split_string,\n",
    "    write_cobra_model,\n",
    ")\n",
    "from rbc_gem_utils.qc import (\n",
    "    reset_reaction_bounds,\n",
    "    reset_subsystem_groups,\n",
    "    standardardize_metabolite_formulas,\n",
    ")\n",
    "from rbc_gem_utils.util import strip_plural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a5ce1-932d-4622-a823-c54b76b48d99",
   "metadata": {},
   "source": [
    "### Define configuration\n",
    "#### COBRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d3e47-f2f1-44e6-9333-4adec35ef021",
   "metadata": {},
   "outputs": [],
   "source": [
    "COBRA_CONFIGURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907271c3-244f-4dbe-8539-bfd8adcb4fb3",
   "metadata": {},
   "source": [
    "## Set notebook options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c935e77-d22e-48bc-a9a9-8983392a649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "update_version = \"1.3.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967b496-7302-49a9-a474-45b13dc70980",
   "metadata": {},
   "source": [
    "## Load RBC-GEM model\n",
    "### Version: 1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d69b8-f885-4cda-9598-505f2b72b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirpath = get_dirpath(\"model\")\n",
    "model = read_cobra_model(filename=model_dirpath / f\"{GEM_NAME}.yml\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60f5b7-60f2-4300-94ce-77f2b0951345",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081c9f6-3475-4a71-bc23-7352e08b4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_types = [\"metabolites\", \"genes\", \"reactions\"]\n",
    "retired_shorthands = [\"met\", \"gene\", \"rxn\"]\n",
    "\n",
    "dataframes_updated = {}\n",
    "dataframes_removed = {}\n",
    "\n",
    "# For export\n",
    "dataframes_evidence = {}\n",
    "dataframes_removals = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1dd6fa-b301-462c-9bb2-21ce46f82a46",
   "metadata": {},
   "source": [
    "### Dataframes for updates and removals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e5f90-331c-49ee-a2cd-5e2f4fca3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_updated = dict(\n",
    "    (\n",
    "        (\n",
    "            attribute_type,\n",
    "            pd.read_csv(\n",
    "                get_dirpath(\"curation\")\n",
    "                / f\"{attribute_type}_updated_{update_version}.tsv\",\n",
    "                sep=\"\\t\",\n",
    "                index_col=None,\n",
    "            ),\n",
    "        )\n",
    "        if (\n",
    "            get_dirpath(\"curation\") / f\"{attribute_type}_updated_{update_version}.tsv\"\n",
    "        ).exists()\n",
    "        else (attribute_type, pd.DataFrame())\n",
    "    )\n",
    "    for attribute_type in attribute_types\n",
    ")\n",
    "\n",
    "dataframes_removed = dict(\n",
    "    (\n",
    "        (\n",
    "            attribute_type,\n",
    "            pd.read_csv(\n",
    "                get_dirpath(\"curation\")\n",
    "                / f\"{attribute_type}_removed_{update_version}.tsv\",\n",
    "                sep=\"\\t\",\n",
    "                index_col=None,\n",
    "            ),\n",
    "        )\n",
    "        if (\n",
    "            get_dirpath(\"curation\") / f\"{attribute_type}_removed_{update_version}.tsv\"\n",
    "        ).exists()\n",
    "        else (attribute_type, pd.DataFrame())\n",
    "    )\n",
    "    for attribute_type in attribute_types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70f39b-d83b-47fe-8893-088b6d95429a",
   "metadata": {},
   "source": [
    "#### Determine IDs to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5978532-a50e-4a53-9626-911199d561d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_mapping_dicts = dict(\n",
    "    (\n",
    "        (attribute_type, {})\n",
    "        if dataframes_updated[attribute_type].empty\n",
    "        or dataframes_updated[attribute_type][[attribute_type, \"retired\"]]\n",
    "        .dropna()\n",
    "        .empty\n",
    "        else (\n",
    "            attribute_type,\n",
    "            dataframes_updated[attribute_type][[attribute_type, \"retired\"]]\n",
    "            .dropna()\n",
    "            .set_index(\"retired\")[attribute_type]\n",
    "            .to_dict(),\n",
    "        )\n",
    "    )\n",
    "    for attribute_type in attribute_types\n",
    ")\n",
    "id_mapping_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774ce5e-5cc7-4bb1-bf3f-68fe2e92047b",
   "metadata": {},
   "source": [
    "#### Load omic evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefc10e-82d5-4a0c-ab52-23758fc41278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteomic_evidence = pd.read_csv(\n",
    "    get_dirpath(\"proteomics\", use_temp=\"external\") / \"proteomic_evidence_table.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index_col=0,\n",
    ")\n",
    "df_proteomic_evidence = pd.concat(\n",
    "    (\n",
    "        df_proteomic_evidence.sum(axis=1),\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                uniprot_id: build_string(\n",
    "                    sorted(\n",
    "                        [\n",
    "                            f\"{pubmed}\"\n",
    "                            for pubmed, is_detected in value_dict.items()\n",
    "                            if bool(is_detected)\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                for uniprot_id, value_dict in df_proteomic_evidence.T.to_dict().items()\n",
    "            },\n",
    "            orient=\"index\",\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df_proteomic_evidence.columns = [\n",
    "    \"proteomic evidence (#studies)\",\n",
    "    \"proteomic evidence (pubmed)\",\n",
    "]\n",
    "df_proteomic_evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c443b-d26f-41e6-a674-30a1c91900db",
   "metadata": {},
   "source": [
    "## Apply updates\n",
    "Update order: \n",
    "1. Metabolites\n",
    "2. Genes\n",
    "3. Reactions\n",
    "### Deprecate identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa09151-f2d0-47fd-b95b-51a731d20580",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute_type, col_key in zip(attribute_types, retired_shorthands):\n",
    "    id_mapping_dict = id_mapping_dicts[attribute_type]\n",
    "    if not id_mapping_dict:\n",
    "        print(f\"No identifiers to deprecate/update for {attribute_type}.\")\n",
    "        continue\n",
    "    id_mapping_df = pd.DataFrame.from_dict(id_mapping_dict, orient=\"index\")\n",
    "    id_mapping_df = id_mapping_df.reset_index(drop=False)\n",
    "    id_mapping_df.columns = [f\"{col_key}Retired\", f\"{col_key}s\"]\n",
    "    # Reverse column irder for mapping\n",
    "    id_mapping_df = id_mapping_df.loc[:, list(id_mapping_df.columns[::-1])]\n",
    "\n",
    "    # Get DataFrame for previous deprecated IDs\n",
    "    previous_id_mapping_df = pd.read_csv(\n",
    "        get_dirpath(\"deprecatedIdentifiers\")\n",
    "        / f\"{attribute_type}_deprecatedIdentifiers.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index_col=None,\n",
    "    )\n",
    "\n",
    "    for idx, row in id_mapping_df.iterrows():\n",
    "        new_id, retiring = row[list(id_mapping_df.columns)]\n",
    "        previously_retired = previous_id_mapping_df[\n",
    "            previous_id_mapping_df[f\"{col_key}s\"] == retiring\n",
    "        ]\n",
    "        retired_set_of_ids = {retiring}\n",
    "        if not previously_retired.empty:\n",
    "            # Get all previously retired IDs\n",
    "            retired_set_of_ids.update(\n",
    "                previously_retired[f\"{col_key}Retired\"].apply(split_string).item()\n",
    "            )\n",
    "            # Pulling the ID out of retirement\n",
    "            if new_id in retired_set_of_ids:\n",
    "                retired_set_of_ids.remove(new_id)\n",
    "            retired_set_of_ids.add(retiring)\n",
    "        id_mapping_df.loc[idx, f\"{col_key}Retired\"] = build_string(\n",
    "            retired_set_of_ids, sep=\";\"\n",
    "        )\n",
    "\n",
    "    # Replace ID\n",
    "    for old, new in id_mapping_dict.items():\n",
    "        try:\n",
    "            obj = getattr(model, attribute_type).get_by_id(old)\n",
    "        except KeyError:\n",
    "            print(f\"Could not map {old} to new ID.\")\n",
    "        else:\n",
    "            try:\n",
    "                obj.id = id_mapping_dict[obj.id]\n",
    "            except ValueError as e:\n",
    "                warn(f\"{e}, this is expected if removing/renaming a duplicate\")\n",
    "                getattr(model, f\"remove_{attribute_type}\")([obj])\n",
    "    # Repair model\n",
    "    model.repair(rebuild_index=True, rebuild_relationships=True)\n",
    "    # Add to DataFrane\n",
    "    id_mapping_df = pd.concat((id_mapping_df, previous_id_mapping_df), axis=0)\n",
    "    id_mapping_df = (\n",
    "        id_mapping_df.drop_duplicates()\n",
    "        .sort_values(f\"{col_key}s\", ascending=True)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    get_dirpath(\n",
    "        \"deprecatedIdentifiers\", use_temp=\"interim\" if not overwrite else None\n",
    "    ).mkdir(exist_ok=True, parents=True)\n",
    "    id_mapping_df.to_csv(\n",
    "        get_dirpath(\n",
    "            \"deprecatedIdentifiers\", use_temp=\"interim\" if not overwrite else None\n",
    "        )\n",
    "        / f\"{attribute_type}_deprecatedIdentifiers.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b32955-a0d5-45c6-81e4-183760ce44d0",
   "metadata": {},
   "source": [
    "#### Metabolites\n",
    "* Removed odd symbol characters from names:\n",
    "    * polyadprib1, polyadprib2\n",
    "* Compartment corrections:\n",
    "    * e217obglcur_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9d8bb-9581-4278-a2db-f24a7c4425c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_type = \"metabolites\"\n",
    "attr_cols = [\"name\", \"formula\", \"charge\", \"compartment\"]\n",
    "obj_type = Metabolite\n",
    "\n",
    "df_updated = dataframes_updated[attribute_type]\n",
    "if not df_updated.empty:\n",
    "    df_updated = (\n",
    "        df_updated.drop(\"retired\", axis=1).set_index(attribute_type).convert_dtypes()\n",
    "    )\n",
    "    for idx, row in df_updated.iterrows():\n",
    "        obj_id = idx\n",
    "        # Deprecated IDs should be updated at this point, only refers to new metabolites\n",
    "        try:\n",
    "            has_id = getattr(model, attribute_type).has_id(obj_id)\n",
    "            if not has_id:\n",
    "                if attribute_type == \"genes\":\n",
    "                    # No 'add_genes' method in cobrapy\n",
    "                    add_method = getattr(model, f\"{attribute_type}\").extend\n",
    "                else:\n",
    "                    add_method = getattr(model, f\"add_{attribute_type}\")\n",
    "                add_method([obj_type(obj_id)])\n",
    "        except ValueError as e:\n",
    "            print(f\"Error with {obj_id}\")\n",
    "            raise e\n",
    "\n",
    "        obj = getattr(model, attribute_type).get_by_id(obj_id)\n",
    "        for attr, value in zip(attr_cols, row.convert_dtypes()[attr_cols].fillna(\"\")):\n",
    "            if value:\n",
    "                attr = attr.replace(\" \", \"_\")\n",
    "                setattr(obj, attr, value)\n",
    "        annotations_dict = {\n",
    "            k: v\n",
    "            for k, v in row.convert_dtypes()[\n",
    "                ~row.index.isin([attribute_type] + attr_cols)\n",
    "            ]\n",
    "            .to_dict()\n",
    "            .items()\n",
    "            if not \"evidence\" in k and (v and v != float(\"nan\"))\n",
    "        }\n",
    "        try:\n",
    "            notes_dict = {\"notes\": annotations_dict.pop(\"notes\")}\n",
    "        except KeyError:\n",
    "            notes_dict = obj.notes\n",
    "        obj.annotation.update(annotations_dict)\n",
    "        obj.notes.update(notes_dict)\n",
    "\n",
    "    # Update evidence\n",
    "    try:\n",
    "        df_previous_evidence = pd.read_csv(\n",
    "            get_dirpath(\"curation\") / f\"{attribute_type}_evidence.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        df_previous_evidence = pd.DataFrame([], columns=[attribute_type], dtype=str)\n",
    "\n",
    "    # Replace previous IDs with new ones\n",
    "    df_previous_evidence[attribute_type] = df_previous_evidence[attribute_type].replace(\n",
    "        id_mapping_dicts[attribute_type]\n",
    "    )\n",
    "    # Replace non-empty values with previous ones\n",
    "    df_previous_values = (\n",
    "        df_previous_evidence[\n",
    "            df_previous_evidence[attribute_type].isin(df_updated.index)\n",
    "        ]\n",
    "        .set_index(attribute_type)\n",
    "        .convert_dtypes()\n",
    "    )\n",
    "    cols_to_update = list(\n",
    "        df_previous_evidence.columns[\n",
    "            ~df_previous_evidence.columns.isin(\n",
    "                attr_cols + [attribute_type, strip_plural(attribute_type)]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # Evidence can be problematic due to data coercion\n",
    "    cols_to_update = [c for c in cols_to_update if \"evidence\" not in c]\n",
    "\n",
    "    # Set indices to align\n",
    "    df_updated.loc[list(df_updated.index), cols_to_update] = df_updated.loc[\n",
    "        list(df_updated.index), cols_to_update\n",
    "    ].fillna(\n",
    "        df_previous_values.loc[list(df_updated.index), cols_to_update],\n",
    "        method=None,\n",
    "        axis=1,\n",
    "    )\n",
    "    # Reset index of updated DataFrame\n",
    "    df_updated = df_updated.reset_index(drop=False)\n",
    "\n",
    "    # Add updated entries to DataFrame\n",
    "    df_evidence = (\n",
    "        pd.concat((df_updated, df_previous_evidence), axis=0)\n",
    "        .replace(\"nan\", str)\n",
    "        .convert_dtypes()\n",
    "    )\n",
    "    df_evidence = (\n",
    "        df_evidence.drop_duplicates(subset=[attribute_type], keep=\"first\")\n",
    "        .sort_values(attribute_type, ascending=True)\n",
    "        .reset_index(drop=True)\n",
    "    )[df_previous_evidence.columns]\n",
    "    dataframes_evidence[attribute_type] = df_evidence\n",
    "df_evidence[df_evidence[attribute_type].isin(df_updated[attribute_type])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa1ed6-3934-4014-85dc-c4d3a7175cf7",
   "metadata": {},
   "source": [
    "##### Standardize metabolite formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385822c4-5487-44cc-a8b6-6f7389e5882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_type = \"metabolites\"\n",
    "df_evidence = dataframes_evidence[attribute_type].set_index(attribute_type)\n",
    "met_formulas = standardardize_metabolite_formulas(\n",
    "    dict(zip(model.metabolites.list_attr(\"id\"), model.metabolites.list_attr(\"formula\")))\n",
    ")\n",
    "for mid, formula in met_formulas.items():\n",
    "    model.metabolites.get_by_id(mid).formula = formula\n",
    "    df_evidence.loc[mid, \"formula\"] = formula\n",
    "dataframes_evidence[attribute_type] = df_evidence.reset_index(drop=False)\n",
    "dataframes_evidence[attribute_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142935ef-76b4-4ccb-8ba6-2a3f999c2f2b",
   "metadata": {},
   "source": [
    "#### Genes\n",
    "* Added the lost pubmed evidence for the following:\n",
    "    * SLCO1A2, SLCO2B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188598d-3b9d-4c40-9ecc-45752ba68d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_type = \"genes\"\n",
    "attr_cols = []\n",
    "obj_type = Gene\n",
    "\n",
    "df_updated = dataframes_updated[attribute_type]\n",
    "if not df_updated.empty:\n",
    "    df_updated = (\n",
    "        df_updated.drop(\"retired\", axis=1).set_index(attribute_type).convert_dtypes()\n",
    "    )\n",
    "    for idx, row in df_updated.iterrows():\n",
    "        obj_id = idx\n",
    "        # Deprecated IDs should be updated at this point, only refers to new metabolites\n",
    "        try:\n",
    "            has_id = getattr(model, attribute_type).has_id(obj_id)\n",
    "            if not has_id:\n",
    "                if attribute_type == \"genes\":\n",
    "                    # No 'add_genes' method in cobrapy\n",
    "                    add_method = getattr(model, f\"{attribute_type}\").extend\n",
    "                else:\n",
    "                    add_method = getattr(model, f\"add_{attribute_type}\")\n",
    "                add_method([obj_type(obj_id)])\n",
    "        except ValueError as e:\n",
    "            print(f\"Error with {obj_id}\")\n",
    "            raise e\n",
    "\n",
    "        obj = getattr(model, attribute_type).get_by_id(obj_id)\n",
    "        for attr, value in zip(attr_cols, row.convert_dtypes()[attr_cols].fillna(\"\")):\n",
    "            if value:\n",
    "                attr = attr.replace(\" \", \"_\")\n",
    "                setattr(obj, attr, value)\n",
    "        annotations_dict = {\n",
    "            k: v\n",
    "            for k, v in row.convert_dtypes()[\n",
    "                ~row.index.isin([attribute_type] + attr_cols)\n",
    "            ]\n",
    "            .to_dict()\n",
    "            .items()\n",
    "            if not \"evidence\" in k and (v and v != float(\"nan\"))\n",
    "        }\n",
    "        try:\n",
    "            notes_dict = {\"notes\": annotations_dict.pop(\"notes\")}\n",
    "        except KeyError:\n",
    "            notes_dict = obj.notes\n",
    "        obj.annotation.update(annotations_dict)\n",
    "        obj.notes.update(notes_dict)\n",
    "\n",
    "    # Update evidence\n",
    "    try:\n",
    "        df_previous_evidence = pd.read_csv(\n",
    "            get_dirpath(\"curation\") / f\"{attribute_type}_evidence.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        df_previous_evidence = pd.DataFrame([], columns=[attribute_type], dtype=str)\n",
    "\n",
    "    # Replace previous IDs with new ones\n",
    "    df_previous_evidence[attribute_type] = df_previous_evidence[attribute_type].replace(\n",
    "        id_mapping_dicts[attribute_type]\n",
    "    )\n",
    "    # Replace non-empty values with previous ones\n",
    "    df_previous_values = (\n",
    "        df_previous_evidence[\n",
    "            df_previous_evidence[attribute_type].isin(df_updated.index)\n",
    "        ]\n",
    "        .set_index(attribute_type)\n",
    "        .convert_dtypes()\n",
    "    )\n",
    "    cols_to_update = list(\n",
    "        df_previous_evidence.columns[\n",
    "            ~df_previous_evidence.columns.isin(\n",
    "                attr_cols + [attribute_type, strip_plural(attribute_type)]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # Evidence can be problematic due to data coercion\n",
    "    cols_to_update = [c for c in cols_to_update if \"evidence\" not in c]\n",
    "\n",
    "    # Set indices to align\n",
    "    df_updated.loc[list(df_updated.index), cols_to_update] = df_updated.loc[\n",
    "        list(df_updated.index), cols_to_update\n",
    "    ].fillna(\n",
    "        df_previous_values.loc[list(df_updated.index), cols_to_update],\n",
    "        method=None,\n",
    "        axis=1,\n",
    "    )\n",
    "    # Reset index of updated DataFrame\n",
    "    df_updated = df_updated.reset_index(drop=False)\n",
    "\n",
    "    # Add updated entries to DataFrame\n",
    "    df_evidence = (\n",
    "        pd.concat((df_updated, df_previous_evidence), axis=0)\n",
    "        .replace(\"nan\", str)\n",
    "        .convert_dtypes()\n",
    "    )\n",
    "    df_evidence = (\n",
    "        df_evidence.drop_duplicates(subset=[attribute_type], keep=\"first\")\n",
    "        .sort_values(attribute_type, ascending=True)\n",
    "        .reset_index(drop=True)\n",
    "    )[df_previous_evidence.columns]\n",
    "    dataframes_evidence[attribute_type] = df_evidence\n",
    "df_evidence[df_evidence[attribute_type].isin(df_updated[attribute_type])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b663bd-ec10-4b25-8185-774ddebad38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_type = \"genes\"\n",
    "df_evidence = dataframes_evidence[attribute_type].set_index(attribute_type)\n",
    "gene_names = df_evidence[\"name\"].to_dict()\n",
    "df_evidence = df_evidence.reset_index(drop=False)\n",
    "for gid, gname in gene_names.items():\n",
    "    model.genes.get_by_id(gid).name = gname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7ece2-0414-4a4a-ae01-c54bda877529",
   "metadata": {},
   "source": [
    "##### Annotate evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d17ef-8853-4e7a-a055-97773294e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_evidence = dataframes_evidence[attribute_type]\n",
    "# columns_ordered = list(df_evidence.columns)\n",
    "# df_evidence = df_evidence.set_index(\"uniprot\")\n",
    "# df_omic_evidence = df_proteomic_evidence[df_proteomic_evidence.index.isin(df_evidence.index)]\n",
    "# df_evidence.loc[df_omic_evidence.index, df_omic_evidence.columns] = df_omic_evidence\n",
    "\n",
    "# df_no_evidence  = df_evidence[~df_evidence.index.isin(df_proteomic_evidence.index)][df_omic_evidence.columns]\n",
    "# df_no_evidence.loc[:, df_proteomic_evidence.columns[0]] = 0\n",
    "# df_no_evidence.loc[:, df_proteomic_evidence.columns[1]] = pd.NA\n",
    "# df_evidence.loc[df_no_evidence.index, df_no_evidence.columns] = df_no_evidence\n",
    "\n",
    "# dataframes_evidence[attribute_type] = df_evidence.reset_index(drop=False).loc[:, columns_ordered]\n",
    "# dataframes_evidence[attribute_type]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b1b3476-7c28-4164-a425-87ea22f92085",
   "metadata": {},
   "source": [
    "#### Reactions\n",
    "* Added the lost pubmed evidence for the following genes/proteins:\n",
    "    * CHOLATEt, CPPP3te, DGCHOLte, DHEASte, E217BGLCRte, ESTRONESte, GCHOLAte, GDCHOLAte, GUDCHOLAte, PGD2te, PGE2te, PRGNStec, TCHOLAte, TDCHOLAte, TDECHOLAte, TETIODTHYt2, TRIIODTHYt2, TUDCHOLAte\n",
    "    * Based on the protein evidence and UniProt database\n",
    "* Removed odd symbol characters from names:\n",
    "\t*  ACMAH\n",
    "* Updated subsystems for the following:\n",
    "    * PAFH, PAFS: Glycerophopsholipid metabolism --> Ether lipid metabolism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25730a7-5ab0-4827-8e18-18ffb1b3f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_type = \"reactions\"\n",
    "attr_cols = [\"name\", \"reaction\", \"gene reaction rule\", \"subsystem\"]\n",
    "obj_type = Reaction\n",
    "\n",
    "df_updated = dataframes_updated[attribute_type]\n",
    "if not df_updated.empty:\n",
    "    df_updated = (\n",
    "        df_updated.drop(\"retired\", axis=1).set_index(attribute_type).convert_dtypes()\n",
    "    )\n",
    "    for idx, row in df_updated.iterrows():\n",
    "        obj_id = idx\n",
    "        # Deprecated IDs should be updated at this point, only refers to new metabolites\n",
    "        try:\n",
    "            has_id = getattr(model, attribute_type).has_id(obj_id)\n",
    "            if not has_id:\n",
    "                if attribute_type == \"genes\":\n",
    "                    # No 'add_genes' method in cobrapy\n",
    "                    add_method = getattr(model, f\"{attribute_type}\").extend\n",
    "                else:\n",
    "                    add_method = getattr(model, f\"add_{attribute_type}\")\n",
    "                add_method([obj_type(obj_id)])\n",
    "        except ValueError as e:\n",
    "            print(f\"Error with {obj_id}\")\n",
    "            raise e\n",
    "\n",
    "        obj = getattr(model, attribute_type).get_by_id(obj_id)\n",
    "        for attr, value in zip(attr_cols, row.convert_dtypes()[attr_cols].fillna(\"\")):\n",
    "            if value:\n",
    "                attr = attr.replace(\" \", \"_\")\n",
    "                setattr(obj, attr, value)\n",
    "        annotations_dict = {\n",
    "            k: v\n",
    "            for k, v in row.convert_dtypes()[\n",
    "                ~row.index.isin([attribute_type] + attr_cols)\n",
    "            ]\n",
    "            .to_dict()\n",
    "            .items()\n",
    "            if not \"evidence\" in k and (v and v != float(\"nan\"))\n",
    "        }\n",
    "        try:\n",
    "            notes_dict = {\"notes\": annotations_dict.pop(\"notes\")}\n",
    "        except KeyError:\n",
    "            notes_dict = obj.notes\n",
    "        obj.annotation.update(annotations_dict)\n",
    "        obj.notes.update(notes_dict)\n",
    "\n",
    "    # Update evidence\n",
    "    try:\n",
    "        df_previous_evidence = pd.read_csv(\n",
    "            get_dirpath(\"curation\") / f\"{attribute_type}_evidence.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=None,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        df_previous_evidence = pd.DataFrame([], columns=[attribute_type], dtype=str)\n",
    "\n",
    "    # Replace previous IDs with new ones\n",
    "    df_previous_evidence[attribute_type] = df_previous_evidence[attribute_type].replace(\n",
    "        id_mapping_dicts[attribute_type]\n",
    "    )\n",
    "    # Replace non-empty values with previous ones\n",
    "    df_previous_values = (\n",
    "        df_previous_evidence[\n",
    "            df_previous_evidence[attribute_type].isin(df_updated.index)\n",
    "        ]\n",
    "        .set_index(attribute_type)\n",
    "        .convert_dtypes()\n",
    "    )\n",
    "    cols_to_update = list(\n",
    "        df_previous_evidence.columns[\n",
    "            ~df_previous_evidence.columns.isin(\n",
    "                attr_cols + [attribute_type, strip_plural(attribute_type)]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # Evidence can be problematic due to data coercion\n",
    "    cols_to_update = [c for c in cols_to_update if \"evidence\" not in c]\n",
    "\n",
    "    # Set indices to align\n",
    "    df_updated.loc[list(df_updated.index), cols_to_update] = df_updated.loc[\n",
    "        list(df_updated.index), cols_to_update\n",
    "    ].fillna(\n",
    "        df_previous_values.loc[list(df_updated.index), cols_to_update],\n",
    "        method=None,\n",
    "        axis=1,\n",
    "    )\n",
    "    # Reset index of updated DataFrame\n",
    "    df_updated = df_updated.reset_index(drop=False)\n",
    "\n",
    "    # Add updated entries to DataFrame\n",
    "    df_evidence = (\n",
    "        pd.concat((df_updated, df_previous_evidence), axis=0)\n",
    "        .replace(\"nan\", str)\n",
    "        .convert_dtypes()\n",
    "    )\n",
    "    df_evidence = (\n",
    "        df_evidence.drop_duplicates(subset=[attribute_type], keep=\"first\")\n",
    "        .sort_values(attribute_type, ascending=True)\n",
    "        .reset_index(drop=True)\n",
    "    )[df_previous_evidence.columns]\n",
    "    dataframes_evidence[attribute_type] = df_evidence\n",
    "df_evidence[df_evidence[attribute_type].isin(df_updated[attribute_type])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64d45450-d19e-4e09-b76b-8ad6471b8153",
   "metadata": {},
   "source": [
    "## Refine model through removing items\n",
    "Removal order: \n",
    "1. Reactions\n",
    "2. Genes\n",
    "3. Metabolites\n",
    "#### Reactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d434a25-de3f-4e6b-98be-bb902e3092eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_type = \"reactions\"\n",
    "# try:\n",
    "#     df_removal = pd.read_csv(\n",
    "#         get_dirpath(\"curation\") / f\"{attribute_type}_removed.tsv\",\n",
    "#         sep=\"\\t\",\n",
    "#         index_col=None,\n",
    "#     )\n",
    "# except FileNotFoundError:\n",
    "#     df_removed = pd.DataFrame([], columns=[attribute_type], dtype=str)\n",
    "\n",
    "# to_remove = []\n",
    "# for reaction in df_removed[attribute_type]:\n",
    "#     try:\n",
    "#         reaction = getattr(model, attribute_type).get_by_id(reaction)\n",
    "#     except KeyError:\n",
    "#         continue\n",
    "#     to_remove.append(reaction)\n",
    "\n",
    "# model.remove_reactions(to_remove)\n",
    "# # Clean up removal file before archival\n",
    "# df_removed = (\n",
    "#     df_removed.drop_duplicates(subset=[attribute_type])\n",
    "#     .sort_values(attribute_type, ascending=True)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# dataframes_evidence[attribute_type] = dataframes_evidence[attribute_type][\n",
    "#     ~dataframes_evidence[attribute_type][attribute_type].isin(\n",
    "#         df_removed[attribute_type].values\n",
    "#     )\n",
    "# ]\n",
    "# dataframes_removed[attribute_type] = df_removed\n",
    "# dataframes_removed[attribute_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279505a-5e9f-44f3-b4ba-33e9b957d6e2",
   "metadata": {},
   "source": [
    "#### Genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987ef03-a8fb-433e-8396-99a6d9bd6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_type = \"genes\"\n",
    "# try:\n",
    "#     df_removed = pd.read_csv(\n",
    "#         get_dirpath(\"curation\") / f\"{attribute_type}_removed.tsv\",\n",
    "#         sep=\"\\t\",\n",
    "#         index_col=None,\n",
    "#         dtype=str,\n",
    "#     )\n",
    "# except FileNotFoundError:\n",
    "#     df_removed = pd.DataFrame([], columns=[attribute_type], dtype=str)\n",
    "\n",
    "# to_remove = []\n",
    "# for gene in df_removed[attribute_type]:\n",
    "#     try:\n",
    "#         gene = model.genes.get_by_id(gene)\n",
    "#     except KeyError:\n",
    "#         continue\n",
    "#     to_remove.append(gene)\n",
    "# model.genes -= to_remove\n",
    "\n",
    "# # Clean up removal file before archival\n",
    "# df_removed = (\n",
    "#     df_removed.drop_duplicates(subset=[attribute_type])\n",
    "#     .sort_values(attribute_type, ascending=True)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# for gene in model.genes:\n",
    "#     if gene.reactions:\n",
    "#         continue\n",
    "#     print(f\"Orphaned: {gene}\")\n",
    "\n",
    "# dataframes_evidence[attribute_type] = dataframes_evidence[attribute_type][\n",
    "#     ~dataframes_evidence[attribute_type][attribute_type].isin(\n",
    "#         df_removed[attribute_type].values\n",
    "#     )\n",
    "# ]\n",
    "# dataframes_removed[attribute_type] = df_removed\n",
    "# dataframes_removed[attribute_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7e51b-9730-439a-a0ce-271b65d72dcd",
   "metadata": {},
   "source": [
    "#### Metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b992c-9399-45aa-921f-c415db9e0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_type = \"metabolites\"\n",
    "# try:\n",
    "#     df_removed = pd.read_csv(\n",
    "#         get_dirpath(\"curation\") / f\"{attribute_type}_removed.tsv\",\n",
    "#         sep=\"\\t\",\n",
    "#         index_col=None,\n",
    "#         dtype=str,\n",
    "#     )\n",
    "# except FileNotFoundError:\n",
    "#     df_removed = pd.DataFrame([], columns=[attribute_type], dtype=str)\n",
    "\n",
    "# to_remove = []\n",
    "# for metabolite in df_removed[attribute_type]:\n",
    "#     try:\n",
    "#         metabolite = model.metabolites.get_by_id(metabolite)\n",
    "#     except KeyError:\n",
    "#         continue\n",
    "#     model.remove_metabolites([metabolite])\n",
    "# model.remove_metabolites(to_remove)\n",
    "\n",
    "# # Clean up removal file before archival\n",
    "# df_removed = (\n",
    "#     df_removed.drop_duplicates(subset=[attribute_type])\n",
    "#     .sort_values(attribute_type, ascending=True)\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "# for metabolite in model.metabolites:\n",
    "#     if metabolite.reactions:\n",
    "#         continue\n",
    "#     print(f\"Orphaned: {metabolite}\")\n",
    "\n",
    "# dataframes_evidence[attribute_type] = dataframes_evidence[attribute_type][\n",
    "#     ~dataframes_evidence[attribute_type][attribute_type].isin(\n",
    "#         df_removed[attribute_type].values\n",
    "#     )\n",
    "# ]\n",
    "# dataframes_removed[attribute_type] = df_removed\n",
    "# dataframes_removed[attribute_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe3007-e6fe-4fdd-97a7-4f764d13ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dirpath(\"curation\", use_temp=\"interim\" if not overwrite else None).mkdir(exist_ok=True, parents=True)\n",
    "# for dtype, dataframe_dict in zip([\"evidence\", \"removals\"], [dataframes_evidence, dataframes_removals]):\n",
    "#     for attribute_type in attribute_types:\n",
    "#         df = dataframe_dict.get(attribute_type)\n",
    "#         if df is not None and not df.empty:\n",
    "#             df.to_csv(\n",
    "#                 get_dirpath(\"curation\", use_temp=\"interim\" if not overwrite else None) / f\"{attribute_type}_{dtype}.tsv\",\n",
    "#                 sep=\"\\t\",\n",
    "#                 index=False,\n",
    "#             )\n",
    "#             print(f\"Saving {dtype} for {attribute_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886da88c-00c0-4638-974f-2766333f4d7b",
   "metadata": {},
   "source": [
    "### Ensure all metabolites, genes, and reactions exist\n",
    "If removed (e.g., a duplicate), will show up in missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56939d1-4a0c-4f68-b200-b84d7da345d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_sets = {}\n",
    "for attribute_type in attribute_types:\n",
    "    obj_list = getattr(model, attribute_type)\n",
    "    if attribute_type == \"reactions\":\n",
    "        obj_list = obj_list.query(lambda x: not x.subsystem == \"Pseudoreactions\")\n",
    "    id_set = set(obj_list.list_attr(\"id\"))\n",
    "    missing_sets[attribute_type] = id_set.symmetric_difference(\n",
    "        dataframes_evidence[attribute_type][attribute_type].values\n",
    "    )\n",
    "    print(f\"Number of missing {attribute_type}: {len(missing_sets[attribute_type])}\")\n",
    "missing_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83e690-0829-4236-9161-165a400539cb",
   "metadata": {},
   "source": [
    "### Check for extra metabolites, genes, and reactions without any associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b542d-2669-43ab-b212-4d875f54558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute_type in attribute_types:\n",
    "    if attribute_type == \"reactions\":\n",
    "        query_function = lambda x: not len(x.metabolites)\n",
    "    else:\n",
    "        query_function = lambda x: not len(x.reactions)\n",
    "    extras_list = getattr(model, attribute_type).query(query_function)\n",
    "    if extras_list:\n",
    "        print(\n",
    "            \"\\n\".join((\"\", attribute_type.capitalize(), len(attribute_type) * \"=\", \"\"))\n",
    "        )\n",
    "        for item in extras_list:\n",
    "            print(item)\n",
    "    else:\n",
    "        print(f\"No extra {attribute_type}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac24451-ec72-4565-8cb8-8fc57c6ee2d9",
   "metadata": {},
   "source": [
    "#### Add boundary reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424c4c7-dd7d-4473-b9e4-f0b69b9278b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create from a list\n",
    "boundaries = {\n",
    "    # All exchange boundary reactions added\n",
    "    \"exchange\": model.metabolites.query(lambda x: x.compartment == \"e\").list_attr(\"id\"),\n",
    "    # Intracellular demands, only used for accumulation is allowed for a compound\n",
    "    \"demand\": [],\n",
    "    # Intracellular sinks, only used for when a source is needed for a compound\n",
    "    \"sink\": [\n",
    "        # Globin/Hemoglobin\n",
    "        \"oxyhb_c\",\n",
    "        \"hb4_23dpg_c\",\n",
    "        \"hb_hco2_c\",\n",
    "        \"globin_c\",\n",
    "        \"hbsno_c\",\n",
    "        \"carboxyhb_c\",\n",
    "        \"cclglobin_c\",\n",
    "        \"hemedegprods_c\",\n",
    "        \"hba1c_c\",\n",
    "        # Amino acids\n",
    "        # AA protein Residues\n",
    "        \"protres_arg__L_c\",\n",
    "        \"protres_asn__L_c\",\n",
    "        \"protres_asp__L_c\",\n",
    "        \"protres_cys__L_c\",\n",
    "        \"protres_gln__L_c\",\n",
    "        \"protres_glu__L_c\",\n",
    "        \"protres_his__L_c\",\n",
    "        \"protres_lys__L_c\",\n",
    "        \"protres_met__L_c\",\n",
    "        \"protres_ser__L_c\",\n",
    "        \"protres_thr__L_c\",\n",
    "        \"protres_tyr__L_c\",\n",
    "        \"protres_tyr__L_c\",\n",
    "        # Other AA residues\n",
    "        \"protres_asp__D_c\",\n",
    "        \"protres_isoasp__L_c\",\n",
    "        \"protres_isoasp__D_c\",\n",
    "        # Phosphorylated residues\n",
    "        \"protres_Nproshispi_c\",\n",
    "        \"protres_Ntelehispi_c\",\n",
    "        \"protres_serpi_c\",\n",
    "        \"protres_thrpi_c\",\n",
    "        \"protres_tyrpi_c\",\n",
    "        # Acetylated residues\n",
    "        \"protres_aclys__L_c\",\n",
    "        # Glycosylated residues\n",
    "        \"protres_ser3oacgam_c\",\n",
    "        \"protres_thr3oacgam_c\",\n",
    "        \"protres_serTAg_c\",\n",
    "        \"protres_thrTAg_c\",\n",
    "        # Glycated residues\n",
    "        \"protres_frulys_c\",\n",
    "        \"protres_rbllys_c\",\n",
    "        # Methylated residues\n",
    "        \"protres_admarg__L_c\",\n",
    "        \"protres_sdmarg__L_c\",\n",
    "        # Lipidated residues\n",
    "        \"protres_ttdcacys_c\",\n",
    "        \"protres_hxdcacys_c\",\n",
    "        \"protres_ocdcacys_c\",\n",
    "        # Oxidized residues\n",
    "        \"protres_metSox__SL_c\",\n",
    "        # Nitrosylated residues\n",
    "        \"protres_snocys__L_c\",\n",
    "        # ADP-ribosylated residues\n",
    "        \"protres_oadpribser_c\",\n",
    "        \"protres_sadpribcys_c\",\n",
    "        # Amine\n",
    "        \"protres_gludpam_c\",\n",
    "        \"protres_gluhista_c\",\n",
    "        \"protres_glunpphr_c\",\n",
    "        \"protres_glusrtn_c\",\n",
    "        \"protres_glu5meo__L_c\",\n",
    "        \"protres_lysglu_protres_c\",\n",
    "        # Ubiquitin\n",
    "        \"polyubb_c\",\n",
    "        \"ubiquitin_c\",\n",
    "        \"accprot_monoubiqlys_c\",\n",
    "        \"accprot_ubiqlys_c\",\n",
    "        \"accprot_lys__L_c\",\n",
    "        \"cullin_lys__L_c\",\n",
    "        \"cullin_nedd8lys_c\",\n",
    "        \"nedd8_c\",\n",
    "        # Small ions\n",
    "        \"na1_c\",\n",
    "        \"k_c\",\n",
    "        \"ca2_c\",\n",
    "        \"hno_c\",\n",
    "        \"co3r_c\",\n",
    "        # Vitamin E\n",
    "        \"avite1_c\",\n",
    "        \"avite1qn_c\",\n",
    "        # 'Redoxins'\n",
    "        \"prdx2crd_c\",\n",
    "        \"prdx2cso3_c\",\n",
    "        \"grdx2crd_c\",\n",
    "        \"grdx2cox_c\",\n",
    "        # Phospholipids\n",
    "        \"pc_hs_c\",\n",
    "        \"pco_hs_c\",\n",
    "        \"pcp_hs_c\",\n",
    "        \"pe_hs_c\",\n",
    "        \"pep_hs_c\",\n",
    "        \"ps_hs_c\",\n",
    "        \"paf_hs_c\",\n",
    "        \"pail_hs_c\",\n",
    "        \"pail345p_hs_c\",\n",
    "        \"pail34p_hs_c\",\n",
    "        \"pail35p_hs_c\",\n",
    "        \"pail3p_hs_c\",\n",
    "        \"pail45p_hs_c\",\n",
    "        \"pail4p_hs_c\",\n",
    "        \"pail5p_hs_c\",\n",
    "        \"sphmyln_hs_c\",\n",
    "        # CoA\n",
    "        # 'FAcoa_10_DC_c',\n",
    "        # 'FAcoa_12_DC_c',\n",
    "        # 'FAcoa_16_DC_c',\n",
    "        # 'FAcoa_4_DC_c',\n",
    "        # 'FAcoa_5_2EDC_c',\n",
    "        # 'FAcoa_5_DC_c',\n",
    "        # 'FAcoa_6_DC_c',\n",
    "        # 'FAcoa_7_DC_c',\n",
    "        # 'FAcoa_8_DC_c',\n",
    "        # 'FAcoa_5_3M3OH__S_c',\n",
    "        # 'FAcoa_hs_10_3OH__S_c',\n",
    "        # 'FAcoa_hs_12_3OH__S_c',\n",
    "        # 'FAcoa_hs_14_3OH__S_c',\n",
    "        # 'FAcoa_hs_14_5E8Z3OH__S_c',\n",
    "        # 'FAcoa_hs_14_7Z3OH__S_c',\n",
    "        # 'FAcoa_hs_16_3OH__R_c',\n",
    "        # 'FAcoa_hs_16_3OH__S_c',\n",
    "        # 'FAcoa_hs_16_7E10Z3OH__S_c',\n",
    "        # 'FAcoa_hs_16_9Z3OH__S_c',\n",
    "        # 'FAcoa_hs_17_3OH__R_c',\n",
    "        # 'FAcoa_hs_18_3OH__R_c',\n",
    "        # 'FAcoa_hs_18_3OH__S_c',\n",
    "        # 'FAcoa_hs_18_9Z12Z3OH__S_c',\n",
    "        # 'FAcoa_hs_18_9Z3OH__S_c',\n",
    "        # 'FAcoa_hs_19_3OH__R_c',\n",
    "        # 'FAcoa_hs_20_11Z14Z17Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_11Z14Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_11Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_13Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_3OH__R_c',\n",
    "        # 'FAcoa_hs_20_8Z11Z14Z17Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_8Z11Z14Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_8Z11Z3OH__R_c',\n",
    "        # 'FAcoa_hs_20_9Z3OH__R_c',\n",
    "        # 'FAcoa_hs_21_3OH__R_c',\n",
    "        # 'FAcoa_hs_22_10Z13Z16Z19Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_10Z13Z16Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_11Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_13Z16Z19Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_13Z16Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_13Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_3OH__R_c',\n",
    "        # 'FAcoa_hs_22_7Z10Z13Z16Z19Z3OH__R_c',\n",
    "        # 'FAcoa_hs_22_7Z10Z13Z16Z3OH__R_c',\n",
    "        # 'FAcoa_hs_23_3OH__R_c',\n",
    "        # 'FAcoa_hs_24_12Z15Z18Z21Z3OH__R_c',\n",
    "        # 'FAcoa_hs_24_15Z3OH__R_c',\n",
    "        # 'FAcoa_hs_24_3OH__R_c',\n",
    "        # 'FAcoa_hs_24_9Z12Z15Z18Z21Z3OH__R_c',\n",
    "        # 'FAcoa_hs_24_9Z12Z15Z18Z3OH__R_c',\n",
    "        # 'FAcoa_hs_26_17Z3OH__R_c',\n",
    "        # 'FAcoa_hs_26_3OH__R_c',\n",
    "        # 'FAcoa_hs_3_3OH__S_c',\n",
    "        # 'FAcoa_hs_4_3OH__R_c',\n",
    "        # 'FAcoa_hs_6_3OH__S_c',\n",
    "        # 'FAcoa_hs_7_3OH__S_c',\n",
    "        # 'FAcoa_hs_8_3OH__S_c',\n",
    "        # 'FAcoa_hs_9_3OH__S_c',\n",
    "        # 'FAcoa_5_2E2M_c',\n",
    "        # 'FAcoa_5_2M_c',\n",
    "        # 'FAcoa_hs_10_2E6Z_c',\n",
    "        # 'FAcoa_hs_10_2E_c',\n",
    "        # 'FAcoa_hs_12_2E_c',\n",
    "        # 'FAcoa_hs_14_2E_c',\n",
    "        # 'FAcoa_hs_16_2E_c',\n",
    "        # 'FAcoa_hs_17_2E_c',\n",
    "        # 'FAcoa_hs_18_2E_c',\n",
    "        # 'FAcoa_hs_19_2E_c',\n",
    "        # 'FAcoa_hs_20_2E11Z14Z17Z_c',\n",
    "        # 'FAcoa_hs_20_2E11Z14Z_c',\n",
    "        # 'FAcoa_hs_20_2E11Z_c',\n",
    "        # 'FAcoa_hs_20_2E13Z_c',\n",
    "        # 'FAcoa_hs_20_2E8Z11Z14Z17Z_c',\n",
    "        # 'FAcoa_hs_20_2E8Z11Z14Z_c',\n",
    "        # 'FAcoa_hs_20_2E8Z11Z_c',\n",
    "        # 'FAcoa_hs_20_2E9Z_c',\n",
    "        # 'FAcoa_hs_20_2E_c',\n",
    "        # 'FAcoa_hs_21_2E_c',\n",
    "        # 'FAcoa_hs_22_2E10Z13Z16Z19Z_c',\n",
    "        # 'FAcoa_hs_22_2E10Z13Z16Z_c',\n",
    "        # 'FAcoa_hs_22_2E11Z_c',\n",
    "        # 'FAcoa_hs_22_2E13Z16Z19Z_c',\n",
    "        # 'FAcoa_hs_22_2E13Z16Z_c',\n",
    "        # 'FAcoa_hs_22_2E13Z_c',\n",
    "        # 'FAcoa_hs_22_2E7Z10Z13Z16Z19Z_c',\n",
    "        # 'FAcoa_hs_22_2E7Z10Z13Z16Z_c',\n",
    "        # 'FAcoa_hs_22_2E_c',\n",
    "        # 'FAcoa_hs_23_2E_c',\n",
    "        # 'FAcoa_hs_24_2E12Z15Z18Z21Z_c',\n",
    "        # 'FAcoa_hs_24_2E15Z_c',\n",
    "        # 'FAcoa_hs_24_2E9Z12Z15Z18Z21Z_c',\n",
    "        # 'FAcoa_hs_24_2E9Z12Z15Z18Z_c',\n",
    "        # 'FAcoa_hs_24_2E_c',\n",
    "        # 'FAcoa_hs_26_2E17Z_c',\n",
    "        # 'FAcoa_hs_26_2E_c',\n",
    "        # 'FAcoa_hs_3_2E_c',\n",
    "        # 'FAcoa_hs_4_2E_c',\n",
    "        # 'FAcoa_hs_6_2E_c',\n",
    "        # 'FAcoa_hs_8_2E_c',\n",
    "        # 'FAcoa_hs_14_5E8Z_c',\n",
    "        # 'FAcoa_4_2M_c',\n",
    "        # 'FAcoa_hs_16_3O_c',\n",
    "        # 'FAcoa_hs_17_3O_c',\n",
    "        # 'FAcoa_hs_18_3O_c',\n",
    "        # 'FAcoa_hs_19_3O_c',\n",
    "        # 'FAcoa_hs_20_11Z14Z17Z3O_c',\n",
    "        # 'FAcoa_hs_20_11Z14Z3O_c',\n",
    "        # 'FAcoa_hs_20_11Z3O_c',\n",
    "        # 'FAcoa_hs_20_13Z3O_c',\n",
    "        # 'FAcoa_hs_20_3O_c',\n",
    "        # 'FAcoa_hs_20_8Z11Z14Z17Z3O_c',\n",
    "        # 'FAcoa_hs_20_8Z11Z14Z3O_c',\n",
    "        # 'FAcoa_hs_20_8Z11Z3O_c',\n",
    "        # 'FAcoa_hs_20_9Z3O_c',\n",
    "        # 'FAcoa_hs_21_3O_c',\n",
    "        # 'FAcoa_hs_22_10Z13Z16Z19Z3O_c',\n",
    "        # 'FAcoa_hs_22_10Z13Z16Z3O_c',\n",
    "        # 'FAcoa_hs_22_11Z3O_c',\n",
    "        # 'FAcoa_hs_22_13Z16Z19Z3O_c',\n",
    "        # 'FAcoa_hs_22_13Z16Z3O_c',\n",
    "        # 'FAcoa_hs_22_13Z3O_c',\n",
    "        # 'FAcoa_hs_22_3O_c',\n",
    "        # 'FAcoa_hs_22_7Z10Z13Z16Z19Z3O_c',\n",
    "        # 'FAcoa_hs_22_7Z10Z13Z16Z3O_c',\n",
    "        # 'FAcoa_hs_23_3O_c',\n",
    "        # 'FAcoa_hs_24_12Z15Z18Z21Z3O_c',\n",
    "        # 'FAcoa_hs_24_15Z3O_c',\n",
    "        # 'FAcoa_hs_24_3O_c',\n",
    "        # 'FAcoa_hs_24_9Z12Z15Z18Z21Z3O_c',\n",
    "        # 'FAcoa_hs_24_9Z12Z15Z18Z3O_c',\n",
    "        # 'FAcoa_hs_26_17Z3O_c',\n",
    "        # 'FAcoa_hs_26_3O_c',\n",
    "        # 'dmnoncoa_c',\n",
    "        # 'dmhptcoa_c',\n",
    "        # # Carnitine\n",
    "        # 'FAcrn_10_DC_c',\n",
    "        # 'FAcrn_12_DC_c',\n",
    "        # 'FAcrn_16_DC_c',\n",
    "        # 'FAcrn_4_2M_c',\n",
    "        # 'FAcrn_4_DC_c',\n",
    "        # 'FAcrn_5_2E2M_c',\n",
    "        # 'FAcrn_5_2EDC_c',\n",
    "        # 'FAcrn_5_2M_c',\n",
    "        # 'FAcrn_5_3M3OH__S_c',\n",
    "        # 'FAcrn_5_DC_c',\n",
    "        # 'FAcrn_6_DC_c',\n",
    "        # 'FAcrn_7_DC_c',\n",
    "        # 'FAcrn_8_DC_c',\n",
    "        # 'FAcrn_hs_10_0_c',\n",
    "        # 'FAcrn_hs_10_2E6Z_c',\n",
    "        # 'FAcrn_hs_10_2E_c',\n",
    "        # 'FAcrn_hs_10_3OH__S_c',\n",
    "        # 'FAcrn_hs_11_0_c',\n",
    "        # 'FAcrn_hs_12_0_c',\n",
    "        # 'FAcrn_hs_12_2E_c',\n",
    "        # 'FAcrn_hs_12_3OH__S_c',\n",
    "        # 'FAcrn_hs_13_0_c',\n",
    "        # 'FAcrn_hs_14_0_c',\n",
    "        # 'FAcrn_hs_14_2E_c',\n",
    "        # 'FAcrn_hs_14_3OH__S_c',\n",
    "        # 'FAcrn_hs_14_5E8Z3OH__S_c',\n",
    "        # 'FAcrn_hs_14_5E8Z_c',\n",
    "        # 'FAcrn_hs_14_5Z_c',\n",
    "        # 'FAcrn_hs_14_7Z3OH__S_c',\n",
    "        # 'FAcrn_hs_14_7Z_c',\n",
    "        # 'FAcrn_hs_14_9Z_c',\n",
    "        # 'FAcrn_hs_15_0_c',\n",
    "        # 'FAcrn_hs_16_0_c',\n",
    "        # 'FAcrn_hs_16_2E_c',\n",
    "        # 'FAcrn_hs_16_3OH__S_c',\n",
    "        # 'FAcrn_hs_16_7E10Z3OH__S_c',\n",
    "        # 'FAcrn_hs_16_7Z_c',\n",
    "        # 'FAcrn_hs_16_9Z3OH__S_c',\n",
    "        # 'FAcrn_hs_16_9Z_c',\n",
    "        # 'FAcrn_hs_17_0_c',\n",
    "        # 'FAcrn_hs_17_10Z_c',\n",
    "        # 'FAcrn_hs_17_9Z_c',\n",
    "        # 'FAcrn_hs_18_0_c',\n",
    "        # 'FAcrn_hs_18_11Z_c',\n",
    "        # 'FAcrn_hs_18_13Z_c',\n",
    "        # 'FAcrn_hs_18_2E_c',\n",
    "        # 'FAcrn_hs_18_3OH__S_c',\n",
    "        # 'FAcrn_hs_18_6Z9Z12Z15Z_c',\n",
    "        # 'FAcrn_hs_18_6Z9Z12Z_c',\n",
    "        # 'FAcrn_hs_18_6Z9Z_c',\n",
    "        # 'FAcrn_hs_18_7Z_c',\n",
    "        # 'FAcrn_hs_18_9E_c',\n",
    "        # 'FAcrn_hs_18_9Z12Z15Z_c',\n",
    "        # 'FAcrn_hs_18_9Z12Z3OH__S_c',\n",
    "        # 'FAcrn_hs_18_9Z12Z_c',\n",
    "        # 'FAcrn_hs_18_9Z3OH__S_c',\n",
    "        # 'FAcrn_hs_18_9Z_c',\n",
    "        # 'FAcrn_hs_19_0_c',\n",
    "        # 'FAcrn_hs_20_0_c',\n",
    "        # 'FAcrn_hs_20_11Z14Z17Z_c',\n",
    "        # 'FAcrn_hs_20_11Z14Z_c',\n",
    "        # 'FAcrn_hs_20_11Z_c',\n",
    "        # 'FAcrn_hs_20_13Z_c',\n",
    "        # 'FAcrn_hs_20_5Z8Z11Z14Z17Z_c',\n",
    "        # 'FAcrn_hs_20_5Z8Z11Z14Z_c',\n",
    "        # 'FAcrn_hs_20_5Z8Z11Z_c',\n",
    "        # 'FAcrn_hs_20_8Z11Z14Z17Z_c',\n",
    "        # 'FAcrn_hs_20_8Z11Z14Z_c',\n",
    "        # 'FAcrn_hs_20_8Z11Z_c',\n",
    "        # 'FAcrn_hs_20_9Z_c',\n",
    "        # 'FAcrn_hs_21_0_c',\n",
    "        # 'FAcrn_hs_22_0_c',\n",
    "        # 'FAcrn_hs_22_10Z13Z16Z19Z_c',\n",
    "        # 'FAcrn_hs_22_10Z13Z16Z_c',\n",
    "        # 'FAcrn_hs_22_11Z_c',\n",
    "        # 'FAcrn_hs_22_13Z16Z19Z_c',\n",
    "        # 'FAcrn_hs_22_13Z16Z_c',\n",
    "        # 'FAcrn_hs_22_13Z_c',\n",
    "        # 'FAcrn_hs_22_4Z7Z10Z13Z16Z19Z_c',\n",
    "        # 'FAcrn_hs_22_4Z7Z10Z13Z16Z_c',\n",
    "        # 'FAcrn_hs_22_7Z10Z13Z16Z19Z_c',\n",
    "        # 'FAcrn_hs_22_7Z10Z13Z16Z_c',\n",
    "        # 'FAcrn_hs_23_0_c',\n",
    "        # 'FAcrn_hs_24_0_c',\n",
    "        # 'FAcrn_hs_24_12Z15Z18Z21Z_c',\n",
    "        # 'FAcrn_hs_24_15Z_c',\n",
    "        # 'FAcrn_hs_24_6Z9Z12Z15Z18Z21Z_c',\n",
    "        # 'FAcrn_hs_24_6Z9Z12Z15Z18Z_c',\n",
    "        # 'FAcrn_hs_24_9Z12Z15Z18Z21Z_c',\n",
    "        # 'FAcrn_hs_24_9Z12Z15Z18Z_c',\n",
    "        # 'FAcrn_hs_26_0_c',\n",
    "        # 'FAcrn_hs_26_17Z_c',\n",
    "        # 'FAcrn_hs_3_0_c',\n",
    "        # 'FAcrn_hs_3_2E_c',\n",
    "        # 'FAcrn_hs_3_3OH__S_c',\n",
    "        # 'FAcrn_hs_4_0_c',\n",
    "        # 'FAcrn_hs_4_2E_c',\n",
    "        # 'FAcrn_hs_4_3OH__R_c',\n",
    "        # 'FAcrn_hs_5_0_c',\n",
    "        # 'FAcrn_hs_6_0_c',\n",
    "        # 'FAcrn_hs_6_2E_c',\n",
    "        # 'FAcrn_hs_6_3OH__S_c',\n",
    "        # 'FAcrn_hs_7_0_c',\n",
    "        # 'FAcrn_hs_7_3OH__S_c',\n",
    "        # 'FAcrn_hs_8_0_c',\n",
    "        # 'FAcrn_hs_8_2E_c',\n",
    "        # 'FAcrn_hs_8_3OH__S_c',\n",
    "        # 'FAcrn_hs_9_0_c',\n",
    "        # 'FAcrn_hs_9_3OH__S_c',\n",
    "        # 'acrn_c',\n",
    "        # 'dmhptcrn_c',\n",
    "        # 'dmnoncrn_c',\n",
    "        # 'malcrn_c',\n",
    "        # tRNA\n",
    "        # 'trnaala_c',\n",
    "        # 'trnaarg_c',\n",
    "        # 'trnaasn_c',\n",
    "        # 'trnaasp_c',\n",
    "        # 'trnacys_c',\n",
    "        # 'trnagln_c',\n",
    "        # 'trnaglu_c',\n",
    "        # 'trnagly_c',\n",
    "        # 'trnahis_c',\n",
    "        # 'trnaile_c',\n",
    "        # 'trnaleu_c',\n",
    "        # 'trnalys_c',\n",
    "        # 'trnamet_c',\n",
    "        # 'trnaphe_c',\n",
    "        # 'trnapro_c',\n",
    "        # 'trnaser_c',\n",
    "        # 'trnathr_c',\n",
    "        # 'trnatrp_c',\n",
    "        # 'trnatyr_c',\n",
    "        # 'trnaval_c',\n",
    "        # 'alatrna_c',\n",
    "        # 'argtrna_c',\n",
    "        # 'asntrna_c',\n",
    "        # 'asptrna_c',\n",
    "        # 'cystrna_c',\n",
    "        # 'glntrna_c',\n",
    "        # 'glutrna_c',\n",
    "        # 'glytrna_c',\n",
    "        # 'histrna_c',\n",
    "        # 'iletrna_c',\n",
    "        # 'leutrna_c',\n",
    "        # 'lystrna_c',\n",
    "        # 'mettrna_c',\n",
    "        # 'phetrna_c',\n",
    "        # 'protrna_c',\n",
    "        # 'sertrna_c',\n",
    "        # 'thrtrna_c',\n",
    "        # 'trptrna_c',\n",
    "        # 'tyrtrna_c',\n",
    "        # 'valtrna_c',\n",
    "        # Sugar\n",
    "        # '2ddglcn_c',\n",
    "        # '3dfru_c',\n",
    "        # Nucleotides\n",
    "        # \"23camp_c\",\n",
    "        # \"23ccmp_c\",\n",
    "        # \"23cgmp_c\",\n",
    "        # \"23cump_c\",\n",
    "        # \"dctp_c\",\n",
    "        # \"dgtp_c\",\n",
    "        # \"datp_c\",\n",
    "        # \"dttp_c\",\n",
    "        # 'dutp_c',\n",
    "        # \"psump_c\",\n",
    "        # \"psi_c\",\n",
    "        # Sourced from somewhere/\n",
    "        # Drains to somewhere/accumulates\n",
    "        # 'so2gth_c',\n",
    "        # \"dh15kprostge1_c\",\n",
    "        # \"dh15kprostge2_c\",\n",
    "        # \"dh15kprostge3_c\",\n",
    "        # \"dh15kprostgf1_c\",\n",
    "        # \"dh15kprostgf2_c\",\n",
    "        # \"dh15kprostgf3_c\",\n",
    "        # 'polyadprib2_c',\n",
    "        # 'polyadprib1_c',\n",
    "    ],\n",
    "}\n",
    "model.remove_reactions(model.reactions.query(lambda x: x.boundary))\n",
    "default_closed = []\n",
    "for btype, met_list in boundaries.items():\n",
    "    for met in met_list:\n",
    "        met = model.metabolites.get_by_id(met)\n",
    "        try:\n",
    "            reaction = model.add_boundary(met, type=btype)\n",
    "        except ValueError:\n",
    "            rid = {\n",
    "                \"exchange\": f\"EX_{met}\",\n",
    "                \"demand\": f\"DM_{met}\",\n",
    "                \"sink\": f\"SK_{met}\",\n",
    "            }[btype]\n",
    "            reaction = model.reactions.get_by_id(rid)\n",
    "            reaction.name = f\"{met.name} {btype}\"\n",
    "\n",
    "        if met in default_closed:\n",
    "            reaction.lower_bound = 0\n",
    "\n",
    "for reaction in model.boundary:\n",
    "    reaction.subsystem = \"Pseudoreactions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff186a49-66a1-444c-92dc-0f1eca0464d9",
   "metadata": {},
   "source": [
    "#### Reset subsystem groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037b248-ee81-442e-aa81-dd8acd25380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_subsystem_groups(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ba5b6-68bb-4160-bcfa-58fe424d8025",
   "metadata": {},
   "source": [
    "### Check mass balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47506ac-f31a-4730-93dc-95fef5cf1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reaction in model.reactions:\n",
    "    if reaction.boundary:\n",
    "        continue\n",
    "    try:\n",
    "        if reaction.check_mass_balance():\n",
    "            print(reaction)\n",
    "            print(reaction.check_mass_balance())\n",
    "            print()\n",
    "    except:\n",
    "        print({m.id: m.charge for m in reaction.metabolites})\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d61d2b-a4a0-4ac8-84c6-68bd7b421790",
   "metadata": {},
   "source": [
    "### Set bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc710bb4-325e-4db2-bd30-c3595b60052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_reaction_bounds(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad316c-ec10-461b-9c38-4e1bdeed2db5",
   "metadata": {},
   "source": [
    "### Ensure correct types before export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea115b87-ffa6-4773-8207-08701a8d03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBML will not export charges correctly if they are float\n",
    "for metabolite in model.metabolites:\n",
    "    metabolite.charge = int(metabolite.charge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e6dc2-ed20-455b-aadd-8a03db5666f1",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742aeb63-f41b-4280-8fc0-9a79e9410e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_dirpath = get_dirpath(\"model\", use_temp=\"interim\" if not overwrite else None)\n",
    "new_model_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "write_cobra_model(\n",
    "    model=model, filename=new_model_dirpath / f\"{model.id.replace('_', '-')}.xml\"\n",
    ")\n",
    "write_cobra_model(\n",
    "    model=model, filename=new_model_dirpath / f\"{model.id.replace('_', '-')}.json\"\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d93a7-23dc-47ee-b9b9-f330fdfa8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Genes: {len(set([x.id for x in model.genes]))}\")\n",
    "print(f\"Metabolites (all): {len(set([x.id for x in model.metabolites]))}\")\n",
    "nmets_unique = len({x.id.replace(f\"_{x.compartment}\", \"\") for x in model.metabolites})\n",
    "print(f\"Metabolites (unique): {nmets_unique}\")\n",
    "print(\n",
    "    f\"Reactions: {len(set([x.id for x in model.reactions.query(lambda x: not x.boundary)]))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0abe0d-2051-491d-a716-5b573465d3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
