{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb238750-50f1-4a09-8448-90a1cfe2291a",
   "metadata": {},
   "source": [
    "# Update Protein Identifiers to UniProt\n",
    "\n",
    "Note: Requires internet connection to download information from the UniProt.\n",
    "\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a985c9-3bd3-446e-b811-d0b722648c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rbc_gem_utils import (\n",
    "    build_string,\n",
    "    check_database_release_online,\n",
    "    get_dirpath,\n",
    "    show_versions,\n",
    ")\n",
    "from rbc_gem_utils.database.uniprot import (\n",
    "    UNIPROT_DB_TAG,\n",
    "    UNIPROT_ID_RE,\n",
    "    get_release_UniProt,\n",
    "    query_UniProt,\n",
    ")\n",
    "\n",
    "# Display versions of last time notebook ran and worked\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225a706-6855-4ed8-a327-f22e1bda7384",
   "metadata": {},
   "source": [
    "## Check UniProt release\n",
    "If the release does not match the expected release, it is because database has been updated since the last time this code was utilized. \n",
    "\n",
    "* According to [UniProt](https://www.uniprot.org/help/downloads), updates to the database are made every eight weeks.\n",
    "* If the current release does not match the expected release, it is because database has been updated since the last time this code was utilized.\n",
    "    * If the notebook works without needing any significant modifications, the only update needed is to the release in the [uniprot.py](../../src/rbc_gem_utils/database/uniprot.py) source code file to resolve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6223f-049f-43c1-9de3-826a210530e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "release = get_release_UniProt()\n",
    "\n",
    "use_interim = not check_database_release_online(UNIPROT_DB_TAG, verbose=True, **{})\n",
    "# Use different directory paths for unexpected behavior\n",
    "if use_interim:\n",
    "    warn(\n",
    "        \"Online release of database has been updated since the last time notebook was used.\"\n",
    "    )\n",
    "\n",
    "\n",
    "database_dirpath = get_dirpath(\n",
    "    \"database\", UNIPROT_DB_TAG, use_temp=\"interim\" if use_interim else None\n",
    ")\n",
    "annotation_dirpath = get_dirpath(\n",
    "    \"annotation\", use_temp=\"interim\" if use_interim else None\n",
    ")\n",
    "\n",
    "# Ensure directories exist\n",
    "database_dirpath.mkdir(exist_ok=True, parents=True)\n",
    "annotation_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef99e6b-4b44-4c61-8b14-534815b88aff",
   "metadata": {},
   "source": [
    "## Load aggregated proteomic data, raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181104e6-aa91-4efe-b508-6fc72f7384db",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "\n",
    "excel_filepath_raw = (\n",
    "    get_dirpath(\"proteomics\", use_temp=\"external\") / \"proteomics_aggregated_raw.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c3c1a-4779-4a85-bdcd-1f4816710da4",
   "metadata": {},
   "source": [
    "### Load obsolete identifier mapping\n",
    "Meant to get all IDs into UniProt identifiers. Does not account for obselete/deleted/old UniProt IDs. Those must be manually checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3bded-3f93-4ecb-8649-52394578aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obsolete = pd.read_csv(\n",
    "    get_dirpath(\"proteomics\", use_temp=\"external\") / \"proteomics_obsolete.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    dtype=str,\n",
    "    index_col=None,\n",
    ")\n",
    "df_obsolete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a65016-f8c7-4d18-bc99-57efd400d59e",
   "metadata": {},
   "source": [
    "### Load table of contents, raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf7893-3b99-46be-8be8-ae4037c5d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contents_raw = pd.read_excel(\n",
    "    excel_filepath_raw, sheet_name=\"Table of Contents\", dtype=str\n",
    ").fillna(\"\")\n",
    "df_contents_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c3e07-fc94-45e5-81b1-0267b8dcce88",
   "metadata": {},
   "source": [
    "### Map other identifiers to UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95c99d-71b4-4727-ac90-423f51b770a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_table_dict = {\"Table of Contents\": df_contents_raw.copy()}\n",
    "obsolete_dict = {}\n",
    "problems = {}\n",
    "index_name = \"Uniprot\"\n",
    "for idx, (sheet_name, id_type) in df_contents_raw[\n",
    "    [\"PubMed/Sheet Name\", \"ID type\"]\n",
    "].iterrows():\n",
    "    df = pd.read_excel(\n",
    "        excel_filepath_raw, sheet_name=sheet_name, usecols=[0], dtype=str\n",
    "    )\n",
    "    df.columns = [id_type]\n",
    "    if id_type != \"UniProt\":\n",
    "        # Map to obsolete identifiers\n",
    "        df_obsolete_mapping = (\n",
    "            df_obsolete[[id_type, \"UniProt\"]].dropna(how=\"all\").drop_duplicates().copy()\n",
    "        )\n",
    "        if id_type == \"GI\":\n",
    "            df[id_type] = df[id_type].apply(\n",
    "                lambda x: x.split(\"|\")[-1] if str(x).startswith(\"gi|\") else x\n",
    "            )\n",
    "        df_obsolete_mapping = df.merge(\n",
    "            df_obsolete_mapping, left_on=id_type, right_on=id_type, how=\"left\"\n",
    "        )\n",
    "        obsolete_dict[sheet_name] = df_obsolete_mapping.copy()\n",
    "        counts = df_obsolete_mapping.nunique()\n",
    "        counts[\"Obsolete\"] = (\n",
    "            df_obsolete_mapping[\"UniProt\"].isna().value_counts()[True].item()\n",
    "        )\n",
    "\n",
    "        counts = {k: v for (k, v) in sorted(counts.to_dict().items())}\n",
    "        updated_table_dict[\"Table of Contents\"].loc[idx, \"ID type\"] = \"UniProt\"\n",
    "        note_str = build_string([f\"{v} {k}\" for k, v in counts.items() if v != 0])\n",
    "        updated_table_dict[\"Table of Contents\"].loc[idx, \"Notes\"] = note_str\n",
    "        updated_table_dict[sheet_name] = list(\n",
    "            df_obsolete_mapping[\"UniProt\"].dropna().unique()\n",
    "        )\n",
    "    else:\n",
    "        check_mixed_ids = df[\"UniProt\"][\n",
    "            ~df[\"UniProt\"].apply(lambda x: True if UNIPROT_ID_RE.search(x) else False)\n",
    "        ]\n",
    "        counts = {\"UniProt\": 0}\n",
    "        if not check_mixed_ids.empty:\n",
    "            problems[sheet_name] = df\n",
    "        df[\"UniProt\"] = df[\"UniProt\"].apply(\n",
    "            lambda x: (\n",
    "                UNIPROT_ID_RE.search(x).group()\n",
    "                if isinstance(x, str) and UNIPROT_ID_RE.search(x)\n",
    "                else x\n",
    "            )\n",
    "        )\n",
    "        counts.update({\"UniProt\": df[\"UniProt\"].nunique()})\n",
    "        counts = {k: v for (k, v) in sorted(counts.items())}\n",
    "        note_str = build_string([f\"{v} {k}\" for k, v in counts.items() if v != 0])\n",
    "        updated_table_dict[\"Table of Contents\"].loc[idx, \"Notes\"] = note_str\n",
    "        updated_table_dict[sheet_name] = list(df[\"UniProt\"].dropna().unique())\n",
    "\n",
    "updated_table_dict[\"Table of Contents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a91f76-a2bc-4fc0-b38d-1cb165d783c1",
   "metadata": {},
   "source": [
    "### Map UniProt IDs to current UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c66c2a-aaa8-42f9-b96a-c1f73955f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_failed = {}\n",
    "all_unmapped = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a7aea-cbd7-4146-adf5-c344fbdfed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all relevant information for now and save\n",
    "query_parameters = {\n",
    "    \"query\": \" && \".join(\n",
    "        [\n",
    "            \"(organism_id:9606)\",  # Homo sapiens (Human)\n",
    "        ]\n",
    "    ),\n",
    "    \"format\": \"tsv\",\n",
    "    \"size\": 500,\n",
    "    \"compressed\": True,\n",
    "    \"fields\": \",\".join(\n",
    "        [\n",
    "            \"reviewed\",\n",
    "            \"accession\",\n",
    "            \"gene_primary\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "idx = -1\n",
    "# Use redo sheets to remap specific sheets that failed\n",
    "redo_sheets = set([])\n",
    "issues = [\"28689405\"]\n",
    "for sheet_name, query_ids in updated_table_dict.copy().items():\n",
    "    if sheet_name == \"Table of Contents\" or (\n",
    "        redo_sheets and sheet_name not in redo_sheets\n",
    "    ):\n",
    "        idx += 1\n",
    "        continue\n",
    "    print(f\"{idx}) {sheet_name}\\n{(4 + len(sheet_name)) * '-'}\")\n",
    "    try:\n",
    "        df_results, uniparc, failed_ids, unmapped_ids = query_UniProt(\n",
    "            query_ids,\n",
    "            query_parameters=query_parameters,\n",
    "            from_db=\"UniProtKB\",\n",
    "            to_db=\"UniProtKB\",\n",
    "            return_failed=True,\n",
    "        )\n",
    "    except:\n",
    "        # Try additional time before continuing\n",
    "        print(f\"Issue with {sheet_name}, retry after extraction is finished\\n\")\n",
    "        idx += 1\n",
    "        issues += [sheet_name]\n",
    "        continue\n",
    "    if failed_ids:\n",
    "        print(f\"Failed IDS: {failed_ids}\\n\")\n",
    "        all_failed[sheet_name] = set(failed_ids)\n",
    "    if unmapped_ids:\n",
    "        print(f\"Unmmaped IDS: {unmapped_ids}\\n\")\n",
    "        all_unmapped[sheet_name] = set(unmapped_ids)\n",
    "    df_uniprot = df_results[\"Entry\"].drop_duplicates().dropna().reset_index(drop=True)\n",
    "    df_uniprot.name = index_name\n",
    "    updated_table_dict[sheet_name] = df_uniprot\n",
    "    updated_table_dict[\"Table of Contents\"].loc[\n",
    "        idx, \"Notes\"\n",
    "    ] += f\" -->  {len(df_uniprot)} UniProt {release}\"\n",
    "    idx += 1\n",
    "    print()\n",
    "print(issues)\n",
    "updated_table_dict[\"Table of Contents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3752297-aa9a-46b8-b33b-d7dadc6bca91",
   "metadata": {},
   "source": [
    "#### Quick check unmapped against known deleted entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d2c7a-b98e-4e35-b4b9-0ef82583ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_issues = df_obsolete[[\"UniProt\", \"Known issue?\"]].dropna(subset=\"Known issue?\")\n",
    "known_issues = known_issues.set_index(\"UniProt\")[\"Known issue?\"].to_dict()\n",
    "\n",
    "for k, values in all_unmapped.items():\n",
    "    print(f\"Sheet: {k}\")\n",
    "    for v in values:\n",
    "        if not UNIPROT_ID_RE.search(v):\n",
    "            # print(f\"{v}\\tNot a UniProt ID\")\n",
    "            continue\n",
    "\n",
    "        elif v in known_issues:\n",
    "            # print(f\"{v}\\t{known_issues[v]}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{v}\\tUnclear\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d099c-d020-4fed-98ee-56608f794225",
   "metadata": {},
   "source": [
    "### Export aggregated proteomic data, updated IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac9b40-8e35-4681-ba0f-000832f9c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    with pd.ExcelWriter(\n",
    "        get_dirpath(\"proteomics\", use_temp=\"external\") / \"proteomics_aggregated.xlsx\"\n",
    "    ) as writer:\n",
    "        for sheet_name, df in updated_table_dict.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b6a0f-4251-46de-9022-fab5b50cc916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
