{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2537d45b-6871-43b9-81f8-e3639df15ac5",
   "metadata": {},
   "source": [
    "# Prepare Proteomic Data - Intensities, REDS Recall\n",
    "\n",
    "1. Nemkov T, Stephenson D, Earley EJ, Keele GR, Hay A, Key A, Haiman ZB, Erickson C, Dzieciatkowska M, Reisz JA, Moore A, Stone M, Deng X, Kleinman S, Spitalnik SL, Hod EA, Hudson KE, Hansen KC, Palsson BO, Churchill GA, Roubinian N, Norris PJ, Busch MP, Zimring JC, Page GP, D'Alessandro A. Biological and genetic determinants of glycolysis: Phosphofructokinase isoforms boost energy status of stored red blood cells and transfusion outcomes. Cell Metab. 2024 Sep 3;36(9):1979-1997.e13. doi: 10.1016/j.cmet.2024.06.007. Epub 2024 Jul 3. PMID: 38964323; PMCID: PMC11374506.\n",
    "\n",
    "2. D'Alessandro A, Culp-Hill R, Reisz JA, Anderson M, Fu X, Nemkov T, Gehrke S, Zheng C, Kanias T, Guo Y, Page G, Gladwin MT, Kleinman S, Lanteri M, Stone M, Busch M, Zimring JC; Recipient Epidemiology and Donor Evaluation Study-III (REDS-III). Heterogeneity of blood processing and storage additives in different centers impacts stored red blood cell metabolism as much as storage time: lessons from REDS-III-Omics. Transfusion. 2019 Jan;59(1):89-100. doi: 10.1111/trf.14979. Epub 2018 Oct 24. PMID: 30353560; PMCID: PMC6322946.\n",
    "\n",
    "3. Josephson CD, Glynn S, Mathew S, Birch R, Bakkour S, Baumann Kreuziger L, Busch MP, Chapman K, Dinardo C, Hendrickson J, Hod EA, Kelly S, Luban N, Mast A, Norris P, Custer B, Sabino E, Sachais B, Spencer BR, Stone M, Kleinman S; National Heart, Lung, and Blood Institute (NHLBI) Recipient Epidemiology and Donor Evaluation Study-IV-Pediatric (REDS-IV-P). The Recipient Epidemiology and Donor Evaluation Study-IV-Pediatric (REDS-IV-P): A research program striving to improve blood donor safety and optimize transfusion outcomes across the lifespan. Transfusion. 2022 May;62(5):982-999. doi: 10.1111/trf.16869. Epub 2022 Apr 19. PMID: 35441384; PMCID: PMC9353062.\n",
    "\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rbc_gem_utils import get_dirpath, show_versions\n",
    "from rbc_gem_utils.util import AVOGADRO_NUMBER, ensure_iterable\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4b793-86d1-4ecf-9e1a-9f91c54815c6",
   "metadata": {},
   "source": [
    "## Set organism, dataset, and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190e52c-6c91-497b-92f5-5df61e5fba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Human\"\n",
    "dataset_name = \"REDSRecall\"\n",
    "raw_data_dirpath = get_dirpath(use_temp=\"raw\") / organism / dataset_name\n",
    "\n",
    "# Ensure directory exists\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "processed_data_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4761b-2ed4-4d09-97cc-4ce43a185296",
   "metadata": {},
   "source": [
    "## Set data value type and variables for columns keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577ff39-113a-4e3d-96b8-d29013a3118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_values_dtype = \"Intensities\"\n",
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"PUBLIC RECALL DONOR ID\"\n",
    "time_key = \"DAY\"\n",
    "\n",
    "time_abbrev = \"D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a004c-c2a0-47f8-97c1-b507e3e3d176",
   "metadata": {},
   "source": [
    "## Load RBC Proteomics\n",
    "### Load protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787503ec-3da3-4dae-82c8-0b4ea76dee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protein_data = pd.read_csv(\n",
    "    raw_data_dirpath / \"ProteinData.csv\",\n",
    "    index_col=None,\n",
    ").convert_dtypes()\n",
    "# Check to see if expected columns are included. If so, then order columns as listed.\n",
    "# Comes directly from UniProt if possible\n",
    "df_protein_data = df_protein_data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"Entry\",\n",
    "        \"Entry Name\",\n",
    "        \"Protein\",\n",
    "        \"Protein Names\",\n",
    "        \"Gene Names (Primary)\",\n",
    "        \"Length\",\n",
    "        \"Mass\",  # Should be in DA\n",
    "    ],\n",
    "]\n",
    "# Sort the data via alphabetical order of protein IDs for consistency\n",
    "df_protein_data = df_protein_data.set_index(\"Entry\").sort_index()\n",
    "df_protein_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b2cec-b956-4cf8-9682-5deb6b29f420",
   "metadata": {},
   "source": [
    "#### Load proteomics and map to UniProt if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354b5e9-a86e-48df-8e48-7d94910df420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteomics = pd.read_csv(\n",
    "    raw_data_dirpath / f\"Protein{protein_values_dtype}.csv\",\n",
    "    index_col=None,\n",
    ").convert_dtypes()\n",
    "original_ids_type = \"Protein\"\n",
    "\n",
    "# Create sample IDs from donor and time points, then set as index\n",
    "df_proteomics.index = pd.Index(\n",
    "    df_proteomics[[donor_key, time_key]]\n",
    "    .apply(lambda x: f\"{x[donor_key]}_{time_abbrev}{x[time_key]}\", axis=1)\n",
    "    .values,\n",
    "    name=sample_key,\n",
    ")\n",
    "\n",
    "# Transform Protein IDs to UniProt IDs\n",
    "if original_ids_type != \"uniprot\" and any(\n",
    "    df_proteomics.columns.isin(df_protein_data[original_ids_type])\n",
    "):\n",
    "    mapping_dict = df_protein_data.reset_index(drop=False)\n",
    "    mapping_dict = mapping_dict.set_index(original_ids_type)[df_protein_data.index.name]\n",
    "    mapping_dict = mapping_dict.to_dict()\n",
    "    df_proteomics = df_proteomics.rename(mapping_dict, axis=1)\n",
    "\n",
    "# Sort for consistency\n",
    "df_proteomics = df_proteomics.sort_index(axis=0)[\n",
    "    [donor_key, time_key] + list(df_protein_data.index)\n",
    "]\n",
    "donor_ids = df_proteomics[donor_key].unique()\n",
    "timepoints = df_proteomics[time_key].unique()\n",
    "print(f\"Number of donors: {len(donor_ids)}\")\n",
    "print(f\"Number of timepoints: {len(timepoints)}\")\n",
    "print(f\"Number of expected samples: {len(donor_ids) * len(timepoints)}\")\n",
    "print(f\"Number of actual samples: {len(df_proteomics)}\")\n",
    "print(\n",
    "    f\"Number of duplicated IDs: {len(df_proteomics[df_proteomics.index.duplicated()])}\"\n",
    ")\n",
    "df_proteomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674b682-9f90-4f01-ab1a-21a6955c80f7",
   "metadata": {},
   "source": [
    "### Load metadata corresponding to samples (optional)\n",
    "#### Genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1db251-1e6b-453b-ad36-961610509b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_genotypes = pd.read_csv(\n",
    "        raw_data_dirpath / \"Genotypes.csv\",\n",
    "        index_col=[donor_key],\n",
    "    ).convert_dtypes()\n",
    "except FileNotFoundError:\n",
    "    df_genotypes = pd.DataFrame([])\n",
    "\n",
    "for col, series in df_genotypes.items():\n",
    "    counts = series.value_counts().sort_index()\n",
    "    print(col)\n",
    "    if len(counts) == 1:\n",
    "        df_genotypes = df_genotypes.drop(col, axis=1)\n",
    "    for k, v in counts.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print()\n",
    "df_genotypes = df_genotypes.replace(-1, pd.NA)\n",
    "df_genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e02f06-9499-4848-9d6f-0d1f4cf40019",
   "metadata": {},
   "source": [
    "#### Phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafb6c6-7dd9-476f-bb06-09d0d72b206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_phenotypes = pd.read_csv(\n",
    "        raw_data_dirpath / \"Phenotypes.csv\",\n",
    "        index_col=[donor_key],\n",
    "    ).convert_dtypes()\n",
    "except FileNotFoundError:\n",
    "    df_phenotypes = pd.DataFrame([])\n",
    "df_phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add4012-32b3-4ac1-b5f7-6f9f5c43cd1b",
   "metadata": {},
   "source": [
    "##### Cut phenotype data into ranges if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f54796-cfa1-44ac-8c29-75b885f38bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts = {\n",
    "#     \"BMI\": [0, 25, 30, 40, 60],\n",
    "#     \"Age\": [0, 20, 40, 60, 80, 100],\n",
    "# }\n",
    "# if not df_phenotypes.empty:\n",
    "#     for col, bins in cuts.items():\n",
    "#         labels = []\n",
    "#         for idx in range(1, len(bins)):\n",
    "#             if idx == 1 or idx == len(bins) - 1:\n",
    "#                 labels += [f\"lt{bins[idx]:d}\"]\n",
    "#             elif idx:\n",
    "#                 labels += [f\"gt{bins[idx - 1]:d}\"]\n",
    "#             else:\n",
    "#                 labels += [f\"{bins[idx - 1]:d}to{bins[idx]:d}\"]\n",
    "#         df_phenotypes[f\"{col}_Range\"] = pd.cut(\n",
    "#             df_phenotypes[col], bins=bins, labels=labels, right=False\n",
    "#         )\n",
    "# df_phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79161a-43e2-4f91-9cc5-360d31dc06b0",
   "metadata": {},
   "source": [
    "#### Combine into one DataFrame for MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f4f6f-f3b9-42f9-b379-128f1aaff3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proteomics: {df_proteomics[donor_key].nunique()} donors\")\n",
    "print(\n",
    "    f\"  Genomics: {df_genotypes.dropna(how='all', axis=0).index.nunique() if not df_genotypes.empty else 0} donors\"\n",
    ")\n",
    "print(\n",
    "    f\"Phenotypes: {df_phenotypes.dropna(how='all', axis=0).index.nunique() if not df_phenotypes.empty else 0} donors\"\n",
    ")\n",
    "\n",
    "\n",
    "df_metadata = pd.concat((df_genotypes, df_phenotypes), axis=1).convert_dtypes()\n",
    "\n",
    "if not df_metadata.empty:\n",
    "    df_metadata = df_metadata.reset_index(drop=False)\n",
    "    # Ensure only metadata corresponds to the available omics data\n",
    "    if not df_metadata[donor_key].isin(df_proteomics[donor_key]).all():\n",
    "        df_metadata = df_metadata[df_metadata[donor_key].isin(df_proteomics[donor_key])]\n",
    "\n",
    "    # If time was not included in metadata, add as a part of index to ensure index matches samples\n",
    "    if time_key and time_key not in df_metadata.index:\n",
    "        df_metadata = (\n",
    "            pd.concat(\n",
    "                (\n",
    "                    df_metadata,\n",
    "                    pd.Series(\n",
    "                        [list(df_proteomics[time_key].unique())]\n",
    "                        * len(df_metadata.index),\n",
    "                        index=df_metadata.index,\n",
    "                        name=time_key,\n",
    "                    ),\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "            .explode(time_key)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    # Create sample IDs from donor and time points, then set as index\n",
    "    df_metadata.index = pd.Index(\n",
    "        df_metadata[[donor_key, time_key]]\n",
    "        .apply(lambda x: f\"{x[donor_key]}_{time_abbrev}{x[time_key]}\", axis=1)\n",
    "        .values,\n",
    "        name=sample_key,\n",
    "    )\n",
    "    print(f\"\\nFinal data: {df_metadata[donor_key].nunique()} donors\")\n",
    "    df_metadata = df_metadata.drop([donor_key, time_key], axis=1)\n",
    "else:\n",
    "    print(f\"\\nFinal Meta: 0 donors\")\n",
    "\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7183f5-8f21-4a7d-b58d-c91eff007fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_metadata[[\"Gender\", \"G6PD_V68M\"]].copy()\n",
    "df.index = [x.split(\"_\")[0] for x in df.index]\n",
    "df = (\n",
    "    df.groupby(level=0).agg(lambda x: list(x.unique())).explode([\"Gender\", \"G6PD_V68M\"])\n",
    ")\n",
    "df.groupby(\"Gender\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fec6f-5d4b-4165-a368-1dcb5d5ae527",
   "metadata": {},
   "source": [
    "### Get MCH per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1c5f7-77de-4f5d-974f-a0ca2c1f9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide in picograms. Set as None to use metadata if provided\n",
    "mch_sample_value = None\n",
    "if mch_sample_value is None:\n",
    "    try:\n",
    "        df_MCH_per_sample = pd.read_csv(\n",
    "            raw_data_dirpath / \"Phenotypes.csv\",\n",
    "            index_col=None,\n",
    "        )\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\n",
    "            \"Cannot determine MCH. No phenotype data provided and a default value is not provided\"\n",
    "        )\n",
    "\n",
    "    # Ensure only metadata corresponds to the available omics data\n",
    "    if not df_MCH_per_sample[donor_key].isin(df_proteomics[donor_key]).all():\n",
    "        df_MCH_per_sample = df_MCH_per_sample[\n",
    "            df_MCH_per_sample[donor_key].isin(df_proteomics[donor_key])\n",
    "        ]\n",
    "\n",
    "    if \"CBC.MCH\" not in df_MCH_per_sample.columns:\n",
    "        if all([x in df_MCH_per_sample.columns for x in [\"CBC.HGB\", \"CBC.RBC\"]]):\n",
    "            df_MCH_per_sample[\"CBC.MCH\"] = (\n",
    "                df_MCH_per_sample[\"CBC.HGB\"] / df_MCH_per_sample[\"CBC.RBC\"]\n",
    "            ) * 10\n",
    "        elif all([x in df_MCH_per_sample.columns for x in [\"CBC.MCHC\", \"CBC.MCV\"]]):\n",
    "            df_MCH_per_sample[\"CBC.MCH\"] = (\n",
    "                df_MCH_per_sample[\"CBC.MCHC\"] * df_MCH_per_sample[\"CBC.MCV\"]\n",
    "            ) / 100\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Cannot determine MCH, one of the following combinations is needed: (CBC.HGB and CBC.RBC) or (CBC.MCHC and CBC.MCV)\"\n",
    "            )\n",
    "    df_MCH_per_sample = df_MCH_per_sample.set_index(donor_key)[\"CBC.MCH\"]\n",
    "    n_missing = len(df_MCH_per_sample[df_MCH_per_sample.isna()])\n",
    "    print(f\"Missing values for {n_missing} samples.\")\n",
    "    print(f\"Mean MCH in pg: {df_MCH_per_sample.mean():.2f}\")\n",
    "    df_MCH_per_sample = df_MCH_per_sample.fillna(df_MCH_per_sample.mean())\n",
    "else:\n",
    "    print(\"Using default MCH value provided for all samples\")\n",
    "    df_MCH_per_sample = pd.Series(\n",
    "        [mch_sample_value] * df_proteomics[donor_key].nunique(),\n",
    "        index=pd.Index(df_proteomics[donor_key].unique(), name=donor_key),\n",
    "        name=\"CBC.MCH\",\n",
    "    )\n",
    "    print(f\"Mean MCH in pg: {mch_sample_value:.2f}\")\n",
    "\n",
    "df_MCH_per_sample = df_MCH_per_sample.reset_index(drop=False)\n",
    "# If time was not included in metadata, add as a part of index to ensure index matches samples\n",
    "if time_key and time_key not in df_MCH_per_sample.index:\n",
    "    df_MCH_per_sample = (\n",
    "        pd.concat(\n",
    "            (\n",
    "                df_MCH_per_sample,\n",
    "                pd.Series(\n",
    "                    [list(df_proteomics[time_key].unique())]\n",
    "                    * len(df_MCH_per_sample.index),\n",
    "                    index=df_MCH_per_sample.index,\n",
    "                    name=time_key,\n",
    "                ),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        .explode(time_key)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "# Create sample IDs from donor and time points, then set as index\n",
    "df_MCH_per_sample.index = pd.Index(\n",
    "    df_MCH_per_sample[[donor_key, time_key]]\n",
    "    .apply(lambda x: f\"{x[donor_key]}_{time_abbrev}{x[time_key]}\", axis=1)\n",
    "    .values,\n",
    "    name=sample_key,\n",
    ")\n",
    "df_MCH_per_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91bdb4-0386-4420-aee2-e0697508a0ad",
   "metadata": {},
   "source": [
    "### Remove duplicated IDs in samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186b750-96be-4f76-9e2f-cb29b8742ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteomics = df_proteomics[~df_proteomics.index.duplicated(keep=False)]\n",
    "df_MCH_per_sample = df_MCH_per_sample.loc[df_proteomics.index]\n",
    "sample_ids = list(df_proteomics.index)\n",
    "df_proteomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e24168-4aa1-4edf-9b69-f6983c462b8a",
   "metadata": {},
   "source": [
    "### Get data subsets using operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccab7c8-4007-4d67-819d-51554743eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [\n",
    "    \"mean\",\n",
    "    \"median\",\n",
    "]\n",
    "operation_dfs_proteomics = []\n",
    "operation_dfs_MCH = []\n",
    "fill_keys = set()\n",
    "\n",
    "\n",
    "def group_data(df, operation, keys, columns, prefix_values=None, name_col=None):\n",
    "    keys = ensure_iterable(keys)\n",
    "    if not prefix_values:\n",
    "        prefix_values = [\"\"] * len(keys)\n",
    "    if isinstance(prefix_values, dict):\n",
    "        prefix_values = {k: prefix_values.get(k, \"\") for k in keys}\n",
    "    else:\n",
    "        prefix_values = dict(zip(keys, prefix_values))\n",
    "\n",
    "    df = df.groupby(keys, as_index=False, observed=False)[columns]\n",
    "    df = getattr(df, operation.lower())()\n",
    "    labels = df[keys].apply(\n",
    "        lambda x: \"_\".join([f\"{prefix_values[key]}{x[key]}\" for key in keys]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[name_col] = [f\"{operation.capitalize()}_{value}\" for value in labels]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb966f-e113-4a17-a752-bf3794d63a0b",
   "metadata": {},
   "source": [
    "#### Group by donor only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f263b05-118b-48df-93f1-1a1a16dc4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = [donor_key]\n",
    "# prefix_values = {}\n",
    "\n",
    "# operation_dfs_proteomics += [\n",
    "#     group_data(\n",
    "#         df_proteomics.reset_index(drop=False),\n",
    "#         operation,\n",
    "#         keys=keys,\n",
    "#         columns=list(df_protein_data.index),\n",
    "#         prefix_values=prefix_values,\n",
    "#         name_col=sample_key,\n",
    "#     )\n",
    "#     for operation in operations\n",
    "# ]\n",
    "\n",
    "# operation_dfs_MCH += [\n",
    "#     group_data(\n",
    "#         df_MCH_per_sample.reset_index(drop=False),\n",
    "#         operation,\n",
    "#         keys=keys,\n",
    "#         columns=[\"CBC.MCH\"],\n",
    "#         prefix_values=prefix_values,\n",
    "#         name_col=sample_key,\n",
    "#     )\n",
    "#     for operation in operations\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48a5c1-f213-489f-8d3e-449e801a1563",
   "metadata": {},
   "source": [
    "#### Group by time only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c88d7-1540-48c4-967d-f77df6ff5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [time_key]\n",
    "prefix_values = {time_key: time_abbrev}\n",
    "\n",
    "operation_dfs_proteomics += [\n",
    "    group_data(\n",
    "        df_proteomics.reset_index(drop=False),\n",
    "        operation,\n",
    "        keys=keys,\n",
    "        columns=list(df_protein_data.index),\n",
    "        prefix_values=prefix_values,\n",
    "        name_col=sample_key,\n",
    "    )\n",
    "    for operation in operations\n",
    "]\n",
    "\n",
    "operation_dfs_MCH += [\n",
    "    group_data(\n",
    "        df_MCH_per_sample.reset_index(drop=False),\n",
    "        operation,\n",
    "        keys=keys,\n",
    "        columns=[\"CBC.MCH\"],\n",
    "        prefix_values=prefix_values,\n",
    "        name_col=sample_key,\n",
    "    )\n",
    "    for operation in operations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fcec66-43d6-421d-a87d-69c91578a75a",
   "metadata": {},
   "source": [
    "#### Group by metadata only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c872f4-60dd-4b1e-8928-5e00ee0e7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_prefixes = dict(zip(list(df_genotypes.columns), list(df_genotypes.columns)))\n",
    "keys_prefixes.update(\n",
    "    # \"Gender\": \"Sex\",\n",
    "    # \"BMI_Range\": \"BMI\",\n",
    "    # \"Age_Range\": \"Age\",\n",
    ")\n",
    "keys_prefixes = {k: f\"{v}_\" for k, v in keys_prefixes.items()}\n",
    "for key, prefix in keys_prefixes.items():\n",
    "\n",
    "    operation_dfs_proteomics += [\n",
    "        group_data(\n",
    "            pd.merge(\n",
    "                df_proteomics,\n",
    "                df_metadata,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "                how=\"left\",\n",
    "            ).reset_index(drop=False),\n",
    "            operation,\n",
    "            keys=[key],\n",
    "            columns=list(df_protein_data.index),\n",
    "            prefix_values={key: prefix},\n",
    "            name_col=sample_key,\n",
    "        )\n",
    "        for operation in operations\n",
    "    ]\n",
    "\n",
    "    operation_dfs_MCH += [\n",
    "        group_data(\n",
    "            pd.merge(\n",
    "                df_MCH_per_sample,\n",
    "                df_metadata,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "                how=\"left\",\n",
    "            ).reset_index(drop=False),\n",
    "            operation,\n",
    "            keys=[key],\n",
    "            columns=[\"CBC.MCH\"],\n",
    "            prefix_values={key: prefix},\n",
    "            name_col=sample_key,\n",
    "        )\n",
    "        for operation in operations\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17158b-d6ca-4b6a-8958-ab5112282a69",
   "metadata": {},
   "source": [
    "### Add to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d51146-aaec-45f0-b11b-75755a7c7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_proteomics_op = pd.concat(operation_dfs_proteomics, axis=0).drop_duplicates()\n",
    "except (KeyError, ValueError):\n",
    "    df_proteomics_final = df_proteomics[df_protein_data.index].copy()\n",
    "else:\n",
    "    df_proteomics_final = pd.concat(\n",
    "        (df_proteomics.reset_index(drop=False), df_proteomics_op), axis=0\n",
    "    )\n",
    "    df_proteomics_final = df_proteomics_final.set_index(sample_key)[\n",
    "        df_protein_data.index\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    df_MCH_op = pd.concat(operation_dfs_MCH, axis=0).drop_duplicates()\n",
    "except (KeyError, ValueError):\n",
    "    if isinstance(df_MCH_per_sample, pd.DataFrame):\n",
    "        df_MCH_final = df_MCH_per_sample[\"CBC.MCH\"].copy()\n",
    "    else:\n",
    "        df_MCH_final = df_MCH_per_sample.copy()\n",
    "else:\n",
    "    df_MCH_final = pd.concat(\n",
    "        (df_MCH_per_sample.reset_index(drop=False), df_MCH_op), axis=0\n",
    "    )\n",
    "    df_MCH_final = df_MCH_final.set_index(sample_key)[\"CBC.MCH\"]\n",
    "\n",
    "df_MCH_final.name = \"MCH\"\n",
    "df_MCH_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802c393-2eae-4d2a-9945-b67424ced402",
   "metadata": {},
   "source": [
    "### Normalize data by hemoglobin mass\n",
    "#### Set percent for hemoglobin and low abundance protoemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5087c7-dc26-49de-9cea-6e87b65ebe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_PERCENT, LA_PERCENT = (0.95, 0.05)\n",
    "df_percent_abundance = df_proteomics_final.apply(lambda x: x / x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95dc7f3-1ac7-42c8-8094-21834deee0c2",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd5c66-3013-458f-9ab9-28f09c9f097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELED_PERCENT = HB_PERCENT + LA_PERCENT\n",
    "assert 1 >= MODELED_PERCENT\n",
    "HB_PROTEINS = {\n",
    "    \"HBA\": \"P69905\",  # Hemoglobin subunit alpha\n",
    "    \"HBB\": \"P68871\",  # Hemoglobin subunit beta\n",
    "    \"HBD\": \"P02042\",  # Hemoglobin subunit delta\n",
    "    \"HBE1\": \"P02100\",  # Hemoglobin subunit beta\n",
    "    \"HBG1\": \"P69891\",  # Hemoglobin subunit gamma-1\n",
    "    \"HBG2\": \"P69892\",  # Hemoglobin subunit gamma-2\n",
    "    \"HBM\": \"Q6B0K9\",  # Hemoglobin subunit mu\n",
    "    \"HBQ1\": \"P09105\",  # Hemoglobin subunit theta-1\n",
    "    \"HBZ\": \"P02008\",  # Hemoglobin subunit zeta\n",
    "}\n",
    "\n",
    "# Protein intensity / Total intensity --> Percent protein abundance / total protein\n",
    "df_percent_hb = df_percent_abundance.loc[\n",
    "    :, df_percent_abundance.columns.isin(list(HB_PROTEINS.values()))\n",
    "]\n",
    "df_percent_la = df_percent_abundance.loc[\n",
    "    :, ~df_percent_abundance.columns.isin(list(HB_PROTEINS.values()))\n",
    "]\n",
    "\n",
    "df_summary = {\n",
    "    \"Perfect total\": 1.0,\n",
    "    \"Current total\": df_percent_abundance.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Hemoglobin total\": df_percent_hb.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Low abundance total\": df_percent_la.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "}\n",
    "\n",
    "# # Scale hemoglobin and low abundance protoeme percentages\n",
    "# df_percent_hb = HB_PERCENT * df_percent_hb.div(df_percent_hb.sum(axis=1), axis=0)\n",
    "# df_percent_la = LA_PERCENT * df_percent_la.div(df_percent_la.sum(axis=1), axis=0)\n",
    "\n",
    "# Combine dataframes back into one\n",
    "df_percent_abundance = pd.concat((df_percent_hb, df_percent_la), axis=1)\n",
    "\n",
    "df_summary[\"Hemoglobin scaled\"] = (\n",
    "    df_percent_hb.loc[sample_ids].sum(axis=1).mean().item()\n",
    ")\n",
    "df_summary[\"Low abundance scaled\"] = (\n",
    "    df_percent_la.loc[sample_ids].sum(axis=1).mean().item()\n",
    ")\n",
    "df_summary[\"Remaining scaled\"] = 1 - (HB_PERCENT + LA_PERCENT)\n",
    "df_summary = pd.DataFrame.from_dict(\n",
    "    {\" \" * max(30 - len(k), 0) + k: [f\"{v * 100:.1f}%\"] for k, v in df_summary.items()},\n",
    "    orient=\"index\",\n",
    "    columns=[\"Percentage\"],\n",
    ")\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1a16b-80bd-4a9a-8322-edf429fe4a2d",
   "metadata": {},
   "source": [
    "### Transform data to copy numbers and expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cd4d4-0cef-48ce-adb2-42bf3326976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_to_mw = df_protein_data[\"Mass\"].astype(float)\n",
    "\n",
    "gDW_total_protein = (\n",
    "    df_MCH_final  # pgDW HB\n",
    "    * (1 / HB_PERCENT)  # pgDW total protein / pgDW HB\n",
    "    * (1 / 1e12)  #  gDW total protein / pgDW total protein\n",
    ")  #  gDW total protein\n",
    "\n",
    "# Percent protein abundance / total protein --> Specific protein concentration / total protein\n",
    "df_mol_per_gDW = df_percent_abundance.div(\n",
    "    df_uniprot_to_mw, axis=1  # mol protein / gDW total protein\n",
    ")\n",
    "# Convert from mol / gDW protein --> nmol / gDW protein\n",
    "df_nmol_per_gDW = df_mol_per_gDW * (1e9 / 1)  # nmol protein / mol protein\n",
    "\n",
    "# Convert from mol / gDW protein --> copy numbers / cell\n",
    "df_copy_numbers = df_mol_per_gDW.mul(gDW_total_protein, axis=0) * AVOGADRO_NUMBER\n",
    "df_copy_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a48d59-829a-4340-b5fd-04a51df6ad55",
   "metadata": {},
   "source": [
    "## Export absolute quantitative data and metadata per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991455f-0b5b-43d7-82cb-ec7fc7eb98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict = {\n",
    "    \"ProteinData\": df_protein_data,\n",
    "    \"ProteinIntensities\": df_proteomics_final,\n",
    "    \"ProteinConcentrations\": df_nmol_per_gDW,\n",
    "    \"ProteinCopyNumbers\": df_copy_numbers,\n",
    "    \"MCH\": df_MCH_final,\n",
    "    \"Metadata\": df_metadata,\n",
    "}\n",
    "for data_type, df in dataframes_dict.items():\n",
    "    # df.to_csv(\n",
    "    #     processed_data_dirpath / f\"{data_type}.tsv\", sep=\"\\t\", index=True\n",
    "    # )\n",
    "    df.to_csv(processed_data_dirpath / f\"{data_type}.csv\", index=True)\n",
    "    print(f\"Saved data for {data_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c440ba-0bc6-4011-8fde-98bf6c3129e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
