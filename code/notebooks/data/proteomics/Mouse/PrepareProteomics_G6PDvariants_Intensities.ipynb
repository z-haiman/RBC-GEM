{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2537d45b-6871-43b9-81f8-e3639df15ac5",
   "metadata": {},
   "source": [
    "# Prepare Proteomic Data - Intensities, G6PD variants\n",
    "## Setup\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255cec1-1c92-48cd-b35a-01065975dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rbc_gem_utils import get_dirpath, show_versions\n",
    "from rbc_gem_utils.util import AVOGADRO_NUMBER, ensure_iterable\n",
    "\n",
    "# Show versions of notebook\n",
    "show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e90ab-1c3a-45ab-b325-e8dff0b55bbb",
   "metadata": {},
   "source": [
    "## Set organism, dataset, and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190e52c-6c91-497b-92f5-5df61e5fba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Mouse\"\n",
    "dataset_name = \"G6PDvariants\"\n",
    "raw_data_dirpath = get_dirpath(use_temp=\"raw\") / organism / dataset_name\n",
    "\n",
    "# Ensure directory exists\n",
    "processed_data_dirpath = get_dirpath(use_temp=\"processed\") / organism / dataset_name\n",
    "processed_data_dirpath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd18522-df68-43f8-b23b-d37d0cd0500b",
   "metadata": {},
   "source": [
    "## Set data value type and variables for columns keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c1fb4-8f47-4c22-8d1d-6ccecb87b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_values_dtype = \"Intensities\"\n",
    "sample_key = \"SAMPLE ID\"\n",
    "donor_key = \"MOUSE ID\"\n",
    "time_key = \"TIME\"\n",
    "\n",
    "time_abbrev = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5834924-55c8-4dec-9a46-82a78086e113",
   "metadata": {},
   "source": [
    "## Load RBC Proteomics\n",
    "### Load protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f4e17-4942-4507-aae2-645a2997a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_protein_data = pd.read_csv(\n",
    "    raw_data_dirpath / \"ProteinData.csv\",\n",
    "    index_col=None,\n",
    ")\n",
    "# Check to see if expected columns are included. If so, then order columns as listed.\n",
    "# Comes directly from UniProt if possible\n",
    "df_protein_data = df_protein_data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"Entry\",\n",
    "        \"Entry Name\",\n",
    "        \"Protein\",\n",
    "        \"Protein Names\",\n",
    "        \"Gene Names (Primary)\",\n",
    "        \"Length\",\n",
    "        \"Mass\",  # Should be in DA\n",
    "    ],\n",
    "]\n",
    "# Sort the data via alphabetical order of protein IDs for consistency\n",
    "df_protein_data = df_protein_data.set_index(\"Entry\").sort_index()\n",
    "df_protein_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2f72c7-7211-4804-8709-a446152f5faf",
   "metadata": {},
   "source": [
    "#### Load proteomics and map to UniProt if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf35fa9-4939-4acb-b584-5e172547b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteomics = pd.read_csv(\n",
    "    raw_data_dirpath / f\"Protein{protein_values_dtype}.csv\",\n",
    "    index_col=None,\n",
    ")\n",
    "original_ids_type = \"uniprot\"\n",
    "\n",
    "# Create sample IDs from donor and time points, then set as index\n",
    "df_proteomics.index = pd.Index(\n",
    "    df_proteomics[[donor_key, time_key]]\n",
    "    .apply(lambda x: f\"{x[donor_key]}_{time_abbrev}{x[time_key]}\", axis=1)\n",
    "    .values,\n",
    "    name=sample_key,\n",
    ")\n",
    "\n",
    "# Transform Protein IDs to UniProt IDs\n",
    "if original_ids_type != \"uniprot\" and any(\n",
    "    df_proteomics.columns.isin(df_protein_data[original_ids_type])\n",
    "):\n",
    "    mapping_dict = df_protein_data.reset_index(drop=False)\n",
    "    mapping_dict = mapping_dict.set_index(original_ids_type)[df_protein_data.index.name]\n",
    "    mapping_dict = mapping_dict.to_dict()\n",
    "    df_proteomics = df_proteomics.rename(mapping_dict, axis=1)\n",
    "\n",
    "# Sort for consistency\n",
    "df_proteomics = df_proteomics.sort_index(axis=0)[\n",
    "    [donor_key, time_key] + list(df_protein_data.index)\n",
    "]\n",
    "donor_ids = df_proteomics[donor_key].unique()\n",
    "timepoints = df_proteomics[time_key].unique()\n",
    "print(f\"Number of donors: {len(donor_ids)}\")\n",
    "print(f\"Number of timepoints: {len(timepoints)}\")\n",
    "print(f\"Number of expected samples: {len(donor_ids) * len(timepoints)}\")\n",
    "print(f\"Number of actual samples: {len(df_proteomics)}\")\n",
    "df_proteomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840c559-3fff-43e2-a7a7-167e58046012",
   "metadata": {},
   "source": [
    "### Load metadata corresponding to samples (optional)\n",
    "#### Genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754dc39-db43-4076-95f5-93c5352b1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_genotypes = pd.read_csv(\n",
    "        raw_data_dirpath / \"Genotypes.csv\",\n",
    "        index_col=[donor_key],\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    df_genotypes = pd.DataFrame([])\n",
    "df_genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b23d6-e5e0-40c0-a814-90b916b80b2a",
   "metadata": {},
   "source": [
    "#### Phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fd55b-c559-4d59-b7f6-570aa8965394",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_phenotypes = pd.read_csv(\n",
    "        raw_data_dirpath / \"Phenotypes.csv\",\n",
    "        index_col=[donor_key],\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    df_phenotypes = pd.DataFrame([])\n",
    "df_phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304e790-5a28-4d2e-acea-e43caf360c24",
   "metadata": {},
   "source": [
    "#### Combine into one DataFrame for MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e7c33-97f6-4c32-a453-880bba1796d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proteomics: {df_proteomics[donor_key].nunique()} donors\")\n",
    "print(\n",
    "    f\"  Genomics: {df_genotypes.index.nunique() if not df_genotypes.empty else 0} donors\"\n",
    ")\n",
    "print(\n",
    "    f\"Phenotypes: {df_phenotypes.index.nunique() if not df_phenotypes.empty else 0} donors\"\n",
    ")\n",
    "\n",
    "df_metadata = pd.concat((df_genotypes, df_phenotypes), axis=1)\n",
    "\n",
    "\n",
    "if not df_metadata.empty:\n",
    "    df_metadata = df_metadata.reset_index(drop=False)\n",
    "    # Ensure only metadata corresponds to the available omics data\n",
    "    if not df_metadata[donor_key].isin(df_proteomics[donor_key]).all():\n",
    "        df_metadata = df_metadata[df_metadata[donor_key].isin(df_proteomics[donor_key])]\n",
    "\n",
    "    # If time was not included in metadata, add as a part of index to ensure index matches samples\n",
    "    if time_key and time_key not in df_metadata.index:\n",
    "        df_metadata = (\n",
    "            pd.concat(\n",
    "                (\n",
    "                    df_metadata,\n",
    "                    pd.Series(\n",
    "                        [list(df_proteomics[time_key].unique())]\n",
    "                        * len(df_metadata.index),\n",
    "                        index=df_metadata.index,\n",
    "                        name=time_key,\n",
    "                    ),\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "            .explode(time_key)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    # Create sample IDs from donor and time points, then set as index\n",
    "    df_metadata.index = pd.Index(\n",
    "        df_metadata[[donor_key, time_key]]\n",
    "        .apply(lambda x: f\"{x[donor_key]}_{time_abbrev}{x[time_key]}\", axis=1)\n",
    "        .values,\n",
    "        name=sample_key,\n",
    "    )\n",
    "    print(f\"\\nFinal data: {df_metadata[donor_key].nunique()} donors\")\n",
    "    df_metadata = df_metadata.drop([donor_key, time_key], axis=1)\n",
    "else:\n",
    "    print(f\"\\nFinal Meta: 0 donors\")\n",
    "\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f31b38-a4ea-4432-af3f-daffe7f32021",
   "metadata": {},
   "source": [
    "### Get MCH per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101727d1-49e9-4671-a2fc-7e91b96311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide in picograms. Set as None to use metadata if provided\n",
    "mch_sample_value = 13.9\n",
    "if mch_sample_value is None:\n",
    "    try:\n",
    "        df_MCH_per_sample = pd.read_csv(\n",
    "            raw_data_dirpath / \"Phenotypes.csv\",\n",
    "            index_col=None,\n",
    "        )\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\n",
    "            \"Cannot determine MCH. No phenotype data provided and a default value is not provided\"\n",
    "        )\n",
    "\n",
    "    # Ensure only metadata corresponds to the available omics data\n",
    "    if not df_MCH_per_sample[donor_key].isin(df_proteomics[donor_key]).all():\n",
    "        df_MCH_per_sample = df_MCH_per_sample[\n",
    "            df_MCH_per_sample[donor_key].isin(df_proteomics[donor_key])\n",
    "        ]\n",
    "\n",
    "    if \"CBC.MCH\" not in df_MCH_per_sample.columns:\n",
    "        if all([x in df_MCH_per_sample.columns for x in [\"CBC.HGB\", \"CBC.RBC\"]]):\n",
    "            df_MCH_per_sample[\"CBC.MCH\"] = (\n",
    "                df_MCH_per_sample[\"CBC.HGB\"] / df_MCH_per_sample[\"CBC.RBC\"]\n",
    "            ) * 10\n",
    "        elif all([x in df_MCH_per_sample.columns for x in [\"CBC.MCHC\", \"CBC.MCV\"]]):\n",
    "            df_MCH_per_sample[\"CBC.MCH\"] = (\n",
    "                df_MCH_per_sample[\"CBC.MCHC\"] * df_MCH_per_sample[\"CBC.MCV\"]\n",
    "            ) / 100\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Cannot determine MCH, one of the following combinations is needed: (CBC.HGB and CBC.RBC) or (CBC.MCHC and CBC.MCV)\"\n",
    "            )\n",
    "    df_MCH_per_sample = df_MCH_per_sample.set_index(donor_key)[\"CBC.MCH\"]\n",
    "    n_missing = len(df_MCH_per_sample[df_MCH_per_sample.isna()])\n",
    "    print(f\"Missing values for {n_missing} samples.\")\n",
    "    print(f\"Mean MCH in pg: {df_MCH_per_sample.mean():.2f}\")\n",
    "    df_MCH_per_sample = df_MCH_per_sample.fillna(df_MCH_per_sample.mean())\n",
    "else:\n",
    "    print(\"Using default MCH value provided for all samples\")\n",
    "    df_MCH_per_sample = pd.Series(\n",
    "        [mch_sample_value] * df_proteomics[donor_key].nunique(),\n",
    "        index=pd.Index(df_proteomics[donor_key].unique(), name=donor_key),\n",
    "        name=\"CBC.MCH\",\n",
    "    )\n",
    "    print(f\"Mean MCH in pg: {mch_sample_value:.2f}\")\n",
    "\n",
    "df_MCH_per_sample = df_MCH_per_sample.reset_index(drop=False)\n",
    "# If time was not included in metadata, add as a part of index to ensure index matches samples\n",
    "if time_key and time_key not in df_MCH_per_sample.index:\n",
    "    df_MCH_per_sample = (\n",
    "        pd.concat(\n",
    "            (\n",
    "                df_MCH_per_sample,\n",
    "                pd.Series(\n",
    "                    [list(df_proteomics[time_key].unique())]\n",
    "                    * len(df_MCH_per_sample.index),\n",
    "                    index=df_MCH_per_sample.index,\n",
    "                    name=time_key,\n",
    "                ),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        .explode(time_key)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "# Create sample IDs from donor and time points, then set as index\n",
    "df_MCH_per_sample.index = pd.Index(\n",
    "    df_MCH_per_sample[[donor_key, time_key]]\n",
    "    .apply(lambda x: f\"{x[donor_key]}_{time_abbrev}{x[time_key]}\", axis=1)\n",
    "    .values,\n",
    "    name=sample_key,\n",
    ")\n",
    "df_MCH_per_sample = df_MCH_per_sample.loc[df_proteomics.index]\n",
    "sample_ids = list(df_proteomics.index)\n",
    "\n",
    "df_MCH_per_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc96ad-7725-483d-b645-3e8753219c1c",
   "metadata": {},
   "source": [
    "### Get data subsets using operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab79366-e1bf-455b-b077-fefacffc2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [\n",
    "    \"mean\",\n",
    "    \"median\",\n",
    "]\n",
    "operation_dfs_proteomics = []\n",
    "operation_dfs_MCH = []\n",
    "fill_keys = set()\n",
    "\n",
    "\n",
    "def group_data(df, operation, keys, columns, prefix_values=None, name_col=None):\n",
    "    keys = ensure_iterable(keys)\n",
    "    if not prefix_values:\n",
    "        prefix_values = [\"\"] * len(keys)\n",
    "    if isinstance(prefix_values, dict):\n",
    "        prefix_values = {k: prefix_values.get(k, \"\") for k in keys}\n",
    "    else:\n",
    "        prefix_values = dict(zip(keys, prefix_values))\n",
    "\n",
    "    df = df.groupby(keys, as_index=False, observed=False)[columns]\n",
    "    df = getattr(df, operation.lower())()\n",
    "    labels = df[keys].apply(\n",
    "        lambda x: \"_\".join([f\"{prefix_values[key]}{x[key]}\" for key in keys]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[name_col] = [f\"{operation.capitalize()}_{value}\" for value in labels]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ad102-57f1-41b3-9f16-042bb78d7eaa",
   "metadata": {},
   "source": [
    "#### Group by time and phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8fb17-0da0-4b60-8f34-eac7a7538da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [time_key, \"G6PD_PHENOTYPE\"]\n",
    "prefix_values = {}\n",
    "\n",
    "operation_dfs_proteomics += [\n",
    "    group_data(\n",
    "        pd.merge(\n",
    "            df_proteomics, df_metadata, left_index=True, right_index=True, how=\"left\"\n",
    "        ).reset_index(drop=False),\n",
    "        operation,\n",
    "        keys=keys,\n",
    "        columns=list(df_protein_data.index),\n",
    "        prefix_values=None,\n",
    "        name_col=sample_key,\n",
    "    )\n",
    "    for operation in operations\n",
    "]\n",
    "\n",
    "operation_dfs_MCH += [\n",
    "    group_data(\n",
    "        pd.merge(\n",
    "            df_MCH_per_sample,\n",
    "            df_metadata,\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"left\",\n",
    "        ).reset_index(drop=False),\n",
    "        operation,\n",
    "        keys=keys,\n",
    "        columns=[\"CBC.MCH\"],\n",
    "        prefix_values=None,\n",
    "        name_col=sample_key,\n",
    "    )\n",
    "    for operation in operations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f42988-297d-4f9c-86f5-88425f74e6fc",
   "metadata": {},
   "source": [
    "### Add to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16184e-34c3-4261-b8c9-10f411862d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_proteomics_op = pd.concat(operation_dfs_proteomics, axis=0).drop_duplicates()\n",
    "except (KeyError, ValueError):\n",
    "    df_proteomics_final = df_proteomics[df_protein_data.index].copy()\n",
    "else:\n",
    "    df_proteomics_final = pd.concat(\n",
    "        (df_proteomics.reset_index(drop=False), df_proteomics_op), axis=0\n",
    "    )\n",
    "    df_proteomics_final = df_proteomics_final.set_index(sample_key)[\n",
    "        df_protein_data.index\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    df_MCH_op = pd.concat(operation_dfs_MCH, axis=0).drop_duplicates()\n",
    "except (KeyError, ValueError):\n",
    "    df_MCH_final = df_MCH_per_sample[\"CBC.MCH\"].copy()\n",
    "else:\n",
    "    df_MCH_final = pd.concat(\n",
    "        (df_MCH_per_sample.reset_index(drop=False), df_MCH_op), axis=0\n",
    "    )\n",
    "    df_MCH_final = df_MCH_final.set_index(sample_key)[\"CBC.MCH\"]\n",
    "\n",
    "df_MCH_final.name = \"MCH\"\n",
    "df_proteomics_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec154e8-9032-44d5-82e4-ce7f1cec870f",
   "metadata": {},
   "source": [
    "### Normalize data by hemoglobin mass\n",
    "#### Set percent for hemoglobin and low abundance protoemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb2e36-bc32-4a25-a158-4bda090f6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "HB_PERCENT, LA_PERCENT = (0.95, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66910837-0787-4332-8d8f-dcac6ed31f0c",
   "metadata": {},
   "source": [
    "#### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ca8d6-7d9a-4275-a1a6-e1748169b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELED_PERCENT = HB_PERCENT + LA_PERCENT\n",
    "assert 1 >= MODELED_PERCENT\n",
    "# Identify hemoglobin proteins\n",
    "HB_PROTEINS = {\n",
    "    k.replace(\"-\", \"_\"): v\n",
    "    for k, v in {\n",
    "        \"Hba\": \"P01942\",  # Hemoglobin subunit alpha\n",
    "        \"Hba-a1\": \"P01942\",\n",
    "        \"Hbb-b1\": \"P02088\",  # Hemoglobin subunit beta-1\n",
    "        \"Hbb-b2\": \"P02089\",  # Hemoglobin subunit beta-2\n",
    "        \"Hbb-bh0\": \"P04443\",  # Hemoglobin subunit beta-H0\n",
    "        \"Hbb-bh1\": \"P04444\",  # Hemoglobin subunit beta-H1\n",
    "        \"Hbz\": \"P06467\",  # Hemoglobin subunit zeta\n",
    "        \"Hba-x\": \"P06467\",\n",
    "        \"Hbz1\": \"P06467\",\n",
    "        \"Hbb-y\": \"P02104\",  # Hemoglobin subunit epsilon-Y2\n",
    "    }.items()\n",
    "}\n",
    "# Protein intensity / Total intensity --> Percent protein abundance / total protein\n",
    "df_percent_abundance = df_proteomics_final.apply(lambda x: x / x.sum(), axis=1)\n",
    "df_percent_hb = df_percent_abundance.loc[\n",
    "    :, df_percent_abundance.columns.isin(list(HB_PROTEINS.values()))\n",
    "]\n",
    "df_percent_la = df_percent_abundance.loc[\n",
    "    :, ~df_percent_abundance.columns.isin(list(HB_PROTEINS.values()))\n",
    "]\n",
    "\n",
    "# Scale hemoglobin and low abundance protoeme percentages\n",
    "df_percent_hb_normalized = HB_PERCENT * df_percent_hb.div(\n",
    "    df_percent_hb.sum(axis=1), axis=0\n",
    ")\n",
    "df_percent_la_normalized = LA_PERCENT * df_percent_la.div(\n",
    "    df_percent_la.sum(axis=1), axis=0\n",
    ")\n",
    "\n",
    "# Combine dataframes back into one\n",
    "df_percent_abundance_normalized = pd.concat(\n",
    "    (df_percent_hb_normalized, df_percent_la_normalized), axis=1\n",
    ")\n",
    "\n",
    "df_summary = {\n",
    "    \"Perfect total\": 1.0,\n",
    "    \"Current total\": df_percent_abundance.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Hemoglobin total\": df_percent_hb.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "    \"Low abundance total\": df_percent_la.loc[sample_ids].sum(axis=1).mean().item(),\n",
    "}\n",
    "df_summary[\"Hemoglobin scaled\"] = HB_PERCENT\n",
    "df_summary[\"Low abundance scaled\"] = LA_PERCENT\n",
    "df_summary[\"Remaining scaled\"] = 1 - (HB_PERCENT + LA_PERCENT)\n",
    "df_summary = pd.DataFrame.from_dict(\n",
    "    {\" \" * max(30 - len(k), 0) + k: [f\"{v * 100:.1f}%\"] for k, v in df_summary.items()},\n",
    "    orient=\"index\",\n",
    "    columns=[\"Percentage\"],\n",
    ")\n",
    "print(df_summary)\n",
    "df_percent_abundance_normalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd935dd-50bc-4faf-8290-59d932c240d1",
   "metadata": {},
   "source": [
    "### Transform data to copy numbers and expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c8505-531e-40cf-8704-7ef0fe6370d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_to_mw = df_protein_data[\"Mass\"].astype(float)\n",
    "\n",
    "gDW_total_protein = (\n",
    "    df_MCH_final  # pgDW HB\n",
    "    * (1 / HB_PERCENT)  # pgDW total protein / pgDW HB\n",
    "    * (1 / 1e12)  #  gDW total protein / pgDW total protein\n",
    ")  #  gDW total protein\n",
    "\n",
    "# Percent protein abundance / total protein --> Specific protein concentration / total protein\n",
    "df_mol_per_gDW = df_percent_abundance_normalized.div(\n",
    "    df_uniprot_to_mw, axis=1  # mol protein / gDW total protein\n",
    ")\n",
    "# Convert from mol / gDW protein --> nmol / gDW protein\n",
    "df_nmol_per_gDW = df_mol_per_gDW * (1e9 / 1)  # nmol protein / mol protein\n",
    "\n",
    "# Convert from mol / gDW protein --> copy numbers / cell\n",
    "df_copy_numbers = df_mol_per_gDW.mul(gDW_total_protein, axis=0) * AVOGADRO_NUMBER\n",
    "df_copy_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d2b8e-a28c-40bb-bd3d-c7ce64e8aef1",
   "metadata": {},
   "source": [
    "## Export absolute quantitative data and metadata per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc133bf3-864e-4b2e-933c-620e07a86bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict = {\n",
    "    \"ProteinData\": df_protein_data,\n",
    "    \"ProteinIntensities\": df_proteomics_final,\n",
    "    \"ProteinConcentrations\": df_nmol_per_gDW,\n",
    "    \"ProteinCopyNumbers\": df_copy_numbers,\n",
    "    \"MCH\": df_MCH_final,\n",
    "    \"Metadata\": df_metadata,\n",
    "}\n",
    "for data_type, df in dataframes_dict.items():\n",
    "    # df.to_csv(\n",
    "    #     processed_data_dirpath / f\"{data_type}.tsv\", sep=\"\\t\", index=True\n",
    "    # )\n",
    "    df.to_csv(processed_data_dirpath / f\"{data_type}.csv\", index=True)\n",
    "    print(f\"Saved data for {data_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf5207-1de5-4573-bea9-5416ae2172f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
